[dgx13:65727:0:65727] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  65727) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb5e05a906d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a264) [0x7fb5e05a9264]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a42a) [0x7fb5e05a942a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb6738f7420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fb5e06276a4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fb5e0650829]
 6  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x2146f) [0x7fb5e056346f]
 7  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x248c8) [0x7fb5e05668c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb5e05b2499]
 9  /opt/conda/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fb5e056566d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fb5e06248ca]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fb5e06dd06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56069d66e6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56069d67b519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x56069d71e162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fb66991f1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56069d67377c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x56069d625d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x56069d6727f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x56069d670929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56069d67b519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56069d66c128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x56069d688ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56069d68944c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x56069d74c10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56069d67377c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56069d66e6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x56069d688dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56069d66e6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56069d67b519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56069d66b5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56069d67b7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56069d66b312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56069d67b519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56069d66c128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56069d66a094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56069d669d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56069d669d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56069d71707b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x56069d743fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x56069d740353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x56069d73816a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x56069d73805c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x56069d737297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x56069d70af07]
=================================
[dgx13:65739:0:65739] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  65739) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0915a2806d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a264) [0x7f0915a28264]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a42a) [0x7f0915a2842a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f09d0d7d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f0915aa66a4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f0915acf829]
 6  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x2146f) [0x7f09159e246f]
 7  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x248c8) [0x7f09159e58c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0915a31499]
 9  /opt/conda/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f09159e466d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0915aa38ca]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f0915b5c06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d3574416fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d35744e519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55d35745be83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55d357566b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55d3573f8d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55d3574457f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55d357443929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d35744e519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d35743f128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55d35745bccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55d35745c44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55d35751f10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d35744677c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d3574416fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55d35745bdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d3574416fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d35744e519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d35743e5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d35744e7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55d35743e312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d35744e519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d35743f128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d35743d094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55d35743cd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55d35743cd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55d3574ea07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55d357516fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55d357513353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55d35750b16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55d35750b05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55d35750a297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55d3574ddf07]
=================================
[dgx13:65730:0:65730] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
[dgx13:65736:0:65736] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  65730) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fef7804a06d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a264) [0x7fef7804a264]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a42a) [0x7fef7804a42a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff018948420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fef7377b6a4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fef737a4829]
 6  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x2146f) [0x7fef7371546f]
 7  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x248c8) [0x7fef737188c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fef78053499]
 9  /opt/conda/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fef7371766d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fef737788ca]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fef780b006a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55860288a6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558602897519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x5586028a4e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x5586029afb2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x558602841d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55860288e7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55860288c929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558602897519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x558602888128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x5586028a4ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5586028a544c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55860296810e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55860288f77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55860288a6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x5586028a4dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55860288a6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558602897519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5586028875c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5586028977c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x558602887312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x558602897519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x558602888128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558602886094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x558602885d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x558602885d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55860293307b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55860295ffca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55860295c353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55860295416a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55860295405c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x558602953297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x558602926f07]
=================================
==== backtrace (tid:  65736) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f762c2ab06d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a264) [0x7f762c2ab264]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a42a) [0x7f762c2ab42a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f76cd5f8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f762c3296a4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f762c352829]
 6  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x2146f) [0x7f762c26546f]
 7  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x248c8) [0x7f762c2688c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f762c2b4499]
 9  /opt/conda/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f762c26766d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f762c3268ca]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f762c3df06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d6bb4f36fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d6bb500519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55d6bb5a3162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f76c361f1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d6bb4f877c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55d6bb4aad05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55d6bb4f77f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55d6bb4f5929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d6bb500519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d6bb4f1128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55d6bb50dccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55d6bb50e44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55d6bb5d110e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d6bb4f877c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d6bb4f36fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55d6bb50ddac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d6bb4f36fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d6bb500519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d6bb4f05c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d6bb5007c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55d6bb4f0312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d6bb500519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d6bb4f1128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d6bb4ef094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55d6bb4eed68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55d6bb4eed19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55d6bb59c07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55d6bb5c8fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55d6bb5c5353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55d6bb5bd16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55d6bb5bd05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55d6bb5bc297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55d6bb58ff07]
=================================
[dgx13:65715:0:65715] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  65715) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f3ed5dbe06d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a264) [0x7f3ed5dbe264]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2a42a) [0x7f3ed5dbe42a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f3f91110420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f3ed5e3c6a4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f3ed5e65829]
 6  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x2146f) [0x7f3ed5d7846f]
 7  /opt/conda/envs/gdf/lib/./libuct.so.0(+0x248c8) [0x7f3ed5d7b8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f3ed5dc7499]
 9  /opt/conda/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f3ed5d7a66d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f3ed5e398ca]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f3ed5ef206a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55955b1506fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55955b15d519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55955b16ae83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55955b275b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55955b107d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55955b1547f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55955b152929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55955b15d519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55955b14e128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55955b16accb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55955b16b44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55955b22e10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55955b15577c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55955b1506fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55955b16adac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55955b1506fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55955b15d519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55955b14d5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55955b15d7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55955b14d312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55955b15d519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55955b14e128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55955b14c094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55955b14bd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55955b14bd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55955b1f907b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55955b225fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55955b222353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55955b21a16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55955b21a05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55955b219297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55955b1ecf07]
=================================
2023-11-18 07:21:38,843 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33397
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7feec5560200, tag: 0x940ca31358c1a05, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7feec5560200, tag: 0x940ca31358c1a05, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-11-18 07:21:38,843 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33397
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f23486ed200, tag: 0xe601b25cb45f78bc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f23486ed200, tag: 0xe601b25cb45f78bc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 07:21:38,845 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40599 -> ucx://127.0.0.1:34179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feec5560180, tag: 0x357263ce11f41c6a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-11-18 07:21:38,846 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7feec5560300, tag: 0x1575b0779efc9d5e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7feec5560300, tag: 0x1575b0779efc9d5e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 07:21:38,846 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f23486ed100, tag: 0xf6fa2cd036859504, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f23486ed100, tag: 0xf6fa2cd036859504, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 07:21:38,846 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7feec5560240, tag: 0xec644cd8a55fa836, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7feec5560240, tag: 0xec644cd8a55fa836, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 07:21:38,847 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40599 -> ucx://127.0.0.1:47533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feec5560100, tag: 0xe772e2c30da62467, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-11-18 07:21:38,843 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33397
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f1510214240, tag: 0xbce730ebd40319a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f1510214240, tag: 0xbce730ebd40319a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-11-18 07:21:38,847 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37715 -> ucx://127.0.0.1:33397
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1510214440, tag: 0x30f57f6e5af37bd6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-11-18 07:21:38,849 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1510214140, tag: 0x99f11f602047130f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1510214140, tag: 0x99f11f602047130f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 07:21:38,849 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f1510214280, tag: 0xc6419fc19b6380c3, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f1510214280, tag: 0xc6419fc19b6380c3, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 07:21:38,853 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:53735 -> ucx://127.0.0.1:43495
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f23486ed340, tag: 0xca9d7d9491d988ff, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-11-18 07:21:38,853 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43495
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f23486ed1c0, tag: 0xdf321f18a79d30a2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f23486ed1c0, tag: 0xdf321f18a79d30a2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-11-18 07:21:38,879 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1510214200, tag: 0xd99967b05f8302cc, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1510214200, tag: 0xd99967b05f8302cc, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 07:21:38,935 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
2023-11-18 07:21:39,961 - distributed.nanny - WARNING - Restarting worker
2023-11-18 07:21:41,601 - distributed.nanny - WARNING - Restarting worker
2023-11-18 07:21:41,775 - distributed.nanny - ERROR - Failed to initialize worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-hbdud3kk'
2023-11-18 07:21:41,816 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-hbdud3kk'
2023-11-18 07:21:41,841 - distributed.nanny - ERROR - Failed to restart worker after its process exited
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 563, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-hbdud3kk'
2023-11-18 07:21:43,260 - distributed.nanny - ERROR - Failed to initialize worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-dz7ao10a'
2023-11-18 07:21:43,291 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-dz7ao10a'
2023-11-18 07:21:43,311 - distributed.nanny - ERROR - Failed to restart worker after its process exited
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 563, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-dz7ao10a'
2023-11-18 07:21:44,126 - distributed.nanny - WARNING - Restarting worker
2023-11-18 07:21:45,777 - distributed.nanny - ERROR - Failed to initialize worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-h6k3mgra'
2023-11-18 07:21:45,780 - distributed.nanny - WARNING - Restarting worker
2023-11-18 07:21:45,846 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-h6k3mgra'
2023-11-18 07:21:45,871 - distributed.nanny - ERROR - Failed to restart worker after its process exited
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 563, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-h6k3mgra'
2023-11-18 07:21:45,871 - distributed.nanny - WARNING - Restarting worker
2023-11-18 07:21:47,392 - distributed.nanny - ERROR - Failed to initialize worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-ws1be004'
2023-11-18 07:21:47,441 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-ws1be004'
2023-11-18 07:21:47,446 - distributed.nanny - ERROR - Failed to initialize worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-grjmnthb'
2023-11-18 07:21:47,465 - distributed.nanny - ERROR - Failed to restart worker after its process exited
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 563, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-ws1be004'
2023-11-18 07:21:47,496 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-grjmnthb'
2023-11-18 07:21:47,515 - distributed.nanny - ERROR - Failed to restart worker after its process exited
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 563, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 940, in run
    worker = worker_factory()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 718, in __init__
    ServerNode.__init__(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 363, in __init__
    self._workdir = self._workspace.new_work_dir(prefix=f"{name}-")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 274, in new_work_dir
    return WorkDir(self, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diskutils.py", line 49, in __init__
    self.dir_path = tempfile.mkdtemp(prefix=prefix, dir=workspace.base_dir)
  File "/opt/conda/envs/gdf/lib/python3.9/tempfile.py", line 363, in mkdtemp
    _os.mkdir(file, 0o700)
OSError: [Errno 28] No space left on device: '/tmp/dask-scratch-space/worker-grjmnthb'
2023-11-18 07:21:51,343 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60179
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:60179 after 30 s
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 33 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
