============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.4.0, pluggy-1.2.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-07-31 05:41:01,985 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:01,989 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38143 instead
  warnings.warn(
2023-07-31 05:41:01,993 - distributed.scheduler - INFO - State start
2023-07-31 05:41:02,013 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:02,014 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-07-31 05:41:02,015 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38143/status
2023-07-31 05:41:02,278 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41085'
2023-07-31 05:41:02,297 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33191'
2023-07-31 05:41:02,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44475'
2023-07-31 05:41:02,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46257'
2023-07-31 05:41:02,739 - distributed.scheduler - INFO - Receive client connection: Client-d48cb1f9-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:02,751 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43860
2023-07-31 05:41:03,058 - distributed.scheduler - INFO - Receive client connection: Client-d61575a0-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:03,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43882
2023-07-31 05:41:03,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:03,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:03,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:03,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:03,995 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:03,999 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-07-31 05:41:04,012 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33797
2023-07-31 05:41:04,012 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33797
2023-07-31 05:41:04,012 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42909
2023-07-31 05:41:04,012 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-31 05:41:04,012 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:04,012 - distributed.worker - INFO -               Threads:                          4
2023-07-31 05:41:04,012 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-31 05:41:04,012 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h2udi_2k
2023-07-31 05:41:04,013 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3b470452-07bf-48c2-bf69-d3fb36d332ad
2023-07-31 05:41:04,013 - distributed.worker - INFO - Starting Worker plugin PreImport-f242ad6a-cb81-4949-aa4f-e47522a4c3b7
2023-07-31 05:41:04,013 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a69c5d04-4393-48a3-8510-1b5f0c0f5fa8
2023-07-31 05:41:04,013 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:04,030 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33797', status: init, memory: 0, processing: 0>
2023-07-31 05:41:04,032 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33797
2023-07-31 05:41:04,032 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43892
2023-07-31 05:41:04,033 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-31 05:41:04,033 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:04,035 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-31 05:41:04,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:04,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:04,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:04,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:04,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:04,044 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:05,207 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42361
2023-07-31 05:41:05,208 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42361
2023-07-31 05:41:05,208 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43701
2023-07-31 05:41:05,208 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,208 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,208 - distributed.worker - INFO -               Threads:                          4
2023-07-31 05:41:05,208 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-31 05:41:05,208 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lge59znw
2023-07-31 05:41:05,208 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36c8a5fa-2491-4933-9eec-4d65c3de8045
2023-07-31 05:41:05,209 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8492221c-2278-40c9-af16-e3506a40b868
2023-07-31 05:41:05,209 - distributed.worker - INFO - Starting Worker plugin PreImport-ac0cceef-6943-41c8-80e4-157d91cca062
2023-07-31 05:41:05,209 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,227 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42361', status: init, memory: 0, processing: 0>
2023-07-31 05:41:05,228 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42361
2023-07-31 05:41:05,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33284
2023-07-31 05:41:05,228 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,229 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-31 05:41:05,352 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38229
2023-07-31 05:41:05,352 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38229
2023-07-31 05:41:05,352 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43971
2023-07-31 05:41:05,352 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,352 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,352 - distributed.worker - INFO -               Threads:                          4
2023-07-31 05:41:05,352 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-31 05:41:05,352 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y8jqttf_
2023-07-31 05:41:05,352 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7bcb03c4-c31b-49c6-afae-5b57f5324ba3
2023-07-31 05:41:05,353 - distributed.worker - INFO - Starting Worker plugin PreImport-9f7dbc61-6fc2-4833-9e3f-178c26b73978
2023-07-31 05:41:05,353 - distributed.worker - INFO - Starting Worker plugin RMMSetup-60f96421-2096-428a-b4d4-a66255193036
2023-07-31 05:41:05,353 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,378 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38229', status: init, memory: 0, processing: 0>
2023-07-31 05:41:05,378 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38229
2023-07-31 05:41:05,378 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33296
2023-07-31 05:41:05,379 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,379 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,382 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-31 05:41:05,452 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41307
2023-07-31 05:41:05,452 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41307
2023-07-31 05:41:05,452 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34503
2023-07-31 05:41:05,452 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,452 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,452 - distributed.worker - INFO -               Threads:                          4
2023-07-31 05:41:05,452 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-31 05:41:05,452 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-u522kb0w
2023-07-31 05:41:05,452 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be22d428-89b6-4589-a572-f907cdf0fcbb
2023-07-31 05:41:05,452 - distributed.worker - INFO - Starting Worker plugin PreImport-9f083cf7-4b47-4b67-a0de-0e9e7872a3b9
2023-07-31 05:41:05,453 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2667e24f-fb60-47fc-b153-0cfcc7a2a436
2023-07-31 05:41:05,453 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,471 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41307', status: init, memory: 0, processing: 0>
2023-07-31 05:41:05,471 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41307
2023-07-31 05:41:05,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33306
2023-07-31 05:41:05,472 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-31 05:41:05,472 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:05,474 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-31 05:41:05,559 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,559 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,559 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,559 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,560 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,560 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,560 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,560 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-31 05:41:05,564 - distributed.scheduler - INFO - Remove client Client-d61575a0-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:05,564 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43882; closing.
2023-07-31 05:41:05,565 - distributed.scheduler - INFO - Remove client Client-d61575a0-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:05,565 - distributed.scheduler - INFO - Close client connection: Client-d61575a0-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:05,565 - distributed.scheduler - INFO - Remove client Client-d48cb1f9-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:05,566 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43860; closing.
2023-07-31 05:41:05,566 - distributed.scheduler - INFO - Remove client Client-d48cb1f9-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:05,566 - distributed.scheduler - INFO - Close client connection: Client-d48cb1f9-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:05,567 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41085'. Reason: nanny-close
2023-07-31 05:41:05,568 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:05,568 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33191'. Reason: nanny-close
2023-07-31 05:41:05,569 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:05,569 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42361. Reason: nanny-close
2023-07-31 05:41:05,569 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44475'. Reason: nanny-close
2023-07-31 05:41:05,569 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:05,570 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38229. Reason: nanny-close
2023-07-31 05:41:05,570 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46257'. Reason: nanny-close
2023-07-31 05:41:05,570 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:05,570 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33284; closing.
2023-07-31 05:41:05,570 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41307. Reason: nanny-close
2023-07-31 05:41:05,570 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-31 05:41:05,571 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42361', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:05,571 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42361
2023-07-31 05:41:05,571 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33797. Reason: nanny-close
2023-07-31 05:41:05,571 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-31 05:41:05,572 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:05,572 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42361
2023-07-31 05:41:05,572 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33296; closing.
2023-07-31 05:41:05,572 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38229', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:05,572 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38229
2023-07-31 05:41:05,573 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-31 05:41:05,573 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33306; closing.
2023-07-31 05:41:05,573 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:05,573 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41307', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:05,573 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42361
2023-07-31 05:41:05,573 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41307
2023-07-31 05:41:05,573 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:05,574 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43892; closing.
2023-07-31 05:41:05,574 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-31 05:41:05,574 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33797', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:05,574 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33797
2023-07-31 05:41:05,574 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:41:05,575 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:06,727 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43265', status: init, memory: 0, processing: 0>
2023-07-31 05:41:06,728 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43265
2023-07-31 05:41:06,728 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33312
2023-07-31 05:41:06,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33312; closing.
2023-07-31 05:41:06,772 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43265', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:06,772 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43265
2023-07-31 05:41:06,772 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:41:06,885 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:41:06,885 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:06,886 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:06,887 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-07-31 05:41:06,888 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-07-31 05:41:09,428 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:09,432 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40653 instead
  warnings.warn(
2023-07-31 05:41:09,437 - distributed.scheduler - INFO - State start
2023-07-31 05:41:09,458 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:09,459 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:41:09,460 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40653/status
2023-07-31 05:41:09,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34775'
2023-07-31 05:41:09,748 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41017'
2023-07-31 05:41:09,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45969'
2023-07-31 05:41:09,758 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35885'
2023-07-31 05:41:09,769 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46579'
2023-07-31 05:41:09,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41005'
2023-07-31 05:41:09,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34613'
2023-07-31 05:41:09,791 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42543'
2023-07-31 05:41:11,317 - distributed.scheduler - INFO - Receive client connection: Client-d8d38a5a-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:11,334 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54802
2023-07-31 05:41:11,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,523 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,542 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,589 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,601 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,606 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,609 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,620 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:11,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:11,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:11,714 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:14,678 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43615
2023-07-31 05:41:14,679 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43615
2023-07-31 05:41:14,679 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41861
2023-07-31 05:41:14,679 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:14,679 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:14,679 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:14,679 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:14,679 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-12zbavbk
2023-07-31 05:41:14,679 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d9d31f97-ff7a-40a6-9bb5-346d91b2420b
2023-07-31 05:41:14,806 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2a6b533d-9d7b-4cae-a446-ac44fac385fe
2023-07-31 05:41:14,806 - distributed.worker - INFO - Starting Worker plugin PreImport-9494d045-71e6-4584-882c-15c31456d7a6
2023-07-31 05:41:14,806 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:14,834 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43615', status: init, memory: 0, processing: 0>
2023-07-31 05:41:14,837 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43615
2023-07-31 05:41:14,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59440
2023-07-31 05:41:14,838 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:14,838 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:14,840 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,326 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35025
2023-07-31 05:41:15,327 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35025
2023-07-31 05:41:15,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41293
2023-07-31 05:41:15,327 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,327 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,327 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,327 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,327 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mdfjb6vj
2023-07-31 05:41:15,327 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68c870ba-c3fd-44cd-8a0b-325ed3293b99
2023-07-31 05:41:15,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-03147076-2bda-48d2-80f7-4d150f7bfbad
2023-07-31 05:41:15,344 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36909
2023-07-31 05:41:15,344 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36909
2023-07-31 05:41:15,344 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34313
2023-07-31 05:41:15,344 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,344 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,344 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,345 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,345 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p6ltfppc
2023-07-31 05:41:15,345 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f322fbe4-e46f-45ab-84d9-92b204564ec4
2023-07-31 05:41:15,346 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fef7624c-551a-4318-82e8-66b0c2be0832
2023-07-31 05:41:15,389 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34117
2023-07-31 05:41:15,389 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34117
2023-07-31 05:41:15,389 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36307
2023-07-31 05:41:15,389 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,389 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,390 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,390 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,390 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xcd4u4wm
2023-07-31 05:41:15,390 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fe8d12f7-4dd5-4c6f-b178-a1ee215c1885
2023-07-31 05:41:15,421 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40781
2023-07-31 05:41:15,421 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40781
2023-07-31 05:41:15,421 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43835
2023-07-31 05:41:15,421 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,421 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,421 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,421 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,421 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ww7wncy2
2023-07-31 05:41:15,422 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fb76035a-1166-4bb5-a01e-8888729cbe41
2023-07-31 05:41:15,442 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44779
2023-07-31 05:41:15,442 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44779
2023-07-31 05:41:15,442 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41039
2023-07-31 05:41:15,442 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,442 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,442 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,442 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,442 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vvtul0ob
2023-07-31 05:41:15,443 - distributed.worker - INFO - Starting Worker plugin PreImport-03e66ce3-3676-470b-b639-7ca2a0d92d7b
2023-07-31 05:41:15,443 - distributed.worker - INFO - Starting Worker plugin RMMSetup-acf5bea3-0c66-42f1-bd30-92ea2df5e414
2023-07-31 05:41:15,458 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35971
2023-07-31 05:41:15,458 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35971
2023-07-31 05:41:15,458 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43591
2023-07-31 05:41:15,458 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,459 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,459 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,459 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,459 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-25gyh6u2
2023-07-31 05:41:15,459 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4749c21c-3d89-421a-85d7-892acf2a70ed
2023-07-31 05:41:15,462 - distributed.worker - INFO - Starting Worker plugin RMMSetup-97e1668f-a551-4f73-9623-bcd35d598112
2023-07-31 05:41:15,465 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33387
2023-07-31 05:41:15,465 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33387
2023-07-31 05:41:15,465 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37197
2023-07-31 05:41:15,465 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,465 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,465 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:15,465 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:15,465 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a2qf11i_
2023-07-31 05:41:15,466 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4b0b3fe3-e3f9-42bd-85ed-7693de784509
2023-07-31 05:41:15,599 - distributed.worker - INFO - Starting Worker plugin PreImport-b628e45d-4e6f-4bde-a467-4b76ad364131
2023-07-31 05:41:15,600 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5754b5ea-92e0-48af-ade9-b9bae2103609
2023-07-31 05:41:15,610 - distributed.worker - INFO - Starting Worker plugin PreImport-359245eb-8a07-4b0a-b8ec-3b3b0dffd288
2023-07-31 05:41:15,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27269dcb-e111-4a9a-96ce-8af1808e2520
2023-07-31 05:41:15,610 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,610 - distributed.worker - INFO - Starting Worker plugin PreImport-1ac8ea27-cd04-4002-b6dc-7fed3370d04b
2023-07-31 05:41:15,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-76efee22-7bf4-4f28-bd11-b0aa23c681ce
2023-07-31 05:41:15,611 - distributed.worker - INFO - Starting Worker plugin PreImport-23a1d553-90c1-45e8-bdd0-c29e54390835
2023-07-31 05:41:15,611 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,611 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,611 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,616 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7fd59377-853d-4c6f-8790-11e50e67d31a
2023-07-31 05:41:15,617 - distributed.worker - INFO - Starting Worker plugin PreImport-70d237bf-0e19-46ad-be2a-4c1cfca46cee
2023-07-31 05:41:15,617 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,626 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35025', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,626 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35025
2023-07-31 05:41:15,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59452
2023-07-31 05:41:15,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,627 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,628 - distributed.worker - INFO - Starting Worker plugin PreImport-6c97d410-13fc-4e27-97a1-d4fd0bea6da5
2023-07-31 05:41:15,629 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40781', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,638 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40781
2023-07-31 05:41:15,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59462
2023-07-31 05:41:15,638 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,638 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,640 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,646 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36909', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,647 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36909
2023-07-31 05:41:15,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59478
2023-07-31 05:41:15,647 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,647 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,647 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44779', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,648 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44779
2023-07-31 05:41:15,648 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59472
2023-07-31 05:41:15,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,649 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,660 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34117', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,661 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34117
2023-07-31 05:41:15,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59482
2023-07-31 05:41:15,662 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33387', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,662 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,662 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,663 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33387
2023-07-31 05:41:15,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59494
2023-07-31 05:41:15,663 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,664 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,665 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,666 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,668 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35971', status: init, memory: 0, processing: 0>
2023-07-31 05:41:15,669 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35971
2023-07-31 05:41:15,669 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59500
2023-07-31 05:41:15,669 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:15,670 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:15,672 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:15,777 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,777 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,777 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,777 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,777 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,778 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,778 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,778 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:15,783 - distributed.scheduler - INFO - Remove client Client-d8d38a5a-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:15,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54802; closing.
2023-07-31 05:41:15,783 - distributed.scheduler - INFO - Remove client Client-d8d38a5a-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:15,784 - distributed.scheduler - INFO - Close client connection: Client-d8d38a5a-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:15,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35885'. Reason: nanny-close
2023-07-31 05:41:15,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,785 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34775'. Reason: nanny-close
2023-07-31 05:41:15,786 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,786 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41017'. Reason: nanny-close
2023-07-31 05:41:15,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36909. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45969'. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44779. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43615. Reason: nanny-close
2023-07-31 05:41:15,787 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46579'. Reason: nanny-close
2023-07-31 05:41:15,788 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,788 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41005'. Reason: nanny-close
2023-07-31 05:41:15,788 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35025. Reason: nanny-close
2023-07-31 05:41:15,788 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34613'. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59478; closing.
2023-07-31 05:41:15,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35971. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,789 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36909', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,789 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36909
2023-07-31 05:41:15,789 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42543'. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34117. Reason: nanny-close
2023-07-31 05:41:15,789 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:15,790 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40781. Reason: nanny-close
2023-07-31 05:41:15,790 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,790 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,790 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,790 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59472; closing.
2023-07-31 05:41:15,790 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,791 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33387. Reason: nanny-close
2023-07-31 05:41:15,791 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,791 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36909
2023-07-31 05:41:15,791 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44779', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,791 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44779
2023-07-31 05:41:15,791 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36909
2023-07-31 05:41:15,791 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,791 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36909
2023-07-31 05:41:15,792 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59440; closing.
2023-07-31 05:41:15,792 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,792 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59452; closing.
2023-07-31 05:41:15,792 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,792 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36909
2023-07-31 05:41:15,792 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43615', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,793 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43615
2023-07-31 05:41:15,793 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,793 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35025', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,793 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,793 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:15,793 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35025
2023-07-31 05:41:15,793 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,794 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59500; closing.
2023-07-31 05:41:15,794 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59462; closing.
2023-07-31 05:41:15,794 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59482; closing.
2023-07-31 05:41:15,794 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:15,795 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35971', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,795 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35971
2023-07-31 05:41:15,795 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40781', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,795 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40781
2023-07-31 05:41:15,796 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34117', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,796 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34117
2023-07-31 05:41:15,796 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59494; closing.
2023-07-31 05:41:15,796 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33387', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:15,797 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33387
2023-07-31 05:41:15,797 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:41:17,605 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:41:17,606 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:17,606 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:17,607 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:41:17,608 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-07-31 05:41:20,221 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:20,226 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42857 instead
  warnings.warn(
2023-07-31 05:41:20,231 - distributed.scheduler - INFO - State start
2023-07-31 05:41:20,253 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:20,254 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:41:20,254 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42857/status
2023-07-31 05:41:20,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38317'
2023-07-31 05:41:20,443 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33247'
2023-07-31 05:41:20,457 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34367'
2023-07-31 05:41:20,459 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45875'
2023-07-31 05:41:20,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36065'
2023-07-31 05:41:20,476 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34361'
2023-07-31 05:41:20,484 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36881'
2023-07-31 05:41:20,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37285'
2023-07-31 05:41:21,023 - distributed.scheduler - INFO - Receive client connection: Client-df340b7d-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:21,035 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59674
2023-07-31 05:41:22,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,221 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,235 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,235 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,236 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:22,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:22,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:22,379 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:25,816 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41037
2023-07-31 05:41:25,816 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41037
2023-07-31 05:41:25,816 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40303
2023-07-31 05:41:25,816 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,816 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,816 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:25,816 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:25,816 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vtdzwfzx
2023-07-31 05:41:25,817 - distributed.worker - INFO - Starting Worker plugin RMMSetup-87aad015-a017-441e-a5ee-e15bf7b66f1c
2023-07-31 05:41:25,821 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46427
2023-07-31 05:41:25,821 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46427
2023-07-31 05:41:25,821 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38557
2023-07-31 05:41:25,821 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,821 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,821 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:25,821 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:25,821 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-iqf6q8qv
2023-07-31 05:41:25,822 - distributed.worker - INFO - Starting Worker plugin PreImport-8edb71ef-51dc-43f4-ac9a-57be81a3b7f5
2023-07-31 05:41:25,822 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f8cdbbf-86e5-4ea1-abe6-b6a81e4b1a6e
2023-07-31 05:41:25,822 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9ecc1348-a1a7-47fb-8874-1b9982bf271d
2023-07-31 05:41:25,825 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c311f36d-3a46-4daf-af05-6a43b55e95e3
2023-07-31 05:41:25,825 - distributed.worker - INFO - Starting Worker plugin PreImport-d00559a6-a8ee-4551-95c2-5b188b16df0a
2023-07-31 05:41:25,825 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,846 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,855 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41037', status: init, memory: 0, processing: 0>
2023-07-31 05:41:25,857 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41037
2023-07-31 05:41:25,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50328
2023-07-31 05:41:25,857 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,858 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:25,875 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32785
2023-07-31 05:41:25,875 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32785
2023-07-31 05:41:25,875 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41903
2023-07-31 05:41:25,875 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,875 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,875 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:25,875 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:25,876 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dsnqdf05
2023-07-31 05:41:25,876 - distributed.worker - INFO - Starting Worker plugin PreImport-567fc20d-def4-4be8-b261-6b7feba9a705
2023-07-31 05:41:25,876 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4f5b96a2-0d52-42c3-8328-d48c33db1b5e
2023-07-31 05:41:25,876 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ae9684d-f39a-42bd-9b2f-9dcf9305a3b1
2023-07-31 05:41:25,877 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46427', status: init, memory: 0, processing: 0>
2023-07-31 05:41:25,878 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46427
2023-07-31 05:41:25,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50336
2023-07-31 05:41:25,879 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,879 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,881 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,881 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:25,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32785', status: init, memory: 0, processing: 0>
2023-07-31 05:41:25,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32785
2023-07-31 05:41:25,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50348
2023-07-31 05:41:25,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:25,919 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:25,921 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,081 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41559
2023-07-31 05:41:26,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41559
2023-07-31 05:41:26,082 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38153
2023-07-31 05:41:26,082 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,082 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,082 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:26,082 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:26,082 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h3tudunt
2023-07-31 05:41:26,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a511556f-98a1-4fd1-8062-9c38d7924618
2023-07-31 05:41:26,090 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41343
2023-07-31 05:41:26,090 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41343
2023-07-31 05:41:26,090 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37767
2023-07-31 05:41:26,090 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,090 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,090 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:26,090 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:26,090 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1p8dr8l7
2023-07-31 05:41:26,091 - distributed.worker - INFO - Starting Worker plugin RMMSetup-15349905-430f-4add-b829-d37dfd5d1d7d
2023-07-31 05:41:26,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42121
2023-07-31 05:41:26,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42121
2023-07-31 05:41:26,093 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43603
2023-07-31 05:41:26,093 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,093 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43909
2023-07-31 05:41:26,093 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:26,093 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:26,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43909
2023-07-31 05:41:26,093 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-i4b4j21a
2023-07-31 05:41:26,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43823
2023-07-31 05:41:26,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,094 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,094 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:26,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:26,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4tavuf25
2023-07-31 05:41:26,094 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-80624b2c-6912-4041-b1ba-3ef71c08dbbc
2023-07-31 05:41:26,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f590aeea-6af7-4bc1-908b-e9a3146675b6
2023-07-31 05:41:26,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-277c211e-7367-44de-999c-35335532dfc6
2023-07-31 05:41:26,097 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37969
2023-07-31 05:41:26,098 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37969
2023-07-31 05:41:26,098 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45909
2023-07-31 05:41:26,098 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,098 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,098 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:26,098 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:26,098 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-eo32w54c
2023-07-31 05:41:26,099 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7e8be45-2747-41b6-a628-2bceaa15f35d
2023-07-31 05:41:26,112 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a09040aa-6bbc-4824-9f41-42f7059af41a
2023-07-31 05:41:26,114 - distributed.worker - INFO - Starting Worker plugin PreImport-6175b4c0-8983-44c0-901b-568536db6937
2023-07-31 05:41:26,115 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,115 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-addc927a-49b3-4b9b-8f87-3fc38ec3383a
2023-07-31 05:41:26,115 - distributed.worker - INFO - Starting Worker plugin PreImport-b6f418ab-49f1-438f-87d4-bdc3b5834d11
2023-07-31 05:41:26,115 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,116 - distributed.worker - INFO - Starting Worker plugin PreImport-947e189f-27a0-4bc7-9c55-782ced5446e2
2023-07-31 05:41:26,116 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,117 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-873f232d-d718-477c-8947-651c01b2c56e
2023-07-31 05:41:26,118 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e34b7f0-729a-430c-ac52-c646c12b8832
2023-07-31 05:41:26,118 - distributed.worker - INFO - Starting Worker plugin PreImport-04a9908d-a17f-4192-b685-641ba01cdcbc
2023-07-31 05:41:26,118 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,118 - distributed.worker - INFO - Starting Worker plugin PreImport-f992c73f-a89e-47e7-a92c-7061317e35d9
2023-07-31 05:41:26,119 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,142 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43909', status: init, memory: 0, processing: 0>
2023-07-31 05:41:26,143 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43909
2023-07-31 05:41:26,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50382
2023-07-31 05:41:26,143 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,143 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,144 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37969', status: init, memory: 0, processing: 0>
2023-07-31 05:41:26,144 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37969
2023-07-31 05:41:26,144 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50370
2023-07-31 05:41:26,145 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,145 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,145 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,147 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,148 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41343', status: init, memory: 0, processing: 0>
2023-07-31 05:41:26,148 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41343
2023-07-31 05:41:26,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50354
2023-07-31 05:41:26,149 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,149 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,149 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42121', status: init, memory: 0, processing: 0>
2023-07-31 05:41:26,150 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42121
2023-07-31 05:41:26,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50380
2023-07-31 05:41:26,150 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41559', status: init, memory: 0, processing: 0>
2023-07-31 05:41:26,150 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,150 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,151 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41559
2023-07-31 05:41:26,151 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50394
2023-07-31 05:41:26,151 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:26,152 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:26,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,153 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:26,236 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:26,242 - distributed.scheduler - INFO - Remove client Client-df340b7d-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:26,242 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59674; closing.
2023-07-31 05:41:26,242 - distributed.scheduler - INFO - Remove client Client-df340b7d-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:26,243 - distributed.scheduler - INFO - Close client connection: Client-df340b7d-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:26,244 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45875'. Reason: nanny-close
2023-07-31 05:41:26,244 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38317'. Reason: nanny-close
2023-07-31 05:41:26,245 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,246 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46427. Reason: nanny-close
2023-07-31 05:41:26,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33247'. Reason: nanny-close
2023-07-31 05:41:26,246 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,246 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32785. Reason: nanny-close
2023-07-31 05:41:26,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34367'. Reason: nanny-close
2023-07-31 05:41:26,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36065'. Reason: nanny-close
2023-07-31 05:41:26,247 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41559. Reason: nanny-close
2023-07-31 05:41:26,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34361'. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41037. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50336; closing.
2023-07-31 05:41:26,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43909. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36881'. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46427', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,248 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46427
2023-07-31 05:41:26,249 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37285'. Reason: nanny-close
2023-07-31 05:41:26,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37969. Reason: nanny-close
2023-07-31 05:41:26,249 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:26,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50348; closing.
2023-07-31 05:41:26,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41343. Reason: nanny-close
2023-07-31 05:41:26,249 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,249 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,249 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,249 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32785', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,250 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:32785
2023-07-31 05:41:26,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,250 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42121. Reason: nanny-close
2023-07-31 05:41:26,250 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46427
2023-07-31 05:41:26,251 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,251 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,251 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,251 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,251 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46427
2023-07-31 05:41:26,252 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,251 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50348>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-07-31 05:41:26,252 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,252 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46427
2023-07-31 05:41:26,252 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50394; closing.
2023-07-31 05:41:26,253 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50382; closing.
2023-07-31 05:41:26,253 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:26,253 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50328; closing.
2023-07-31 05:41:26,253 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,253 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41559', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,253 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41559
2023-07-31 05:41:26,253 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43909', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,254 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43909
2023-07-31 05:41:26,254 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41037', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,254 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:26,254 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41037
2023-07-31 05:41:26,254 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50370; closing.
2023-07-31 05:41:26,255 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37969', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,255 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37969
2023-07-31 05:41:26,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50354; closing.
2023-07-31 05:41:26,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50380; closing.
2023-07-31 05:41:26,256 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41343', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,256 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41343
2023-07-31 05:41:26,256 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42121', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:26,257 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42121
2023-07-31 05:41:26,257 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:41:27,812 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:41:27,813 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:27,813 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:27,815 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:41:27,815 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-07-31 05:41:30,131 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:30,136 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46259 instead
  warnings.warn(
2023-07-31 05:41:30,140 - distributed.scheduler - INFO - State start
2023-07-31 05:41:30,161 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:30,162 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:41:30,163 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46259/status
2023-07-31 05:41:30,328 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33657'
2023-07-31 05:41:30,350 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40697'
2023-07-31 05:41:30,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44683'
2023-07-31 05:41:30,363 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45533'
2023-07-31 05:41:30,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46315'
2023-07-31 05:41:30,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33989'
2023-07-31 05:41:30,401 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41137'
2023-07-31 05:41:30,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38073'
2023-07-31 05:41:32,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,175 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,209 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,227 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,228 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,251 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,318 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:32,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:32,408 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:32,474 - distributed.scheduler - INFO - Receive client connection: Client-e52ab414-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:32,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50546
2023-07-31 05:41:35,678 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41415
2023-07-31 05:41:35,679 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41415
2023-07-31 05:41:35,679 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40633
2023-07-31 05:41:35,679 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:35,679 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:35,679 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:35,679 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:35,679 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vywbahc3
2023-07-31 05:41:35,679 - distributed.worker - INFO - Starting Worker plugin RMMSetup-071ebe8b-4af5-417a-ac22-15cf7b1bc55b
2023-07-31 05:41:36,095 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43283
2023-07-31 05:41:36,096 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43283
2023-07-31 05:41:36,096 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41335
2023-07-31 05:41:36,096 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,096 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,096 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,096 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,096 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ipxd1q1m
2023-07-31 05:41:36,097 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff2d0bb6-4802-42c5-b669-89c0d2d95df0
2023-07-31 05:41:36,124 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33699
2023-07-31 05:41:36,124 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33699
2023-07-31 05:41:36,124 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44527
2023-07-31 05:41:36,124 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,125 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,125 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,125 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,125 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xh_tlb0k
2023-07-31 05:41:36,125 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bb57e6e9-2678-4c96-95e8-66970f302df2
2023-07-31 05:41:36,125 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f94b8a5f-47d1-416a-bde6-ae6ba2d6fde5
2023-07-31 05:41:36,156 - distributed.scheduler - INFO - Receive client connection: Client-e9d738ba-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:36,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55262
2023-07-31 05:41:36,169 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43573
2023-07-31 05:41:36,170 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43573
2023-07-31 05:41:36,170 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34775
2023-07-31 05:41:36,170 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,170 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,170 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,170 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,170 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6mhpvrg6
2023-07-31 05:41:36,171 - distributed.worker - INFO - Starting Worker plugin PreImport-aab69837-0015-467d-a6a4-7ebf178d8cdf
2023-07-31 05:41:36,171 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0570cfda-5664-40fa-aa8b-e9b3e1a93924
2023-07-31 05:41:36,190 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41491
2023-07-31 05:41:36,190 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41491
2023-07-31 05:41:36,190 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42079
2023-07-31 05:41:36,190 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,190 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,190 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,191 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,191 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zogysyho
2023-07-31 05:41:36,191 - distributed.worker - INFO - Starting Worker plugin RMMSetup-14d298e7-8cd1-4980-be5d-ce375faa0b97
2023-07-31 05:41:36,236 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45273
2023-07-31 05:41:36,237 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45273
2023-07-31 05:41:36,237 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42491
2023-07-31 05:41:36,237 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,237 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,237 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,237 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,237 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v_ti1c20
2023-07-31 05:41:36,237 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e6fb508d-1014-42da-a648-342cd50ebf29
2023-07-31 05:41:36,243 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44873
2023-07-31 05:41:36,243 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44873
2023-07-31 05:41:36,243 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39049
2023-07-31 05:41:36,243 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,243 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,243 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,243 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,243 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-06i0ka5x
2023-07-31 05:41:36,244 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f61db497-fb9a-4a07-975d-e1a517421abb
2023-07-31 05:41:36,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7ac7445f-6516-44c1-8d32-b743f89a519e
2023-07-31 05:41:36,247 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37239
2023-07-31 05:41:36,247 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37239
2023-07-31 05:41:36,248 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37821
2023-07-31 05:41:36,248 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,248 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,248 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:36,248 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:36,248 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-apagydqb
2023-07-31 05:41:36,249 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd1d5685-354b-4878-b06c-baa52bd5cc17
2023-07-31 05:41:36,388 - distributed.worker - INFO - Starting Worker plugin PreImport-7007d768-788d-4695-b5b4-5480b1e7b343
2023-07-31 05:41:36,389 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2330d645-8f5a-4de7-984a-24eefe9b1ec2
2023-07-31 05:41:36,389 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,437 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41415', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,439 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41415
2023-07-31 05:41:36,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55276
2023-07-31 05:41:36,439 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,440 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,443 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,502 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a785f8d4-55cb-444d-9b20-1dae36dce7ef
2023-07-31 05:41:36,503 - distributed.worker - INFO - Starting Worker plugin PreImport-491a6414-413f-4d11-abc0-361513bcbd78
2023-07-31 05:41:36,504 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,531 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a4aff6d0-68e3-4a8c-be7b-55106e384170
2023-07-31 05:41:36,532 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,532 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f98b325a-3c0d-451f-b55b-9a97c66ff885
2023-07-31 05:41:36,533 - distributed.worker - INFO - Starting Worker plugin PreImport-ce5ce7ea-598b-48ba-9b2b-453abacf3ade
2023-07-31 05:41:36,533 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,544 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bb14abcb-e274-4174-87ee-a81fc571d733
2023-07-31 05:41:36,545 - distributed.worker - INFO - Starting Worker plugin PreImport-8c64673f-87b4-4112-b20d-1379a938f5b5
2023-07-31 05:41:36,545 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab8a9703-654a-46c3-b247-424f1120be64
2023-07-31 05:41:36,551 - distributed.worker - INFO - Starting Worker plugin PreImport-a0d6f120-ec6a-49ea-a041-b7b2468ccdd2
2023-07-31 05:41:36,552 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,553 - distributed.worker - INFO - Starting Worker plugin PreImport-a74b05d8-2ca5-47c0-b756-8597ddf93581
2023-07-31 05:41:36,554 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,564 - distributed.worker - INFO - Starting Worker plugin PreImport-8b5c32be-c7fe-49eb-a3db-1cfc8e842eee
2023-07-31 05:41:36,565 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,566 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41491', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,570 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41491
2023-07-31 05:41:36,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55286
2023-07-31 05:41:36,571 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,571 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,579 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43283', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,580 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43283
2023-07-31 05:41:36,580 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55308
2023-07-31 05:41:36,581 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,581 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,583 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,596 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45273', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,598 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45273
2023-07-31 05:41:36,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55314
2023-07-31 05:41:36,599 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,599 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,602 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,602 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43573', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,603 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43573
2023-07-31 05:41:36,603 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55302
2023-07-31 05:41:36,604 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,604 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,608 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,611 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33699', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,612 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33699
2023-07-31 05:41:36,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55338
2023-07-31 05:41:36,613 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,613 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,614 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37239', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,615 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37239
2023-07-31 05:41:36,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55322
2023-07-31 05:41:36,616 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,616 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,618 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,632 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44873', status: init, memory: 0, processing: 0>
2023-07-31 05:41:36,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44873
2023-07-31 05:41:36,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55344
2023-07-31 05:41:36,633 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:36,634 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:36,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:36,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,694 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,703 - distributed.scheduler - INFO - Remove client Client-e9d738ba-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:36,703 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55262; closing.
2023-07-31 05:41:36,704 - distributed.scheduler - INFO - Remove client Client-e9d738ba-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:36,706 - distributed.scheduler - INFO - Close client connection: Client-e9d738ba-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:36,709 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,709 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,709 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,709 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,710 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,710 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,710 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,710 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,724 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:41:36,735 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:41:36,737 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:41:36,740 - distributed.scheduler - INFO - Remove client Client-e52ab414-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:36,740 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50546; closing.
2023-07-31 05:41:36,741 - distributed.scheduler - INFO - Remove client Client-e52ab414-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:36,741 - distributed.scheduler - INFO - Close client connection: Client-e52ab414-2f64-11ee-8acd-d8c49764f6bb
2023-07-31 05:41:36,742 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44683'. Reason: nanny-close
2023-07-31 05:41:36,743 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33989'. Reason: nanny-close
2023-07-31 05:41:36,744 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,744 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33657'. Reason: nanny-close
2023-07-31 05:41:36,744 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41415. Reason: nanny-close
2023-07-31 05:41:36,744 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,744 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40697'. Reason: nanny-close
2023-07-31 05:41:36,745 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43573. Reason: nanny-close
2023-07-31 05:41:36,745 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,745 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45533'. Reason: nanny-close
2023-07-31 05:41:36,745 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43283. Reason: nanny-close
2023-07-31 05:41:36,745 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46315'. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44873. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41137'. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33699. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,746 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55276; closing.
2023-07-31 05:41:36,747 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,747 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38073'. Reason: nanny-close
2023-07-31 05:41:36,747 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41491. Reason: nanny-close
2023-07-31 05:41:36,747 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41415', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,747 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,747 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:36,747 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,747 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41415
2023-07-31 05:41:36,747 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37239. Reason: nanny-close
2023-07-31 05:41:36,748 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,748 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,748 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55302; closing.
2023-07-31 05:41:36,748 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,748 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45273. Reason: nanny-close
2023-07-31 05:41:36,748 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,748 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55308; closing.
2023-07-31 05:41:36,749 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,749 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41415
2023-07-31 05:41:36,749 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43573', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,749 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41415
2023-07-31 05:41:36,749 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43573
2023-07-31 05:41:36,749 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43283', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,750 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41415
2023-07-31 05:41:36,750 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,750 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43283
2023-07-31 05:41:36,750 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,750 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,750 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:36,751 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55344; closing.
2023-07-31 05:41:36,751 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,751 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55338; closing.
2023-07-31 05:41:36,751 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,751 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44873', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,751 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44873
2023-07-31 05:41:36,751 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:36,752 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33699', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,752 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33699
2023-07-31 05:41:36,752 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55286; closing.
2023-07-31 05:41:36,752 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55322; closing.
2023-07-31 05:41:36,753 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55314; closing.
2023-07-31 05:41:36,753 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41491', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,753 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41491
2023-07-31 05:41:36,753 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37239', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,754 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37239
2023-07-31 05:41:36,754 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45273', status: closing, memory: 0, processing: 0>
2023-07-31 05:41:36,754 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45273
2023-07-31 05:41:36,754 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:41:37,074 - distributed.scheduler - INFO - Receive client connection: Client-ea634102-2f64-11ee-8518-d8c49764f6bb
2023-07-31 05:41:37,075 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55352
2023-07-31 05:41:38,511 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:41:38,512 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:38,512 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:38,514 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:41:38,514 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-07-31 05:41:40,799 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:40,804 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44051 instead
  warnings.warn(
2023-07-31 05:41:40,808 - distributed.scheduler - INFO - State start
2023-07-31 05:41:40,829 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:40,830 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:40,831 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:40,831 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-07-31 05:41:41,212 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44783'
2023-07-31 05:41:41,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45321'
2023-07-31 05:41:41,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34263'
2023-07-31 05:41:41,248 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37051'
2023-07-31 05:41:41,260 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41863'
2023-07-31 05:41:41,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45825'
2023-07-31 05:41:41,280 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38615'
2023-07-31 05:41:41,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44127'
2023-07-31 05:41:42,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:42,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:43,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:43,229 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,251 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,262 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,275 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:43,289 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:46,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45825'. Reason: nanny-close
2023-07-31 05:41:46,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44783'. Reason: nanny-close
2023-07-31 05:41:46,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34263'. Reason: nanny-close
2023-07-31 05:41:46,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37051'. Reason: nanny-close
2023-07-31 05:41:46,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41863'. Reason: nanny-close
2023-07-31 05:41:46,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38615'. Reason: nanny-close
2023-07-31 05:41:46,123 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44127'. Reason: nanny-close
2023-07-31 05:41:46,123 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45321'. Reason: nanny-close
2023-07-31 05:41:48,493 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44785
2023-07-31 05:41:48,493 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44785
2023-07-31 05:41:48,494 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42291
2023-07-31 05:41:48,494 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,493 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44905
2023-07-31 05:41:48,494 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,494 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44905
2023-07-31 05:41:48,494 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,494 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,494 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36247
2023-07-31 05:41:48,494 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pd9l1_za
2023-07-31 05:41:48,494 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,494 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,494 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,494 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,494 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-87_fs2w8
2023-07-31 05:41:48,494 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8d8c22e-a00a-4632-b381-8048adccb338
2023-07-31 05:41:48,494 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fe653811-fc7a-4276-ad4b-f8b4e1d22cef
2023-07-31 05:41:48,495 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bc3db411-be86-45a8-b2ae-8174b0941b60
2023-07-31 05:41:48,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-110c47ae-657c-4e8b-ba7d-6edb101d3db1
2023-07-31 05:41:48,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34725
2023-07-31 05:41:48,507 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34725
2023-07-31 05:41:48,507 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37473
2023-07-31 05:41:48,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,507 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,507 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39759
2023-07-31 05:41:48,507 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,507 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39759
2023-07-31 05:41:48,507 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_kfuy0ou
2023-07-31 05:41:48,507 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32815
2023-07-31 05:41:48,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,507 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,507 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,508 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,508 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lrg9kviw
2023-07-31 05:41:48,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-85924849-b8c9-412a-9b2e-f39cd3f11157
2023-07-31 05:41:48,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-35be66c6-bd1c-4e4d-b0ce-7990097003db
2023-07-31 05:41:48,521 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44009
2023-07-31 05:41:48,522 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44009
2023-07-31 05:41:48,522 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33565
2023-07-31 05:41:48,522 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,522 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,522 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,522 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,522 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s163kcmr
2023-07-31 05:41:48,523 - distributed.worker - INFO - Starting Worker plugin RMMSetup-57e8dc23-7dcc-4e46-b590-5c79208b0e60
2023-07-31 05:41:48,523 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46547
2023-07-31 05:41:48,524 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46547
2023-07-31 05:41:48,524 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40205
2023-07-31 05:41:48,524 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,524 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,524 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,524 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,524 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-57g6j66u
2023-07-31 05:41:48,524 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f68cee86-7bfe-4069-beec-a1fd41c54d8c
2023-07-31 05:41:48,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40483
2023-07-31 05:41:48,604 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40483
2023-07-31 05:41:48,605 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36083
2023-07-31 05:41:48,605 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,605 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,605 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,605 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,605 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c8yu79wv
2023-07-31 05:41:48,605 - distributed.worker - INFO - Starting Worker plugin PreImport-f1fc0cdd-448e-4321-a748-b2b3215b3226
2023-07-31 05:41:48,605 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6aabf0c-3476-46bf-a329-5dbc74c091f9
2023-07-31 05:41:48,614 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35521
2023-07-31 05:41:48,614 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35521
2023-07-31 05:41:48,614 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36119
2023-07-31 05:41:48,614 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:41:48,614 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,614 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:41:48,615 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:41:48,615 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-e69yystm
2023-07-31 05:41:48,615 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8365b451-1317-4927-9857-f57c0ed5f3d4
2023-07-31 05:41:48,762 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-959f030c-9c3f-4114-bf5d-dad4dc37417b
2023-07-31 05:41:48,762 - distributed.worker - INFO - Starting Worker plugin PreImport-0689344c-6e69-4ebe-9c10-824358f820cd
2023-07-31 05:41:48,762 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,762 - distributed.worker - INFO - Starting Worker plugin PreImport-501ff45d-5ab6-486e-926e-0f9b46edb82a
2023-07-31 05:41:48,762 - distributed.worker - INFO - Starting Worker plugin PreImport-1042ca32-21f5-4e6c-9a16-ded64fafc82f
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin PreImport-5b26f5e8-6927-45c0-a3d0-5413cb84ae0f
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bac8f3dd-4799-4175-9263-85557c6fd231
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b1dde39-4f3b-41c6-9ece-9d6a2b3eaeae
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-90b23b91-eaff-4cc4-ae3e-f1eeacdf67d9
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-284c674b-b00b-45f3-93e6-b16ea953f6eb
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1fc04c5-dda1-4f94-8fdc-44fa707ac411
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin PreImport-e4c4deab-b5f8-49d4-8953-4b5d2a929bac
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin PreImport-2fad366c-286d-4cda-9d7a-5d004fa8c06e
2023-07-31 05:41:48,763 - distributed.worker - INFO - Starting Worker plugin PreImport-253a997b-eb65-4846-a11c-d900a481ff7c
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,763 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:48,764 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:50,895 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:50,895 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:50,899 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:50,923 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:50,923 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:50,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:50,949 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:50,950 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:50,951 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35521. Reason: nanny-close
2023-07-31 05:41:50,951 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44905. Reason: nanny-close
2023-07-31 05:41:50,953 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:50,954 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:50,955 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:50,955 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:51,280 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:51,280 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:51,282 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:51,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:51,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44785. Reason: nanny-close
2023-07-31 05:41:51,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:51,311 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:51,870 - distributed.nanny - WARNING - Restarting worker
2023-07-31 05:41:51,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:51,920 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:51,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:51,977 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:51,977 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:51,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:52,097 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:52,098 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:52,099 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46547. Reason: nanny-close
2023-07-31 05:41:52,099 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44009. Reason: nanny-close
2023-07-31 05:41:52,101 - distributed.nanny - WARNING - Restarting worker
2023-07-31 05:41:52,101 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:52,102 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:52,102 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:52,102 - distributed.nanny - WARNING - Restarting worker
2023-07-31 05:41:52,103 - distributed.nanny - INFO - Worker closed

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:52,145 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:52,146 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:52,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:52,197 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:52,198 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40483. Reason: nanny-close
2023-07-31 05:41:52,201 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:52,202 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:52,322 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:52,322 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:52,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:52,338 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:41:52,338 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:41:52,341 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:41:52,350 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:52,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:41:52,351 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34725. Reason: nanny-close
2023-07-31 05:41:52,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39759. Reason: nanny-close
2023-07-31 05:41:52,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:52,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:41:52,355 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:52,356 - distributed.nanny - INFO - Worker closed
2023-07-31 05:41:53,001 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:53,124 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:53,173 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:53,256 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:53,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:53,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:53,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:53,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:53,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:53,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:41:54,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:54,344 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:41:54,549 - distributed.nanny - WARNING - Restarting worker
2023-07-31 05:41:54,556 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 711, in start
    await self.process.start()
asyncio.exceptions.CancelledError
2023-07-31 05:41:54,566 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53585 parent=53251 started daemon>
2023-07-31 05:41:54,566 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53569 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53566 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53563 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53560 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53536 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53533 parent=53251 started daemon>
2023-07-31 05:41:54,567 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=53519 parent=53251 started daemon>
2023-07-31 05:41:54,902 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 53533 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-07-31 05:41:57,421 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:57,427 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33137 instead
  warnings.warn(
2023-07-31 05:41:57,431 - distributed.scheduler - INFO - State start
2023-07-31 05:41:57,453 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:41:57,455 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:41:57,455 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:41:57,455 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-07-31 05:41:57,751 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40873'
2023-07-31 05:41:59,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2no2pkgt', purging
2023-07-31 05:41:59,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dppgsvnt', purging
2023-07-31 05:41:59,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-st35v9mb', purging
2023-07-31 05:41:59,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:41:59,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-31 05:42:00,171 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:01,332 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40187
2023-07-31 05:42:01,332 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40187
2023-07-31 05:42:01,332 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-07-31 05:42:01,332 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:01,332 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:01,332 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:01,332 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-31 05:42:01,332 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9855fxew
2023-07-31 05:42:01,333 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f31c3dc-2ee2-454f-bcfb-ed8d656d6638
2023-07-31 05:42:01,333 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3a52116-fbf0-4bf7-a181-ca10b579e3ef
2023-07-31 05:42:01,333 - distributed.worker - INFO - Starting Worker plugin PreImport-0d0fc632-f637-4f5b-bc9c-e1c728dc1ccd
2023-07-31 05:42:01,333 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:01,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:01,361 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:01,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:01,368 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:01,473 - distributed.client - ERROR - 
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 511, in connect
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f919da66310>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/client.py", line 1318, in _reconnect
    await self._ensure_connected(timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/client.py", line 1348, in _ensure_connected
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-07-31 05:42:01,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40873'. Reason: nanny-close
2023-07-31 05:42:01,476 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:01,478 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40187. Reason: nanny-close
2023-07-31 05:42:01,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:01,481 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-07-31 05:42:07,012 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:07,017 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45097 instead
  warnings.warn(
2023-07-31 05:42:07,022 - distributed.scheduler - INFO - State start
2023-07-31 05:42:07,174 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:07,175 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:07,176 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:07,176 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-07-31 05:42:07,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43639'
2023-07-31 05:42:09,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:09,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-31 05:42:09,707 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:10,776 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39117
2023-07-31 05:42:10,776 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39117
2023-07-31 05:42:10,777 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42393
2023-07-31 05:42:10,777 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:10,777 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:10,777 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:10,777 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-31 05:42:10,777 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0kwy3ffg
2023-07-31 05:42:10,778 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7595d8f8-9e72-4a95-9061-a3a96b3f44ce
2023-07-31 05:42:10,778 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8a3c08ed-3f35-459b-a7b0-a0f279ff7170
2023-07-31 05:42:10,778 - distributed.worker - INFO - Starting Worker plugin PreImport-3baeec9e-71b1-45cd-8145-a11bd6a17f02
2023-07-31 05:42:10,780 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:11,598 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:11,599 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:11,601 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:11,727 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:13,202 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:13,207 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43639'. Reason: nanny-close
2023-07-31 05:42:13,207 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:13,208 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39117. Reason: nanny-close
2023-07-31 05:42:13,210 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:13,212 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-07-31 05:42:16,269 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:16,273 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44659 instead
  warnings.warn(
2023-07-31 05:42:16,277 - distributed.scheduler - INFO - State start
2023-07-31 05:42:16,299 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:16,300 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:42:16,301 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44659/status
2023-07-31 05:42:18,738 - distributed.scheduler - INFO - Receive client connection: Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:18,752 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60846
2023-07-31 05:42:20,873 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:42:20,873 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:20,874 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:20,875 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:42:20,876 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-07-31 05:42:23,238 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:23,243 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45843 instead
  warnings.warn(
2023-07-31 05:42:23,247 - distributed.scheduler - INFO - State start
2023-07-31 05:42:23,413 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:23,414 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-07-31 05:42:23,415 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45843/status
2023-07-31 05:42:23,509 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44703'
2023-07-31 05:42:23,658 - distributed.scheduler - INFO - Receive client connection: Client-04ca82ac-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:23,672 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43898
2023-07-31 05:42:25,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:25,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:25,316 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:26,311 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37953
2023-07-31 05:42:26,311 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37953
2023-07-31 05:42:26,311 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45287
2023-07-31 05:42:26,311 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-31 05:42:26,311 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:26,311 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:26,311 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-31 05:42:26,312 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bzlunvn7
2023-07-31 05:42:26,312 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4ef630a3-a404-499d-91f1-a45ced1d745d
2023-07-31 05:42:26,312 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab81ff04-6d50-41f3-aa89-c0675b7b158c
2023-07-31 05:42:26,313 - distributed.worker - INFO - Starting Worker plugin PreImport-4feb3b99-05f8-4d92-a3d4-834a0f7bb50e
2023-07-31 05:42:26,313 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:26,344 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37953', status: init, memory: 0, processing: 0>
2023-07-31 05:42:26,346 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37953
2023-07-31 05:42:26,346 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39658
2023-07-31 05:42:26,346 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-31 05:42:26,347 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:26,349 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-31 05:42:26,377 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:26,380 - distributed.scheduler - INFO - Remove client Client-04ca82ac-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:26,381 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43898; closing.
2023-07-31 05:42:26,381 - distributed.scheduler - INFO - Remove client Client-04ca82ac-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:26,381 - distributed.scheduler - INFO - Close client connection: Client-04ca82ac-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:26,382 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44703'. Reason: nanny-close
2023-07-31 05:42:26,383 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:26,384 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37953. Reason: nanny-close
2023-07-31 05:42:26,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39658; closing.
2023-07-31 05:42:26,386 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-31 05:42:26,386 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37953', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:26,387 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37953
2023-07-31 05:42:26,387 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:42:26,387 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:27,801 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:42:27,802 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:27,802 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:27,803 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-07-31 05:42:27,803 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-07-31 05:42:30,108 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:30,113 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34449 instead
  warnings.warn(
2023-07-31 05:42:30,117 - distributed.scheduler - INFO - State start
2023-07-31 05:42:30,140 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:30,141 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:42:30,142 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34449/status
2023-07-31 05:42:30,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43849'
2023-07-31 05:42:30,419 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45547'
2023-07-31 05:42:30,422 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36239'
2023-07-31 05:42:30,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37263'
2023-07-31 05:42:30,450 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44097'
2023-07-31 05:42:30,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38891'
2023-07-31 05:42:30,478 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35399'
2023-07-31 05:42:30,490 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46793'
2023-07-31 05:42:31,554 - distributed.scheduler - INFO - Receive client connection: Client-08f2f13c-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:31,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59372
2023-07-31 05:42:32,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,170 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,229 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,253 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,266 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,317 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,318 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,321 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:32,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:32,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:32,459 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:33,967 - distributed.scheduler - INFO - Receive client connection: Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:33,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59378
2023-07-31 05:42:35,201 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43665
2023-07-31 05:42:35,202 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43665
2023-07-31 05:42:35,202 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38431
2023-07-31 05:42:35,202 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,202 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,202 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,202 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,202 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mx7q_n6f
2023-07-31 05:42:35,203 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1017333-4e15-4608-a87a-507f9a417b1a
2023-07-31 05:42:35,326 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9044cbf3-1a19-4f30-9443-508d5ef64e9e
2023-07-31 05:42:35,326 - distributed.worker - INFO - Starting Worker plugin PreImport-4b19a806-b294-4aa3-b3a4-11c6898341ac
2023-07-31 05:42:35,326 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,353 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43665', status: init, memory: 0, processing: 0>
2023-07-31 05:42:35,354 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43665
2023-07-31 05:42:35,354 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39346
2023-07-31 05:42:35,354 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,354 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:35,526 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37849
2023-07-31 05:42:35,526 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37849
2023-07-31 05:42:35,526 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34443
2023-07-31 05:42:35,526 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,527 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,527 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,527 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,527 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1pk4hy20
2023-07-31 05:42:35,527 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5592b41c-b9d9-4ffd-9da8-ed572c90a996
2023-07-31 05:42:35,528 - distributed.worker - INFO - Starting Worker plugin RMMSetup-638f7753-9571-447e-9394-fa9324aa96d0
2023-07-31 05:42:35,529 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39931
2023-07-31 05:42:35,529 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39931
2023-07-31 05:42:35,529 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32947
2023-07-31 05:42:35,529 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,529 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,530 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,530 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,530 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2ylewbfr
2023-07-31 05:42:35,530 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c71a9b2b-c5ec-4f59-82dc-1ba422c83b7b
2023-07-31 05:42:35,789 - distributed.worker - INFO - Starting Worker plugin PreImport-4dca013d-1b87-4466-9776-7fb2b8e80985
2023-07-31 05:42:35,789 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-19f475f1-af66-4b69-96ab-7392e3e496b0
2023-07-31 05:42:35,790 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,817 - distributed.worker - INFO - Starting Worker plugin PreImport-30742324-8887-4305-927d-5487c3438b5a
2023-07-31 05:42:35,817 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,824 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34059
2023-07-31 05:42:35,824 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34059
2023-07-31 05:42:35,824 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37279
2023-07-31 05:42:35,824 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,824 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,824 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,824 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,824 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-br_ujesj
2023-07-31 05:42:35,825 - distributed.worker - INFO - Starting Worker plugin RMMSetup-50010e9b-3f91-4187-86e1-d1aea5767724
2023-07-31 05:42:35,835 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39931', status: init, memory: 0, processing: 0>
2023-07-31 05:42:35,835 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39931
2023-07-31 05:42:35,835 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39360
2023-07-31 05:42:35,836 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,836 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,839 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:35,856 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37379
2023-07-31 05:42:35,856 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37379
2023-07-31 05:42:35,856 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37759
2023-07-31 05:42:35,856 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,856 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,856 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,856 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,856 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ujk7_dcy
2023-07-31 05:42:35,857 - distributed.worker - INFO - Starting Worker plugin PreImport-884a316f-43be-4304-8cc5-3918c0d96997
2023-07-31 05:42:35,857 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2cc9b57e-4743-41cc-9d4d-3ade0f267e27
2023-07-31 05:42:35,864 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43081
2023-07-31 05:42:35,865 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43081
2023-07-31 05:42:35,865 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41209
2023-07-31 05:42:35,865 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,865 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,865 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,865 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,865 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38993
2023-07-31 05:42:35,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rud7mhfn
2023-07-31 05:42:35,866 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38993
2023-07-31 05:42:35,866 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33131
2023-07-31 05:42:35,866 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,866 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,866 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,866 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7_94kwa6
2023-07-31 05:42:35,866 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37849', status: init, memory: 0, processing: 0>
2023-07-31 05:42:35,866 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd968c51-d867-4c8e-9bca-c7a1d9a948fd
2023-07-31 05:42:35,867 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37849
2023-07-31 05:42:35,867 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4ad2b67c-6a46-4915-aeda-0f77ba5f7141
2023-07-31 05:42:35,867 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39366
2023-07-31 05:42:35,867 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6863e8be-a5a1-4324-8fbe-74f6d789915c
2023-07-31 05:42:35,867 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,868 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,869 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34889
2023-07-31 05:42:35,869 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34889
2023-07-31 05:42:35,869 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38047
2023-07-31 05:42:35,870 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:35,870 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:35,870 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:35,870 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-31 05:42:35,870 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-endahhit
2023-07-31 05:42:35,870 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:35,870 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b83a146e-7375-4ae8-81e3-03570dcb42bd
2023-07-31 05:42:36,010 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f12cecb-f074-402f-aaba-b6b1f6001008
2023-07-31 05:42:36,010 - distributed.worker - INFO - Starting Worker plugin PreImport-8904f412-bb83-4197-a26d-d5c99f8164bb
2023-07-31 05:42:36,010 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,018 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5daac820-d5a2-46ed-a0f8-53eaf03cab6e
2023-07-31 05:42:36,018 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d4daec23-bfa7-414a-9fde-63daff32de99
2023-07-31 05:42:36,018 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0358b013-5670-49c9-b08e-c4d708ee97e4
2023-07-31 05:42:36,018 - distributed.worker - INFO - Starting Worker plugin PreImport-136795b1-51b0-4d6c-9df6-3fea035144f2
2023-07-31 05:42:36,018 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,018 - distributed.worker - INFO - Starting Worker plugin PreImport-d9120bfd-7a73-4ba9-ae87-00d7015a8424
2023-07-31 05:42:36,019 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,019 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,038 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34059', status: init, memory: 0, processing: 0>
2023-07-31 05:42:36,039 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34059
2023-07-31 05:42:36,039 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39382
2023-07-31 05:42:36,039 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:36,040 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,042 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:36,044 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34889', status: init, memory: 0, processing: 0>
2023-07-31 05:42:36,045 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34889
2023-07-31 05:42:36,045 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39388
2023-07-31 05:42:36,045 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:36,045 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:36,055 - distributed.worker - INFO - Starting Worker plugin PreImport-c778ceee-2e2b-4bdf-9ac2-c258bd15be17
2023-07-31 05:42:36,056 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,064 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37379', status: init, memory: 0, processing: 0>
2023-07-31 05:42:36,065 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37379
2023-07-31 05:42:36,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39390
2023-07-31 05:42:36,066 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:36,066 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38993', status: init, memory: 0, processing: 0>
2023-07-31 05:42:36,066 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,066 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38993
2023-07-31 05:42:36,067 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39400
2023-07-31 05:42:36,067 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:36,067 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,069 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:36,070 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:36,091 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43081', status: init, memory: 0, processing: 0>
2023-07-31 05:42:36,092 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43081
2023-07-31 05:42:36,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39408
2023-07-31 05:42:36,093 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:36,093 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:36,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:36,180 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,180 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,181 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,196 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:36,201 - distributed.scheduler - INFO - Remove client Client-08f2f13c-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:36,201 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59372; closing.
2023-07-31 05:42:36,201 - distributed.scheduler - INFO - Remove client Client-08f2f13c-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:36,202 - distributed.scheduler - INFO - Close client connection: Client-08f2f13c-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:36,203 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45547'. Reason: nanny-close
2023-07-31 05:42:36,203 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,204 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44097'. Reason: nanny-close
2023-07-31 05:42:36,204 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,205 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43849'. Reason: nanny-close
2023-07-31 05:42:36,205 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39931. Reason: nanny-close
2023-07-31 05:42:36,205 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,205 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36239'. Reason: nanny-close
2023-07-31 05:42:36,205 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37379. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43665. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37263'. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38891'. Reason: nanny-close
2023-07-31 05:42:36,206 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37849. Reason: nanny-close
2023-07-31 05:42:36,207 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,207 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35399'. Reason: nanny-close
2023-07-31 05:42:36,207 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39360; closing.
2023-07-31 05:42:36,207 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43081. Reason: nanny-close
2023-07-31 05:42:36,207 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,207 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,207 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39931', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,208 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39931
2023-07-31 05:42:36,208 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46793'. Reason: nanny-close
2023-07-31 05:42:36,208 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,208 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38993. Reason: nanny-close
2023-07-31 05:42:36,208 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,208 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:36,208 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34059. Reason: nanny-close
2023-07-31 05:42:36,208 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,209 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,209 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39346; closing.
2023-07-31 05:42:36,209 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,209 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39931
2023-07-31 05:42:36,209 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39931
2023-07-31 05:42:36,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39390; closing.
2023-07-31 05:42:36,209 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34889. Reason: nanny-close
2023-07-31 05:42:36,210 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,210 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39931
2023-07-31 05:42:36,210 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,210 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43665', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,210 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39931
2023-07-31 05:42:36,210 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43665
2023-07-31 05:42:36,210 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,210 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37379', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,210 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37379
2023-07-31 05:42:36,210 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,211 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39366; closing.
2023-07-31 05:42:36,211 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,211 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:36,211 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37849', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,211 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37849
2023-07-31 05:42:36,211 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,212 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39408; closing.
2023-07-31 05:42:36,212 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,212 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43081', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,212 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43081
2023-07-31 05:42:36,212 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:36,212 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39382; closing.
2023-07-31 05:42:36,213 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39400; closing.
2023-07-31 05:42:36,213 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39388; closing.
2023-07-31 05:42:36,213 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34059', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,213 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34059
2023-07-31 05:42:36,214 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38993', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,214 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38993
2023-07-31 05:42:36,214 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34889', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:36,214 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34889
2023-07-31 05:42:36,214 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:42:37,359 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46505', status: init, memory: 0, processing: 0>
2023-07-31 05:42:37,359 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46505
2023-07-31 05:42:37,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39418
2023-07-31 05:42:37,872 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:42:37,872 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:37,873 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:37,874 - distributed.core - INFO - Connection to tcp://127.0.0.1:39418 has been closed.
2023-07-31 05:42:37,874 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46505', status: running, memory: 0, processing: 0>
2023-07-31 05:42:37,874 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46505
2023-07-31 05:42:37,874 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:42:37,876 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:42:37,876 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-07-31 05:42:40,271 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:40,276 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37223 instead
  warnings.warn(
2023-07-31 05:42:40,280 - distributed.scheduler - INFO - State start
2023-07-31 05:42:40,302 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:40,304 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:42:40,304 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37223/status
2023-07-31 05:42:40,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37289'
2023-07-31 05:42:42,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:42,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:42,278 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:42,475 - distributed.scheduler - INFO - Receive client connection: Client-0ef1e1e3-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:42,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39712
2023-07-31 05:42:43,379 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37585
2023-07-31 05:42:43,379 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37585
2023-07-31 05:42:43,379 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44011
2023-07-31 05:42:43,379 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:43,380 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:43,380 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:43,380 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-31 05:42:43,380 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-utdk95mt
2023-07-31 05:42:43,380 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01af778a-e573-476b-85d9-0188a74c7490
2023-07-31 05:42:43,498 - distributed.worker - INFO - Starting Worker plugin PreImport-ec528568-235c-4055-af20-9994f433fa75
2023-07-31 05:42:43,498 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c8addc0e-4d62-436b-8739-95bf7caf4cd5
2023-07-31 05:42:43,499 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:43,545 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37585', status: init, memory: 0, processing: 0>
2023-07-31 05:42:43,546 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37585
2023-07-31 05:42:43,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39724
2023-07-31 05:42:43,547 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:43,547 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:43,552 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:43,621 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:42:43,626 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:43,628 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:43,632 - distributed.scheduler - INFO - Remove client Client-0ef1e1e3-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:43,632 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39712; closing.
2023-07-31 05:42:43,632 - distributed.scheduler - INFO - Remove client Client-0ef1e1e3-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:43,633 - distributed.scheduler - INFO - Close client connection: Client-0ef1e1e3-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:43,634 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37289'. Reason: nanny-close
2023-07-31 05:42:43,634 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:43,636 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37585. Reason: nanny-close
2023-07-31 05:42:43,638 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39724; closing.
2023-07-31 05:42:43,638 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:43,639 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37585', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:43,639 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37585
2023-07-31 05:42:43,639 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:42:43,640 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:43,905 - distributed.scheduler - INFO - Receive client connection: Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:43,906 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39738
2023-07-31 05:42:45,002 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:42:45,003 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:45,003 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:45,004 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:42:45,005 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-07-31 05:42:47,336 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:47,341 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41627 instead
  warnings.warn(
2023-07-31 05:42:47,345 - distributed.scheduler - INFO - State start
2023-07-31 05:42:47,368 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-31 05:42:47,369 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-31 05:42:47,369 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41627/status
2023-07-31 05:42:47,568 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40795'
2023-07-31 05:42:47,679 - distributed.scheduler - INFO - Receive client connection: Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:47,693 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36884
2023-07-31 05:42:48,020 - distributed.scheduler - INFO - Receive client connection: Client-132b6e76-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:48,020 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36898
2023-07-31 05:42:49,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:42:49,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:42:49,287 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-31 05:42:50,300 - distributed.scheduler - INFO - Remove client Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:50,301 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36884; closing.
2023-07-31 05:42:50,301 - distributed.scheduler - INFO - Remove client Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:50,302 - distributed.scheduler - INFO - Close client connection: Client-0338d299-2f65-11ee-8518-d8c49764f6bb
2023-07-31 05:42:50,315 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42895
2023-07-31 05:42:50,315 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42895
2023-07-31 05:42:50,315 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41149
2023-07-31 05:42:50,315 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-31 05:42:50,316 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:50,316 - distributed.worker - INFO -               Threads:                          1
2023-07-31 05:42:50,316 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-31 05:42:50,316 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jc6nqz44
2023-07-31 05:42:50,316 - distributed.worker - INFO - Starting Worker plugin RMMSetup-209d7c6f-01ce-4456-9556-e77654bf2dd3
2023-07-31 05:42:50,438 - distributed.worker - INFO - Starting Worker plugin PreImport-e94bdb68-e943-4bc7-96af-9b5c4515057f
2023-07-31 05:42:50,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-efcffa86-4b4d-4861-b495-ebb5c99d3bd4
2023-07-31 05:42:50,439 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:50,476 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42895', status: init, memory: 0, processing: 0>
2023-07-31 05:42:50,478 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42895
2023-07-31 05:42:50,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36924
2023-07-31 05:42:50,478 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-31 05:42:50,478 - distributed.worker - INFO - -------------------------------------------------
2023-07-31 05:42:50,483 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-31 05:42:50,486 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-07-31 05:42:50,491 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-31 05:42:50,495 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:50,496 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-31 05:42:50,499 - distributed.scheduler - INFO - Remove client Client-132b6e76-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:50,499 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36898; closing.
2023-07-31 05:42:50,499 - distributed.scheduler - INFO - Remove client Client-132b6e76-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:50,499 - distributed.scheduler - INFO - Close client connection: Client-132b6e76-2f65-11ee-8acd-d8c49764f6bb
2023-07-31 05:42:50,500 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40795'. Reason: nanny-close
2023-07-31 05:42:50,512 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-31 05:42:50,513 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42895. Reason: nanny-close
2023-07-31 05:42:50,515 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36924; closing.
2023-07-31 05:42:50,515 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-31 05:42:50,515 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42895', status: closing, memory: 0, processing: 0>
2023-07-31 05:42:50,515 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42895
2023-07-31 05:42:50,515 - distributed.scheduler - INFO - Lost all workers
2023-07-31 05:42:50,516 - distributed.nanny - INFO - Worker closed
2023-07-31 05:42:51,868 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-31 05:42:51,868 - distributed.scheduler - INFO - Scheduler closing...
2023-07-31 05:42:51,869 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-31 05:42:51,870 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-31 05:42:51,870 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41463 instead
  warnings.warn(
2023-07-31 05:43:02,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:02,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:02,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39203 instead
  warnings.warn(
2023-07-31 05:43:14,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:14,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:14,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41149 instead
  warnings.warn(
2023-07-31 05:43:24,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:24,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:24,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39301 instead
  warnings.warn(
2023-07-31 05:43:35,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:35,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:35,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42101 instead
  warnings.warn(
2023-07-31 05:43:48,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:43:48,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:43:48,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33661 instead
  warnings.warn(
2023-07-31 05:44:01,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:01,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:01,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34979 instead
  warnings.warn(
2023-07-31 05:44:16,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:16,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:16,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45437 instead
  warnings.warn(
2023-07-31 05:44:32,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-31 05:44:32,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-31 05:44:32,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43467 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36359 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38881 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37547 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42313 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46127 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45719 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35889 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44265 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39383 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44133 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33033 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34147 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34359 instead
  warnings.warn(
2023-07-31 05:48:12,673 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-eb29917a-e70e-4259-9beb-a644e021c458
Function:  _run_coroutine_on_worker
args:      (337088536136410298489574591555248415698, <function shuffle_task at 0x7faa0c1638b0>, ('explicit-comms-shuffle-e097386536174eabd41defafccacc725', {0: set(), 1: {"('from_pandas-042f56ad2fd1cc4d095a550ce07a5908', 0)"}}, {0: {0}, 1: set()}, ['key'], 1, False, 1, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
