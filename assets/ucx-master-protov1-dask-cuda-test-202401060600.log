============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-06 06:24:26,871 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:26,876 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:24:26,879 - distributed.scheduler - INFO - State start
2024-01-06 06:24:26,902 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:26,903 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-06 06:24:26,904 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:24:26,904 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:24:27,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42393'
2024-01-06 06:24:27,036 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37995'
2024-01-06 06:24:27,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33929'
2024-01-06 06:24:27,050 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35053'
2024-01-06 06:24:28,796 - distributed.scheduler - INFO - Receive client connection: Client-3cb83c8d-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:28,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36446
2024-01-06 06:24:28,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:28,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:28,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:28,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:28,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:28,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:28,904 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:28,904 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:28,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41875
2024-01-06 06:24:28,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42381
2024-01-06 06:24:28,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41875
2024-01-06 06:24:28,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42381
2024-01-06 06:24:28,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:28,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44567
2024-01-06 06:24:28,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:24:28,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40893
2024-01-06 06:24:28,905 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:24:28,905 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:24:28,905 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,905 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:24:28,905 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:24:28,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-x0gchnya
2024-01-06 06:24:28,905 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:24:28,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-9_tztl33
2024-01-06 06:24:28,905 - distributed.worker - INFO - Starting Worker plugin PreImport-3fc93226-e2ed-45ad-8919-679e6e6eafed
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a32751a-4909-4521-b58e-8f382e1eb8ad
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin PreImport-8fd78acc-4552-4e71-b003-ca5d4f922a27
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66909000-00d9-49bf-9320-e8b532591c10
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6c2d4c1b-eb05-4c77-8a16-fc00ed43fd80
2024-01-06 06:24:28,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33055
2024-01-06 06:24:28,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-01f6c568-315c-4c2a-8f44-f1da359a6373
2024-01-06 06:24:28,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33055
2024-01-06 06:24:28,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43081
2024-01-06 06:24:28,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:24:28,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,906 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:24:28,906 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:24:28,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-9d7zwxlr
2024-01-06 06:24:28,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f4d38128-2487-447d-a5b8-e43ca268b0d4
2024-01-06 06:24:28,906 - distributed.worker - INFO - Starting Worker plugin PreImport-ca1d8aa1-3608-4db6-a034-5875c18c495c
2024-01-06 06:24:28,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61874241-4f83-4627-a990-0b65d02d3210
2024-01-06 06:24:28,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:28,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:28,941 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:28,942 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41201
2024-01-06 06:24:28,942 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41201
2024-01-06 06:24:28,942 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45767
2024-01-06 06:24:28,942 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:24:28,942 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:28,942 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:24:28,942 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:24:28,942 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-g657_pt1
2024-01-06 06:24:28,942 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9b92df4-f9da-4feb-94fc-542099e6f944
2024-01-06 06:24:28,943 - distributed.worker - INFO - Starting Worker plugin PreImport-58a66f44-1d80-478e-a126-dc347d23fe19
2024-01-06 06:24:28,943 - distributed.worker - INFO - Starting Worker plugin RMMSetup-394d54c2-6099-49a4-91df-2a926f970f70
2024-01-06 06:24:28,943 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:29,046 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41875', status: init, memory: 0, processing: 0>
2024-01-06 06:24:29,047 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41875
2024-01-06 06:24:29,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36470
2024-01-06 06:24:29,048 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42381', status: init, memory: 0, processing: 0>
2024-01-06 06:24:29,048 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:29,049 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42381
2024-01-06 06:24:29,049 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36474
2024-01-06 06:24:29,049 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:24:29,049 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:29,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:29,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:24:29,051 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:24:29,051 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:29,051 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33055', status: init, memory: 0, processing: 0>
2024-01-06 06:24:29,052 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33055
2024-01-06 06:24:29,052 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36484
2024-01-06 06:24:29,052 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:24:29,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:29,053 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:24:29,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:29,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:24:29,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41201', status: init, memory: 0, processing: 0>
2024-01-06 06:24:29,063 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41201
2024-01-06 06:24:29,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36490
2024-01-06 06:24:29,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:29,065 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:24:29,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:29,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:24:29,125 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:24:29,125 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:24:29,125 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:24:29,125 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-06 06:24:29,131 - distributed.scheduler - INFO - Remove client Client-3cb83c8d-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:29,131 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36446; closing.
2024-01-06 06:24:29,131 - distributed.scheduler - INFO - Remove client Client-3cb83c8d-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:29,131 - distributed.scheduler - INFO - Close client connection: Client-3cb83c8d-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:29,133 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42393'. Reason: nanny-close
2024-01-06 06:24:29,133 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:29,134 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37995'. Reason: nanny-close
2024-01-06 06:24:29,134 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:29,134 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33929'. Reason: nanny-close
2024-01-06 06:24:29,134 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33055. Reason: nanny-close
2024-01-06 06:24:29,135 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:29,135 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35053'. Reason: nanny-close
2024-01-06 06:24:29,135 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42381. Reason: nanny-close
2024-01-06 06:24:29,135 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41875. Reason: nanny-close
2024-01-06 06:24:29,136 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:24:29,137 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36484; closing.
2024-01-06 06:24:29,137 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:24:29,137 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33055', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522269.1373222')
2024-01-06 06:24:29,137 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:24:29,135 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:29,138 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36474; closing.
2024-01-06 06:24:29,138 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:29,138 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41201. Reason: nanny-close
2024-01-06 06:24:29,138 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42381', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522269.1386514')
2024-01-06 06:24:29,139 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:29,139 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:29,139 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36470; closing.
2024-01-06 06:24:29,139 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522269.1395674')
2024-01-06 06:24:29,140 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36490; closing.
2024-01-06 06:24:29,140 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:24:29,140 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41201', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522269.1408937')
2024-01-06 06:24:29,141 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:24:29,142 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:29,798 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:24:29,798 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:24:29,799 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:24:29,800 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-06 06:24:29,801 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-06 06:24:32,080 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:32,084 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:24:32,088 - distributed.scheduler - INFO - State start
2024-01-06 06:24:32,111 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:32,112 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:24:32,113 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:24:32,113 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:24:32,155 - distributed.scheduler - INFO - Receive client connection: Client-3fc5933b-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:32,169 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35748
2024-01-06 06:24:32,275 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40173'
2024-01-06 06:24:32,297 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39271'
2024-01-06 06:24:32,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38009'
2024-01-06 06:24:32,318 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33231'
2024-01-06 06:24:32,327 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44585'
2024-01-06 06:24:32,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41547'
2024-01-06 06:24:32,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33431'
2024-01-06 06:24:32,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45841'
2024-01-06 06:24:34,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,218 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,218 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,219 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,219 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35189
2024-01-06 06:24:34,219 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35189
2024-01-06 06:24:34,219 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40355
2024-01-06 06:24:34,219 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,219 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,219 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39203
2024-01-06 06:24:34,219 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,219 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39203
2024-01-06 06:24:34,219 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m450jf59
2024-01-06 06:24:34,219 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39569
2024-01-06 06:24:34,219 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41669
2024-01-06 06:24:34,219 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39569
2024-01-06 06:24:34,219 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,220 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,220 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42223
2024-01-06 06:24:34,220 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin PreImport-358f3ce4-a0ae-4e96-8ccf-268c93953229
2024-01-06 06:24:34,220 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,220 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,220 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,220 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5o7trqwl
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-154f8a94-7945-4b06-bf19-f84182dc115e
2024-01-06 06:24:34,220 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,220 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,220 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1s_11kkl
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0f18b769-90bf-4860-80c9-48fa88c8d082
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin RMMSetup-60a6e9e5-9ca7-4275-9f3c-f71e8e24ac0d
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin PreImport-bc3a8c25-f6db-4a31-9a33-2060fb14103a
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b528d82-f411-4f49-b805-3e616bf22a2a
2024-01-06 06:24:34,220 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6b48c1f1-aa3b-4b63-bc6d-f2eddba74859
2024-01-06 06:24:34,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,229 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,230 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44425
2024-01-06 06:24:34,230 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44425
2024-01-06 06:24:34,230 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42997
2024-01-06 06:24:34,230 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,230 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,230 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,230 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,231 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hvt2rk88
2024-01-06 06:24:34,231 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-55c0c2df-96ee-4c67-bba3-69b50c5526a4
2024-01-06 06:24:34,233 - distributed.worker - INFO - Starting Worker plugin PreImport-776b5b05-e21b-4864-b159-8fa6bf933247
2024-01-06 06:24:34,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6a077bef-28eb-4827-8353-d1f85e7f08e4
2024-01-06 06:24:34,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,310 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,311 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,311 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45847
2024-01-06 06:24:34,311 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45847
2024-01-06 06:24:34,311 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36071
2024-01-06 06:24:34,311 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,311 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,312 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,311 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41337
2024-01-06 06:24:34,312 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41337
2024-01-06 06:24:34,312 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,312 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sgfndyrm
2024-01-06 06:24:34,312 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43079
2024-01-06 06:24:34,312 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,312 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,312 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,312 - distributed.worker - INFO - Starting Worker plugin RMMSetup-164ce73f-23f2-4778-86a2-b38258e47b8b
2024-01-06 06:24:34,312 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,312 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8a85axy7
2024-01-06 06:24:34,312 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8baab3a4-bc1f-425f-822b-450961cd0576
2024-01-06 06:24:34,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:34,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:34,313 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,314 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36417
2024-01-06 06:24:34,314 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36417
2024-01-06 06:24:34,314 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38679
2024-01-06 06:24:34,314 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,314 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,314 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,314 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,315 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4ydr26r9
2024-01-06 06:24:34,315 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7cf895c5-cb68-4c93-b87a-54c58538eef0
2024-01-06 06:24:34,318 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:34,318 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39035
2024-01-06 06:24:34,318 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39035
2024-01-06 06:24:34,319 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40681
2024-01-06 06:24:34,319 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:34,319 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:34,319 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:34,319 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:34,319 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fupo32h3
2024-01-06 06:24:34,319 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d7c2ccba-d0d7-4c03-9ef4-7ce881542906
2024-01-06 06:24:36,482 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-725b6947-7112-44d9-adbf-4afd47fa0470
2024-01-06 06:24:36,483 - distributed.worker - INFO - Starting Worker plugin PreImport-feccea19-0e8c-417f-b46e-2213d896f2c0
2024-01-06 06:24:36,484 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,531 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39203', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,532 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39203
2024-01-06 06:24:36,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35824
2024-01-06 06:24:36,534 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,535 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,536 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,538 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,545 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,581 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39569', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,582 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39569
2024-01-06 06:24:36,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35836
2024-01-06 06:24:36,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,584 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,584 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,586 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,602 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,612 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,628 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35189', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,629 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35189
2024-01-06 06:24:36,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35838
2024-01-06 06:24:36,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,630 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,631 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,642 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9ecce01e-0ac6-4542-8110-d976adb380e5
2024-01-06 06:24:36,643 - distributed.worker - INFO - Starting Worker plugin PreImport-52b0e2d5-0db6-4c29-9b79-e5fdf241b506
2024-01-06 06:24:36,644 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,646 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5ae3ba9a-a06d-4cb6-9abe-19b761e601eb
2024-01-06 06:24:36,647 - distributed.worker - INFO - Starting Worker plugin PreImport-95a24249-91ac-42a7-826d-58102f3f8ac2
2024-01-06 06:24:36,647 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,656 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-54e99ff8-95b1-4113-b86d-94cc214be253
2024-01-06 06:24:36,657 - distributed.worker - INFO - Starting Worker plugin PreImport-7ad32bea-8b35-4edb-9c86-47f16b628e25
2024-01-06 06:24:36,657 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,672 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44425', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,673 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44425
2024-01-06 06:24:36,673 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35846
2024-01-06 06:24:36,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,678 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,678 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,678 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41337', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,679 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41337
2024-01-06 06:24:36,679 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35852
2024-01-06 06:24:36,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,680 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c73284c-ef97-4e20-80e0-010b69f7dad2
2024-01-06 06:24:36,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39035', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,681 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,681 - distributed.worker - INFO - Starting Worker plugin PreImport-09afa310-8ba3-4e16-95e3-24224116accc
2024-01-06 06:24:36,681 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,681 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39035
2024-01-06 06:24:36,681 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35854
2024-01-06 06:24:36,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,682 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,683 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,683 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,685 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,688 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45847', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45847
2024-01-06 06:24:36,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35850
2024-01-06 06:24:36,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,692 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,692 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,720 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36417', status: init, memory: 0, processing: 0>
2024-01-06 06:24:36,720 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36417
2024-01-06 06:24:36,721 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35870
2024-01-06 06:24:36,722 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:36,723 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:36,723 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:36,724 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:36,750 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,750 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,750 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,750 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,751 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,751 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,751 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,751 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:36,757 - distributed.scheduler - INFO - Remove client Client-3fc5933b-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:36,757 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35748; closing.
2024-01-06 06:24:36,757 - distributed.scheduler - INFO - Remove client Client-3fc5933b-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:36,758 - distributed.scheduler - INFO - Close client connection: Client-3fc5933b-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:36,759 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40173'. Reason: nanny-close
2024-01-06 06:24:36,759 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,759 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39271'. Reason: nanny-close
2024-01-06 06:24:36,760 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,760 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38009'. Reason: nanny-close
2024-01-06 06:24:36,760 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44425. Reason: nanny-close
2024-01-06 06:24:36,760 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33231'. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39569. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44585'. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35189. Reason: nanny-close
2024-01-06 06:24:36,761 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41547'. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41337. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33431'. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,762 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39203. Reason: nanny-close
2024-01-06 06:24:36,763 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45841'. Reason: nanny-close
2024-01-06 06:24:36,763 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45847. Reason: nanny-close
2024-01-06 06:24:36,763 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35846; closing.
2024-01-06 06:24:36,763 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:36,763 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,763 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36417. Reason: nanny-close
2024-01-06 06:24:36,763 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,763 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44425', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7637835')
2024-01-06 06:24:36,764 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39035. Reason: nanny-close
2024-01-06 06:24:36,764 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,764 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,764 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35852; closing.
2024-01-06 06:24:36,765 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35838; closing.
2024-01-06 06:24:36,765 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,765 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,765 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,765 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,765 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,766 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,766 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,766 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41337', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7661433')
2024-01-06 06:24:36,766 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35189', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.766536')
2024-01-06 06:24:36,766 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35836; closing.
2024-01-06 06:24:36,767 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:36,767 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,767 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,767 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,768 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:36,767 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35852>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35852>: Stream is closed
2024-01-06 06:24:36,769 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39569', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7695465')
2024-01-06 06:24:36,769 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35824; closing.
2024-01-06 06:24:36,770 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35850; closing.
2024-01-06 06:24:36,770 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39203', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7707474')
2024-01-06 06:24:36,771 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7710788')
2024-01-06 06:24:36,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35870; closing.
2024-01-06 06:24:36,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35854; closing.
2024-01-06 06:24:36,772 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36417', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7719567')
2024-01-06 06:24:36,772 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39035', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522276.7724128')
2024-01-06 06:24:36,772 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:24:37,876 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:24:37,876 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:24:37,877 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:24:37,878 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:24:37,878 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-06 06:24:40,180 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:40,184 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:24:40,188 - distributed.scheduler - INFO - State start
2024-01-06 06:24:40,210 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:40,211 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:24:40,212 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:24:40,212 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:24:40,389 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36731'
2024-01-06 06:24:40,405 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46335'
2024-01-06 06:24:40,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33461'
2024-01-06 06:24:40,428 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45105'
2024-01-06 06:24:40,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38019'
2024-01-06 06:24:40,439 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41607'
2024-01-06 06:24:40,448 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35805'
2024-01-06 06:24:40,456 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39279'
2024-01-06 06:24:40,463 - distributed.scheduler - INFO - Receive client connection: Client-44a57937-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:40,482 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57638
2024-01-06 06:24:42,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,343 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,343 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35839
2024-01-06 06:24:42,343 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35839
2024-01-06 06:24:42,344 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35919
2024-01-06 06:24:42,344 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,344 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,344 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,344 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,344 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wpnmyiv1
2024-01-06 06:24:42,344 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c543e82c-73bd-4c2b-946a-e115663ac112
2024-01-06 06:24:42,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,600 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,601 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41215
2024-01-06 06:24:42,601 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41215
2024-01-06 06:24:42,601 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42897
2024-01-06 06:24:42,601 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,601 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,601 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,601 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,601 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7fn06a74
2024-01-06 06:24:42,601 - distributed.worker - INFO - Starting Worker plugin RMMSetup-afdeb69f-9624-4a41-b8b7-c781f2c15651
2024-01-06 06:24:42,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,603 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38255
2024-01-06 06:24:42,604 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38255
2024-01-06 06:24:42,605 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34601
2024-01-06 06:24:42,605 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,605 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,605 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,605 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,605 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,605 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4phgpjxb
2024-01-06 06:24:42,605 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d257b021-3607-4288-a0b1-3866ea3f86e0
2024-01-06 06:24:42,605 - distributed.worker - INFO - Starting Worker plugin PreImport-ec0dcabd-92cd-414e-ab9c-1ca388c82d7f
2024-01-06 06:24:42,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92af96c9-c80c-4d3e-9fca-63975db30399
2024-01-06 06:24:42,606 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44281
2024-01-06 06:24:42,606 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44281
2024-01-06 06:24:42,606 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40963
2024-01-06 06:24:42,606 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,606 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,606 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,606 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,606 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o54qxx1h
2024-01-06 06:24:42,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21c1d654-29bb-44fc-a71e-ca27e5943398
2024-01-06 06:24:42,606 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,607 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45619
2024-01-06 06:24:42,608 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45619
2024-01-06 06:24:42,608 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41873
2024-01-06 06:24:42,608 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,608 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,608 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,608 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,608 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-92yocn5u
2024-01-06 06:24:42,608 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c47794dc-466e-49bc-a749-1b71010a11f7
2024-01-06 06:24:42,610 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,611 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41943
2024-01-06 06:24:42,612 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41943
2024-01-06 06:24:42,612 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39367
2024-01-06 06:24:42,612 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,612 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,612 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,612 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,612 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0sascu9y
2024-01-06 06:24:42,612 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d249fca6-bfff-4d71-8105-839181b02373
2024-01-06 06:24:42,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,626 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,627 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38247
2024-01-06 06:24:42,627 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38247
2024-01-06 06:24:42,627 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35873
2024-01-06 06:24:42,627 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,627 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,627 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,627 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,627 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7jexlhxx
2024-01-06 06:24:42,627 - distributed.worker - INFO - Starting Worker plugin PreImport-8a7a0d64-3385-441a-b0a3-47a68fc5f08e
2024-01-06 06:24:42,627 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0b7a11d-28d6-424e-9d85-abae56bc04a0
2024-01-06 06:24:42,627 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf21f4f3-38fe-4276-916d-44ba713cc58b
2024-01-06 06:24:42,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:42,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:42,690 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:42,691 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46507
2024-01-06 06:24:42,691 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46507
2024-01-06 06:24:42,691 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34367
2024-01-06 06:24:42,691 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:42,691 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:42,691 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:42,691 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:42,692 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xqy704tf
2024-01-06 06:24:42,692 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4cfeeacb-9ceb-4b92-ae04-8677220ce141
2024-01-06 06:24:43,761 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-17b7aa7c-6115-4cd7-8293-61c029f808bc
2024-01-06 06:24:43,762 - distributed.worker - INFO - Starting Worker plugin PreImport-cc71392a-54cd-446b-aeed-4e4efeb1785e
2024-01-06 06:24:43,763 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:43,804 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35839', status: init, memory: 0, processing: 0>
2024-01-06 06:24:43,807 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35839
2024-01-06 06:24:43,807 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57650
2024-01-06 06:24:43,808 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:43,810 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:43,810 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:43,813 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,237 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e5a20148-de9b-4b42-b12c-7709daba6efe
2024-01-06 06:24:46,238 - distributed.worker - INFO - Starting Worker plugin PreImport-37d4e5b6-37af-47f3-a9eb-f7adc4c74897
2024-01-06 06:24:46,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,271 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41215', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41215
2024-01-06 06:24:46,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57668
2024-01-06 06:24:46,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,275 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,275 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,364 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,389 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-469bd2c9-53ca-4133-9de1-96c5164af608
2024-01-06 06:24:46,390 - distributed.worker - INFO - Starting Worker plugin PreImport-810d0693-f5de-4c75-ae73-551bb03b5443
2024-01-06 06:24:46,390 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38255', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,391 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38255
2024-01-06 06:24:46,391 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57678
2024-01-06 06:24:46,391 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,392 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,393 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,393 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,395 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,398 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd560e55-d179-42cb-b99d-c60ca23ef1e1
2024-01-06 06:24:46,398 - distributed.worker - INFO - Starting Worker plugin PreImport-5ca470fe-f5c7-4611-be07-f69ed254bff1
2024-01-06 06:24:46,399 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,404 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-10bd1718-1ccc-4747-b769-63a34f6900ad
2024-01-06 06:24:46,407 - distributed.worker - INFO - Starting Worker plugin PreImport-15302992-a4f7-4f10-b707-6750a084e15b
2024-01-06 06:24:46,407 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,412 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05f89057-1829-46aa-97df-5a4f799d9b44
2024-01-06 06:24:46,413 - distributed.worker - INFO - Starting Worker plugin PreImport-121b90f3-ef10-49b7-95db-42de63c4f4ce
2024-01-06 06:24:46,413 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,429 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44281', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,429 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44281
2024-01-06 06:24:46,429 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57686
2024-01-06 06:24:46,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,432 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,432 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,434 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41943', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,434 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,434 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41943
2024-01-06 06:24:46,434 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57700
2024-01-06 06:24:46,436 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,437 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45619', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,437 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,437 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45619
2024-01-06 06:24:46,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57690
2024-01-06 06:24:46,438 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46507', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,439 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46507
2024-01-06 06:24:46,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57712
2024-01-06 06:24:46,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,439 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,440 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,440 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,440 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,440 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,440 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,442 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,442 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,448 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38247', status: init, memory: 0, processing: 0>
2024-01-06 06:24:46,448 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38247
2024-01-06 06:24:46,448 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57724
2024-01-06 06:24:46,449 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:46,450 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:46,451 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:46,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:46,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,539 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:46,545 - distributed.scheduler - INFO - Remove client Client-44a57937-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:46,545 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57638; closing.
2024-01-06 06:24:46,545 - distributed.scheduler - INFO - Remove client Client-44a57937-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:46,546 - distributed.scheduler - INFO - Close client connection: Client-44a57937-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:46,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36731'. Reason: nanny-close
2024-01-06 06:24:46,547 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46335'. Reason: nanny-close
2024-01-06 06:24:46,548 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33461'. Reason: nanny-close
2024-01-06 06:24:46,548 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38255. Reason: nanny-close
2024-01-06 06:24:46,548 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45105'. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41943. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38019'. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35839. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41607'. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44281. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35805'. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57678; closing.
2024-01-06 06:24:46,550 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46507. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,550 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39279'. Reason: nanny-close
2024-01-06 06:24:46,551 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38255', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5509882')
2024-01-06 06:24:46,551 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38247. Reason: nanny-close
2024-01-06 06:24:46,551 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:46,551 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,551 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41215. Reason: nanny-close
2024-01-06 06:24:46,552 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,552 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45619. Reason: nanny-close
2024-01-06 06:24:46,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,552 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,553 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57650; closing.
2024-01-06 06:24:46,553 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57700; closing.
2024-01-06 06:24:46,553 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,554 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,554 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,554 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35839', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5543313')
2024-01-06 06:24:46,554 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,554 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,554 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41943', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5547416')
2024-01-06 06:24:46,555 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57686; closing.
2024-01-06 06:24:46,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:46,555 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,555 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57712; closing.
2024-01-06 06:24:46,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44281', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5559154')
2024-01-06 06:24:46,556 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46507', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5562866')
2024-01-06 06:24:46,556 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,556 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57724; closing.
2024-01-06 06:24:46,556 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:46,557 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38247', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5573418')
2024-01-06 06:24:46,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57668; closing.
2024-01-06 06:24:46,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57690; closing.
2024-01-06 06:24:46,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41215', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5582447')
2024-01-06 06:24:46,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522286.5586443')
2024-01-06 06:24:46,558 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:24:47,715 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:24:47,716 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:24:47,717 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:24:47,718 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:24:47,718 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-06 06:24:50,256 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:50,260 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:24:50,264 - distributed.scheduler - INFO - State start
2024-01-06 06:24:50,288 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:50,289 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:24:50,290 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:24:50,290 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:24:50,439 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46371'
2024-01-06 06:24:50,463 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36767'
2024-01-06 06:24:50,481 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35355'
2024-01-06 06:24:50,484 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45891'
2024-01-06 06:24:50,496 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44657'
2024-01-06 06:24:50,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43121'
2024-01-06 06:24:50,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40949'
2024-01-06 06:24:50,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44857'
2024-01-06 06:24:50,915 - distributed.scheduler - INFO - Receive client connection: Client-4a94c723-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:50,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40430
2024-01-06 06:24:52,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,367 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,368 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43749
2024-01-06 06:24:52,368 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43749
2024-01-06 06:24:52,368 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32809
2024-01-06 06:24:52,368 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,368 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,368 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,369 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v5sfcbk1
2024-01-06 06:24:52,369 - distributed.worker - INFO - Starting Worker plugin RMMSetup-05d3938a-9ff5-452f-a087-788c5ed90bd5
2024-01-06 06:24:52,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,389 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,390 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45827
2024-01-06 06:24:52,390 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45827
2024-01-06 06:24:52,390 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32807
2024-01-06 06:24:52,390 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,390 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,390 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,390 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,390 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zb4o31qr
2024-01-06 06:24:52,390 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93dcba07-7201-4259-9fd1-49193cf92c86
2024-01-06 06:24:52,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,408 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,409 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34103
2024-01-06 06:24:52,409 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34103
2024-01-06 06:24:52,409 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40519
2024-01-06 06:24:52,409 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,409 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,409 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,409 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,409 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5gnxk7pg
2024-01-06 06:24:52,409 - distributed.worker - INFO - Starting Worker plugin PreImport-e92cacc9-1fc1-4c83-8658-d6f1d598e103
2024-01-06 06:24:52,410 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-70d5ab81-6ee6-451e-a13d-a6eb0fe30bfd
2024-01-06 06:24:52,410 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ccd32c6-aa08-465a-9b98-631d398c5e5d
2024-01-06 06:24:52,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,426 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,427 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39465
2024-01-06 06:24:52,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39465
2024-01-06 06:24:52,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34059
2024-01-06 06:24:52,428 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,428 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,428 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,428 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qurpqx5x
2024-01-06 06:24:52,428 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5a9e8c5c-2d89-4e48-81b4-4a6a7ab6539b
2024-01-06 06:24:52,428 - distributed.worker - INFO - Starting Worker plugin PreImport-e817430e-72bf-4cd1-94e1-76b9e4f54f7a
2024-01-06 06:24:52,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5f6bd7c3-8dca-4f60-a038-f88bf404ffeb
2024-01-06 06:24:52,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,456 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,456 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43679
2024-01-06 06:24:52,457 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43679
2024-01-06 06:24:52,457 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33359
2024-01-06 06:24:52,457 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,457 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,457 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,457 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,457 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eq8cbij3
2024-01-06 06:24:52,457 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6f26dc5e-188a-4727-b63a-893f1dea05bc
2024-01-06 06:24:52,458 - distributed.worker - INFO - Starting Worker plugin PreImport-decd4564-9b29-484e-ad1c-acf8a589a8ad
2024-01-06 06:24:52,458 - distributed.worker - INFO - Starting Worker plugin RMMSetup-19b6cedc-9668-4aa4-b6ea-d3e9886e94cd
2024-01-06 06:24:52,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,647 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,648 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43883
2024-01-06 06:24:52,648 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43883
2024-01-06 06:24:52,648 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39129
2024-01-06 06:24:52,648 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,648 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,648 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,648 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,648 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pmvupw8u
2024-01-06 06:24:52,649 - distributed.worker - INFO - Starting Worker plugin PreImport-ba3db95f-970b-49fe-a871-1d853473936e
2024-01-06 06:24:52,649 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a9bc8ca0-a293-4880-85fa-e248972f013c
2024-01-06 06:24:52,650 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d9f5e652-fc3f-4553-b0d1-c82cdf42622d
2024-01-06 06:24:52,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:24:52,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:24:52,746 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,747 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37927
2024-01-06 06:24:52,747 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37927
2024-01-06 06:24:52,747 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37125
2024-01-06 06:24:52,747 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,747 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,747 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,747 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,747 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4jju4t41
2024-01-06 06:24:52,748 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df115289-08ca-40d3-ada8-34ab7716e85e
2024-01-06 06:24:52,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:24:52,753 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34347
2024-01-06 06:24:52,753 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34347
2024-01-06 06:24:52,753 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33855
2024-01-06 06:24:52,753 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:24:52,753 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:52,753 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:24:52,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:24:52,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sbd_43hx
2024-01-06 06:24:52,754 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58944063-ffdc-4cbb-ba72-cc1337cbe3c6
2024-01-06 06:24:53,738 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b4959e7-9f9e-4704-b3ed-f19358b0e3a3
2024-01-06 06:24:53,739 - distributed.worker - INFO - Starting Worker plugin PreImport-3e4bbef8-39d9-444a-9766-825b79edc923
2024-01-06 06:24:53,740 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:53,767 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43749', status: init, memory: 0, processing: 0>
2024-01-06 06:24:53,769 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43749
2024-01-06 06:24:53,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40446
2024-01-06 06:24:53,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:53,771 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:53,771 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:53,773 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:54,920 - distributed.worker - INFO - Starting Worker plugin PreImport-38f8d073-9dad-4a93-bfde-35a7d2bebf04
2024-01-06 06:24:54,921 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27f3a5f5-363b-477b-b02f-794ba4539098
2024-01-06 06:24:54,922 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:54,954 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:54,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:54,965 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45827', status: init, memory: 0, processing: 0>
2024-01-06 06:24:54,966 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45827
2024-01-06 06:24:54,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40468
2024-01-06 06:24:54,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:54,967 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:54,968 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:54,969 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:54,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:54,999 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34103', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,000 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34103
2024-01-06 06:24:55,000 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40484
2024-01-06 06:24:55,001 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,002 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39465', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,003 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,003 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,003 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39465
2024-01-06 06:24:55,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40486
2024-01-06 06:24:55,005 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,005 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,006 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,006 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,008 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,015 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af596e32-4b9c-4563-87d9-b4403d33733a
2024-01-06 06:24:55,016 - distributed.worker - INFO - Starting Worker plugin PreImport-07acfd98-cfa3-4004-91b1-9aaa07b3e985
2024-01-06 06:24:55,017 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,020 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43679', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,021 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43679
2024-01-06 06:24:55,021 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40496
2024-01-06 06:24:55,024 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,026 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,026 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,030 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,036 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9401ba21-a783-4278-9aae-37bc7c788cca
2024-01-06 06:24:55,037 - distributed.worker - INFO - Starting Worker plugin PreImport-3065e776-bba8-499f-a3cd-ebb2aa145707
2024-01-06 06:24:55,038 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,057 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43883', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,058 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43883
2024-01-06 06:24:55,058 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40498
2024-01-06 06:24:55,059 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,061 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,061 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34347', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,062 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34347
2024-01-06 06:24:55,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40512
2024-01-06 06:24:55,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,065 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,075 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37927', status: init, memory: 0, processing: 0>
2024-01-06 06:24:55,076 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37927
2024-01-06 06:24:55,076 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40518
2024-01-06 06:24:55,077 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:24:55,078 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:24:55,078 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:24:55,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:24:55,153 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,153 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,153 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,153 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,154 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,154 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,154 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,154 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,166 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,167 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:24:55,175 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:24:55,177 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:24:55,179 - distributed.scheduler - INFO - Remove client Client-4a94c723-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:55,180 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40430; closing.
2024-01-06 06:24:55,180 - distributed.scheduler - INFO - Remove client Client-4a94c723-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:55,181 - distributed.scheduler - INFO - Close client connection: Client-4a94c723-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:24:55,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46371'. Reason: nanny-close
2024-01-06 06:24:55,182 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,183 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36767'. Reason: nanny-close
2024-01-06 06:24:55,183 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,183 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35355'. Reason: nanny-close
2024-01-06 06:24:55,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45827. Reason: nanny-close
2024-01-06 06:24:55,183 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,184 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45891'. Reason: nanny-close
2024-01-06 06:24:55,184 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34103. Reason: nanny-close
2024-01-06 06:24:55,184 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,184 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44657'. Reason: nanny-close
2024-01-06 06:24:55,184 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43883. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43121'. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34347. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40949'. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40468; closing.
2024-01-06 06:24:55,185 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43749. Reason: nanny-close
2024-01-06 06:24:55,185 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,185 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,186 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1859815')
2024-01-06 06:24:55,186 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44857'. Reason: nanny-close
2024-01-06 06:24:55,186 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39465. Reason: nanny-close
2024-01-06 06:24:55,186 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,186 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:24:55,186 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43679. Reason: nanny-close
2024-01-06 06:24:55,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,187 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,187 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37927. Reason: nanny-close
2024-01-06 06:24:55,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,187 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40498; closing.
2024-01-06 06:24:55,188 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40484; closing.
2024-01-06 06:24:55,188 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,189 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,189 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,189 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1892095')
2024-01-06 06:24:55,189 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,189 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34103', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1896026')
2024-01-06 06:24:55,189 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,189 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40512; closing.
2024-01-06 06:24:55,190 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40446; closing.
2024-01-06 06:24:55,190 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,190 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34347', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.190674')
2024-01-06 06:24:55,190 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:24:55,191 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43749', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1909578')
2024-01-06 06:24:55,191 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40486; closing.
2024-01-06 06:24:55,191 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,192 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39465', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1921816')
2024-01-06 06:24:55,192 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40496; closing.
2024-01-06 06:24:55,192 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40518; closing.
2024-01-06 06:24:55,193 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43679', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1931803')
2024-01-06 06:24:55,193 - distributed.nanny - INFO - Worker closed
2024-01-06 06:24:55,193 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37927', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522295.1935956')
2024-01-06 06:24:55,193 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:24:56,298 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:24:56,299 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:24:56,299 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:24:56,300 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:24:56,301 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-06 06:24:58,634 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:58,638 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:24:58,642 - distributed.scheduler - INFO - State start
2024-01-06 06:24:58,667 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:24:58,668 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:24:58,668 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:24:58,669 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:24:58,922 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42029'
2024-01-06 06:24:58,937 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45963'
2024-01-06 06:24:58,945 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42423'
2024-01-06 06:24:58,959 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39177'
2024-01-06 06:24:58,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46283'
2024-01-06 06:24:58,971 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44393'
2024-01-06 06:24:58,979 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40873'
2024-01-06 06:24:58,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42083'
2024-01-06 06:25:01,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,016 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,018 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46193
2024-01-06 06:25:01,018 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46193
2024-01-06 06:25:01,018 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37645
2024-01-06 06:25:01,018 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,018 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,018 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,018 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,018 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-17lpselg
2024-01-06 06:25:01,018 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4db68c02-2624-46a8-8b5c-4ceac5b1c634
2024-01-06 06:25:01,020 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,021 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36435
2024-01-06 06:25:01,021 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36435
2024-01-06 06:25:01,021 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36017
2024-01-06 06:25:01,021 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,021 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,021 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,021 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,022 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z237tww4
2024-01-06 06:25:01,022 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5acc4dd9-c564-41c1-a298-58885992a972
2024-01-06 06:25:01,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,029 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,030 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38037
2024-01-06 06:25:01,030 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38037
2024-01-06 06:25:01,030 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45705
2024-01-06 06:25:01,030 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,030 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,030 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,030 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,030 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b3l8p7cd
2024-01-06 06:25:01,030 - distributed.worker - INFO - Starting Worker plugin RMMSetup-38083438-8ffa-4e5a-82b9-9b5c6a55fcce
2024-01-06 06:25:01,031 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38119
2024-01-06 06:25:01,031 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38119
2024-01-06 06:25:01,031 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43917
2024-01-06 06:25:01,031 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,031 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,031 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,031 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,031 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,031 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qlfogkzf
2024-01-06 06:25:01,031 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4218dd0e-e45a-4020-b525-de417f261c94
2024-01-06 06:25:01,032 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35595
2024-01-06 06:25:01,033 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35595
2024-01-06 06:25:01,033 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33657
2024-01-06 06:25:01,033 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,033 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,033 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,033 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,033 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qr442v67
2024-01-06 06:25:01,033 - distributed.worker - INFO - Starting Worker plugin PreImport-49a56910-7a1a-4078-b758-fe91e784561c
2024-01-06 06:25:01,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-72995d28-6c2b-47c5-a19a-eca0651090ad
2024-01-06 06:25:01,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd5895b4-b82b-406b-bb43-ecc7043a4176
2024-01-06 06:25:01,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,065 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,066 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40693
2024-01-06 06:25:01,066 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40693
2024-01-06 06:25:01,067 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35941
2024-01-06 06:25:01,067 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,067 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,067 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,067 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,067 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ntj0o7m9
2024-01-06 06:25:01,067 - distributed.worker - INFO - Starting Worker plugin PreImport-554e4ff3-7517-40d7-8cd8-7ef85fbd21cd
2024-01-06 06:25:01,067 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7ac8685f-f40b-4c44-ad44-f0bbcdfec1b0
2024-01-06 06:25:01,068 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f3589d70-bf61-4a98-af93-27e695d01325
2024-01-06 06:25:01,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,081 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35317
2024-01-06 06:25:01,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35317
2024-01-06 06:25:01,082 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40969
2024-01-06 06:25:01,082 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,082 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,082 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,082 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,082 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3pnzq3u4
2024-01-06 06:25:01,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c1eccbcc-91ad-4285-8d4c-1c2b310fd782
2024-01-06 06:25:01,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:01,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:01,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:01,129 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44073
2024-01-06 06:25:01,129 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44073
2024-01-06 06:25:01,129 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44965
2024-01-06 06:25:01,129 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:01,129 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:01,129 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:01,129 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:01,129 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r6zhww7j
2024-01-06 06:25:01,130 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b8bc13f8-dd7f-4adc-bef7-f3aa75dabb9b
2024-01-06 06:25:02,381 - distributed.scheduler - INFO - Receive client connection: Client-4fae5b6c-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:02,396 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38720
2024-01-06 06:25:05,001 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,023 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7bae0d8a-f9d2-453d-be3f-af37d452dd04
2024-01-06 06:25:05,024 - distributed.worker - INFO - Starting Worker plugin PreImport-9c9ae9b5-f0b0-449f-8564-bef0b6da31ad
2024-01-06 06:25:05,026 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,031 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35595', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,032 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35595
2024-01-06 06:25:05,032 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38742
2024-01-06 06:25:05,032 - distributed.worker - INFO - Starting Worker plugin PreImport-9b9b6600-a8ba-4238-ba56-f35d098ebe5f
2024-01-06 06:25:05,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e3f0623-322e-4f16-9d2b-0e10846f0d20
2024-01-06 06:25:05,033 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,033 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,034 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,034 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,036 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,052 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-59a4e851-bcce-43be-90bf-d0661d8e1a48
2024-01-06 06:25:05,052 - distributed.worker - INFO - Starting Worker plugin PreImport-b19e9e60-e837-454c-9b64-ee0a24b230c3
2024-01-06 06:25:05,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,057 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd6ace5b-add2-4245-a4f5-e9e702803702
2024-01-06 06:25:05,057 - distributed.worker - INFO - Starting Worker plugin PreImport-b48aa38e-4a3a-4473-bcac-3ccde30d24c7
2024-01-06 06:25:05,058 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38037', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,059 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,059 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38037
2024-01-06 06:25:05,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38764
2024-01-06 06:25:05,060 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46193', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,061 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46193
2024-01-06 06:25:05,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38754
2024-01-06 06:25:05,061 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,061 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,063 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,070 - distributed.worker - INFO - Starting Worker plugin PreImport-e3bec883-2c4f-4371-a326-25154a63171f
2024-01-06 06:25:05,071 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c7e1349-5567-4107-bfb9-ed550d17b35f
2024-01-06 06:25:05,071 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,072 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f79033de-96dd-4368-b4c8-f2dc98447e89
2024-01-06 06:25:05,074 - distributed.worker - INFO - Starting Worker plugin PreImport-1a643dc9-b870-40fd-b316-cda9d6f9af4b
2024-01-06 06:25:05,074 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,075 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,076 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36435', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,077 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36435
2024-01-06 06:25:05,077 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38780
2024-01-06 06:25:05,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,079 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,079 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,080 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,095 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38119', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,095 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38119
2024-01-06 06:25:05,095 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38794
2024-01-06 06:25:05,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,098 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,098 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,100 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35317', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,100 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35317
2024-01-06 06:25:05,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38808
2024-01-06 06:25:05,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,102 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,104 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,112 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44073', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,112 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44073
2024-01-06 06:25:05,112 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38816
2024-01-06 06:25:05,113 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40693', status: init, memory: 0, processing: 0>
2024-01-06 06:25:05,114 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40693
2024-01-06 06:25:05,114 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38832
2024-01-06 06:25:05,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,115 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,115 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,115 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:05,116 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:05,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:05,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:05,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,223 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,224 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,224 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,224 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,224 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,236 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,237 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,237 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:05,245 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,247 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:05,249 - distributed.scheduler - INFO - Remove client Client-4fae5b6c-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:05,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38720; closing.
2024-01-06 06:25:05,250 - distributed.scheduler - INFO - Remove client Client-4fae5b6c-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:05,250 - distributed.scheduler - INFO - Close client connection: Client-4fae5b6c-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:05,251 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42029'. Reason: nanny-close
2024-01-06 06:25:05,252 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,252 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45963'. Reason: nanny-close
2024-01-06 06:25:05,253 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,253 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42423'. Reason: nanny-close
2024-01-06 06:25:05,253 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46193. Reason: nanny-close
2024-01-06 06:25:05,253 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,254 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39177'. Reason: nanny-close
2024-01-06 06:25:05,254 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,254 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38119. Reason: nanny-close
2024-01-06 06:25:05,254 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46283'. Reason: nanny-close
2024-01-06 06:25:05,254 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36435. Reason: nanny-close
2024-01-06 06:25:05,255 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,255 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44393'. Reason: nanny-close
2024-01-06 06:25:05,255 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,255 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35595. Reason: nanny-close
2024-01-06 06:25:05,255 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40873'. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42083'. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40693. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38754; closing.
2024-01-06 06:25:05,256 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,256 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,256 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46193', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.256708')
2024-01-06 06:25:05,256 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38037. Reason: nanny-close
2024-01-06 06:25:05,256 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44073. Reason: nanny-close
2024-01-06 06:25:05,257 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35317. Reason: nanny-close
2024-01-06 06:25:05,257 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,257 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38780; closing.
2024-01-06 06:25:05,257 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,258 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,258 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,258 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36435', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.2587192')
2024-01-06 06:25:05,259 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,259 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,259 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,259 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,259 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38742; closing.
2024-01-06 06:25:05,260 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38794; closing.
2024-01-06 06:25:05,260 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,260 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,260 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:05,260 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35595', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.260701')
2024-01-06 06:25:05,261 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38119', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.261076')
2024-01-06 06:25:05,261 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38832; closing.
2024-01-06 06:25:05,261 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,261 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38764; closing.
2024-01-06 06:25:05,262 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,262 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40693', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.2622578')
2024-01-06 06:25:05,262 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:05,262 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38037', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.2626462')
2024-01-06 06:25:05,263 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38816; closing.
2024-01-06 06:25:05,263 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38808; closing.
2024-01-06 06:25:05,263 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44073', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.2636902')
2024-01-06 06:25:05,264 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35317', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522305.2640643')
2024-01-06 06:25:05,264 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:06,469 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:06,470 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:06,471 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:06,472 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:06,472 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-06 06:25:08,966 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:08,970 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:08,974 - distributed.scheduler - INFO - State start
2024-01-06 06:25:08,996 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:08,998 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:08,998 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:08,999 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:09,083 - distributed.scheduler - INFO - Receive client connection: Client-55babbac-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:09,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38922
2024-01-06 06:25:09,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43401'
2024-01-06 06:25:09,136 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35597'
2024-01-06 06:25:09,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43027'
2024-01-06 06:25:09,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38123'
2024-01-06 06:25:09,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40157'
2024-01-06 06:25:09,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37699'
2024-01-06 06:25:09,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44569'
2024-01-06 06:25:09,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46155'
2024-01-06 06:25:11,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,035 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,036 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38707
2024-01-06 06:25:11,037 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38707
2024-01-06 06:25:11,037 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40669
2024-01-06 06:25:11,037 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,037 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,037 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,037 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,037 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rsz39nv7
2024-01-06 06:25:11,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,038 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6c6bd90-88bf-4a0a-8054-aa179b2fcda1
2024-01-06 06:25:11,039 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,040 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35237
2024-01-06 06:25:11,040 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35237
2024-01-06 06:25:11,040 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37475
2024-01-06 06:25:11,040 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,040 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,040 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,040 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,040 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ye_f8ny
2024-01-06 06:25:11,041 - distributed.worker - INFO - Starting Worker plugin PreImport-4af09200-174b-448d-acf7-56a510a44d24
2024-01-06 06:25:11,041 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5d0eb67-d3d9-4e22-8e58-0fb3be4027ca
2024-01-06 06:25:11,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,042 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36681
2024-01-06 06:25:11,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36681
2024-01-06 06:25:11,043 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37741
2024-01-06 06:25:11,043 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,043 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,043 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-clw_yya9
2024-01-06 06:25:11,043 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b0b2e77-0a82-4635-8611-ac3223404b23
2024-01-06 06:25:11,052 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bfc34583-8bcb-4254-bfec-6e84a5faaa87
2024-01-06 06:25:11,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,087 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,088 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37103
2024-01-06 06:25:11,088 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37103
2024-01-06 06:25:11,088 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34329
2024-01-06 06:25:11,088 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,088 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,088 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,088 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n93mdykj
2024-01-06 06:25:11,088 - distributed.worker - INFO - Starting Worker plugin RMMSetup-533f2802-0085-48b9-82cc-eaf8293dbdff
2024-01-06 06:25:11,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44325
2024-01-06 06:25:11,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44325
2024-01-06 06:25:11,093 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34895
2024-01-06 06:25:11,093 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,093 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,093 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,093 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,093 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rcsortgi
2024-01-06 06:25:11,094 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38619
2024-01-06 06:25:11,094 - distributed.worker - INFO - Starting Worker plugin PreImport-5b7e9b6d-a393-4db2-a166-eaff4b3c07ab
2024-01-06 06:25:11,094 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38619
2024-01-06 06:25:11,094 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3924c58-af17-468e-b7d6-ba4f759a49d2
2024-01-06 06:25:11,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40603
2024-01-06 06:25:11,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0bb5127a-7b22-4931-b9ad-844aef5c9991
2024-01-06 06:25:11,094 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,094 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sb94o_my
2024-01-06 06:25:11,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eff8fd9d-0191-4fa0-9d21-37158442e6d5
2024-01-06 06:25:11,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,110 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,110 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45883
2024-01-06 06:25:11,110 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45883
2024-01-06 06:25:11,111 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37135
2024-01-06 06:25:11,111 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,111 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,111 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,111 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,111 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aw11o0qc
2024-01-06 06:25:11,111 - distributed.worker - INFO - Starting Worker plugin RMMSetup-615efd33-f65a-4d5c-aa0d-4751aed4eda3
2024-01-06 06:25:11,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:11,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:11,146 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:11,147 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45237
2024-01-06 06:25:11,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45237
2024-01-06 06:25:11,147 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45323
2024-01-06 06:25:11,147 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:11,147 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:11,147 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:11,147 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:11,147 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s2_2o9cy
2024-01-06 06:25:11,148 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c60e069-9870-4586-8480-36c4cfeccb54
2024-01-06 06:25:13,061 - distributed.worker - INFO - Starting Worker plugin PreImport-3bb70968-ac83-4fb5-856f-07a13d63a6fb
2024-01-06 06:25:13,062 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd0d646c-79cb-4ca5-b133-d61b99617d25
2024-01-06 06:25:13,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,089 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c9a32d2a-05ae-46f9-9fa1-6cda71da189f
2024-01-06 06:25:13,090 - distributed.worker - INFO - Starting Worker plugin PreImport-993b11d7-0d31-4b8b-9676-6a3b8f58c592
2024-01-06 06:25:13,091 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,099 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36681', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,100 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36681
2024-01-06 06:25:13,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52636
2024-01-06 06:25:13,101 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,103 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,105 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,122 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38707', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,123 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38707
2024-01-06 06:25:13,123 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52642
2024-01-06 06:25:13,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,125 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,125 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,127 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,186 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,222 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35237', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,223 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35237
2024-01-06 06:25:13,223 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52652
2024-01-06 06:25:13,224 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,226 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,226 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,231 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,244 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f0b325f9-b9bb-4d01-b6d2-58a24083e743
2024-01-06 06:25:13,244 - distributed.worker - INFO - Starting Worker plugin PreImport-626656f2-f5bd-48db-a41f-99e19188ec1b
2024-01-06 06:25:13,245 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,257 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44325', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,258 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44325
2024-01-06 06:25:13,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52662
2024-01-06 06:25:13,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,260 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,260 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,271 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38619', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38619
2024-01-06 06:25:13,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52676
2024-01-06 06:25:13,273 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,274 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,402 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-43e0d5dd-ff58-42f2-843f-90bd315cd509
2024-01-06 06:25:13,403 - distributed.worker - INFO - Starting Worker plugin PreImport-27bc670e-da53-4aeb-a293-0de4ab0e5f8b
2024-01-06 06:25:13,404 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,409 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-839e6746-b300-469c-82e4-bea092585b41
2024-01-06 06:25:13,410 - distributed.worker - INFO - Starting Worker plugin PreImport-7f42cc98-6353-435d-8b50-f96725094031
2024-01-06 06:25:13,411 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,432 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77c9b8a5-488d-4a3c-850b-a2aa37f11ea8
2024-01-06 06:25:13,433 - distributed.worker - INFO - Starting Worker plugin PreImport-93d4e6f4-7391-463f-9a8a-d4cac8dbc87c
2024-01-06 06:25:13,433 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,439 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37103', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,440 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37103
2024-01-06 06:25:13,440 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52678
2024-01-06 06:25:13,442 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,443 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,443 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,444 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,447 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45883', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,447 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45883
2024-01-06 06:25:13,448 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52682
2024-01-06 06:25:13,449 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,450 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,450 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,453 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,457 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45237', status: init, memory: 0, processing: 0>
2024-01-06 06:25:13,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45237
2024-01-06 06:25:13,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52684
2024-01-06 06:25:13,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:13,459 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:13,459 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:13,460 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:13,537 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,537 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,537 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,537 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,538 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:13,543 - distributed.scheduler - INFO - Remove client Client-55babbac-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:13,543 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38922; closing.
2024-01-06 06:25:13,543 - distributed.scheduler - INFO - Remove client Client-55babbac-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:13,544 - distributed.scheduler - INFO - Close client connection: Client-55babbac-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:13,545 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43401'. Reason: nanny-close
2024-01-06 06:25:13,545 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35597'. Reason: nanny-close
2024-01-06 06:25:13,546 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43027'. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36681. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38123'. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35237. Reason: nanny-close
2024-01-06 06:25:13,547 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40157'. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44325. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37699'. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45237. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44569'. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37103. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46155'. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45883. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:13,549 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,549 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52636; closing.
2024-01-06 06:25:13,549 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38619. Reason: nanny-close
2024-01-06 06:25:13,550 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36681', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5499623')
2024-01-06 06:25:13,550 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,550 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,550 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38707. Reason: nanny-close
2024-01-06 06:25:13,550 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52662; closing.
2024-01-06 06:25:13,551 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44325', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5511765')
2024-01-06 06:25:13,551 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,551 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,551 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,551 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,552 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,552 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52652; closing.
2024-01-06 06:25:13,552 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52684; closing.
2024-01-06 06:25:13,553 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,553 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:13,554 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,554 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,553 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52662>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-06 06:25:13,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35237', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5555925')
2024-01-06 06:25:13,555 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:13,556 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52678; closing.
2024-01-06 06:25:13,556 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45237', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5562792')
2024-01-06 06:25:13,556 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52682; closing.
2024-01-06 06:25:13,557 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37103', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5573263')
2024-01-06 06:25:13,557 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.557644')
2024-01-06 06:25:13,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52676; closing.
2024-01-06 06:25:13,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52642; closing.
2024-01-06 06:25:13,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.558669')
2024-01-06 06:25:13,559 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522313.5589817')
2024-01-06 06:25:13,559 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:14,661 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:14,661 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:14,662 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:14,663 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:14,663 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-06 06:25:17,083 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:17,087 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:17,091 - distributed.scheduler - INFO - State start
2024-01-06 06:25:17,217 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:17,218 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:17,219 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:17,219 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:17,324 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40089'
2024-01-06 06:25:18,773 - distributed.scheduler - INFO - Receive client connection: Client-5a9c7309-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:18,788 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52788
2024-01-06 06:25:19,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:19,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:19,764 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:19,765 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45589
2024-01-06 06:25:19,765 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45589
2024-01-06 06:25:19,765 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-06 06:25:19,765 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:19,765 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:19,766 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:19,766 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:25:19,766 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mn9wu7bx
2024-01-06 06:25:19,766 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c4fa918-7e73-4e4e-bbe0-fd6f2e19e5b4
2024-01-06 06:25:19,766 - distributed.worker - INFO - Starting Worker plugin PreImport-0c3e189e-4070-4284-bfaa-f49d9bb6f7f3
2024-01-06 06:25:19,766 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fbd6ff0e-5b42-4d66-939f-45b8f0b1d1ea
2024-01-06 06:25:19,767 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:19,823 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45589', status: init, memory: 0, processing: 0>
2024-01-06 06:25:19,824 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45589
2024-01-06 06:25:19,824 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52812
2024-01-06 06:25:19,825 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:19,826 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:19,826 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:19,827 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:19,913 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:19,915 - distributed.scheduler - INFO - Remove client Client-5a9c7309-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:19,916 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52788; closing.
2024-01-06 06:25:19,916 - distributed.scheduler - INFO - Remove client Client-5a9c7309-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:19,916 - distributed.scheduler - INFO - Close client connection: Client-5a9c7309-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:19,917 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40089'. Reason: nanny-close
2024-01-06 06:25:19,917 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:19,918 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45589. Reason: nanny-close
2024-01-06 06:25:19,920 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:19,920 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52812; closing.
2024-01-06 06:25:19,920 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45589', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522319.9207778')
2024-01-06 06:25:19,921 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:19,921 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:20,482 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:20,483 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:20,483 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:20,484 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:20,484 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-06 06:25:24,906 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:24,911 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:24,915 - distributed.scheduler - INFO - State start
2024-01-06 06:25:24,938 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:24,939 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:24,942 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:24,943 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:24,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44423'
2024-01-06 06:25:25,759 - distributed.scheduler - INFO - Receive client connection: Client-5f331c12-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:25,776 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59562
2024-01-06 06:25:26,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:26,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:27,345 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:27,346 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38987
2024-01-06 06:25:27,346 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38987
2024-01-06 06:25:27,346 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44593
2024-01-06 06:25:27,346 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:27,346 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:27,346 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:27,346 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:25:27,346 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w71l0f_2
2024-01-06 06:25:27,347 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-024a01f7-d448-422e-9bc2-85b71a5b21d5
2024-01-06 06:25:27,347 - distributed.worker - INFO - Starting Worker plugin PreImport-d0b4f95d-0268-4710-9fd7-85739effc997
2024-01-06 06:25:27,349 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb70153f-d58c-4e5c-a081-53f705f17423
2024-01-06 06:25:27,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:27,414 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38987', status: init, memory: 0, processing: 0>
2024-01-06 06:25:27,415 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38987
2024-01-06 06:25:27,415 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59570
2024-01-06 06:25:27,416 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:27,417 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:27,417 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:27,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:27,514 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:27,517 - distributed.scheduler - INFO - Remove client Client-5f331c12-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:27,517 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59562; closing.
2024-01-06 06:25:27,517 - distributed.scheduler - INFO - Remove client Client-5f331c12-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:27,517 - distributed.scheduler - INFO - Close client connection: Client-5f331c12-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:27,518 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44423'. Reason: nanny-close
2024-01-06 06:25:27,519 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:27,520 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38987. Reason: nanny-close
2024-01-06 06:25:27,522 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59570; closing.
2024-01-06 06:25:27,522 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:27,522 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38987', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522327.5228872')
2024-01-06 06:25:27,523 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:27,524 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:28,234 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:28,235 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:28,235 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:28,236 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:28,237 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-06 06:25:30,448 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:30,453 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:30,456 - distributed.scheduler - INFO - State start
2024-01-06 06:25:30,480 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:30,481 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:30,481 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:30,482 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:33,049 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:36916'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36916>: Stream is closed
2024-01-06 06:25:33,359 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:33,359 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:33,360 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:33,361 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:33,361 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-06 06:25:35,577 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:35,583 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:35,586 - distributed.scheduler - INFO - State start
2024-01-06 06:25:35,609 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:35,609 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-06 06:25:35,610 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:35,610 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:35,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40527'
2024-01-06 06:25:36,133 - distributed.scheduler - INFO - Receive client connection: Client-662d0204-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:25:36,146 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50280
2024-01-06 06:25:37,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:37,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:37,320 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:37,321 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38063
2024-01-06 06:25:37,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38063
2024-01-06 06:25:37,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36229
2024-01-06 06:25:37,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:25:37,321 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:37,321 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:37,321 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:25:37,321 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-5qn612xx
2024-01-06 06:25:37,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13c28064-636a-4551-9b76-f8dcfce29397
2024-01-06 06:25:37,322 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-63401455-30f8-40b1-a135-faf68514613c
2024-01-06 06:25:37,322 - distributed.worker - INFO - Starting Worker plugin PreImport-a6cbdabe-7479-4710-8c85-66609e7a9050
2024-01-06 06:25:37,322 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:37,381 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38063', status: init, memory: 0, processing: 0>
2024-01-06 06:25:37,382 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38063
2024-01-06 06:25:37,382 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50340
2024-01-06 06:25:37,383 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:37,384 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:25:37,384 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:37,385 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:25:37,504 - distributed.scheduler - INFO - Receive client connection: Client-65a50038-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:37,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50354
2024-01-06 06:25:37,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:37,518 - distributed.scheduler - INFO - Remove client Client-65a50038-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:37,518 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50354; closing.
2024-01-06 06:25:37,518 - distributed.scheduler - INFO - Remove client Client-65a50038-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:37,518 - distributed.scheduler - INFO - Close client connection: Client-65a50038-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:37,519 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40527'. Reason: nanny-close
2024-01-06 06:25:37,520 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:37,521 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38063. Reason: nanny-close
2024-01-06 06:25:37,523 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50340; closing.
2024-01-06 06:25:37,523 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:25:37,523 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38063', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522337.5234451')
2024-01-06 06:25:37,523 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:37,524 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:38,235 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:38,236 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:38,236 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:38,238 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-06 06:25:38,239 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-06 06:25:40,438 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:40,442 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:40,445 - distributed.scheduler - INFO - State start
2024-01-06 06:25:40,467 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:40,468 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:40,468 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:40,469 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:40,520 - distributed.scheduler - INFO - Receive client connection: Client-6892403a-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:40,536 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45474
2024-01-06 06:25:40,654 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38371'
2024-01-06 06:25:40,670 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37749'
2024-01-06 06:25:40,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44837'
2024-01-06 06:25:40,691 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45327'
2024-01-06 06:25:40,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38117'
2024-01-06 06:25:40,702 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37191'
2024-01-06 06:25:40,712 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41319'
2024-01-06 06:25:40,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34645'
2024-01-06 06:25:42,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,503 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,503 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43405
2024-01-06 06:25:42,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43405
2024-01-06 06:25:42,504 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37837
2024-01-06 06:25:42,504 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,504 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,504 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,504 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0zl_q1dt
2024-01-06 06:25:42,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2a7fbf9c-332b-4a82-a41a-7c6ea43fac24
2024-01-06 06:25:42,509 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,510 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44953
2024-01-06 06:25:42,510 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44953
2024-01-06 06:25:42,510 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42031
2024-01-06 06:25:42,510 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,510 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,510 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,510 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,510 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w2v8mhth
2024-01-06 06:25:42,510 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13ff5703-0d7f-4c96-a7dd-6614ad15db26
2024-01-06 06:25:42,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,545 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,546 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46229
2024-01-06 06:25:42,546 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46229
2024-01-06 06:25:42,546 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36345
2024-01-06 06:25:42,546 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,546 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,546 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,546 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_1s0o9yn
2024-01-06 06:25:42,546 - distributed.worker - INFO - Starting Worker plugin PreImport-8e057272-4180-4b59-800a-5ed249a91f28
2024-01-06 06:25:42,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46431
2024-01-06 06:25:42,547 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46431
2024-01-06 06:25:42,547 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eb95c18a-ed93-47a0-87f0-c31d951b8d56
2024-01-06 06:25:42,547 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45489
2024-01-06 06:25:42,547 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,547 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,547 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,547 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,547 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jizhgl0q
2024-01-06 06:25:42,547 - distributed.worker - INFO - Starting Worker plugin PreImport-cdd18278-bb2d-4c70-a997-b7b46f783e9f
2024-01-06 06:25:42,547 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b88f585-bf10-4e32-a55d-0dca877e378c
2024-01-06 06:25:42,547 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6b250bf0-23e4-4c02-a894-a3f1016408b7
2024-01-06 06:25:42,547 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c79d6ab9-ad71-41d3-acf6-391d96e37609
2024-01-06 06:25:42,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,555 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,556 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42975
2024-01-06 06:25:42,556 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42975
2024-01-06 06:25:42,556 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42967
2024-01-06 06:25:42,556 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,556 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,556 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,556 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,556 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tov0jqkq
2024-01-06 06:25:42,556 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65c8e3ce-57f8-4ceb-b2f9-b030da293396
2024-01-06 06:25:42,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,616 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,616 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35445
2024-01-06 06:25:42,616 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35445
2024-01-06 06:25:42,617 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38767
2024-01-06 06:25:42,617 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,617 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,617 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,617 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,617 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tmsfk1_y
2024-01-06 06:25:42,617 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63a85d3f-a820-4dc5-b257-a03fc7491aec
2024-01-06 06:25:42,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,805 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,806 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41607
2024-01-06 06:25:42,807 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41607
2024-01-06 06:25:42,807 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40019
2024-01-06 06:25:42,807 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,807 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,807 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,807 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xgj3vvw4
2024-01-06 06:25:42,807 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c1acdc4a-2d7c-4755-b260-746a04cb168b
2024-01-06 06:25:42,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:42,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:42,812 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:42,813 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33737
2024-01-06 06:25:42,813 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33737
2024-01-06 06:25:42,814 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42317
2024-01-06 06:25:42,814 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:42,814 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:42,814 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:42,814 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:25:42,814 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mvamovdh
2024-01-06 06:25:42,814 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3c2776b4-dc10-4816-ac19-9092f77d7ce3
2024-01-06 06:25:43,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b2e3e4b2-49d5-4ef8-aa13-ecf4b3fda06c
2024-01-06 06:25:43,809 - distributed.worker - INFO - Starting Worker plugin PreImport-6be24907-f980-4cd0-8243-936574422e4c
2024-01-06 06:25:43,809 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:43,832 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43405', status: init, memory: 0, processing: 0>
2024-01-06 06:25:43,833 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43405
2024-01-06 06:25:43,833 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45580
2024-01-06 06:25:43,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:43,835 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:43,835 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:43,836 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,489 - distributed.worker - INFO - Starting Worker plugin PreImport-ee53a2f5-7686-4bd5-a13d-fb84a5caaa8b
2024-01-06 06:25:44,492 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69c8e8d4-4536-4492-baba-22a0283bde0d
2024-01-06 06:25:44,493 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,523 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44953', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,524 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44953
2024-01-06 06:25:44,524 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45584
2024-01-06 06:25:44,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,526 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,526 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,528 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,559 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,581 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46229', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,582 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46229
2024-01-06 06:25:44,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45590
2024-01-06 06:25:44,583 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46431', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,583 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46431
2024-01-06 06:25:44,583 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45598
2024-01-06 06:25:44,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,585 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,585 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,585 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,585 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,600 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2728a0e3-6606-45a2-9db3-36c68f9ba5f2
2024-01-06 06:25:44,601 - distributed.worker - INFO - Starting Worker plugin PreImport-4e3da2b0-9436-41a8-8bdc-ab7c58859816
2024-01-06 06:25:44,602 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,625 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42975', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,625 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42975
2024-01-06 06:25:44,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45608
2024-01-06 06:25:44,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,627 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,628 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,628 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-160a42bd-551c-41d9-93c0-94d7f4c7ebb6
2024-01-06 06:25:44,630 - distributed.worker - INFO - Starting Worker plugin PreImport-6e47b326-ec85-4cc0-a872-2e3f1419a637
2024-01-06 06:25:44,631 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,641 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee25a7db-8602-476c-a924-c3d2589e3457
2024-01-06 06:25:44,642 - distributed.worker - INFO - Starting Worker plugin PreImport-b31c7879-d9d5-4751-8ca2-1a50e0068090
2024-01-06 06:25:44,642 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,650 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-123cbe75-b3ef-48b0-9a38-c2f651922af8
2024-01-06 06:25:44,651 - distributed.worker - INFO - Starting Worker plugin PreImport-34a3af30-408a-48be-b23f-a54f892efd4a
2024-01-06 06:25:44,652 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,656 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33737', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,656 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33737
2024-01-06 06:25:44,656 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45614
2024-01-06 06:25:44,657 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,658 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,659 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,660 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,666 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35445', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,666 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35445
2024-01-06 06:25:44,666 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45624
2024-01-06 06:25:44,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,668 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,668 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,669 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,683 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41607', status: init, memory: 0, processing: 0>
2024-01-06 06:25:44,683 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41607
2024-01-06 06:25:44,684 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45638
2024-01-06 06:25:44,685 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:44,686 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:44,686 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:44,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:44,696 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,696 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,696 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,696 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,696 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,697 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,697 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,697 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:25:44,710 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,710 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,710 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,710 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,710 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,711 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,711 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,711 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:44,715 - distributed.scheduler - INFO - Remove client Client-6892403a-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:44,715 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45474; closing.
2024-01-06 06:25:44,715 - distributed.scheduler - INFO - Remove client Client-6892403a-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:44,716 - distributed.scheduler - INFO - Close client connection: Client-6892403a-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:44,717 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38371'. Reason: nanny-close
2024-01-06 06:25:44,718 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,718 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37749'. Reason: nanny-close
2024-01-06 06:25:44,719 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,719 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44837'. Reason: nanny-close
2024-01-06 06:25:44,719 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44953. Reason: nanny-close
2024-01-06 06:25:44,719 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,720 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45327'. Reason: nanny-close
2024-01-06 06:25:44,720 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46229. Reason: nanny-close
2024-01-06 06:25:44,720 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,721 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46431. Reason: nanny-close
2024-01-06 06:25:44,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38117'. Reason: nanny-close
2024-01-06 06:25:44,721 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37191'. Reason: nanny-close
2024-01-06 06:25:44,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33737. Reason: nanny-close
2024-01-06 06:25:44,722 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,722 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45584; closing.
2024-01-06 06:25:44,722 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,722 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44953', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.722399')
2024-01-06 06:25:44,722 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41319'. Reason: nanny-close
2024-01-06 06:25:44,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41607. Reason: nanny-close
2024-01-06 06:25:44,722 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,723 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34645'. Reason: nanny-close
2024-01-06 06:25:44,723 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43405. Reason: nanny-close
2024-01-06 06:25:44,723 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45598; closing.
2024-01-06 06:25:44,723 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:44,723 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42975. Reason: nanny-close
2024-01-06 06:25:44,723 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,724 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,724 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,724 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46431', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7245502')
2024-01-06 06:25:44,724 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35445. Reason: nanny-close
2024-01-06 06:25:44,724 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45590; closing.
2024-01-06 06:25:44,725 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,725 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,725 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,725 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,726 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,726 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:44,727 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,727 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,725 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:45598>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:45598>: Stream is closed
2024-01-06 06:25:44,727 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,727 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46229', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7275064')
2024-01-06 06:25:44,727 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45614; closing.
2024-01-06 06:25:44,728 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:44,728 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7284226')
2024-01-06 06:25:44,728 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45638; closing.
2024-01-06 06:25:44,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41607', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7293384')
2024-01-06 06:25:44,729 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45580; closing.
2024-01-06 06:25:44,729 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45608; closing.
2024-01-06 06:25:44,730 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43405', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7303793')
2024-01-06 06:25:44,730 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.730723')
2024-01-06 06:25:44,731 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45624; closing.
2024-01-06 06:25:44,731 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35445', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522344.7314944')
2024-01-06 06:25:44,731 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:45,633 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:45,633 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:45,634 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:45,635 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:45,636 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-06 06:25:47,843 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:47,848 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:47,851 - distributed.scheduler - INFO - State start
2024-01-06 06:25:47,873 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:47,873 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:47,874 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:47,874 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:47,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35863'
2024-01-06 06:25:49,094 - distributed.scheduler - INFO - Receive client connection: Client-6cfd2bc6-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:49,109 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45734
2024-01-06 06:25:49,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:49,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:49,736 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:49,737 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39941
2024-01-06 06:25:49,737 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39941
2024-01-06 06:25:49,737 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37267
2024-01-06 06:25:49,737 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:49,737 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:49,737 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:49,737 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:25:49,738 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cq9yeu0_
2024-01-06 06:25:49,738 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff39ab78-8897-4e74-9482-5d7543dc64d0
2024-01-06 06:25:50,045 - distributed.worker - INFO - Starting Worker plugin PreImport-347f83e6-ae7b-4900-8abc-cd59b743b7cc
2024-01-06 06:25:50,045 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-901a04d0-de9c-410b-9b78-97be87d3e181
2024-01-06 06:25:50,046 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:50,100 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39941', status: init, memory: 0, processing: 0>
2024-01-06 06:25:50,101 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39941
2024-01-06 06:25:50,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37994
2024-01-06 06:25:50,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:50,102 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:50,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:50,104 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:50,163 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:50,167 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:50,169 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:50,171 - distributed.scheduler - INFO - Remove client Client-6cfd2bc6-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:50,171 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45734; closing.
2024-01-06 06:25:50,172 - distributed.scheduler - INFO - Remove client Client-6cfd2bc6-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:50,172 - distributed.scheduler - INFO - Close client connection: Client-6cfd2bc6-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:50,173 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35863'. Reason: nanny-close
2024-01-06 06:25:50,173 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:50,175 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39941. Reason: nanny-close
2024-01-06 06:25:50,177 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37994; closing.
2024-01-06 06:25:50,177 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:50,177 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39941', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522350.1772206')
2024-01-06 06:25:50,177 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:50,178 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:50,888 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:50,888 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:50,889 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:50,890 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:50,890 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-06 06:25:52,995 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:53,000 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:25:53,004 - distributed.scheduler - INFO - State start
2024-01-06 06:25:53,025 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:53,026 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:25:53,027 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:25:53,027 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:25:53,122 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37003'
2024-01-06 06:25:53,281 - distributed.scheduler - INFO - Receive client connection: Client-701775bf-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:53,296 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38092
2024-01-06 06:25:54,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:54,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:54,791 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:54,792 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35093
2024-01-06 06:25:54,792 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35093
2024-01-06 06:25:54,792 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40247
2024-01-06 06:25:54,792 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:25:54,792 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:54,792 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:25:54,792 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:25:54,792 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zj1t4zhx
2024-01-06 06:25:54,793 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3910d386-159b-449f-ac4b-b7c6cfc557f9
2024-01-06 06:25:55,080 - distributed.worker - INFO - Starting Worker plugin PreImport-c96fef38-d11f-4cd6-abdf-3da6acca765e
2024-01-06 06:25:55,080 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8957e13f-efb9-41f8-bb27-7875537bf5ec
2024-01-06 06:25:55,081 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:55,145 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35093', status: init, memory: 0, processing: 0>
2024-01-06 06:25:55,146 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35093
2024-01-06 06:25:55,146 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38112
2024-01-06 06:25:55,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:25:55,147 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:25:55,147 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:55,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:25:55,234 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-06 06:25:55,239 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:25:55,243 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:55,244 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:25:55,247 - distributed.scheduler - INFO - Remove client Client-701775bf-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:55,247 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38092; closing.
2024-01-06 06:25:55,247 - distributed.scheduler - INFO - Remove client Client-701775bf-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:55,247 - distributed.scheduler - INFO - Close client connection: Client-701775bf-ac5c-11ee-b775-d8c49764f6bb
2024-01-06 06:25:55,248 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37003'. Reason: nanny-close
2024-01-06 06:25:55,249 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:25:55,250 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35093. Reason: nanny-close
2024-01-06 06:25:55,252 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:25:55,252 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38112; closing.
2024-01-06 06:25:55,252 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35093', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522355.2522953')
2024-01-06 06:25:55,252 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:25:55,253 - distributed.nanny - INFO - Worker closed
2024-01-06 06:25:56,014 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:25:56,014 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:25:56,015 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:56,016 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:25:56,016 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39525 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34585 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39151 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38671 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35923 instead
  warnings.warn(
[1704522542.659579] [dgx13:70286:0]            sock.c:481  UCX  ERROR bind(fd=123 addr=0.0.0.0:40604) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39911 instead
  warnings.warn(
[1704522560.353640] [dgx13:70467:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:54582) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36863 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43959 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36741 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36071 instead
  warnings.warn(
[1704522753.117098] [dgx13:73597:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:37684) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33813 instead
  warnings.warn(
[1704522770.897365] [dgx13:73945:0]            sock.c:481  UCX  ERROR bind(fd=151 addr=0.0.0.0:33704) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46403 instead
  warnings.warn(
[1704522831.728814] [dgx13:74816:0]            sock.c:481  UCX  ERROR bind(fd=123 addr=0.0.0.0:41422) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34233 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46711 instead
  warnings.warn(
2024-01-06 06:35:16,600 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 439, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 505, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 445, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34319 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36003 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32925 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33157 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42137 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35543 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34909 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44921 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] [1704523342.709624] [dgx13:82401:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:51258) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33535 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43927 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34539 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42525 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43029 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38347 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42249 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46469 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41441 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41205 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42925 instead
  warnings.warn(
2024-01-06 06:46:58,685 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] 2024-01-06 06:47:07,067 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-06 06:47:07,069 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
[1704523627.853384] [dgx13:86530] UCXPY  WARNING Listener object is being destroyed, but 2 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
[1704523627.853449] [dgx13:86530] UCXPY  WARNING Listener object is being destroyed, but 2 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35647 instead
  warnings.warn(
[1704523649.210277] [dgx13:87035:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:48332) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33143 instead
  warnings.warn(
[1704523662.433444] [dgx13:87058:0]            sock.c:481  UCX  ERROR bind(fd=150 addr=0.0.0.0:37550) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36731 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] [1704523709.781405] [dgx13:87759:0]            sock.c:481  UCX  ERROR bind(fd=173 addr=0.0.0.0:44271) failed: Address already in use
[1704523715.405271] [dgx13:87928:0]            sock.c:481  UCX  ERROR bind(fd=170 addr=0.0.0.0:49866) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45805 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39399 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35065 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43685 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36639 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-06 06:51:12,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:12,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:12,654 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,655 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33961
2024-01-06 06:51:12,655 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33961
2024-01-06 06:51:12,655 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45905
2024-01-06 06:51:12,655 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,655 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,655 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,655 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h9i7704n
2024-01-06 06:51:12,655 - distributed.worker - INFO - Starting Worker plugin PreImport-ca4a9650-25c1-4205-9a81-b32684c8dff5
2024-01-06 06:51:12,655 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1556eba9-54af-4529-83bb-86116d16e7e8
2024-01-06 06:51:12,656 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5dc5461b-fd45-423c-83a5-cca359e3aecb
2024-01-06 06:51:12,656 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,714 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,714 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34305
2024-01-06 06:51:12,714 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34305
2024-01-06 06:51:12,714 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37197
2024-01-06 06:51:12,715 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,715 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,715 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,715 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fkwr02p3
2024-01-06 06:51:12,715 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c68e0622-f419-4601-866f-4ac021a7b1e1
2024-01-06 06:51:12,715 - distributed.worker - INFO - Starting Worker plugin PreImport-b9a5d246-2c42-480b-afe8-b05690c6d567
2024-01-06 06:51:12,715 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dea841c1-643e-45da-b62e-035876bab0bb
2024-01-06 06:51:12,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,715 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,716 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,716 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39111
2024-01-06 06:51:12,739 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39111
2024-01-06 06:51:12,739 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35347
2024-01-06 06:51:12,739 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,739 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,740 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,740 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t9rrc25c
2024-01-06 06:51:12,740 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28e3bd0b-aa65-4640-b325-0a55354796eb
2024-01-06 06:51:12,740 - distributed.worker - INFO - Starting Worker plugin PreImport-80440090-d0cd-46ab-9bd8-9fde5e60ece7
2024-01-06 06:51:12,741 - distributed.worker - INFO - Starting Worker plugin RMMSetup-78e1028d-102e-4bfc-8ed0-0ac991915eca
2024-01-06 06:51:12,741 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,750 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,750 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39369
2024-01-06 06:51:12,750 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39369
2024-01-06 06:51:12,751 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35881
2024-01-06 06:51:12,751 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,751 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,751 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,751 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7t6mpf8o
2024-01-06 06:51:12,751 - distributed.worker - INFO - Starting Worker plugin PreImport-480ea355-75cb-4a8d-914e-2afab04b8f8f
2024-01-06 06:51:12,751 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-925e8349-6b51-460c-b3fa-703eea2da7bc
2024-01-06 06:51:12,752 - distributed.worker - INFO - Starting Worker plugin RMMSetup-348d0b2f-2ca6-4c94-9d1e-22942a297352
2024-01-06 06:51:12,752 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,781 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,781 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,819 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,820 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42735
2024-01-06 06:51:12,820 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42735
2024-01-06 06:51:12,820 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33381
2024-01-06 06:51:12,820 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,821 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,821 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,821 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_3f1ib30
2024-01-06 06:51:12,821 - distributed.worker - INFO - Starting Worker plugin PreImport-843718f4-800c-40e7-a18a-61c2d9473e4a
2024-01-06 06:51:12,821 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1033be80-cbc4-47fe-a0f2-7c9b4da02f3e
2024-01-06 06:51:12,821 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6bbf9c35-5a37-4f86-8497-030a0f4676ca
2024-01-06 06:51:12,821 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,835 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44009
2024-01-06 06:51:12,836 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44009
2024-01-06 06:51:12,836 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34295
2024-01-06 06:51:12,836 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,836 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,836 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tnaibmr5
2024-01-06 06:51:12,836 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c50165f0-f761-4347-b4a6-8a44c36f77d9
2024-01-06 06:51:12,836 - distributed.worker - INFO - Starting Worker plugin PreImport-97e29f08-5e39-4eb7-a724-ba9448d13b2b
2024-01-06 06:51:12,836 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc166c3d-d20f-47b4-8bd4-8738d662ec03
2024-01-06 06:51:12,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,844 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,844 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,845 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,851 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,851 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,852 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,853 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,907 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:12,908 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34941
2024-01-06 06:51:12,908 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34941
2024-01-06 06:51:12,909 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35525
2024-01-06 06:51:12,909 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,909 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,909 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:12,909 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ak_2duqp
2024-01-06 06:51:12,909 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d101664f-ec22-4b41-990b-d0f12d26caba
2024-01-06 06:51:12,909 - distributed.worker - INFO - Starting Worker plugin PreImport-e5498cfb-735c-44c3-b90a-d64b3d53e3b3
2024-01-06 06:51:12,910 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6dd46852-8e6d-41d4-960c-dffc49febcf5
2024-01-06 06:51:12,910 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,915 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,915 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,915 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,916 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,924 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,925 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:12,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:12,989 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:12,990 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:12,991 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:13,000 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:13,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45197
2024-01-06 06:51:13,001 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45197
2024-01-06 06:51:13,001 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38197
2024-01-06 06:51:13,001 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45923
2024-01-06 06:51:13,001 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:13,001 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:13,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ve8n_j0d
2024-01-06 06:51:13,001 - distributed.worker - INFO - Starting Worker plugin RMMSetup-817c8fd6-8e0d-4a37-8cf2-6d58c84bbd12
2024-01-06 06:51:13,001 - distributed.worker - INFO - Starting Worker plugin PreImport-56589d60-8f68-41bd-b4e3-37c429877976
2024-01-06 06:51:13,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14a2cc5b-30d4-440b-8de7-60ef9c27f9b9
2024-01-06 06:51:13,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:13,072 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:13,073 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45923
2024-01-06 06:51:13,073 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:13,075 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45923
2024-01-06 06:51:13,093 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:51:13,099 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33961. Reason: nanny-close
2024-01-06 06:51:13,100 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34305. Reason: nanny-close
2024-01-06 06:51:13,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39369. Reason: nanny-close
2024-01-06 06:51:13,101 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39111. Reason: nanny-close
2024-01-06 06:51:13,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42735. Reason: nanny-close
2024-01-06 06:51:13,102 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,102 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44009. Reason: nanny-close
2024-01-06 06:51:13,102 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,103 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,103 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34941. Reason: nanny-close
2024-01-06 06:51:13,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,103 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45197. Reason: nanny-close
2024-01-06 06:51:13,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,104 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,104 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,104 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,105 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,105 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,105 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,106 - distributed.core - INFO - Connection to tcp://127.0.0.1:45923 has been closed.
2024-01-06 06:51:13,106 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:13,107 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-06 06:51:51,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:51,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:51,202 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:51,203 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41641
2024-01-06 06:51:51,203 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41641
2024-01-06 06:51:51,203 - distributed.worker - INFO -           Worker name:                          0
2024-01-06 06:51:51,203 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44867
2024-01-06 06:51:51,203 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:35143
2024-01-06 06:51:51,203 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:51,203 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:51,203 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:51:51,203 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e1c8mi5m
2024-01-06 06:51:51,203 - distributed.worker - INFO - Starting Worker plugin PreImport-b678a927-d25c-4005-8d8a-6f0c30007d77
2024-01-06 06:51:51,207 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-06 06:51:51,207 - distributed.worker - INFO - Starting Worker plugin RMMSetup-04723f42-cd92-4ca7-ba96-b811c8516124
2024-01-06 06:51:51,207 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce030044-7b6d-44e0-93af-37c41bce9a30
2024-01-06 06:51:51,207 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41641. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-06 06:51:51,207 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-06 06:51:51,209 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-06 06:51:55,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:55,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:55,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:55,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:51:56,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:51:56,611 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,612 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33701
2024-01-06 06:51:56,612 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33701
2024-01-06 06:51:56,612 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34421
2024-01-06 06:51:56,612 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,612 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,612 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,612 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,612 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e_kiix0z
2024-01-06 06:51:56,612 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b320859f-523c-43a5-8f63-67493be34f8f
2024-01-06 06:51:56,613 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d3b43c31-9d7a-47d2-afed-81e422b8b257
2024-01-06 06:51:56,613 - distributed.worker - INFO - Starting Worker plugin PreImport-b2c1bcc3-0517-47ff-898d-5c4dd61b5182
2024-01-06 06:51:56,613 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,629 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,630 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38747
2024-01-06 06:51:56,630 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38747
2024-01-06 06:51:56,630 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34555
2024-01-06 06:51:56,630 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,630 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,630 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,630 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,630 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i9fwbo8y
2024-01-06 06:51:56,631 - distributed.worker - INFO - Starting Worker plugin PreImport-567e3622-c638-4ba3-846e-6bded5d19f68
2024-01-06 06:51:56,631 - distributed.worker - INFO - Starting Worker plugin RMMSetup-574aaa43-755f-4f8e-86fc-c2f565ed20fd
2024-01-06 06:51:56,631 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee071403-4af9-49bd-ab5b-18ea1600dce1
2024-01-06 06:51:56,631 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,678 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,678 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,679 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42987
2024-01-06 06:51:56,679 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42987
2024-01-06 06:51:56,679 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37515
2024-01-06 06:51:56,679 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,679 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,679 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36661
2024-01-06 06:51:56,679 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,679 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36661
2024-01-06 06:51:56,679 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,679 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32897
2024-01-06 06:51:56,679 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4jcnmyka
2024-01-06 06:51:56,679 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,679 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,679 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,679 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,679 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v67nhuy8
2024-01-06 06:51:56,679 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a1ca1b40-8dc2-4f0f-b7bb-b64de2962b64
2024-01-06 06:51:56,680 - distributed.worker - INFO - Starting Worker plugin PreImport-277111d5-3ce8-4a7e-9e56-7da41156809e
2024-01-06 06:51:56,680 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9455c82b-c48f-4484-9991-27106ffd06e2
2024-01-06 06:51:56,680 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-89e2790e-93b3-4dfe-9791-d96edbce115c
2024-01-06 06:51:56,680 - distributed.worker - INFO - Starting Worker plugin PreImport-33de9941-15c0-4189-ae5e-eadfdd5ffbfc
2024-01-06 06:51:56,680 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b61dab9-a10b-4e7c-bc9a-99a6088cd8a9
2024-01-06 06:51:56,680 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,681 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,687 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:56,688 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,688 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:56,706 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:56,707 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,707 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:56,753 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,753 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43683
2024-01-06 06:51:56,754 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43683
2024-01-06 06:51:56,754 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36889
2024-01-06 06:51:56,754 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,754 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,754 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,754 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,754 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sv8lv7cj
2024-01-06 06:51:56,754 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0e3ed55c-dbea-4b70-89ed-4e658819bb3d
2024-01-06 06:51:56,754 - distributed.worker - INFO - Starting Worker plugin PreImport-3c9addc5-7dbd-4bf3-8094-b710da955834
2024-01-06 06:51:56,754 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd55fa2c-fcfc-417e-a9c3-72257cde6d81
2024-01-06 06:51:56,755 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,762 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,763 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37865
2024-01-06 06:51:56,763 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37865
2024-01-06 06:51:56,763 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33689
2024-01-06 06:51:56,763 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,763 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,763 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,763 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,763 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h4ljkeec
2024-01-06 06:51:56,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc5bbe54-16be-4a9b-a318-3e7dad0272a1
2024-01-06 06:51:56,764 - distributed.worker - INFO - Starting Worker plugin PreImport-bd78f1d6-9052-4e63-abba-672307818c95
2024-01-06 06:51:56,764 - distributed.worker - INFO - Starting Worker plugin RMMSetup-377fd68d-97f3-4179-8c3c-c06a84117a93
2024-01-06 06:51:56,764 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,766 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,767 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41567
2024-01-06 06:51:56,767 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41567
2024-01-06 06:51:56,767 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40989
2024-01-06 06:51:56,767 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,767 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,767 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,767 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,767 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4faj61vw
2024-01-06 06:51:56,767 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3759c2f5-4f56-484a-97ae-164d2fe143f0
2024-01-06 06:51:56,768 - distributed.worker - INFO - Starting Worker plugin PreImport-89067ba5-7158-48e8-a9f5-d3c5f41bfdcb
2024-01-06 06:51:56,768 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5d1cbd7f-b0bf-4363-ab6e-ef9fd8809021
2024-01-06 06:51:56,768 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,799 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:56,799 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,799 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,801 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:56,810 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:56,811 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,811 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,812 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:56,863 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:51:56,864 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33165
2024-01-06 06:51:56,864 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33165
2024-01-06 06:51:56,864 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46633
2024-01-06 06:51:56,864 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40067
2024-01-06 06:51:56,864 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:56,864 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:51:56,864 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:51:56,864 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g9dhwwag
2024-01-06 06:51:56,864 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-52c8872e-d803-46be-899c-aba2bc18c6cd
2024-01-06 06:51:56,865 - distributed.worker - INFO - Starting Worker plugin PreImport-88eb43ec-7479-4edb-9489-b2594de3ae01
2024-01-06 06:51:56,865 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c285934f-8177-47e8-83eb-15ffe13365a5
2024-01-06 06:51:56,865 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:57,048 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:57,049 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:57,049 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:57,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:57,076 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:57,077 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:57,077 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:57,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:57,083 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:57,084 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:57,084 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:57,085 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:57,105 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:51:57,106 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:40067
2024-01-06 06:51:57,106 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:51:57,107 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40067
2024-01-06 06:51:57,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38747. Reason: nanny-close
2024-01-06 06:51:57,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33701. Reason: nanny-close
2024-01-06 06:51:57,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36661. Reason: nanny-close
2024-01-06 06:51:57,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42987. Reason: nanny-close
2024-01-06 06:51:57,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37865. Reason: nanny-close
2024-01-06 06:51:57,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43683. Reason: nanny-close
2024-01-06 06:51:57,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,162 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,162 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41567. Reason: nanny-close
2024-01-06 06:51:57,163 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33165. Reason: nanny-close
2024-01-06 06:51:57,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,163 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,164 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,164 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,164 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,165 - distributed.core - INFO - Connection to tcp://127.0.0.1:40067 has been closed.
2024-01-06 06:51:57,165 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,165 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,166 - distributed.nanny - INFO - Worker closed
2024-01-06 06:51:57,166 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info 2024-01-06 06:53:37,903 - distributed.worker - WARNING - RMM allocation of 1.00 MiB failed, spill-on-demand couldn't find any device memory to spill.
RMM allocs: 1.00 MiB, <ProxyManager dev_limit=25.60 GiB host_limit=0.98 TiB disk=0 B(0) host=0 B(0) dev=0 B(0)>, traceback:
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 937, in _bootstrap
    self._bootstrap_inner()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/threadpoolexecutor.py", line 57, in _worker
    task.run()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/_concurrent_futures_thread.py", line 65, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1541, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2954, in apply_function
    msg = apply_function_simple(function, args, kwargs, time_delay)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2990, in apply_function_simple
    result = function(*args, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_proxify_host_file.py", line 467, in task
    rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/proxify_host_file.py", line 617, in oom
    traceback.print_stack(file=f)


2024-01-06 06:53:38,118 - distributed.worker - WARNING - Compute Failed
Key:       task-5c302f54392a5ca98adb3c55c8357b0e
Function:  task
args:      ()
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_serializer PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[numpy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[cupy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_name PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj0] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj1] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[dask] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[pickle] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[disk] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-None] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucx-None] /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
