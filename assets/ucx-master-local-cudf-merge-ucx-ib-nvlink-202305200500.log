/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43353 instead
  warnings.warn(
2023-05-20 05:53:47,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:53:47,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:53:47,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[1684562030.080807] [dgx13:82385:0]            sock.c:470  UCX  ERROR bind(fd=159 addr=0.0.0.0:34284) failed: Address already in use
[1684562039.095201] [dgx13:82376:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_2: LRU push returned Unsupported operation
[dgx13:82376:0:82376]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  82376) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f17e0cfedcc]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7f17e0cfbd08]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_format+0x114) [0x7f17e0cfbe24]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x81f9a) [0x7f17e0db8f9a]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xc9) [0x7f17e0d8eb59]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x20) [0x7f17e0dd2ab0]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x71e) [0x7f17e0dd79de]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x52) [0x7f17e0dd7192]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x495d8) [0x7f17e0e6e5d8]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x556ab25fbdc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x556ab25fa1a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x556ab25e0d36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556ab25da27a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556ab25ebc05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x556ab25dc3cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556ab25da27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556ab25ebc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x556ab25dc3cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x556ab25e1923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x556ab25e1923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x556ab25e1923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x556ab25e1923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x556ab25e1923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x556ab260070e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f17f1a3d2fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7f17f1a3db4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x556ab25e42bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x556ab2597817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x556ab25e2f83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x556ab25e0d36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556ab25da27a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556ab25ebc05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x556ab25dffa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556ab25da27a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x556ab25f9935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x556ab25fa104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x556ab26c0fc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x556ab25e42bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556ab25df1bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x556ab25f9c72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x556ab25df1bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x556ab25da27a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556ab25ebc05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x556ab25db81b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556ab25ebef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x556ab25db568]
=================================
[1684562039.365370] [dgx13:82387:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:82387:0:82387]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  82387) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fd95869fdcc]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7fd95869cd08]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_format+0x114) [0x7fd95869ce24]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x81f9a) [0x7fd958759f9a]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xc9) [0x7fd95872fb59]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x20) [0x7fd958773ab0]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x71e) [0x7fd9587789de]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x52) [0x7fd958778192]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x495d8) [0x7fd95880f5d8]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x55f0010d1dc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x55f0010d01a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f0010b6d36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f0010b027a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f0010c1c05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f0010b23cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f0010b027a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f0010c1c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f0010b23cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55f0010b7923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55f0010b7923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55f0010b7923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55f0010b7923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55f0010b7923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55f0010d670e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fd9693da2fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7fd9693dab4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f0010ba2bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f00106d817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f0010b8f83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f0010b6d36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f0010b027a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f0010c1c05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f0010b5fa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f0010b027a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f0010cf935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f0010d0104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f001196fc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f0010ba2bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f0010b51bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f0010cfc72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f0010b51bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f0010b027a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f0010c1c05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f0010b181b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f0010c1ef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f0010b1568]
=================================
Task exception was never retrieved
future: <Task finished name='Task-1057' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-20 05:53:59,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f61903c6180, tag: 0xd2583ded4979b013, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f61903c6180, tag: 0xd2583ded4979b013, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,368 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd6f1002100, tag: 0x2ec00af904ba1560, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd6f1002100, tag: 0x2ec00af904ba1560, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc73d605140, tag: 0xbc4e7c1e84a28969, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc73d605140, tag: 0xbc4e7c1e84a28969, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1114' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-20 05:53:59,503 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39707 -> ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 315, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f4fd040f380 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:53:59,508 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f4fd040f200, tag: 0xd701268e6791e912, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f4fd040f200, tag: 0xd701268e6791e912, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,587 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff1b0b06140, tag: 0xbf33c13c0f67cc10, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff1b0b06140, tag: 0xbf33c13c0f67cc10, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1055' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-05-20 05:53:59,641 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f61903c6200, tag: 0x12de0f96252e6f35, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f61903c6200, tag: 0x12de0f96252e6f35, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:52681 after 30 s
2023-05-20 05:53:59,642 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f4fd040f140, tag: 0xa082a69169763955, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f4fd040f140, tag: 0xa082a69169763955, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,642 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59138 -> ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff1b0b06340, tag: 0xb87d20f2975dace2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:53:59,643 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59138 -> ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff1b0b06400, tag: 0x76d608fb14930bfe, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:53:59,643 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39707 -> ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f4fd040f400, tag: 0x302742356a08e8fa, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-1113' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-20 05:53:59,644 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd6f1002200, tag: 0x85da4f30ede37a8a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd6f1002200, tag: 0x85da4f30ede37a8a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,644 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff1b0b060c0, tag: 0x567d6dc88258b222, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff1b0b060c0, tag: 0x567d6dc88258b222, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,645 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa573b11100, tag: 0x9b6ae446328fc83c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa573b11100, tag: 0x9b6ae446328fc83c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,705 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41812 -> ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc73d605300, tag: 0xf120023649d34b55, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:53:59,705 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41812 -> ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc73d6052c0, tag: 0xf258b1fd41410fb1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:53:59,706 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52681
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc73d605280, tag: 0xf89107a1793a56a7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc73d605280, tag: 0xf89107a1793a56a7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:53:59,843 - distributed.nanny - WARNING - Restarting worker
2023-05-20 05:54:00,076 - distributed.nanny - WARNING - Restarting worker
2023-05-20 05:54:01,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:54:01,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:54:01,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:54:01,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[1684562043.056411] [dgx13:82385:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:82385:0:82385]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  82385) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fd6f9ed9dcc]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7fd6f9ed6d08]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_format+0x114) [0x7fd6f9ed6e24]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x81f9a) [0x7fd6f9f93f9a]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xc9) [0x7fd6f9f69b59]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x20) [0x7fd6f9fadab0]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x71e) [0x7fd6f9fb29de]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x52) [0x7fd6f9fb2192]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x495d8) [0x7fd70c0515d8]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x5620144fbdc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x5620144fa1a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5620144e0d36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5620144da27a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5620144ebc05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5620144dc3cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5620144da27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5620144ebc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5620144dc3cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x5620144e1923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x5620144e1923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x5620144e1923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x5620144e1923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x5620144e1923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56201450070e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fd71cc0f2fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7fd71cc0fb4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5620144e42bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x562014497817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5620144e2f83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5620144e0d36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5620144da27a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5620144ebc05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5620144dffa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5620144da27a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5620144f9935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5620144fa104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5620145c0fc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5620144e42bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5620144df1bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5620144f9c72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5620144df1bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5620144da27a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5620144ebc05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5620144db81b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5620144ebef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5620144db568]
=================================
2023-05-20 05:54:03,370 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #048] ep: 0x7fa573b111c0, tag: 0x62b9b77a49f9bdeb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #048] ep: 0x7fa573b111c0, tag: 0x62b9b77a49f9bdeb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-20 05:54:03,442 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #074] ep: 0x7fc73d605180, tag: 0x967e293caed4bb69, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #074] ep: 0x7fc73d605180, tag: 0x967e293caed4bb69, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-20 05:54:03,443 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41826 -> ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #044] ep: 0x7fa573b11380, tag: 0x18e76e4cc9f838b7, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:54:03,443 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41812 -> ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #066] ep: 0x7fc73d605340, tag: 0xdefb68aeb7ed5c48, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:54:03,444 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #053] ep: 0x7f4fd040f280, tag: 0x64ac4fc9adf0a767, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #053] ep: 0x7f4fd040f280, tag: 0x64ac4fc9adf0a767, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-20 05:54:03,444 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37170 -> ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #052] ep: 0x7f61903c6440, tag: 0xc9f9201812861c2f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:54:03,444 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #059] ep: 0x7f61903c6280, tag: 0xb27aa72e18892313, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #059] ep: 0x7f61903c6280, tag: 0xb27aa72e18892313, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-20 05:54:03,448 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39707 -> ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #058] ep: 0x7f4fd040f440, tag: 0x2d66e9e1637d437e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:54:03,457 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7ff1b0b06280 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXConnectionReset('Endpoint 0x7ff1b0b06280 error: Connection reset by remote peer')
2023-05-20 05:54:03,468 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59138 -> ucx://127.0.0.1:49062
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #059] ep: 0x7ff1b0b062c0, tag: 0x4bac66ef1d9b7f61, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-20 05:54:04,379 - distributed.nanny - WARNING - Restarting worker
2023-05-20 05:54:05,163 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-20 05:54:05,163 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-20 05:54:05,356 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-20 05:54:05,356 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-20 05:54:05,421 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7fc1f2
args:      ([                key   payload
28807     808300347  13426936
28822     102480745   3239389
28825     860919431  25290708
28831     824525572  84151161
63076     803296828  70757937
...             ...       ...
99982213  840365479  37059867
99982219  405922508  72957820
99982231  814423897  11569045
99982238  858441549  46772491
99982239  836286524  39998860

[12500893 rows x 2 columns],                 key   payload
72938     908339602  12033125
72951     939111067    169873
72832     948506688  43955460
35396     420234747   1381548
72835     955591762   1184727
...             ...       ...
99996440  715970656  84413921
99996442  917456790  93768629
99996452  958034903  10678976
99996457  905973463  55667384
99996470  948627261  76213362

[12495890 rows x 2 columns],                  key   payload
18656     1069606476   3920937
18658     1063573657  89099239
18660     1046511650  76336640
18665      230297554  67444513
18687     1063550244  26599797
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-20 05:54:05,473 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 4)
Function:  <dask.layers.CallableLazyImport object at 0x7f4a64
args:      ([                key   payload
28827     504685107  84963232
63072     858906477  65709119
102958    859246887  27958404
63077     811533810  67144583
32320     818245319  80860116
...             ...       ...
99993994  208880269  16883155
99994014  305710571  44928793
99982218  807473028  22987011
99982220  502303088  82294604
99982234  835874834  22029322

[12500589 rows x 2 columns],                 key   payload
72935     934096392  78042986
72937     522522784  87880490
72947     927877597  26628852
72833     516714063  85342439
35394     919129854  60120889
...             ...       ...
99996607  927687183  20065229
99996427  914137654  73826755
99996455  960472963  33239876
99996461  965369705  22913167
99996467   24554833  43381603

[12501715 rows x 2 columns],                  key   payload
18672     1063260844  45553535
18678     1046540297  92759345
18681      132264867  37082414
18683      732682436  16397515
59585     1059998293  35356470
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-20 05:54:06,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-20 05:54:06,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-20 05:54:28,376 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48256
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:48256 after 30 s
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
