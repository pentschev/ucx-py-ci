2023-06-28 06:29:48,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:29:48,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:48,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:56693:0:56693] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  56693) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0d308bdced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f0d308bdee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f0d308be0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f0dd10f5420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f0d3093cba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f0d30963dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f0d3087745f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f0d3087a8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0d308c72f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f0d3087965d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0d30939d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f0d309eb17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55d34b078b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55d34b069112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55d34b073c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55d34b081a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55d34b1919b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55d34b01f817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55d34b06af83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55d34b068d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55d34b073c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55d34b067fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55d34b081935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55d34b082104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55d34b148fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55d34b06c2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55d34b0671bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55d34b081c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55d34b0671bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55d34b073c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55d34b06381b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55d34b073ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55d34b063568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55d34b073c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55d34b0643cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55d34b06227a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55d34b061f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55d34b061eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55d34b1128bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55d34b140adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55d34b13cc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55d34b1347ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55d34b1346bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55d34b1338a2]
=================================
2023-06-28 06:29:58,161 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58397 -> ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fec28260380, tag: 0x9731597030564339, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,161 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70b76c3280, tag: 0xcff5bcad88c0c7bb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70b76c3280, tag: 0xcff5bcad88c0c7bb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:29:58,162 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fec28260180, tag: 0xb0511f02ed669eb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fec28260180, tag: 0xb0511f02ed669eb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:29:58,162 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f44c83091c0, tag: 0xc515e04590773084, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f44c83091c0, tag: 0xc515e04590773084, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:55439 after 30 s
2023-06-28 06:29:58,161 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70140db280, tag: 0x1d1b0dd93e53da1d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70140db280, tag: 0x1d1b0dd93e53da1d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,182 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45805 -> ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-06-28 06:29:58,214 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41965 -> ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7fba0f249400 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,217 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7fba0f249200 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXConnectionReset('Endpoint 0x7fba0f249200 error: Connection reset by remote peer')
2023-06-28 06:29:58,239 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 708, in recv
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f2d3581c100 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXConnectionReset('Endpoint 0x7f2d3581c100 error: Connection reset by remote peer')
2023-06-28 06:29:58,246 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:29:58,269 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6c882bd1c0, tag: 0x6dc4613177f81b8a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6c882bd1c0, tag: 0x6dc4613177f81b8a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[dgx13:56689:0:56689] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  56689) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fba0f4b5ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fba0f4b5ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fba0f4b60aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fbabfd1c420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fba0f534ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fba0f55bdc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fba0f46f45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fba0f4728c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fba0f4bf2f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fba0f47165d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fba0f531d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fba0f5e317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x563082477b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x563082468112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563082472c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56308248770e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fba3f8b92fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56308246b2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56308241e817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x563082469f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x563082467d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563082472c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x563082466fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x563082480935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x563082481104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x563082547fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56308246b2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5630824661bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x563082480c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5630824661bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563082472c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56308246281b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563082472ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x563082462568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563082472c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5630824633cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56308246127a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x563082460f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563082460eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5630825118bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56308253fadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56308253bc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5630825337ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5630825336bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5630825328a2]
=================================
[dgx13:56713:0:56713] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  56713) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f2d35a88ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f2d35a88ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f2d35a890aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f2ddc2f3420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f2d35b07ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f2d35b2edc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f2d35a4245f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f2d35a458c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f2d35a922f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f2d35a4465d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f2d35b04d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f2d35bb617a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55a4fded6b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55a4fdec7112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4fded1c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55a4fdee670e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f2d5be8b2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55a4fdeca2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55a4fde7d817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55a4fdec8f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55a4fdec6d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4fded1c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55a4fdec5fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55a4fdedf935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55a4fdee0104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55a4fdfa6fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55a4fdeca2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a4fdec51bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55a4fdedfc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a4fdec51bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4fded1c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a4fdec181b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a4fded1ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55a4fdec1568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a4fded1c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55a4fdec23cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a4fdec027a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55a4fdebff07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a4fdebfeb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a4fdf708bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55a4fdf9eadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55a4fdf9ac24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55a4fdf927ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55a4fdf926bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55a4fdf918a2]
=================================
[dgx13:56697:0:56697] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  56697) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f6c8854eced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f6c8854eee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f6c8854f0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f6d28d91420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f6c885cdba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f6c885f4dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f6c8850845f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f6c8850b8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f6c885582f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f6c8850a65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f6c885cad9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f6c8867c17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55fb12e9cb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55fb12e8d112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fb12e97c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fb12eac70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f6d1c3ad2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55fb12e902bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55fb12e43817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55fb12e8ef83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55fb12e8cd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fb12e97c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55fb12e8bfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55fb12ea5935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55fb12ea6104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55fb12f6cfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55fb12e902bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fb12e8b1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55fb12ea5c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fb12e8b1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fb12e97c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fb12e8781b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fb12e97ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55fb12e87568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fb12e97c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55fb12e883cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fb12e8627a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55fb12e85f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55fb12e85eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55fb12f368bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55fb12f64adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55fb12f60c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55fb12f587ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55fb12f586bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55fb12f578a2]
=================================
2023-06-28 06:29:58,528 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #011] ep: 0x7fec28260140, tag: 0x5539993b7e2272e5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #011] ep: 0x7fec28260140, tag: 0x5539993b7e2272e5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:29:58,528 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70b76c31c0, tag: 0x656687bc98367419, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70b76c31c0, tag: 0x656687bc98367419, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,528 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db2c0, tag: 0xe206c6a5cee3092, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,529 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70140db240, tag: 0x38bd743a6595278d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70140db240, tag: 0x38bd743a6595278d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,529 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f44c8309180, tag: 0x95e3d90c95e82555, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f44c8309180, tag: 0x95e3d90c95e82555, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,529 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c32c0, tag: 0x96246bc4baf45854, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,570 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f44c8309380, tag: 0x8b8edc249a317d24, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,570 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c3300, tag: 0xc986a80c53f15569, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,570 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:41965
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f44c83093c0, tag: 0x29a4574c40035b52, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,571 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70b76c3200, tag: 0x6efea05a8c29ecd2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70b76c3200, tag: 0x6efea05a8c29ecd2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,571 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f44c8309100, tag: 0x3878d26ce037f6a2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f44c8309100, tag: 0x3878d26ce037f6a2, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,572 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70b76c3180, tag: 0x55a1ccbe26f04cee, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70b76c3180, tag: 0x55a1ccbe26f04cee, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,572 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #010] ep: 0x7f44c8309140, tag: 0x6d5f1193fc58e16a, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #010] ep: 0x7f44c8309140, tag: 0x6d5f1193fc58e16a, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-28 06:29:58,573 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c3440, tag: 0x520b9ad4b259f03e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,573 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c33c0, tag: 0xfd528fa742949173, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,595 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:29:58,591 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58397 -> ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fec282602c0, tag: 0x10c20d8b652eb790, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,599 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58397 -> ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fec28260440, tag: 0xee9118e31e821fb9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,600 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fec28260100, tag: 0x3061ebb3d3d54134, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fec28260100, tag: 0x3061ebb3d3d54134, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,650 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db3c0, tag: 0x638abaca8b1a0cbc, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,651 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:57141
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f70140db140, tag: 0x1c28df02e1b0aaf9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f70140db140, tag: 0x1c28df02e1b0aaf9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-28 06:29:58,652 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:55439
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db380, tag: 0x69e78a9111a128b8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,652 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db300, tag: 0xa083ea992998883b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:29:58,654 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f70140db1c0, tag: 0xf3aac4691e87258a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f70140db1c0, tag: 0xf3aac4691e87258a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-28 06:29:58,661 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:29:58,703 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:29:58,651 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45805
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fec28260240, tag: 0x8f872ab5fe9bbc7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fec28260240, tag: 0x8f872ab5fe9bbc7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:29:59,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:29:59,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:00,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:00,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:00,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:00,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:00,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:00,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:00,726 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-ed3372b7e43f8bc031030fc80fa908e4', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7fec10
args:      (               key   payload
shuffle                     
6            52291  34808780
6            52296  62199302
6              611   9770485
6            52302  83907192
6            21224  44493320
...            ...       ...
6        799983357  33872067
6        799983358  54520016
6        799997129   9117575
6        799997138  88541874
6        799997145  27328948

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-28 06:30:00,854 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 2)
Function:  <dask.layers.CallableLazyImport object at 0x7fe6bb
args:      ([                key   payload
19065     831532785   2744448
11430     816455952  78657584
11435     861118242  48509001
11441     862416429   4914051
11451     817086426  48538166
...             ...       ...
99993041  801985388  49227655
99993052  801507887  33962232
99993003  866113391  43865852
99993007    5455421  88743663
99993021  851953210  79353123

[12503879 rows x 2 columns],                 key   payload
39077     418234679   7660186
39079     925115286  30695487
2795      622787760  65796870
39080     421631266  71421431
2803      901659649  21243778
...             ...       ...
99981654  957162367  10865574
99981658  925239548  45442265
99981659  959623492  89935690
99981737  922393414  54842814
99981751  924429681  56581013

[12499576 rows x 2 columns],                  key   payload
20678       34676409  74212645
20680       33425601  51483044
20681     1068576472  43103076
20684     1037608327    515692
80460     1002013377   3351274
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-28 06:30:01,064 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  <dask.layers.CallableLazyImport object at 0x7f6aa8
args:      ([                key   payload
19060     505556044  95520637
11427     845940497  84570493
19066     857629966  33027013
11431     853712590  96572949
11455     203715268   3490766
...             ...       ...
99993004  807518819  77729814
99993013  858427882  19492673
99993015    7465248  82785245
99993017  700980514  37606921
99993022  609103098  59286598

[12498923 rows x 2 columns],                 key   payload
39076     903629694   5358508
39097     956149650  94358999
2785      956621536  85693109
39103     900050212   1522401
2793      418269931  34134424
...             ...       ...
99981738  938947775  12498445
99981739  930960450  86182853
99981740  918766992  49401427
99981754  964076923  88955154
99981756  909662595  79537521

[12501128 rows x 2 columns],                  key   payload
20677     1018621699  65364391
20685     1019777021    467346
20689     1006849733  51082624
20697      232590601   7441676
80449     1008636131  85106885
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

[dgx13:57223:0:57223] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  57223) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f17b449fced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f17b449fee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f17b44a00aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f1846b5d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f17b451eba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f17b4545dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f17b445945f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f17b445c8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f17b44a92f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f17b445b65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f17b451bd9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f17b45cd17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56241ff2db08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56241ff1e112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56241ff28c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56241ff3d70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f17c66fc2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56241ff212bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56241fed4817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56241ff1ff83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56241ff1dd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56241ff28c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56241ff1cfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x56241ff36935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x56241ff37104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56241fffdfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56241ff212bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56241ff1c1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x56241ff36c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56241ff1c1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56241ff28c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56241ff1881b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56241ff28ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56241ff18568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56241ff28c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56241ff193cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56241ff1727a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x56241ff16f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56241ff16eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56241ffc78bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56241fff5adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56241fff1c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56241ffe97ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56241ffe96bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x56241ffe88a2]
=================================
[dgx13:57227:0:57227] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  57227) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f4138ca0ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f4138ca0ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f4138ca10aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f41cb35c420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f4138d1fba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f4138d46dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f4138c5a45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f4138c5d8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f4138caa2f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f4138c5c65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f4138d1cd9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f4138dce17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55b64d999b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55b64d98a112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b64d994c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55b64d9a970e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f414aef62fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55b64d98d2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55b64d940817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55b64d98bf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55b64d989d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b64d994c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55b64d988fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55b64d9a2935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55b64d9a3104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55b64da69fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55b64d98d2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55b64d9881bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55b64d9a2c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55b64d9881bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b64d994c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b64d98481b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b64d994ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55b64d984568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b64d994c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55b64d9853cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b64d98327a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55b64d982f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b64d982eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b64da338bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55b64da61adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55b64da5dc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55b64da557ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55b64da556bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55b64da548a2]
=================================
[dgx13:57233:0:57233] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  57233) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0ff1ac8ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f0ff1ac8ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f0ff1ac90aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f10941b8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f0ff1b47ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f0ff1b6edc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f0ff1a8245f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f0ff1a858c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0ff1ad22f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f0ff1a8465d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0ff1b44d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f0ff1bf617a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55fffe66fb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55fffe660112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fffe66ac05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55fffe678a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55fffe7889b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55fffe616817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55fffe661f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55fffe65fd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fffe66ac05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55fffe65efa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55fffe678935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55fffe679104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55fffe73ffc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55fffe6632bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fffe65e1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55fffe678c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fffe65e1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fffe66ac05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fffe65a81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fffe66aef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55fffe65a568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fffe66ac05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55fffe65b3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fffe65927a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55fffe658f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55fffe658eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55fffe7098bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55fffe737adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55fffe733c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55fffe72b7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55fffe72b6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55fffe72a8a2]
=================================
2023-06-28 06:30:04,287 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58397 -> ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fec28260440, tag: 0x1f76320901a529b9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,288 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70b76c33c0, tag: 0x77ed2c2d7532eb5d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70b76c33c0, tag: 0x77ed2c2d7532eb5d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:30:04,288 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70140db1c0, tag: 0xcf5f2151f452d368, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70140db1c0, tag: 0xcf5f2151f452d368, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:30:04,288 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fec28260100, tag: 0x9125dfef6996499f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fec28260100, tag: 0x9125dfef6996499f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:30:04,288 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f44c8309340, tag: 0xb3e45f8f3937917f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f44c8309340, tag: 0xb3e45f8f3937917f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-28 06:30:04,358 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:30:04,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:58397 -> ucx://127.0.0.1:38279
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fec282602c0, tag: 0x32d677842957efef, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:38279
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c3180, tag: 0x1b14b7966d8714c1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:38279
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db380, tag: 0x83a72c5833111e05, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,398 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48687 -> ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70b76c3440, tag: 0xde4fb5a9357902e2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,402 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37893 -> ucx://127.0.0.1:52807
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70140db140, tag: 0xa0fa39cdee8012a8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,409 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:38279
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f44c83093c0, tag: 0xf2ce311f9fc1a003, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,410 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:53611
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f44c8309100, tag: 0x1f799dd55bbb35cb, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,411 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:52807
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f44c8309380, tag: 0xefce89c9eda8b6d5, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:04,449 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:30:04,491 - distributed.nanny - WARNING - Restarting worker
2023-06-28 06:30:04,628 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-28 06:30:04,629 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-28 06:30:04,656 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-28 06:30:04,656 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-28 06:30:04,782 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2ef5ba233a4400f424ec0e71d2de9a11', 1)
Function:  <dask.layers.CallableLazyImport object at 0x7fe6bb
args:      ([               key  shuffle   payload  _partitions
0            23232        1  57232459            1
1            32259        1  64918379            1
2            23236        1  87935839            1
3            32264        1  45105880            1
4            23250        1  61102912            1
...            ...      ...       ...          ...
12499995  99992985        1  70182065            1
12499996  99992987        1  72593556            1
12499997  99992991        1  60533531            1
12499998  99992998        1  61508318            1
12499999  99993007        1    722431            1

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100031941        1  44889211            1
1         100031955        1  87481438            1
2         100011442        1  19802665            1
3         100031964        1  36624787            1
4         100011445        1  38918330            1
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-28 06:30:04,785 - distributed.worker - ERROR - tuple indices must be integers or slices, not str
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    status = response["status"]
TypeError: tuple indices must be integers or slices, not str
2023-06-28 06:30:04,793 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 359, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #116] ep: 0x7fec282601c0, tag: 0x25fb13a8ecf81d31, nbytes: 4824, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #116] ep: 0x7fec282601c0, tag: 0x25fb13a8ecf81d31, nbytes: 4824, type: <class 'numpy.ndarray'>>: Message truncated")
2023-06-28 06:30:04,793 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44915 -> ucx://127.0.0.1:58397
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #117] ep: 0x7f44c8309400, tag: 0x25fb13a8ecf81d31, nbytes: 50000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-28 06:30:05,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:05,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:05,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:05,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-28 06:30:06,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-28 06:30:06,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
