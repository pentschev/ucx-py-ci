============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-06 06:25:36,366 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:36,370 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39729 instead
  warnings.warn(
2024-01-06 06:25:36,374 - distributed.scheduler - INFO - State start
2024-01-06 06:25:36,396 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:25:36,397 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-06 06:25:36,398 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:25:36,399 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-06 06:25:36,593 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43357'
2024-01-06 06:25:36,614 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36591'
2024-01-06 06:25:36,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38607'
2024-01-06 06:25:36,625 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33649'
2024-01-06 06:25:38,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:38,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:38,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:38,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:38,339 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:38,340 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46361
2024-01-06 06:25:38,340 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46361
2024-01-06 06:25:38,341 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45171
2024-01-06 06:25:38,341 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:25:38,341 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,341 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:25:38,341 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:25:38,341 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-n4ofpaaq
2024-01-06 06:25:38,341 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-022abff1-10d0-4642-be35-3c7886c4ee76
2024-01-06 06:25:38,341 - distributed.worker - INFO - Starting Worker plugin PreImport-508bab6d-a623-4f75-b21f-24b75af15949
2024-01-06 06:25:38,341 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c78b322b-c326-4c41-b371-bda137ee9a71
2024-01-06 06:25:38,341 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,342 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:38,343 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39583
2024-01-06 06:25:38,343 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39583
2024-01-06 06:25:38,343 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39853
2024-01-06 06:25:38,343 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:25:38,343 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,343 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:25:38,343 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:25:38,343 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-77fiqmam
2024-01-06 06:25:38,343 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3e3fc2e9-e7a7-43f4-b0b9-6fc7195cdc09
2024-01-06 06:25:38,344 - distributed.worker - INFO - Starting Worker plugin PreImport-87f6db26-6e84-4439-bd7c-0fb049b27478
2024-01-06 06:25:38,345 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3a9dded9-d33e-478d-b5ee-b8a6ef55b6ac
2024-01-06 06:25:38,345 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:38,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:38,372 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:38,373 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43231
2024-01-06 06:25:38,373 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43231
2024-01-06 06:25:38,373 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36259
2024-01-06 06:25:38,373 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:25:38,373 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,374 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:25:38,374 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:25:38,374 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-_ry9szp_
2024-01-06 06:25:38,374 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-307cb0fb-4e6d-41b2-b0e0-783096e99d71
2024-01-06 06:25:38,375 - distributed.worker - INFO - Starting Worker plugin PreImport-2982537a-791c-40fd-80b9-3b606ea9b56b
2024-01-06 06:25:38,375 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c28444c2-2d8f-4292-b7cc-468337a78be0
2024-01-06 06:25:38,375 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:25:38,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:25:38,434 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:25:38,435 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33039
2024-01-06 06:25:38,435 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33039
2024-01-06 06:25:38,435 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34405
2024-01-06 06:25:38,435 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:25:38,435 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:25:38,435 - distributed.worker - INFO -               Threads:                          4
2024-01-06 06:25:38,436 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-06 06:25:38,436 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-3m3no7uc
2024-01-06 06:25:38,436 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-96bc1eb0-5c75-4aa7-9ed1-c2d7ab1f4df7
2024-01-06 06:25:38,436 - distributed.worker - INFO - Starting Worker plugin PreImport-2000d796-47ee-4688-a6f0-b8ea8072a10c
2024-01-06 06:25:38,436 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3bd1b8b9-7562-48bf-af87-e6c6cfd4763f
2024-01-06 06:25:38,437 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:08,342 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:26:08,345 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:26:08,347 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43357'. Reason: nanny-close
2024-01-06 06:26:08,348 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36591'. Reason: nanny-close
2024-01-06 06:26:08,348 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38607'. Reason: nanny-close
2024-01-06 06:26:08,348 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33649'. Reason: nanny-close
2024-01-06 06:26:08,375 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:26:08,438 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-06 06:26:40,764 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:40,769 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38983 instead
  warnings.warn(
2024-01-06 06:26:40,772 - distributed.scheduler - INFO - State start
2024-01-06 06:26:40,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-3m3no7uc', purging
2024-01-06 06:26:40,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-_ry9szp_', purging
2024-01-06 06:26:40,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-n4ofpaaq', purging
2024-01-06 06:26:40,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-77fiqmam', purging
2024-01-06 06:26:40,863 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:40,864 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:26:40,864 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38983/status
2024-01-06 06:26:40,864 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:26:41,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42723'
2024-01-06 06:26:41,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41715'
2024-01-06 06:26:41,119 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37493'
2024-01-06 06:26:41,134 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45793'
2024-01-06 06:26:41,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46177'
2024-01-06 06:26:41,146 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40135'
2024-01-06 06:26:41,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43575'
2024-01-06 06:26:41,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44877'
2024-01-06 06:26:43,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,023 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,023 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,024 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41883
2024-01-06 06:26:43,024 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41883
2024-01-06 06:26:43,024 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43883
2024-01-06 06:26:43,024 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,024 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,024 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,024 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38157
2024-01-06 06:26:43,024 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,024 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38157
2024-01-06 06:26:43,024 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h4z_f9ur
2024-01-06 06:26:43,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35387
2024-01-06 06:26:43,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,025 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,025 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,025 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1ab6507-fe8d-41bc-bf66-aa4cbedc741d
2024-01-06 06:26:43,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1vha9hn_
2024-01-06 06:26:43,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,025 - distributed.worker - INFO - Starting Worker plugin PreImport-be6e185d-6fd1-4afd-bf59-501c01de1b5d
2024-01-06 06:26:43,025 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-02cbf428-6406-47dc-9b86-1e03494c8a39
2024-01-06 06:26:43,025 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df765cf4-b1a8-4ce9-8132-36cb119dfe47
2024-01-06 06:26:43,029 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45259
2024-01-06 06:26:43,030 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45259
2024-01-06 06:26:43,030 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44219
2024-01-06 06:26:43,030 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,030 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,030 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,030 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,031 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gyr8crfm
2024-01-06 06:26:43,031 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f61daf4d-2a92-4571-b037-536b3fb458f2
2024-01-06 06:26:43,031 - distributed.worker - INFO - Starting Worker plugin PreImport-f66c67b5-8f7c-4e83-a73a-e3393ee706a8
2024-01-06 06:26:43,032 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36b471b5-ceeb-4da3-a740-a1401d940577
2024-01-06 06:26:43,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,107 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,108 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,108 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33217
2024-01-06 06:26:43,108 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33217
2024-01-06 06:26:43,108 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35907
2024-01-06 06:26:43,108 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,108 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,108 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,108 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,108 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9s6kk5ct
2024-01-06 06:26:43,109 - distributed.worker - INFO - Starting Worker plugin PreImport-57756218-6296-4719-8f9c-efb8ec60cdac
2024-01-06 06:26:43,109 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3e9d4fc4-fbb1-4895-b919-490655a3e596
2024-01-06 06:26:43,109 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32807
2024-01-06 06:26:43,109 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,109 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32807
2024-01-06 06:26:43,109 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ac53319a-72c8-4201-bb03-1d78e3c054eb
2024-01-06 06:26:43,109 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44433
2024-01-06 06:26:43,109 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,109 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,109 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,109 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,109 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xw7_a7kl
2024-01-06 06:26:43,109 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d876cee5-73c4-4994-a835-e6df82d7886b
2024-01-06 06:26:43,110 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44743
2024-01-06 06:26:43,110 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44743
2024-01-06 06:26:43,110 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38553
2024-01-06 06:26:43,110 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,110 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,110 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,110 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,110 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z0dcfdpp
2024-01-06 06:26:43,110 - distributed.worker - INFO - Starting Worker plugin RMMSetup-867791d6-e130-48dc-ae1d-10f6465ee784
2024-01-06 06:26:43,111 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,112 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46661
2024-01-06 06:26:43,112 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46661
2024-01-06 06:26:43,112 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34169
2024-01-06 06:26:43,112 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,112 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,112 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,112 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,112 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9cce62sx
2024-01-06 06:26:43,113 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92183fa6-5b30-4422-86f6-d5dcb0be10ff
2024-01-06 06:26:43,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:43,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:43,143 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:43,144 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42679
2024-01-06 06:26:43,144 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42679
2024-01-06 06:26:43,144 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39939
2024-01-06 06:26:43,144 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:43,144 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:43,144 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:43,144 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:43,144 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u1q4fcrd
2024-01-06 06:26:43,144 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ecd20688-21a1-48b7-802c-ee208c04f0e9
2024-01-06 06:26:43,240 - distributed.scheduler - INFO - Receive client connection: Client-8c7f1c94-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:43,256 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39764
2024-01-06 06:26:45,117 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9853366-a5b2-4669-aaf2-ffdf69d1cac8
2024-01-06 06:26:45,118 - distributed.worker - INFO - Starting Worker plugin PreImport-6ee8d60e-3a30-4416-9a39-db535d35168f
2024-01-06 06:26:45,120 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,127 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c63ec6bf-d690-462f-a712-296944bac5ce
2024-01-06 06:26:45,129 - distributed.worker - INFO - Starting Worker plugin PreImport-8d41773b-76e4-4ad2-9624-704f87cbbc2b
2024-01-06 06:26:45,130 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,138 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,158 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41883', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,159 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41883
2024-01-06 06:26:45,159 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39784
2024-01-06 06:26:45,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,162 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,162 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,162 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38157', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,163 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38157
2024-01-06 06:26:45,163 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39812
2024-01-06 06:26:45,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44743', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,164 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,164 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44743
2024-01-06 06:26:45,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39798
2024-01-06 06:26:45,165 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,165 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,166 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,166 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,167 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,167 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,196 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,208 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f98b1f70-c74a-465d-9871-46d0e24ab80d
2024-01-06 06:26:45,210 - distributed.worker - INFO - Starting Worker plugin PreImport-abbd0a86-a95f-4718-b552-dd95f0e44101
2024-01-06 06:26:45,211 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,220 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,232 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45259', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,233 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45259
2024-01-06 06:26:45,233 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39824
2024-01-06 06:26:45,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,236 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,236 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,238 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,248 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33217', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,249 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33217
2024-01-06 06:26:45,249 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39838
2024-01-06 06:26:45,250 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32807', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,250 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,250 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32807
2024-01-06 06:26:45,250 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39832
2024-01-06 06:26:45,251 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,251 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,251 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-619f8ff8-dce8-477e-8fa7-297c22270a1b
2024-01-06 06:26:45,252 - distributed.worker - INFO - Starting Worker plugin PreImport-d8473dde-8e25-4925-b3f8-22d044c526eb
2024-01-06 06:26:45,252 - distributed.worker - INFO - Starting Worker plugin PreImport-3de5a322-c5e4-46e9-a3e3-aff9d1a34cda
2024-01-06 06:26:45,252 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ccbfc880-1913-4b5d-aa91-7b9e5d4ad88f
2024-01-06 06:26:45,252 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,252 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,253 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,253 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,253 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,253 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,255 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,285 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46661', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,286 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46661
2024-01-06 06:26:45,286 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39852
2024-01-06 06:26:45,286 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42679', status: init, memory: 0, processing: 0>
2024-01-06 06:26:45,287 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42679
2024-01-06 06:26:45,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39850
2024-01-06 06:26:45,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,288 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:45,289 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,289 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,290 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:45,290 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:45,291 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,292 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:45,297 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,297 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,298 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,298 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,298 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,298 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,299 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,299 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:45,303 - distributed.scheduler - INFO - Remove client Client-8c7f1c94-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:45,303 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39764; closing.
2024-01-06 06:26:45,303 - distributed.scheduler - INFO - Remove client Client-8c7f1c94-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:45,303 - distributed.scheduler - INFO - Close client connection: Client-8c7f1c94-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:45,304 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42723'. Reason: nanny-close
2024-01-06 06:26:45,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41715'. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37493'. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45259. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45793'. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41883. Reason: nanny-close
2024-01-06 06:26:45,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46177'. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38157. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40135'. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43575'. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44743. Reason: nanny-close
2024-01-06 06:26:45,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44877'. Reason: nanny-close
2024-01-06 06:26:45,308 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,308 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33217. Reason: nanny-close
2024-01-06 06:26:45,308 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,309 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32807. Reason: nanny-close
2024-01-06 06:26:45,309 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39824; closing.
2024-01-06 06:26:45,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,309 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45259', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3095334')
2024-01-06 06:26:45,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,310 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39812; closing.
2024-01-06 06:26:45,310 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39784; closing.
2024-01-06 06:26:45,310 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,310 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,310 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,310 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38157', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3108268')
2024-01-06 06:26:45,311 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,311 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3111942')
2024-01-06 06:26:45,311 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,311 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,311 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39838; closing.
2024-01-06 06:26:45,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39798; closing.
2024-01-06 06:26:45,313 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,313 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,314 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46661. Reason: nanny-close
2024-01-06 06:26:45,312 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39812>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-06 06:26:45,314 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39784>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-06 06:26:45,315 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33217', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3149757')
2024-01-06 06:26:45,315 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44743', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.315337')
2024-01-06 06:26:45,315 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39832; closing.
2024-01-06 06:26:45,316 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.316043')
2024-01-06 06:26:45,316 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,317 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39852; closing.
2024-01-06 06:26:45,317 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46661', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3176317')
2024-01-06 06:26:45,318 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:45,323 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:45,324 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42679. Reason: nanny-close
2024-01-06 06:26:45,327 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39850; closing.
2024-01-06 06:26:45,327 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:45,327 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42679', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522405.3273094')
2024-01-06 06:26:45,327 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:26:45,328 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:46,371 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:26:46,371 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:26:46,372 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:26:46,373 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:26:46,373 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-06 06:26:48,716 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:48,721 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39461 instead
  warnings.warn(
2024-01-06 06:26:48,725 - distributed.scheduler - INFO - State start
2024-01-06 06:26:48,750 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:48,751 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:26:48,751 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39461/status
2024-01-06 06:26:48,752 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:26:48,793 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46405'
2024-01-06 06:26:48,808 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42425'
2024-01-06 06:26:48,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43699'
2024-01-06 06:26:48,824 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46301'
2024-01-06 06:26:48,832 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39399'
2024-01-06 06:26:48,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45487'
2024-01-06 06:26:48,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46631'
2024-01-06 06:26:48,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41811'
2024-01-06 06:26:48,982 - distributed.scheduler - INFO - Receive client connection: Client-912c7995-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:48,998 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40006
2024-01-06 06:26:50,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,877 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,878 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33673
2024-01-06 06:26:50,878 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33673
2024-01-06 06:26:50,878 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45959
2024-01-06 06:26:50,878 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,878 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,878 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,878 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,878 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-glfysegp
2024-01-06 06:26:50,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,878 - distributed.worker - INFO - Starting Worker plugin PreImport-8e15811e-7500-47c1-aadb-cf78da520a5f
2024-01-06 06:26:50,878 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5e4e7fb-ad99-4c2d-9c07-23da80b37cf3
2024-01-06 06:26:50,879 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbf40b41-094e-445d-a905-6d5ec548b593
2024-01-06 06:26:50,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,880 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36687
2024-01-06 06:26:50,880 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36687
2024-01-06 06:26:50,880 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37581
2024-01-06 06:26:50,880 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,880 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,880 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,880 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,880 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9g531gyw
2024-01-06 06:26:50,880 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2183365f-4e94-4f8b-9602-707303de15f4
2024-01-06 06:26:50,880 - distributed.worker - INFO - Starting Worker plugin PreImport-b44c35aa-7d86-4e0b-bfcc-637f66837bec
2024-01-06 06:26:50,880 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5a2319f-21b1-4077-9f8a-4ff3b05f2a82
2024-01-06 06:26:50,881 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,882 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33603
2024-01-06 06:26:50,882 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33603
2024-01-06 06:26:50,882 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41255
2024-01-06 06:26:50,882 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,882 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,882 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,882 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,882 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,883 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-34pr80hu
2024-01-06 06:26:50,883 - distributed.worker - INFO - Starting Worker plugin PreImport-4fb53b00-cb43-46c3-9621-53a981a4ecba
2024-01-06 06:26:50,883 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3e451cfe-934a-46d4-b33c-90a9ca9467b8
2024-01-06 06:26:50,883 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c50a1cdb-13e3-455a-8cc1-bed5bae10130
2024-01-06 06:26:50,883 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44525
2024-01-06 06:26:50,883 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44525
2024-01-06 06:26:50,883 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40061
2024-01-06 06:26:50,883 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,883 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,883 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,884 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,884 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gl9evdvc
2024-01-06 06:26:50,884 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d320f79e-0ba7-43a1-860c-28e5bc51abed
2024-01-06 06:26:50,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,898 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,899 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39783
2024-01-06 06:26:50,899 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39783
2024-01-06 06:26:50,899 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34981
2024-01-06 06:26:50,899 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,899 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,899 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,901 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,901 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3gf6w0ya
2024-01-06 06:26:50,901 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4799b5c3-cb21-498d-b0e8-793365cd19bb
2024-01-06 06:26:50,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:50,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:50,904 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44033
2024-01-06 06:26:50,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44033
2024-01-06 06:26:50,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45749
2024-01-06 06:26:50,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,905 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,905 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,905 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0revnvbe
2024-01-06 06:26:50,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41235
2024-01-06 06:26:50,905 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a38bf535-6ae1-4eed-b34c-8cbbfb8100a8
2024-01-06 06:26:50,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:50,905 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41235
2024-01-06 06:26:50,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38111
2024-01-06 06:26:50,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,906 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,906 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kumd3afc
2024-01-06 06:26:50,906 - distributed.worker - INFO - Starting Worker plugin PreImport-daf8a28a-ec6c-4e2b-a6a6-7fb017622303
2024-01-06 06:26:50,906 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1e5cbb91-1929-4ca2-8a61-9f1183af084f
2024-01-06 06:26:50,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-84ed2a97-29cd-4271-ad70-7499c366e902
2024-01-06 06:26:50,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43995
2024-01-06 06:26:50,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43995
2024-01-06 06:26:50,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44957
2024-01-06 06:26:50,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:50,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:50,907 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:50,907 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:50,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_htv9qg1
2024-01-06 06:26:50,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8c1d920-7995-4e03-ad50-33ff7550be34
2024-01-06 06:26:53,236 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,260 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41235', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,261 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41235
2024-01-06 06:26:53,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43654
2024-01-06 06:26:53,262 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,262 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,263 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,264 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,382 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,411 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36687', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,411 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36687
2024-01-06 06:26:53,412 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43664
2024-01-06 06:26:53,412 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,413 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,413 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,415 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,419 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bb4bf0b0-ae10-4065-aaf2-34eafa024bfe
2024-01-06 06:26:53,420 - distributed.worker - INFO - Starting Worker plugin PreImport-fbcd463c-8a81-4a7f-b45d-3ec0424b980d
2024-01-06 06:26:53,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,425 - distributed.worker - INFO - Starting Worker plugin PreImport-f8921056-b32a-41ba-ad05-2a59eb229432
2024-01-06 06:26:53,426 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe10925b-c9b1-4094-80e1-522ab7d8775b
2024-01-06 06:26:53,426 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,426 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,435 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,442 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a34a2245-4da4-4e96-8f8a-3ea590990cd9
2024-01-06 06:26:53,442 - distributed.worker - INFO - Starting Worker plugin PreImport-13b8a633-6bb5-4cd8-be3e-6b96a0abba20
2024-01-06 06:26:53,442 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,444 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-36b93301-6791-4177-80c0-067664b4cf6c
2024-01-06 06:26:53,445 - distributed.worker - INFO - Starting Worker plugin PreImport-546adc90-c644-45ba-9d19-308db70b2540
2024-01-06 06:26:53,446 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,447 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44525', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,447 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44525
2024-01-06 06:26:53,447 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43678
2024-01-06 06:26:53,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,449 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,449 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,452 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33603', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33603
2024-01-06 06:26:53,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43692
2024-01-06 06:26:53,453 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,454 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,454 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43995', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,468 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43995
2024-01-06 06:26:53,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43712
2024-01-06 06:26:53,469 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39783', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,469 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39783
2024-01-06 06:26:53,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43700
2024-01-06 06:26:53,470 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,470 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,470 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33673', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,470 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33673
2024-01-06 06:26:53,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43710
2024-01-06 06:26:53,471 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,472 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,472 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,473 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,473 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,474 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,480 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44033', status: init, memory: 0, processing: 0>
2024-01-06 06:26:53,481 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44033
2024-01-06 06:26:53,481 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43724
2024-01-06 06:26:53,482 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:26:53,484 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:26:53,484 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:53,486 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:26:53,554 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:26:53,560 - distributed.scheduler - INFO - Remove client Client-912c7995-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:53,560 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40006; closing.
2024-01-06 06:26:53,560 - distributed.scheduler - INFO - Remove client Client-912c7995-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:53,560 - distributed.scheduler - INFO - Close client connection: Client-912c7995-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:53,561 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46405'. Reason: nanny-close
2024-01-06 06:26:53,562 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,562 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42425'. Reason: nanny-close
2024-01-06 06:26:53,562 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,562 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43699'. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36687. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46301'. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33673. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39399'. Reason: nanny-close
2024-01-06 06:26:53,563 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44525. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45487'. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33603. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46631'. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,564 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44033. Reason: nanny-close
2024-01-06 06:26:53,565 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41811'. Reason: nanny-close
2024-01-06 06:26:53,565 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,565 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:26:53,565 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43664; closing.
2024-01-06 06:26:53,565 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39783. Reason: nanny-close
2024-01-06 06:26:53,565 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,565 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43995. Reason: nanny-close
2024-01-06 06:26:53,565 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36687', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.5656788')
2024-01-06 06:26:53,565 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,565 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,566 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41235. Reason: nanny-close
2024-01-06 06:26:53,566 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,566 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,566 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43692; closing.
2024-01-06 06:26:53,566 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43678; closing.
2024-01-06 06:26:53,567 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,567 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,567 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,567 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,567 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,567 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33603', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.5678957')
2024-01-06 06:26:53,568 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44525', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.568267')
2024-01-06 06:26:53,568 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,568 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43710; closing.
2024-01-06 06:26:53,568 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,568 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:26:53,569 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,569 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43692>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43692>: Stream is closed
2024-01-06 06:26:53,570 - distributed.nanny - INFO - Worker closed
2024-01-06 06:26:53,571 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33673', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.57094')
2024-01-06 06:26:53,571 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43724; closing.
2024-01-06 06:26:53,571 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43712; closing.
2024-01-06 06:26:53,572 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.5720637')
2024-01-06 06:26:53,572 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43995', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.5724196')
2024-01-06 06:26:53,572 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43700; closing.
2024-01-06 06:26:53,572 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43654; closing.
2024-01-06 06:26:53,573 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39783', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.5733347')
2024-01-06 06:26:53,573 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41235', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522413.573689')
2024-01-06 06:26:53,573 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:26:54,477 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:26:54,478 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:26:54,478 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:26:54,479 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:26:54,480 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-06 06:26:56,956 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:56,961 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:26:56,965 - distributed.scheduler - INFO - State start
2024-01-06 06:26:56,988 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:26:56,989 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:26:56,989 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:26:56,990 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:26:57,095 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37835'
2024-01-06 06:26:57,115 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36343'
2024-01-06 06:26:57,123 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45601'
2024-01-06 06:26:57,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39421'
2024-01-06 06:26:57,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34509'
2024-01-06 06:26:57,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38739'
2024-01-06 06:26:57,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45471'
2024-01-06 06:26:57,180 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33489'
2024-01-06 06:26:57,875 - distributed.scheduler - INFO - Receive client connection: Client-9621ca56-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:26:57,890 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43912
2024-01-06 06:26:59,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,026 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39871
2024-01-06 06:26:59,026 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40325
2024-01-06 06:26:59,026 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39871
2024-01-06 06:26:59,027 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40325
2024-01-06 06:26:59,027 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43285
2024-01-06 06:26:59,027 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42213
2024-01-06 06:26:59,027 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,027 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,027 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,027 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,027 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,027 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,027 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,027 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,027 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mtxtl21c
2024-01-06 06:26:59,027 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fcojw2nq
2024-01-06 06:26:59,027 - distributed.worker - INFO - Starting Worker plugin PreImport-2b4eac31-839e-4b04-ae62-1b0b63db45c1
2024-01-06 06:26:59,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff4b8b21-3a7c-41dd-9117-02bdbfcc842e
2024-01-06 06:26:59,027 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7eed9618-7a15-4f39-b95a-b08273321d16
2024-01-06 06:26:59,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0877f99c-3001-403a-bc61-d540d4e0fcd7
2024-01-06 06:26:59,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,078 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,079 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,079 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45853
2024-01-06 06:26:59,079 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45853
2024-01-06 06:26:59,079 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39049
2024-01-06 06:26:59,080 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,080 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,080 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,080 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,080 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ghtide_2
2024-01-06 06:26:59,080 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0e4f6271-c698-487f-9e2b-70fb96e26852
2024-01-06 06:26:59,080 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45485
2024-01-06 06:26:59,080 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45485
2024-01-06 06:26:59,080 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36825
2024-01-06 06:26:59,080 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,080 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,080 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j9q6zncq
2024-01-06 06:26:59,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,081 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6bca0ce9-d345-45aa-97fc-d512c9dce396
2024-01-06 06:26:59,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,086 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45403
2024-01-06 06:26:59,086 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45403
2024-01-06 06:26:59,086 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36545
2024-01-06 06:26:59,086 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,087 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,087 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,087 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_c0i82wo
2024-01-06 06:26:59,087 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5a3c9c80-8abe-4a25-9958-0562bc3a687c
2024-01-06 06:26:59,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,115 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,116 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33341
2024-01-06 06:26:59,116 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33341
2024-01-06 06:26:59,116 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35997
2024-01-06 06:26:59,117 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,117 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,117 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,117 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,117 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-92_l8hv0
2024-01-06 06:26:59,117 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,117 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb1ce9e1-9e3f-4817-bf15-a47f3ac7d56f
2024-01-06 06:26:59,118 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42857
2024-01-06 06:26:59,118 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42857
2024-01-06 06:26:59,118 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33979
2024-01-06 06:26:59,118 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,118 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:26:59,118 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,118 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:26:59,118 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5qqjfy45
2024-01-06 06:26:59,118 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36875655-9fe5-4c50-be13-3e376ac98ac9
2024-01-06 06:26:59,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:26:59,123 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43389
2024-01-06 06:26:59,124 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43389
2024-01-06 06:26:59,124 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38565
2024-01-06 06:26:59,124 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:26:59,124 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:26:59,124 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:26:59,124 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:26:59,124 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j34pzs9e
2024-01-06 06:26:59,124 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef7bd02b-4e91-4283-9d51-8303cc52714c
2024-01-06 06:26:59,127 - distributed.worker - INFO - Starting Worker plugin PreImport-688cedd8-2ab1-47de-be34-f9d588911364
2024-01-06 06:26:59,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b270449-fd85-41b6-88e3-b4d3313ed9de
2024-01-06 06:27:01,171 - distributed.worker - INFO - Starting Worker plugin PreImport-c4145f2b-bc51-4b9b-a466-ef474f79f16f
2024-01-06 06:27:01,172 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d62908e0-b24a-409a-927a-e690aac50d56
2024-01-06 06:27:01,172 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,197 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40325', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,199 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40325
2024-01-06 06:27:01,199 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34676
2024-01-06 06:27:01,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,201 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,201 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,202 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,235 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,243 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11d26c93-334e-4e5e-ba1e-7803941c9c09
2024-01-06 06:27:01,244 - distributed.worker - INFO - Starting Worker plugin PreImport-5938ed72-2e39-464f-bebe-a80eb254933d
2024-01-06 06:27:01,245 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,267 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37b5fec3-780a-4cea-9116-b5e2d257e36f
2024-01-06 06:27:01,268 - distributed.worker - INFO - Starting Worker plugin PreImport-a2ca8e9f-940b-417f-94c9-e860fd19a799
2024-01-06 06:27:01,269 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,274 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39871', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,275 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39871
2024-01-06 06:27:01,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34692
2024-01-06 06:27:01,276 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,277 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,277 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,284 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45853', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,285 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45853
2024-01-06 06:27:01,285 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34704
2024-01-06 06:27:01,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,288 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,288 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,305 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45485', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,306 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45485
2024-01-06 06:27:01,306 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34716
2024-01-06 06:27:01,307 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,308 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,308 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-67d37632-7caa-4116-a7c8-8a269bc19a2e
2024-01-06 06:27:01,308 - distributed.worker - INFO - Starting Worker plugin PreImport-9c7d4d6e-c5e6-4a72-92a3-0fb2f9c95ebd
2024-01-06 06:27:01,309 - distributed.worker - INFO - Starting Worker plugin PreImport-87ec7530-6692-447a-85e5-c8c355898860
2024-01-06 06:27:01,309 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9b4308a9-63e6-409f-8906-4257f46c45ff
2024-01-06 06:27:01,309 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,309 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,309 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,314 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61d11f52-db8f-4612-8ad6-c1bd582018ed
2024-01-06 06:27:01,314 - distributed.worker - INFO - Starting Worker plugin PreImport-d9f35218-7a14-4e32-8c28-ff910beedac9
2024-01-06 06:27:01,315 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,333 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45403', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,334 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45403
2024-01-06 06:27:01,334 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34730
2024-01-06 06:27:01,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,336 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,336 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,336 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42857', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,336 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42857
2024-01-06 06:27:01,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34740
2024-01-06 06:27:01,337 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,337 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,338 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,338 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,339 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,340 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33341', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,341 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33341
2024-01-06 06:27:01,341 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34764
2024-01-06 06:27:01,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,342 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,342 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,344 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,344 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43389', status: init, memory: 0, processing: 0>
2024-01-06 06:27:01,345 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43389
2024-01-06 06:27:01,345 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34754
2024-01-06 06:27:01,346 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:01,347 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:01,347 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:01,349 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:01,371 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,371 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,371 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,372 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,372 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,372 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,372 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,372 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,383 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,384 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,384 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:01,392 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:01,394 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:01,397 - distributed.scheduler - INFO - Remove client Client-9621ca56-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:01,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43912; closing.
2024-01-06 06:27:01,397 - distributed.scheduler - INFO - Remove client Client-9621ca56-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:01,398 - distributed.scheduler - INFO - Close client connection: Client-9621ca56-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:01,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37835'. Reason: nanny-close
2024-01-06 06:27:01,399 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36343'. Reason: nanny-close
2024-01-06 06:27:01,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45601'. Reason: nanny-close
2024-01-06 06:27:01,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39421'. Reason: nanny-close
2024-01-06 06:27:01,400 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39871. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45485. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34509'. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40325. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38739'. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45403. Reason: nanny-close
2024-01-06 06:27:01,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45471'. Reason: nanny-close
2024-01-06 06:27:01,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,402 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43389. Reason: nanny-close
2024-01-06 06:27:01,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33489'. Reason: nanny-close
2024-01-06 06:27:01,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:01,403 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45853. Reason: nanny-close
2024-01-06 06:27:01,403 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42857. Reason: nanny-close
2024-01-06 06:27:01,403 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,403 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34692; closing.
2024-01-06 06:27:01,403 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,403 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,403 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39871', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.403509')
2024-01-06 06:27:01,403 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,403 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33341. Reason: nanny-close
2024-01-06 06:27:01,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34676; closing.
2024-01-06 06:27:01,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34716; closing.
2024-01-06 06:27:01,404 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,404 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,404 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,405 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,405 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,405 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,405 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,405 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:01,405 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40325', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4058332')
2024-01-06 06:27:01,406 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,406 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45485', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4061909')
2024-01-06 06:27:01,406 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34730; closing.
2024-01-06 06:27:01,406 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,406 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,407 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:01,407 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45403', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4077039')
2024-01-06 06:27:01,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34754; closing.
2024-01-06 06:27:01,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34740; closing.
2024-01-06 06:27:01,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34704; closing.
2024-01-06 06:27:01,409 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43389', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4090123')
2024-01-06 06:27:01,409 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42857', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4093866')
2024-01-06 06:27:01,409 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45853', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4097216')
2024-01-06 06:27:01,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34764; closing.
2024-01-06 06:27:01,410 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33341', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522421.4105303')
2024-01-06 06:27:01,410 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:02,566 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:02,566 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:02,567 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:02,568 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:02,569 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-06 06:27:05,002 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:05,006 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:05,010 - distributed.scheduler - INFO - State start
2024-01-06 06:27:05,032 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:05,033 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:05,034 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:05,034 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:05,330 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46453'
2024-01-06 06:27:05,350 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35789'
2024-01-06 06:27:05,358 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33225'
2024-01-06 06:27:05,373 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33151'
2024-01-06 06:27:05,376 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36149'
2024-01-06 06:27:05,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33429'
2024-01-06 06:27:05,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39149'
2024-01-06 06:27:05,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39883'
2024-01-06 06:27:07,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,268 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37953
2024-01-06 06:27:07,268 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37953
2024-01-06 06:27:07,268 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34043
2024-01-06 06:27:07,268 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,268 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,268 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,268 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,268 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hxta_i0i
2024-01-06 06:27:07,268 - distributed.worker - INFO - Starting Worker plugin RMMSetup-45282be1-9191-497f-ac29-3b0f1cb8a07c
2024-01-06 06:27:07,415 - distributed.scheduler - INFO - Receive client connection: Client-9ae76c4e-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:07,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34954
2024-01-06 06:27:07,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,569 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,570 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39769
2024-01-06 06:27:07,570 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39769
2024-01-06 06:27:07,570 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46299
2024-01-06 06:27:07,570 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,570 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,570 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,570 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,570 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j1gypr8e
2024-01-06 06:27:07,570 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,571 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,571 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5341c491-1e51-4f7e-9ded-55f13cbf8274
2024-01-06 06:27:07,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:07,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:07,572 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38813
2024-01-06 06:27:07,572 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37689
2024-01-06 06:27:07,572 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38813
2024-01-06 06:27:07,572 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37689
2024-01-06 06:27:07,572 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41391
2024-01-06 06:27:07,572 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44911
2024-01-06 06:27:07,572 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,572 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,572 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,572 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,572 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,572 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,572 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i424rxsh
2024-01-06 06:27:07,572 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ph7xcdpj
2024-01-06 06:27:07,572 - distributed.worker - INFO - Starting Worker plugin PreImport-3a982da2-7ce3-4ce0-a89a-f57f394447a1
2024-01-06 06:27:07,572 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6be88509-4a17-4d57-ae89-bc59a335e9ba
2024-01-06 06:27:07,572 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff68fe1c-a362-4ae5-b750-03c866dc9a96
2024-01-06 06:27:07,573 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d4e6ffbc-b55d-4d4b-a0ca-8ea6a18cfa92
2024-01-06 06:27:07,573 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,574 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35899
2024-01-06 06:27:07,574 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35899
2024-01-06 06:27:07,575 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38471
2024-01-06 06:27:07,575 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,575 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,575 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,575 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,575 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c_jcjfq4
2024-01-06 06:27:07,575 - distributed.worker - INFO - Starting Worker plugin RMMSetup-35e7676b-2d21-4339-bc4a-1409c1dd470f
2024-01-06 06:27:07,576 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,576 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,576 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:07,577 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46331
2024-01-06 06:27:07,577 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38063
2024-01-06 06:27:07,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46331
2024-01-06 06:27:07,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38063
2024-01-06 06:27:07,577 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45707
2024-01-06 06:27:07,577 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36511
2024-01-06 06:27:07,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,577 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33983
2024-01-06 06:27:07,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,577 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,577 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33983
2024-01-06 06:27:07,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,577 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40657
2024-01-06 06:27:07,577 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p2y5kw2r
2024-01-06 06:27:07,577 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g5knmqaz
2024-01-06 06:27:07,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:07,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:07,577 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:07,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:07,578 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a51wq3p4
2024-01-06 06:27:07,578 - distributed.worker - INFO - Starting Worker plugin PreImport-1d3106d8-fc86-4f11-98e2-27c08ff6a6c5
2024-01-06 06:27:07,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b15c150-7180-4245-ae0c-cb9eead9cb65
2024-01-06 06:27:07,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f531c750-a46d-4bf2-88ca-bf6e532d6b5f
2024-01-06 06:27:07,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-476f2120-7f15-4381-8b2e-3781295ff8cf
2024-01-06 06:27:07,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95ba3bc1-a3bf-44d1-a036-ef72cc69589a
2024-01-06 06:27:09,379 - distributed.worker - INFO - Starting Worker plugin PreImport-66c47719-c9b3-4188-9a98-d8b924df81dc
2024-01-06 06:27:09,381 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8d121261-4e67-4010-8930-5151befcf711
2024-01-06 06:27:09,383 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,417 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37953', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,418 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37953
2024-01-06 06:27:09,418 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34976
2024-01-06 06:27:09,419 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,420 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,422 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,568 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b85d255c-446c-46b6-91d7-d2619dab18ad
2024-01-06 06:27:09,569 - distributed.worker - INFO - Starting Worker plugin PreImport-b03ea351-81fd-43db-bac4-9a4ade6cf466
2024-01-06 06:27:09,570 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,577 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28f37859-58c9-434e-980d-ec3c95c0e9ec
2024-01-06 06:27:09,578 - distributed.worker - INFO - Starting Worker plugin PreImport-c7c64e8a-119a-4387-bc06-374c685ee3c5
2024-01-06 06:27:09,578 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,590 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,596 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,605 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39769', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,606 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39769
2024-01-06 06:27:09,606 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34988
2024-01-06 06:27:09,607 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37689', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,607 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,608 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37689
2024-01-06 06:27:09,608 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,608 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34986
2024-01-06 06:27:09,608 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,609 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,610 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,610 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,616 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46331', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,616 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46331
2024-01-06 06:27:09,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34998
2024-01-06 06:27:09,617 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,618 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42eedc31-0786-43f6-98c0-ceafb2ea9167
2024-01-06 06:27:09,618 - distributed.worker - INFO - Starting Worker plugin PreImport-7fd3d8d3-7157-4e89-af8b-ad51825c8aeb
2024-01-06 06:27:09,618 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,618 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,619 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,619 - distributed.worker - INFO - Starting Worker plugin PreImport-f70382ce-070a-408e-aa2b-f91ba4c7b18a
2024-01-06 06:27:09,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3cef7f2-6970-4ac1-8d81-9feaf05c9c80
2024-01-06 06:27:09,620 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,622 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,622 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68ff9448-0c41-4ef2-9dc0-da8208cf445b
2024-01-06 06:27:09,623 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38813', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,624 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38813
2024-01-06 06:27:09,624 - distributed.worker - INFO - Starting Worker plugin PreImport-2a0e2e4c-3dc3-46bb-9d3c-4f20db081c68
2024-01-06 06:27:09,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35008
2024-01-06 06:27:09,624 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,625 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,625 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,640 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33983', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,641 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33983
2024-01-06 06:27:09,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35024
2024-01-06 06:27:09,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,642 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,643 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,656 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35899', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,657 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35899
2024-01-06 06:27:09,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35054
2024-01-06 06:27:09,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,659 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,659 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,663 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38063', status: init, memory: 0, processing: 0>
2024-01-06 06:27:09,663 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38063
2024-01-06 06:27:09,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35040
2024-01-06 06:27:09,665 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:09,666 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:09,667 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:09,669 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:09,712 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,713 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,726 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,726 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,727 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:09,734 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,736 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:09,738 - distributed.scheduler - INFO - Remove client Client-9ae76c4e-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:09,738 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34954; closing.
2024-01-06 06:27:09,739 - distributed.scheduler - INFO - Remove client Client-9ae76c4e-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:09,739 - distributed.scheduler - INFO - Close client connection: Client-9ae76c4e-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:09,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46453'. Reason: nanny-close
2024-01-06 06:27:09,740 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35789'. Reason: nanny-close
2024-01-06 06:27:09,741 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33225'. Reason: nanny-close
2024-01-06 06:27:09,741 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,741 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37953. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33151'. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35899. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36149'. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46331. Reason: nanny-close
2024-01-06 06:27:09,742 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33429'. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39769. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39149'. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38063. Reason: nanny-close
2024-01-06 06:27:09,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39883'. Reason: nanny-close
2024-01-06 06:27:09,744 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,744 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:09,744 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37689. Reason: nanny-close
2024-01-06 06:27:09,744 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34976; closing.
2024-01-06 06:27:09,744 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38813. Reason: nanny-close
2024-01-06 06:27:09,744 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,744 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,744 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37953', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7446923')
2024-01-06 06:27:09,745 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,745 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33983. Reason: nanny-close
2024-01-06 06:27:09,745 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34998; closing.
2024-01-06 06:27:09,745 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35054; closing.
2024-01-06 06:27:09,745 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,746 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,746 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,746 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,746 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,746 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,746 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,746 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46331', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7468905')
2024-01-06 06:27:09,747 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:09,747 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35899', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7473009')
2024-01-06 06:27:09,747 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34988; closing.
2024-01-06 06:27:09,747 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,747 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,748 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,748 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:09,748 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39769', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7488368')
2024-01-06 06:27:09,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35040; closing.
2024-01-06 06:27:09,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35008; closing.
2024-01-06 06:27:09,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34986; closing.
2024-01-06 06:27:09,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38063', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7500386')
2024-01-06 06:27:09,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38813', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.750369')
2024-01-06 06:27:09,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.750677')
2024-01-06 06:27:09,751 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35024; closing.
2024-01-06 06:27:09,751 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33983', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522429.7515125')
2024-01-06 06:27:09,751 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:10,856 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:10,857 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:10,857 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:10,858 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:10,859 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-06 06:27:13,023 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:13,027 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43931 instead
  warnings.warn(
2024-01-06 06:27:13,031 - distributed.scheduler - INFO - State start
2024-01-06 06:27:13,052 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:13,053 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:13,053 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43931/status
2024-01-06 06:27:13,053 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:13,164 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41795'
2024-01-06 06:27:13,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39237'
2024-01-06 06:27:13,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39255'
2024-01-06 06:27:13,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43935'
2024-01-06 06:27:13,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45557'
2024-01-06 06:27:13,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35483'
2024-01-06 06:27:13,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36257'
2024-01-06 06:27:13,234 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44075'
2024-01-06 06:27:15,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,185 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,186 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35231
2024-01-06 06:27:15,186 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35231
2024-01-06 06:27:15,186 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46545
2024-01-06 06:27:15,186 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,187 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,187 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,187 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,187 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-142e8zvu
2024-01-06 06:27:15,187 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01a73c60-295c-40cd-b05e-9530bc264b38
2024-01-06 06:27:15,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,350 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,351 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44365
2024-01-06 06:27:15,351 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44365
2024-01-06 06:27:15,351 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36051
2024-01-06 06:27:15,351 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,351 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,351 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,351 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,351 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i964ldz8
2024-01-06 06:27:15,351 - distributed.worker - INFO - Starting Worker plugin RMMSetup-86e51edb-a91c-445b-873d-0c7cddc9b98a
2024-01-06 06:27:15,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,357 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,358 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46619
2024-01-06 06:27:15,358 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46619
2024-01-06 06:27:15,358 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34413
2024-01-06 06:27:15,358 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,358 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,359 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,359 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,359 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fv0oy1no
2024-01-06 06:27:15,359 - distributed.worker - INFO - Starting Worker plugin PreImport-3b025470-8b19-478b-ac69-1468e2a746ab
2024-01-06 06:27:15,359 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab1d2d4d-0ee4-4411-b4fe-21b52229f926
2024-01-06 06:27:15,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,359 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae33d92e-c92f-4163-9ee1-0065c2588916
2024-01-06 06:27:15,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,365 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44083
2024-01-06 06:27:15,365 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44083
2024-01-06 06:27:15,365 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39747
2024-01-06 06:27:15,365 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,365 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,365 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,365 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:15,365 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d_b_lh4g
2024-01-06 06:27:15,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:15,365 - distributed.worker - INFO - Starting Worker plugin RMMSetup-09b75715-817f-41e7-abce-d6950b3dbcc8
2024-01-06 06:27:15,366 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35817
2024-01-06 06:27:15,367 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35817
2024-01-06 06:27:15,367 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34077
2024-01-06 06:27:15,367 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,367 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,367 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,367 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,367 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p5cs9uaw
2024-01-06 06:27:15,368 - distributed.worker - INFO - Starting Worker plugin PreImport-3ba90e32-db13-4736-903c-4cbd3551b12c
2024-01-06 06:27:15,368 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f995a2ad-ce77-49b1-8a98-050a474d37fe
2024-01-06 06:27:15,368 - distributed.worker - INFO - Starting Worker plugin RMMSetup-243eda27-5235-4e92-9c35-5b0f689d0ed9
2024-01-06 06:27:15,368 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,369 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,369 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:15,369 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35689
2024-01-06 06:27:15,369 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35689
2024-01-06 06:27:15,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37451
2024-01-06 06:27:15,369 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,369 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,370 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,370 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,370 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o18rhdsm
2024-01-06 06:27:15,370 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33949
2024-01-06 06:27:15,370 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33949
2024-01-06 06:27:15,370 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36537
2024-01-06 06:27:15,370 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9afd61ef-b538-45b2-813a-a9fad66a3410
2024-01-06 06:27:15,370 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,370 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,370 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33169
2024-01-06 06:27:15,370 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,370 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33169
2024-01-06 06:27:15,370 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,370 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46727
2024-01-06 06:27:15,370 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-smwht168
2024-01-06 06:27:15,370 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:15,370 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:15,370 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:15,370 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:15,370 - distributed.worker - INFO - Starting Worker plugin RMMSetup-59176063-360e-4fb4-8901-0308e84303c2
2024-01-06 06:27:15,370 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kk2ttmno
2024-01-06 06:27:15,371 - distributed.worker - INFO - Starting Worker plugin PreImport-509e0467-758e-4a7c-ab6e-76f797755b87
2024-01-06 06:27:15,371 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51eae8bf-b635-4605-a238-48541e7c0dbc
2024-01-06 06:27:15,371 - distributed.worker - INFO - Starting Worker plugin RMMSetup-180cf4ba-1bb9-48b6-912e-8e96b8519974
2024-01-06 06:27:16,848 - distributed.scheduler - INFO - Receive client connection: Client-9fc27562-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:16,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59574
2024-01-06 06:27:18,937 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c77a1119-e3fa-4e0d-b074-14a0d908868b
2024-01-06 06:27:18,938 - distributed.worker - INFO - Starting Worker plugin PreImport-2cec06a9-61b5-4459-811e-0417992f0c82
2024-01-06 06:27:18,940 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:18,973 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44365', status: init, memory: 0, processing: 0>
2024-01-06 06:27:18,975 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44365
2024-01-06 06:27:18,975 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59598
2024-01-06 06:27:18,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:18,977 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:18,977 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:18,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:18,989 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc82e6bf-3f42-4acd-a8b6-fb0b5cb73da5
2024-01-06 06:27:18,990 - distributed.worker - INFO - Starting Worker plugin PreImport-4418400f-42cb-4268-8981-baeee3058726
2024-01-06 06:27:18,995 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,034 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35231', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,035 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35231
2024-01-06 06:27:19,035 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59608
2024-01-06 06:27:19,037 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,038 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,038 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,062 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,073 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-20b5f915-d5d0-48da-9287-6391b5d64e89
2024-01-06 06:27:19,073 - distributed.worker - INFO - Starting Worker plugin PreImport-9d9d93dc-5eae-4b33-ab4d-91dd52d4081d
2024-01-06 06:27:19,074 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,085 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33169', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,086 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33169
2024-01-06 06:27:19,085 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e36215e6-55de-4df7-8162-48876b45c3ca
2024-01-06 06:27:19,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59616
2024-01-06 06:27:19,086 - distributed.worker - INFO - Starting Worker plugin PreImport-2ccad066-245e-433f-89b2-37459d74efdf
2024-01-06 06:27:19,086 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,087 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,087 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,089 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,097 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44083', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,098 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44083
2024-01-06 06:27:19,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59626
2024-01-06 06:27:19,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,100 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,100 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,102 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,108 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,108 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35689', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,109 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35689
2024-01-06 06:27:19,109 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59634
2024-01-06 06:27:19,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,111 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,111 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,112 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,112 - distributed.worker - INFO - Starting Worker plugin PreImport-4e4c368d-9996-4245-b7d9-434555de4a05
2024-01-06 06:27:19,112 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,112 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2233bf5b-6240-412c-b61d-daa37fcb0394
2024-01-06 06:27:19,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,135 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35817', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,136 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35817
2024-01-06 06:27:19,136 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59648
2024-01-06 06:27:19,137 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,138 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,138 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,148 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46619', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,149 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46619
2024-01-06 06:27:19,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59638
2024-01-06 06:27:19,151 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33949', status: init, memory: 0, processing: 0>
2024-01-06 06:27:19,151 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33949
2024-01-06 06:27:19,151 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59656
2024-01-06 06:27:19,152 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:19,153 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,153 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,154 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:19,154 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:19,156 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,156 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:19,237 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,238 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,239 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:19,243 - distributed.scheduler - INFO - Remove client Client-9fc27562-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:19,243 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59574; closing.
2024-01-06 06:27:19,244 - distributed.scheduler - INFO - Remove client Client-9fc27562-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:19,244 - distributed.scheduler - INFO - Close client connection: Client-9fc27562-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:19,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41795'. Reason: nanny-close
2024-01-06 06:27:19,245 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39237'. Reason: nanny-close
2024-01-06 06:27:19,246 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39255'. Reason: nanny-close
2024-01-06 06:27:19,246 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35231. Reason: nanny-close
2024-01-06 06:27:19,246 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43935'. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46619. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45557'. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44083. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35483'. Reason: nanny-close
2024-01-06 06:27:19,247 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35817. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36257'. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44365. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44075'. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33949. Reason: nanny-close
2024-01-06 06:27:19,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:19,249 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35689. Reason: nanny-close
2024-01-06 06:27:19,249 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59608; closing.
2024-01-06 06:27:19,249 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,249 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35231', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.2495596')
2024-01-06 06:27:19,249 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33169. Reason: nanny-close
2024-01-06 06:27:19,250 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59626; closing.
2024-01-06 06:27:19,250 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,250 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44083', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.2506795')
2024-01-06 06:27:19,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,250 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,250 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,251 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59638; closing.
2024-01-06 06:27:19,251 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,251 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:19,252 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.252044')
2024-01-06 06:27:19,252 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,252 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59648; closing.
2024-01-06 06:27:19,252 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,252 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,252 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:19,253 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:59626>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-06 06:27:19,254 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.2546687')
2024-01-06 06:27:19,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59598; closing.
2024-01-06 06:27:19,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59656; closing.
2024-01-06 06:27:19,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59634; closing.
2024-01-06 06:27:19,255 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44365', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.255827')
2024-01-06 06:27:19,256 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33949', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.256177')
2024-01-06 06:27:19,256 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.2565165')
2024-01-06 06:27:19,256 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59616; closing.
2024-01-06 06:27:19,257 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33169', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522439.2572744')
2024-01-06 06:27:19,257 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:20,161 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:20,161 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:20,162 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:20,163 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:20,164 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-06 06:27:22,523 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:22,527 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:22,531 - distributed.scheduler - INFO - State start
2024-01-06 06:27:22,562 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:22,563 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:22,564 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:22,565 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:22,615 - distributed.scheduler - INFO - Receive client connection: Client-a55bbbf6-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:22,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53668
2024-01-06 06:27:22,771 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44415'
2024-01-06 06:27:24,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:24,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:25,104 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:25,105 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43465
2024-01-06 06:27:25,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43465
2024-01-06 06:27:25,105 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-06 06:27:25,105 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:25,105 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:25,105 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:25,106 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:27:25,106 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_e477vqn
2024-01-06 06:27:25,106 - distributed.worker - INFO - Starting Worker plugin RMMSetup-18ab748e-de98-4771-bb4d-871210ef916f
2024-01-06 06:27:25,106 - distributed.worker - INFO - Starting Worker plugin PreImport-70cf7353-c77d-4144-b39b-460f872eb9d1
2024-01-06 06:27:25,106 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8926648e-ab32-48e0-8011-1b244d89a031
2024-01-06 06:27:25,106 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:25,166 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43465', status: init, memory: 0, processing: 0>
2024-01-06 06:27:25,167 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43465
2024-01-06 06:27:25,167 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53690
2024-01-06 06:27:25,168 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:25,169 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:25,169 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:25,170 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:25,177 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:25,180 - distributed.scheduler - INFO - Remove client Client-a55bbbf6-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:25,180 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53668; closing.
2024-01-06 06:27:25,180 - distributed.scheduler - INFO - Remove client Client-a55bbbf6-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:25,181 - distributed.scheduler - INFO - Close client connection: Client-a55bbbf6-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:25,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44415'. Reason: nanny-close
2024-01-06 06:27:25,198 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:25,199 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43465. Reason: nanny-close
2024-01-06 06:27:25,201 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:25,202 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53690; closing.
2024-01-06 06:27:25,202 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43465', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522445.2023418')
2024-01-06 06:27:25,202 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:25,203 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:26,148 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:26,148 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:26,149 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:26,151 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:26,152 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-06 06:27:30,471 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:30,475 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46119 instead
  warnings.warn(
2024-01-06 06:27:30,479 - distributed.scheduler - INFO - State start
2024-01-06 06:27:30,879 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:30,881 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:30,881 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46119/status
2024-01-06 06:27:30,882 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:30,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37459'
2024-01-06 06:27:32,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:32,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:33,511 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:33,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37245
2024-01-06 06:27:33,512 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37245
2024-01-06 06:27:33,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37845
2024-01-06 06:27:33,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:33,513 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:33,513 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:33,513 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:27:33,513 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0frm0ibl
2024-01-06 06:27:33,513 - distributed.worker - INFO - Starting Worker plugin RMMSetup-af54c453-c334-4794-9be8-700c38c95da6
2024-01-06 06:27:33,513 - distributed.worker - INFO - Starting Worker plugin PreImport-25503381-ba2c-4d88-bb13-6afa66eff588
2024-01-06 06:27:33,514 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-80c8f79f-f73b-486e-ad31-5f949c224386
2024-01-06 06:27:33,514 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:33,560 - distributed.scheduler - INFO - Receive client connection: Client-aa31d77d-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:33,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37432
2024-01-06 06:27:33,698 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37245', status: init, memory: 0, processing: 0>
2024-01-06 06:27:33,699 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37245
2024-01-06 06:27:33,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37420
2024-01-06 06:27:33,700 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:33,701 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:33,701 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:33,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:33,783 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:33,786 - distributed.scheduler - INFO - Remove client Client-aa31d77d-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:33,786 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37432; closing.
2024-01-06 06:27:33,786 - distributed.scheduler - INFO - Remove client Client-aa31d77d-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:33,787 - distributed.scheduler - INFO - Close client connection: Client-aa31d77d-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:33,788 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37459'. Reason: nanny-close
2024-01-06 06:27:33,788 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:33,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37245. Reason: nanny-close
2024-01-06 06:27:33,791 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37420; closing.
2024-01-06 06:27:33,791 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:33,791 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522453.7918952')
2024-01-06 06:27:33,792 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:33,793 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:34,503 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:34,504 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:34,504 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:34,505 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:34,506 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-06 06:27:36,817 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:36,822 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:36,826 - distributed.scheduler - INFO - State start
2024-01-06 06:27:36,848 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:36,849 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:36,850 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:36,850 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:39,422 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:37446'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37446>: Stream is closed
2024-01-06 06:27:39,702 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:39,702 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:39,703 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:39,703 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:39,704 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-06 06:27:42,155 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:42,160 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:42,164 - distributed.scheduler - INFO - State start
2024-01-06 06:27:42,738 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:42,739 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-06 06:27:42,740 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:42,740 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:42,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44733'
2024-01-06 06:27:43,767 - distributed.scheduler - INFO - Receive client connection: Client-b10d824b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:43,780 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51402
2024-01-06 06:27:44,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:44,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:44,756 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:44,757 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33289
2024-01-06 06:27:44,757 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33289
2024-01-06 06:27:44,757 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37061
2024-01-06 06:27:44,757 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-06 06:27:44,757 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:44,757 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:44,757 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:27:44,757 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-c5_67q8q
2024-01-06 06:27:44,757 - distributed.worker - INFO - Starting Worker plugin PreImport-646ec7c6-6136-496e-be2f-de4b1af8621b
2024-01-06 06:27:44,757 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-88369f54-0b4a-40e2-992f-817f8970a0b0
2024-01-06 06:27:44,758 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae18a093-58ea-407c-bce1-457c439f1811
2024-01-06 06:27:44,758 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:45,449 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33289', status: init, memory: 0, processing: 0>
2024-01-06 06:27:45,451 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33289
2024-01-06 06:27:45,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51420
2024-01-06 06:27:45,452 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:45,452 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-06 06:27:45,453 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:45,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-06 06:27:45,519 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:45,523 - distributed.scheduler - INFO - Remove client Client-b10d824b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:45,523 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51402; closing.
2024-01-06 06:27:45,524 - distributed.scheduler - INFO - Remove client Client-b10d824b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:45,524 - distributed.scheduler - INFO - Close client connection: Client-b10d824b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:45,525 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44733'. Reason: nanny-close
2024-01-06 06:27:45,526 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:45,527 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33289. Reason: nanny-close
2024-01-06 06:27:45,530 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51420; closing.
2024-01-06 06:27:45,530 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-06 06:27:45,530 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33289', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522465.5308368')
2024-01-06 06:27:45,531 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:45,532 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:46,294 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:46,294 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:46,294 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:46,295 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-06 06:27:46,296 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-06 06:27:48,958 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:48,964 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:48,968 - distributed.scheduler - INFO - State start
2024-01-06 06:27:48,997 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:48,998 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:48,999 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:48,999 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:49,109 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38527'
2024-01-06 06:27:49,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45847'
2024-01-06 06:27:49,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39397'
2024-01-06 06:27:49,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33783'
2024-01-06 06:27:49,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43669'
2024-01-06 06:27:49,161 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33217'
2024-01-06 06:27:49,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38175'
2024-01-06 06:27:49,178 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39795'
2024-01-06 06:27:49,429 - distributed.scheduler - INFO - Receive client connection: Client-b4eef39b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:49,448 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33900
2024-01-06 06:27:51,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,069 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,070 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37603
2024-01-06 06:27:51,070 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37603
2024-01-06 06:27:51,070 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42619
2024-01-06 06:27:51,070 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,070 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,070 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,070 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,070 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fuk51u5w
2024-01-06 06:27:51,071 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9a2b20c5-8f95-46e8-a98e-24788b2fc779
2024-01-06 06:27:51,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,076 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,077 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46547
2024-01-06 06:27:51,077 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46547
2024-01-06 06:27:51,077 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44709
2024-01-06 06:27:51,077 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,077 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,077 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,077 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,077 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wbngaofn
2024-01-06 06:27:51,077 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c77b965a-3128-4b9b-81d4-44b87dfa3ec1
2024-01-06 06:27:51,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,101 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,101 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42577
2024-01-06 06:27:51,101 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42577
2024-01-06 06:27:51,101 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44855
2024-01-06 06:27:51,102 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,102 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,102 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,102 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,102 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ziyxxbju
2024-01-06 06:27:51,102 - distributed.worker - INFO - Starting Worker plugin PreImport-679cc6b6-7e23-49f6-86ce-e245001fa968
2024-01-06 06:27:51,102 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9c0a3db-1e16-41be-b37d-5a0cdfcf7a45
2024-01-06 06:27:51,102 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ba099d7-1154-4aa8-a1c0-dac1adc4c7aa
2024-01-06 06:27:51,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,113 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,114 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,114 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,114 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38499
2024-01-06 06:27:51,114 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38499
2024-01-06 06:27:51,114 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37273
2024-01-06 06:27:51,114 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,114 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,114 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,114 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,114 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35001
2024-01-06 06:27:51,114 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hgvhzxq9
2024-01-06 06:27:51,114 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35001
2024-01-06 06:27:51,114 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43921
2024-01-06 06:27:51,115 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,115 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34581
2024-01-06 06:27:51,115 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,115 - distributed.worker - INFO - Starting Worker plugin RMMSetup-670a719c-6f7b-4e17-a64a-e7106f26e7e1
2024-01-06 06:27:51,115 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34581
2024-01-06 06:27:51,115 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,115 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39125
2024-01-06 06:27:51,115 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,115 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,115 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8mv24h2l
2024-01-06 06:27:51,115 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,115 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,115 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,115 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9i3c5p_s
2024-01-06 06:27:51,115 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ed812e2-cfcb-44fe-88c2-9e343072ea56
2024-01-06 06:27:51,115 - distributed.worker - INFO - Starting Worker plugin RMMSetup-25011031-3166-4867-b08a-614059b4983b
2024-01-06 06:27:51,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,166 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,167 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37741
2024-01-06 06:27:51,167 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37741
2024-01-06 06:27:51,167 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46045
2024-01-06 06:27:51,167 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,168 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,168 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,168 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,168 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s22_hu1t
2024-01-06 06:27:51,168 - distributed.worker - INFO - Starting Worker plugin PreImport-194c353d-a332-4a70-b97e-7eb6085a14bc
2024-01-06 06:27:51,168 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5cb6d0bd-27b1-4f9a-b672-20d66724ec71
2024-01-06 06:27:51,168 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8cb7e997-d54f-4600-af98-426f8be0e085
2024-01-06 06:27:51,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:51,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:51,183 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:51,184 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44621
2024-01-06 06:27:51,184 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44621
2024-01-06 06:27:51,184 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39339
2024-01-06 06:27:51,184 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:51,184 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:51,184 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:51,184 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:27:51,184 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cyvfk9dq
2024-01-06 06:27:51,184 - distributed.worker - INFO - Starting Worker plugin RMMSetup-671e13ed-2f2f-471c-b5e4-043de4afc9f6
2024-01-06 06:27:53,418 - distributed.worker - INFO - Starting Worker plugin PreImport-e8060594-fe81-4b44-8a39-af9eac9c39f5
2024-01-06 06:27:53,419 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5c40b8be-c11e-46e0-a10c-0d05910d557c
2024-01-06 06:27:53,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,452 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46547', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,454 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46547
2024-01-06 06:27:53,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41914
2024-01-06 06:27:53,455 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,456 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,456 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,458 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,479 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c31d990d-9bf7-4ca7-81ba-1238d48b9601
2024-01-06 06:27:53,480 - distributed.worker - INFO - Starting Worker plugin PreImport-3eac0c7a-ffa3-477b-9a4d-847ea7c0018a
2024-01-06 06:27:53,481 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,498 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,504 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37603', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,505 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37603
2024-01-06 06:27:53,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41916
2024-01-06 06:27:53,506 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,507 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,507 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,520 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42577', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,521 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42577
2024-01-06 06:27:53,521 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41930
2024-01-06 06:27:53,522 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,523 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,523 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,524 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4877766d-1ffe-405a-b3fd-82015e9f5473
2024-01-06 06:27:53,611 - distributed.worker - INFO - Starting Worker plugin PreImport-7c149049-0efd-4125-950e-f92137d64ba8
2024-01-06 06:27:53,612 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,621 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e708902-ae77-4d0b-acde-86c70c565d7a
2024-01-06 06:27:53,628 - distributed.worker - INFO - Starting Worker plugin PreImport-74141a99-1cf0-4708-b0d4-53640c3d7c38
2024-01-06 06:27:53,629 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,631 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,645 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35001', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,645 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35001
2024-01-06 06:27:53,645 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41934
2024-01-06 06:27:53,647 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,649 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,655 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37741', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,659 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37741
2024-01-06 06:27:53,659 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41952
2024-01-06 06:27:53,660 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,661 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c88aded0-516d-40a1-a37e-ccb01a0f54b3
2024-01-06 06:27:53,661 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,661 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,661 - distributed.worker - INFO - Starting Worker plugin PreImport-0cf64e45-7813-48be-b8f2-a83cc466ede2
2024-01-06 06:27:53,661 - distributed.worker - INFO - Starting Worker plugin PreImport-a5b78486-4306-4fa3-ad7b-601cf1ab00cd
2024-01-06 06:27:53,661 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14d43eaf-1fe5-4eec-84d4-c18c7279c0f2
2024-01-06 06:27:53,662 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,662 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34581', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,662 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,663 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34581
2024-01-06 06:27:53,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41948
2024-01-06 06:27:53,665 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,666 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,666 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,668 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,682 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44621', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,683 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44621
2024-01-06 06:27:53,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41956
2024-01-06 06:27:53,684 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,685 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,685 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38499', status: init, memory: 0, processing: 0>
2024-01-06 06:27:53,695 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38499
2024-01-06 06:27:53,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41962
2024-01-06 06:27:53,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:53,698 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:53,698 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:53,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:53,729 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,729 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,729 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,730 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,730 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,730 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,730 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,731 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-06 06:27:53,743 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,743 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,743 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,743 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,744 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,744 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,744 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,744 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:53,748 - distributed.scheduler - INFO - Remove client Client-b4eef39b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:53,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33900; closing.
2024-01-06 06:27:53,749 - distributed.scheduler - INFO - Remove client Client-b4eef39b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:53,749 - distributed.scheduler - INFO - Close client connection: Client-b4eef39b-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:53,750 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38527'. Reason: nanny-close
2024-01-06 06:27:53,751 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,751 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45847'. Reason: nanny-close
2024-01-06 06:27:53,751 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39397'. Reason: nanny-close
2024-01-06 06:27:53,752 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38499. Reason: nanny-close
2024-01-06 06:27:53,752 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33783'. Reason: nanny-close
2024-01-06 06:27:53,752 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34581. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43669'. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42577. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33217'. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37603. Reason: nanny-close
2024-01-06 06:27:53,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38175'. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46547. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39795'. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35001. Reason: nanny-close
2024-01-06 06:27:53,754 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,755 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37741. Reason: nanny-close
2024-01-06 06:27:53,755 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41962; closing.
2024-01-06 06:27:53,755 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,755 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44621. Reason: nanny-close
2024-01-06 06:27:53,755 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38499', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7552755')
2024-01-06 06:27:53,755 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,755 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,756 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41930; closing.
2024-01-06 06:27:53,756 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,756 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,756 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,756 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,757 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,757 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,757 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:53,757 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42577', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7575824')
2024-01-06 06:27:53,757 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,757 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41916; closing.
2024-01-06 06:27:53,758 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41948; closing.
2024-01-06 06:27:53,758 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,758 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,758 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,759 - distributed.nanny - INFO - Worker closed
2024-01-06 06:27:53,759 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37603', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7594118')
2024-01-06 06:27:53,759 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34581', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7598062')
2024-01-06 06:27:53,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41914; closing.
2024-01-06 06:27:53,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41952; closing.
2024-01-06 06:27:53,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41934; closing.
2024-01-06 06:27:53,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41956; closing.
2024-01-06 06:27:53,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46547', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.761045')
2024-01-06 06:27:53,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37741', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.761327')
2024-01-06 06:27:53,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35001', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7615795')
2024-01-06 06:27:53,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44621', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522473.7618253')
2024-01-06 06:27:53,762 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:54,666 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:27:54,666 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:27:54,667 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:27:54,668 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:27:54,669 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-06 06:27:56,837 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:56,842 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:27:56,845 - distributed.scheduler - INFO - State start
2024-01-06 06:27:56,868 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:27:56,870 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:27:56,870 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:27:56,871 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:27:56,918 - distributed.scheduler - INFO - Receive client connection: Client-b9e6cea9-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:56,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42066
2024-01-06 06:27:56,935 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43879'
2024-01-06 06:27:58,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:27:58,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:27:58,806 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:27:58,807 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41829
2024-01-06 06:27:58,807 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41829
2024-01-06 06:27:58,807 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40753
2024-01-06 06:27:58,807 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:27:58,807 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:58,807 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:27:58,807 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:27:58,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-81ck6xih
2024-01-06 06:27:58,807 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1391ced5-fcf5-4edb-b42e-4b59981a3ed2
2024-01-06 06:27:58,808 - distributed.worker - INFO - Starting Worker plugin PreImport-a712f7a6-345e-4aab-b230-e79b819d0086
2024-01-06 06:27:58,808 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5e071abc-d324-499d-a315-db6da66dea2b
2024-01-06 06:27:59,457 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:59,515 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41829', status: init, memory: 0, processing: 0>
2024-01-06 06:27:59,517 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41829
2024-01-06 06:27:59,517 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42086
2024-01-06 06:27:59,518 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:27:59,518 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:27:59,519 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:27:59,520 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:27:59,613 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:27:59,618 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:59,620 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:27:59,622 - distributed.scheduler - INFO - Remove client Client-b9e6cea9-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:59,622 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42066; closing.
2024-01-06 06:27:59,623 - distributed.scheduler - INFO - Remove client Client-b9e6cea9-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:59,623 - distributed.scheduler - INFO - Close client connection: Client-b9e6cea9-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:27:59,624 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43879'. Reason: nanny-close
2024-01-06 06:27:59,625 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:27:59,626 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41829. Reason: nanny-close
2024-01-06 06:27:59,627 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42086; closing.
2024-01-06 06:27:59,628 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:27:59,628 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41829', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522479.628305')
2024-01-06 06:27:59,628 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:27:59,629 - distributed.nanny - INFO - Worker closed
2024-01-06 06:28:00,239 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:28:00,240 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:28:00,240 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:28:00,241 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:28:00,241 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-06 06:28:02,590 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:28:02,595 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-06 06:28:02,599 - distributed.scheduler - INFO - State start
2024-01-06 06:28:02,653 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-06 06:28:02,654 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-06 06:28:02,654 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-06 06:28:02,654 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-06 06:28:02,725 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40391'
2024-01-06 06:28:04,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:28:04,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:28:04,436 - distributed.scheduler - INFO - Receive client connection: Client-bd4318e5-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:28:04,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:28:04,438 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39957
2024-01-06 06:28:04,438 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39957
2024-01-06 06:28:04,438 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41759
2024-01-06 06:28:04,438 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-06 06:28:04,438 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:28:04,438 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:28:04,438 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:28:04,438 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ehvkn11l
2024-01-06 06:28:04,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-18f6f80d-9f66-4366-ac68-7f54e8b58689
2024-01-06 06:28:04,439 - distributed.worker - INFO - Starting Worker plugin PreImport-d5a9b034-e6e8-47d9-a510-678dd24aa870
2024-01-06 06:28:04,439 - distributed.worker - INFO - Starting Worker plugin RMMSetup-02fc1725-3ebb-4a13-961b-3753c5dd7286
2024-01-06 06:28:04,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39824
2024-01-06 06:28:05,148 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:28:05,500 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39957', status: init, memory: 0, processing: 0>
2024-01-06 06:28:05,501 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39957
2024-01-06 06:28:05,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39838
2024-01-06 06:28:05,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:28:05,503 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-06 06:28:05,503 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:28:05,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-06 06:28:05,579 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-06 06:28:05,584 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-06 06:28:05,588 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:28:05,590 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:28:05,592 - distributed.scheduler - INFO - Remove client Client-bd4318e5-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:28:05,593 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39824; closing.
2024-01-06 06:28:05,593 - distributed.scheduler - INFO - Remove client Client-bd4318e5-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:28:05,593 - distributed.scheduler - INFO - Close client connection: Client-bd4318e5-ac5c-11ee-bd1b-d8c49764f6bb
2024-01-06 06:28:05,594 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40391'. Reason: nanny-close
2024-01-06 06:28:05,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-06 06:28:05,596 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39957. Reason: nanny-close
2024-01-06 06:28:05,597 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-06 06:28:05,597 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39838; closing.
2024-01-06 06:28:05,598 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39957', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704522485.598229')
2024-01-06 06:28:05,598 - distributed.scheduler - INFO - Lost all workers
2024-01-06 06:28:05,599 - distributed.nanny - INFO - Worker closed
2024-01-06 06:28:06,310 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-06 06:28:06,310 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-06 06:28:06,311 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-06 06:28:06,312 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-06 06:28:06,312 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44655 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39891 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32929 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43475 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34995 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41341 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42505 instead
  warnings.warn(
2024-01-06 06:30:45,955 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-06 06:30:45,960 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2024-01-06 06:30:45,969 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucxx://10.33.225.163:41895', name: 6, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45069 instead
  warnings.warn(
2024-01-06 06:31:00,592 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 360, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 443, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39361 instead
  warnings.warn(
[1704522667.336884] [dgx13:71234:0]            sock.c:470  UCX  ERROR bind(fd=177 addr=0.0.0.0:37206) failed: Address already in use
2024-01-06 06:31:16,305 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 439, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 445, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44027 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40711 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32895 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43719 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37609 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43291 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42253 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43385 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37865 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] [1704522846.990931] [dgx13:74401:0]            sock.c:470  UCX  ERROR bind(fd=125 addr=0.0.0.0:37606) failed: Address already in use
[1704522849.960628] [dgx13:74488:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:33538) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33139 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40513 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42457 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35767 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41087 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40357 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39133 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33863 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37225 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42811 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39945 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34477 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36485 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43441 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40501 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35235 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45845 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40855 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39435 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40301 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38853 instead
  warnings.warn(
[1704523449.344193] [dgx13:83743:0]            sock.c:470  UCX  ERROR bind(fd=162 addr=0.0.0.0:55110) failed: Address already in use
2024-01-06 06:44:29,831 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39339 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39129 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39649 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42841 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38045 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35973 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38211 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37343 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36355 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34707 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] [1704523671.080219] [dgx13:86960:0]            sock.c:470  UCX  ERROR bind(fd=134 addr=0.0.0.0:57388) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44413 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39561 instead
  warnings.warn(
[1704523715.151367] [dgx13:87749:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:36997) failed: Address already in use
[1704523715.151419] [dgx13:87739:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:50578) failed: Address already in use
[1704523715.151476] [dgx13:87739:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:44679) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44857 instead
  warnings.warn(
2024-01-06 06:48:54,535 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
[1704523735.225908] [dgx13:87853] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
[1704523735.226000] [dgx13:87853] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34891 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42993 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39135 instead
  warnings.warn(
2024-01-06 06:49:34,429 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2024-01-06 06:49:34,430 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 505, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
unpack(b) received extra data.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
2024-01-06 06:49:34,438 - distributed.core - ERROR - Exception while reading from ucxx://127.0.0.1:57100
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 899, in _handle_comm
    msg = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
Task exception was never retrieved
future: <Task finished name='Task-255' coro=<Server._handle_comm() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py:875> exception=ExtraData(1, b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xb0*\xae\t\x81\x7f\x00\x00\xb0*\xae\t\x81\x7f\x00\x00\x80\x05\xfe\xfe\xfe\xfe\xfe\xfe\xfe\xfe\xfe\x8c\x11dask.optimization\x94\x8c\x10SubgraphCallable\x94\x93\x94(}\x94(\x8c+sort_index-d0c305759b425be102b44e88e8f47cbf\x94\x8cAmerge_chunk-set_index-sort_index-d0c305759b425be102b44e88e8f47cbf\x94h\x05(\x8c\ndask.utils\x94\x8c\x05apply\x94\x93\x94\x8c\x13dask.dataframe.core\x94\x8c\x11apply_and_enforce\x94\x93\x94]\x94(h\x08h\x0b]\x94((h\x08\x8c\x14dask.dataframe.multi\x94\x8c\x0bmerge_chunk\x94\x93\x94]\x94(\x8c\x13__dask_blockwise__3\x94\x8c\x13__dask_blockwise__4\x94e\x8c\x08builtins\x94\x8c\x04dict\x94\x93\x94]\x94(]\x94(\x8c\x03how\x94\x8c\x05inner\x94e]\x94(\x8c\x08right_on\x94\x8c\x03key\x94e]\x94(\x8c\x07left_on\x94h\x1de]\x94(\x8c\nleft_index\x94\x89e]\x94(\x8c\x0bright_index\x94\x89e]\x94(\x8c\x08suffixes\x94\x8c\x02_x\x94\x8c\x02_y\x94\x86\x94e]\x94(\x8c\tindicator\x94\x89e]\x94(\x8c\x0bresult_meta\x94\x8c\x08builtins\x94\x8c\x07getattr\x94\x93\x94\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94\x8c\x10host_deserialize\x94\x86\x94R\x94}\x94(\x8c\x0ftype-serialized\x94C0\x80\x04\x95%\x00\x00\x00\x00\x00\x00\x00\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94.\x94\x8c\x0ccolumn_names\x94C*\x80\x04\x95\x1f\x00\x00\x00\x00\x00\x00\x00\x8c\x03key\x94\x8c\x08payload1\x94\x8c\x08payload2\x94\x87\x94.\x94\x8c\x07columns\x94}\x94(\x8c\x0ftype-serialized\x94C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94\x8c\x05dtype\x94CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94\x8c\x18dtype-is-cudf-serialized\x94\x89\x8c\x04data\x94}\x94(\x8c\x0ftype-serialized\x94C1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94\x8c\x0bframe_count\x94K\x01u\x8c\x04size\x94K\x02hFK\x01u}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x02hFK\x01u}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x02hFK\x01u\x87\x94\x8c\x05index\x94}\x94(\x8c\x0cindex_column\x94}\x94(\x8c\x05start\x94K\x00\x8c\x04stop\x94K\x02\x8c\x04step\x94K\x01u\x8c\x04name\x94C\x04\x80\x04N.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94\x8c\x0ftype-serialized\x94C-\x80\x04\x95"\x00\x00\x00\x00\x00\x00\x00\x8c\x0fcudf.core.index\x94\x8c\nRangeIndex\x94\x93\x94.\x94hFK\x00u\x8c\x11index_frame_count\x94K\x00\x8c\x07is-cuda\x94]\x94(\x88\x88\x88e\x8c\x07lengths\x94]\x94(K\x10K\x10K\x10e\x8c\twriteable\x94NNN\x87\x94u]\x94(\x8c\x12numpy.core.numeric\x94\x8c\x0b_frombuffer\x94\x93\x94(\x97\x98\x8c\x05numpy\x94h?\x93\x94\x8c\x02u1\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01|\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94bK\x10\x85\x94\x8c\x01C\x94t\x94R\x94hi(\x97\x98hnK\x10\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x10\x85\x94hrt\x94R\x94e\x86\x94R\x94ee\x86\x94t\x94\x8c\x13__dask_blockwise__1\x94eh\x16]\x94(]\x94(\x8c\x05_func\x94h\x06\x8c\x0cmethodcaller\x94\x93\x94\x8c\tset_index\x94\x85\x94R\x94e]\x94(\x8c\x05_meta\x94h/h2h3\x86\x94R\x94}\x94(h7C0\x80\x04\x95%\x00\x00\x00\x00\x00\x00\x00\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94.\x94h9C$\x80\x04\x95\x19\x00\x00\x00\x00\x00\x00\x00\x8c\x08payload1\x94\x8c\x08payload2\x94\x86\x94.\x94h;}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x86\x94hS}\x94(h7C-\x80\x04\x95"\x00\x00\x00\x00\x00\x00\x00\x8c\x0fcudf.core.index\x94\x8c\nInt64Index\x94\x93\x94.\x94h9C\x14\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x03key\x94\x85\x94.\x94h;}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x85\x94uh_K\x01h`]\x94(\x88\x88\x88ehb]\x94(K\x00K\x00K\x00ehdNNN\x87\x94u]\x94(hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94e\x86\x94R\x94e]\x94(\x8c\x04drop\x94\x88ee\x86\x94t\x94ah\x16]\x94(]\x94(h\x82h\x84\x8c\nsort_index\x94\x85\x94R\x94e]\x94(h\x89h/h2h3\x86\x94R\x94}\x94(h7C0\x80\x04\x95%\x00\x00\x00\x00\x00\x00\x00\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94.\x94h9C$\x80\x04\x95\x19\x00\x00\x00\x00\x00\x00\x00\x8c\x08payload1\x94\x8c\x08payload2\x94\x86\x94.\x94h;}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x86\x94hS}\x94(h7C-\x80\x04\x95"\x00\x00\x00\x00\x00\x00\x00\x8c\x0fcudf.core.index\x94\x8c\nInt64Index\x94\x93\x94.\x94h9C\x14\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x03key\x94\x85\x94.\x94h;}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x85\x94uh_K\x01h`]\x94(\x88\x88\x88ehb]\x94(K\x00K\x00K\x00ehdNNN\x87\x94u]\x94(hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94e\x86\x94R\x94ee\x86\x94t\x94uh\x04(\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94\x8c\x13__dask_blockwise__3\x94\x8c\x13__dask_blockwise__4\x94\x8c\x13__dask_blockwise__5\x94\x8c\x13__dask_blockwise__6\x94t\x94\x8c6J\xff\x00\xff\xffJ\xff\xff\xff\xffA\x05\x00\x00\x00\x00\x00\x00\xc0\x04\x00\x08\x81\x7f\x00\x00\xc0\x04\x00\x08\x81\x7f\x00\x00`\xdd\xad\t\x81\x7f\x00\x00`\xdd\xad\t\x81\x7f\x00\x00e.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x86\x94hS}\x94(h7C-\x80\x04\x95"\x00\x00\x00\x00\x00\x00\x00\x8c\x0fcudf.core.index\x94\x8c\nInt64Index\x94\x93\x94.\x94h9C\x14\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x03key\x94\x85\x94.\x94h;}\x94(h=C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h?CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94hA\x89hB}\x94(hDC1\x80\x04\x95&\x00\x00\x00\x00\x00\x00\x00\x8c\x17cudf.core.buffer.buffer\x94\x8c\x06Buffer\x94\x93\x94.\x94hFK\x01uhGK\x00hFK\x01u\x85\x94uh_K\x01h`]\x94(\x88\x88\x88ehb]\x94(K\x00K\x00K\x00ehdNNN\x87\x94u]\x94(hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94hi(\x97\x98hnK\x00\x85\x94hrt\x94R\x94e\x86\x94R\x94ee\x86\x94t\x94uh\x04(\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94\x8c\x13__dask_blockwise__3\x94\x8c\x13__dask_blockwise__4\x94\x8c\x13__dask_blockwise__5\x94\x8c\x13__dask_blockwise__6\x94t\x94\x8c6subgraph_callable-6705f98b-28bc-4587-b006-756107b56b84\x94t\x94R\x94(\x8c*set_index-3ccf491452b40dfe352f31b34f8593d4\x94h\x1d\x8c,merge_chunk-ea4fc656abf935e5326486d006ac9541\x94\x8c,from_pandas-492229f08d0dfffad7ce5052624e8563\x94K\x00\x86\x94\x8c,from_pandas-420dc3eec1f39f')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 899, in _handle_comm
    msg = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 450, in read
    return await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 78, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 61, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 201, in msgpack._cmsgpack.unpackb
msgpack.exceptions.ExtraData: unpack(b) received extra data.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] [1704523780.383130] [dgx13:88489:0]            sock.c:470  UCX  ERROR bind(fd=152 addr=0.0.0.0:54188) failed: Address already in use
[1704523781.989361] [dgx13:88664:0]            sock.c:470  UCX  ERROR bind(fd=123 addr=0.0.0.0:59154) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46313 instead
  warnings.warn(
[1704523804.319904] [dgx13:88874:0]            sock.c:470  UCX  ERROR bind(fd=157 addr=0.0.0.0:50607) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33235 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36587 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40989 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] [1704523887.980464] [dgx13:64795:0]            sock.c:470  UCX  ERROR bind(fd=258 addr=0.0.0.0:52530) failed: Address already in use
[1704523893.335951] [dgx13:90079:0]            sock.c:470  UCX  ERROR bind(fd=163 addr=0.0.0.0:36986) failed: Address already in use
PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45847 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33231 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45213 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39909 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35993 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41751 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45305 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40403 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] 2024-01-06 06:52:49,094 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2024-01-06 06:52:49,101 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://127.0.0.1:58092', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] [1704523970.529428] [dgx13:64795:1]            sock.c:470  UCX  ERROR bind(fd=256 addr=0.0.0.0:48308) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-06 06:53:21,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:21,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:21,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:22,345 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,346 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37091
2024-01-06 06:53:22,346 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37091
2024-01-06 06:53:22,346 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34577
2024-01-06 06:53:22,346 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,347 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,347 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,347 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q567sy5u
2024-01-06 06:53:22,347 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2e5eddaf-5f04-4658-ba5b-06cfe3b2b9b1
2024-01-06 06:53:22,347 - distributed.worker - INFO - Starting Worker plugin PreImport-d9bb50a2-3729-451b-8343-ee8545dd55de
2024-01-06 06:53:22,347 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c902fe51-bbef-4da2-a27c-bebbbf711ab1
2024-01-06 06:53:22,347 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,422 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,423 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36783
2024-01-06 06:53:22,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36783
2024-01-06 06:53:22,423 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43289
2024-01-06 06:53:22,424 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,424 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,424 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-66n582p7
2024-01-06 06:53:22,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab934cfa-83d2-4cf7-89c6-fc5d77f9fd8d
2024-01-06 06:53:22,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8278de92-b918-4824-8819-21605f34ec4e
2024-01-06 06:53:22,424 - distributed.worker - INFO - Starting Worker plugin PreImport-f80d3eba-bc13-42f5-ad8a-4730cf8954f4
2024-01-06 06:53:22,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,456 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,457 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38475
2024-01-06 06:53:22,457 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38475
2024-01-06 06:53:22,457 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43173
2024-01-06 06:53:22,457 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,457 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,457 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,457 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qn9l9wcu
2024-01-06 06:53:22,458 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af8e67ac-e87e-4a01-9f6c-8f16cf326dfc
2024-01-06 06:53:22,458 - distributed.worker - INFO - Starting Worker plugin PreImport-1ed77aa5-7586-49be-a0bb-28d1aaa792fe
2024-01-06 06:53:22,458 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1919045a-02a5-4075-b15f-5e7d81180da5
2024-01-06 06:53:22,458 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,542 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,543 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38037
2024-01-06 06:53:22,543 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38037
2024-01-06 06:53:22,543 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33379
2024-01-06 06:53:22,543 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,543 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,543 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,543 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-98z3roz2
2024-01-06 06:53:22,544 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-89928bfa-4ff0-4582-815b-d3fe55adf350
2024-01-06 06:53:22,544 - distributed.worker - INFO - Starting Worker plugin RMMSetup-399b300e-a131-4741-b623-915ede4ac547
2024-01-06 06:53:22,544 - distributed.worker - INFO - Starting Worker plugin PreImport-bb581df1-ea18-4fba-ab19-547df19f36c6
2024-01-06 06:53:22,544 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,545 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37485
2024-01-06 06:53:22,546 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37485
2024-01-06 06:53:22,546 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38257
2024-01-06 06:53:22,546 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,546 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,546 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7tc8gq5v
2024-01-06 06:53:22,547 - distributed.worker - INFO - Starting Worker plugin PreImport-08253d0b-19ba-4e52-a665-bfc212c5573a
2024-01-06 06:53:22,547 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51234f59-934c-42ad-95ea-0359cf1bd414
2024-01-06 06:53:22,547 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9222f9b2-48a5-4b2f-b8af-417e745b50c3
2024-01-06 06:53:22,547 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,559 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34335
2024-01-06 06:53:22,560 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34335
2024-01-06 06:53:22,560 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46203
2024-01-06 06:53:22,560 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,560 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,560 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,560 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n0e_mlio
2024-01-06 06:53:22,560 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dc646efa-270e-4f81-ad44-dc13c50985b1
2024-01-06 06:53:22,560 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff67e400-88c5-497a-a9e3-b9340b168838
2024-01-06 06:53:22,561 - distributed.worker - INFO - Starting Worker plugin PreImport-2c8bd45b-811e-45f0-b871-05bd59ab5264
2024-01-06 06:53:22,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,566 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,566 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,567 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,584 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,584 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,585 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,594 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,595 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37929
2024-01-06 06:53:22,595 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37929
2024-01-06 06:53:22,595 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46079
2024-01-06 06:53:22,595 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,595 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,595 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,596 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-41c9owyl
2024-01-06 06:53:22,596 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e993c5fe-d1c9-4882-8bc5-bf30db040875
2024-01-06 06:53:22,596 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7ed63844-422a-4c11-8e01-bcf30ccd1bfd
2024-01-06 06:53:22,596 - distributed.worker - INFO - Starting Worker plugin PreImport-f367b588-2ee1-4216-896b-e9b3e75d4692
2024-01-06 06:53:22,596 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,603 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,603 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,603 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,605 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,617 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:22,618 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46363
2024-01-06 06:53:22,618 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46363
2024-01-06 06:53:22,618 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41835
2024-01-06 06:53:22,618 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,619 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,619 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:22,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cvs4r6gr
2024-01-06 06:53:22,619 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a9cb7ca1-2e84-46f2-9900-ad3f64ab8165
2024-01-06 06:53:22,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a208dfe7-c1c5-4375-9294-a0510834930d
2024-01-06 06:53:22,619 - distributed.worker - INFO - Starting Worker plugin PreImport-9aedea16-8103-4645-bdae-961bfe2a8567
2024-01-06 06:53:22,619 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,712 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,713 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,713 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,714 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,741 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,741 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,742 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,748 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,749 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,763 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,764 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,764 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,765 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:53:22,771 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45093
2024-01-06 06:53:22,771 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:22,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45093
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,811 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,812 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-06 06:53:22,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37091. Reason: nanny-close
2024-01-06 06:53:22,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38475. Reason: nanny-close
2024-01-06 06:53:22,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36783. Reason: nanny-close
2024-01-06 06:53:22,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38037. Reason: nanny-close
2024-01-06 06:53:22,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37485. Reason: nanny-close
2024-01-06 06:53:22,821 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34335. Reason: nanny-close
2024-01-06 06:53:22,822 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,822 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37929. Reason: nanny-close
2024-01-06 06:53:22,823 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,823 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46363. Reason: nanny-close
2024-01-06 06:53:22,823 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,825 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,825 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,826 - distributed.nanny - INFO - Worker closed
2024-01-06 06:53:22,826 - distributed.core - INFO - Connection to tcp://127.0.0.1:45093 has been closed.
2024-01-06 06:53:22,828 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-06 06:53:59,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:53:59,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:53:59,634 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:53:59,635 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36337
2024-01-06 06:53:59,635 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36337
2024-01-06 06:53:59,635 - distributed.worker - INFO -           Worker name:                          0
2024-01-06 06:53:59,635 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44567
2024-01-06 06:53:59,635 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36803
2024-01-06 06:53:59,635 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:53:59,635 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:53:59,635 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-06 06:53:59,635 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_fz5te6o
2024-01-06 06:53:59,636 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b89a96f2-9031-4c67-a439-9dc494c0dae3
2024-01-06 06:53:59,636 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ffa34025-6b99-4c15-8e8f-cc6eaa680f60
2024-01-06 06:53:59,636 - distributed.worker - INFO - Starting Worker plugin PreImport-29be9cd4-fe80-4721-b7c8-a61a953cd12f
2024-01-06 06:53:59,652 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-06 06:53:59,654 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36337. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-06 06:53:59,654 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-06 06:53:59,658 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-06 06:54:03,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:03,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-06 06:54:04,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-06 06:54:04,565 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,566 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46853
2024-01-06 06:54:04,566 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46853
2024-01-06 06:54:04,566 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46839
2024-01-06 06:54:04,566 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,566 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,566 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,566 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,566 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jxlee2j_
2024-01-06 06:54:04,567 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f2acc0ad-e4b9-4846-b831-d647b2a2cd92
2024-01-06 06:54:04,567 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-34b88554-4336-4330-bbf9-dba6d36943c3
2024-01-06 06:54:04,567 - distributed.worker - INFO - Starting Worker plugin PreImport-ccb76caf-9355-40c6-aa17-79c178ccb10c
2024-01-06 06:54:04,567 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,634 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,634 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,659 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,659 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33579
2024-01-06 06:54:04,659 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33579
2024-01-06 06:54:04,660 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36549
2024-01-06 06:54:04,660 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,660 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,660 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,660 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,660 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dahvrng7
2024-01-06 06:54:04,660 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9eacd14d-8864-4d93-b5ab-5e52dc37c712
2024-01-06 06:54:04,660 - distributed.worker - INFO - Starting Worker plugin RMMSetup-38ad6161-3479-4662-ab72-889c862f7460
2024-01-06 06:54:04,661 - distributed.worker - INFO - Starting Worker plugin PreImport-adce830f-b291-490e-8237-b7078a50adc2
2024-01-06 06:54:04,661 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,672 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,673 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43035
2024-01-06 06:54:04,673 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43035
2024-01-06 06:54:04,673 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39173
2024-01-06 06:54:04,673 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,673 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,673 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,673 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,673 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4rln2zze
2024-01-06 06:54:04,674 - distributed.worker - INFO - Starting Worker plugin PreImport-0793e2bb-0adc-4615-9b1b-ffa660dfff9c
2024-01-06 06:54:04,674 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-521fdad7-d1a3-42d4-a624-7851bbce22af
2024-01-06 06:54:04,674 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c854293-b4b9-47fe-81ca-a511f8c3da0a
2024-01-06 06:54:04,674 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,697 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41947
2024-01-06 06:54:04,698 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41947
2024-01-06 06:54:04,698 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40863
2024-01-06 06:54:04,698 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,698 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,698 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,698 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,698 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-22mfth97
2024-01-06 06:54:04,698 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-154bd58f-eb75-4e6c-8d2a-62f00cb629ac
2024-01-06 06:54:04,698 - distributed.worker - INFO - Starting Worker plugin RMMSetup-88da54a7-4875-41a2-adb8-256de6828d03
2024-01-06 06:54:04,698 - distributed.worker - INFO - Starting Worker plugin PreImport-b8dbecda-1f5d-43ba-b38c-121e2aa3034c
2024-01-06 06:54:04,699 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,728 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,729 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39153
2024-01-06 06:54:04,729 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39153
2024-01-06 06:54:04,729 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45891
2024-01-06 06:54:04,729 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,729 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,729 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,729 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,729 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8vpcexr7
2024-01-06 06:54:04,730 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fcc43859-5015-4328-9b0b-6fe044675b48
2024-01-06 06:54:04,730 - distributed.worker - INFO - Starting Worker plugin PreImport-d60f219b-1311-42f2-9f02-91eedfea4c51
2024-01-06 06:54:04,730 - distributed.worker - INFO - Starting Worker plugin RMMSetup-faa4e5d5-5b7a-446f-a535-d92b1dbcbe4f
2024-01-06 06:54:04,730 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,764 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,765 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,765 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,782 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,783 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39195
2024-01-06 06:54:04,783 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39195
2024-01-06 06:54:04,783 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38657
2024-01-06 06:54:04,783 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,783 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,783 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,783 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,783 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bgbucnbm
2024-01-06 06:54:04,783 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f85c6d04-82a8-40d6-b79b-7bf3ff308634
2024-01-06 06:54:04,784 - distributed.worker - INFO - Starting Worker plugin PreImport-c0bc2983-1756-4c20-846b-1fb9c9c4f152
2024-01-06 06:54:04,784 - distributed.worker - INFO - Starting Worker plugin RMMSetup-86263257-982d-4fdb-9e84-4b67ab42ec2b
2024-01-06 06:54:04,784 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,787 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,787 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,788 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,824 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,824 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,831 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,832 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46667
2024-01-06 06:54:04,832 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46667
2024-01-06 06:54:04,832 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34373
2024-01-06 06:54:04,832 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,832 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,832 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,832 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,832 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sh2y3vgy
2024-01-06 06:54:04,832 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd8f7193-af77-410a-a06b-acf523adddca
2024-01-06 06:54:04,833 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b79b4a6-a8f7-4cda-9159-06330389680a
2024-01-06 06:54:04,833 - distributed.worker - INFO - Starting Worker plugin PreImport-42a21aa2-eb07-4983-b931-1a51a2a77afa
2024-01-06 06:54:04,833 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,840 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-06 06:54:04,841 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36931
2024-01-06 06:54:04,841 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36931
2024-01-06 06:54:04,841 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44155
2024-01-06 06:54:04,841 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,841 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,841 - distributed.worker - INFO -               Threads:                          1
2024-01-06 06:54:04,841 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-06 06:54:04,841 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tvgcoq2b
2024-01-06 06:54:04,841 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-752ea02e-2d39-4e34-b097-1bbadb3b6f67
2024-01-06 06:54:04,842 - distributed.worker - INFO - Starting Worker plugin RMMSetup-078de9ec-9a7e-463d-92bb-a7482a2fe81e
2024-01-06 06:54:04,842 - distributed.worker - INFO - Starting Worker plugin PreImport-4141c537-45eb-415e-b069-2b0e16d0f111
2024-01-06 06:54:04,842 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,847 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,847 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,848 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,877 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,878 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,878 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,879 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,938 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,939 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,939 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,940 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,942 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-06 06:54:04,943 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38341
2024-01-06 06:54:04,943 - distributed.worker - INFO - -------------------------------------------------
2024-01-06 06:54:04,944 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38341
2024-01-06 06:54:04,970 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46853. Reason: nanny-close
2024-01-06 06:54:04,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33579. Reason: nanny-close
2024-01-06 06:54:04,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43035. Reason: nanny-close
2024-01-06 06:54:04,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41947. Reason: nanny-close
2024-01-06 06:54:04,972 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,973 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39153. Reason: nanny-close
2024-01-06 06:54:04,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39195. Reason: nanny-close
2024-01-06 06:54:04,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,974 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36931. Reason: nanny-close
2024-01-06 06:54:04,975 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,975 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46667. Reason: nanny-close
2024-01-06 06:54:04,975 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,975 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,975 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,977 - distributed.core - INFO - Connection to tcp://127.0.0.1:38341 has been closed.
2024-01-06 06:54:04,977 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,977 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,977 - distributed.nanny - INFO - Worker closed
2024-01-06 06:54:04,978 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand FAILED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
