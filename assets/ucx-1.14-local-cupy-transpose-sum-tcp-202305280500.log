2023-05-28 07:31:41,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2u6hyl45', purging
2023-05-28 07:31:41,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:41,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:41,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:43,717 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:43,745 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:43,801 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:43,833 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:43,859 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:43,884 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:43,914 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:44,067 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:45,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zexb65u7', purging
2023-05-28 07:31:45,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-640zna55', purging
2023-05-28 07:31:45,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wbqxaqs', purging
2023-05-28 07:31:45,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6v1gz79', purging
2023-05-28 07:31:45,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-paaotp1p', purging
2023-05-28 07:31:45,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2dnyqpw2', purging
2023-05-28 07:31:45,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpzi03qr', purging
2023-05-28 07:31:45,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7js5gez', purging
2023-05-28 07:31:45,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:45,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:45,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:47,483 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,512 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,544 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,580 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,602 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,630 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:47,810 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:48,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pxtf19jk', purging
2023-05-28 07:31:48,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vtx6on1j', purging
2023-05-28 07:31:48,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jw92rvdk', purging
2023-05-28 07:31:48,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u44uj4lo', purging
2023-05-28 07:31:48,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ztzqi_r9', purging
2023-05-28 07:31:48,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kl8f2k_h', purging
2023-05-28 07:31:48,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8cdd4sc', purging
2023-05-28 07:31:48,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-022ebhxj', purging
2023-05-28 07:31:48,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:48,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:49,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:49,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:51,193 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:51,228 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,281 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,313 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,334 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,359 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,384 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:51,556 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:52,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6n7nh71k', purging
2023-05-28 07:31:52,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9epwlzze', purging
2023-05-28 07:31:52,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l89eimns', purging
2023-05-28 07:31:52,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-074rq1j_', purging
2023-05-28 07:31:52,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uwirj93j', purging
2023-05-28 07:31:52,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cx5vrpkc', purging
2023-05-28 07:31:52,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lt91en1z', purging
2023-05-28 07:31:52,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2k8l_dt0', purging
2023-05-28 07:31:52,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:52,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:52,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:53,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:53,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:54,937 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:54,981 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,007 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,048 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,073 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,098 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,119 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:55,296 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:56,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_zf08u1', purging
2023-05-28 07:31:56,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-60c5iafe', purging
2023-05-28 07:31:56,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-onigsi4v', purging
2023-05-28 07:31:56,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_0v4hke', purging
2023-05-28 07:31:56,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v429bw93', purging
2023-05-28 07:31:56,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfl0vbeg', purging
2023-05-28 07:31:56,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_n96nkz', purging
2023-05-28 07:31:56,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxe8fmsg', purging
2023-05-28 07:31:56,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:56,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:56,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:58,768 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,811 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,838 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,867 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,894 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,917 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:58,941 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:59,095 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:00,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-85dkmace', purging
2023-05-28 07:32:00,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1tkc7_qr', purging
2023-05-28 07:32:00,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga54dcdc', purging
2023-05-28 07:32:00,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_970595', purging
2023-05-28 07:32:00,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-81vfbrig', purging
2023-05-28 07:32:00,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xfjeik82', purging
2023-05-28 07:32:00,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-szsijqqv', purging
2023-05-28 07:32:00,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1k454zh', purging
2023-05-28 07:32:00,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:00,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:00,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:02,525 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,596 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,621 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,646 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,674 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,704 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,730 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:02,875 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:04,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kiwc_uzr', purging
2023-05-28 07:32:04,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f3xd9qx', purging
2023-05-28 07:32:04,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rsdm6hj', purging
2023-05-28 07:32:04,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqmp69ru', purging
2023-05-28 07:32:04,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3s4md8d', purging
2023-05-28 07:32:04,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvntxd0w', purging
2023-05-28 07:32:04,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4r6w7xhw', purging
2023-05-28 07:32:04,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5za7q62h', purging
2023-05-28 07:32:04,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:04,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:04,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:06,374 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,399 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,459 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,486 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,508 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,532 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:06,686 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:07,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngdof0by', purging
2023-05-28 07:32:07,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwo9tbof', purging
2023-05-28 07:32:07,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x77ts_hc', purging
2023-05-28 07:32:07,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6wuof7r', purging
2023-05-28 07:32:07,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh26x4kz', purging
2023-05-28 07:32:07,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_q3m0r77', purging
2023-05-28 07:32:07,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2fdf8kib', purging
2023-05-28 07:32:07,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tmu918oj', purging
2023-05-28 07:32:07,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:07,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:07,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:07,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:07,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:07,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:08,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:08,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:08,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:08,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:08,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:08,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:08,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:08,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:08,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:08,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:10,165 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,190 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,240 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,265 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,292 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,313 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,346 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:10,493 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:11,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pe17wlgm', purging
2023-05-28 07:32:11,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6u9fsa52', purging
2023-05-28 07:32:11,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ase7vair', purging
2023-05-28 07:32:11,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zs0__sqq', purging
2023-05-28 07:32:11,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kfgktae', purging
2023-05-28 07:32:11,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o82ky7qk', purging
2023-05-28 07:32:11,693 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3xk_cm7', purging
2023-05-28 07:32:11,693 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fs7u86kc', purging
2023-05-28 07:32:11,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:11,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:11,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:12,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:12,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:13,902 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:13,925 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:13,986 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:14,010 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:14,034 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:14,060 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:14,086 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:14,283 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:15,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ns5dxb3f', purging
2023-05-28 07:32:15,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fonpyb5v', purging
2023-05-28 07:32:15,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jn_42p8a', purging
2023-05-28 07:32:15,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmf3imhf', purging
2023-05-28 07:32:15,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yo7m_w5e', purging
2023-05-28 07:32:15,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6x5zy6v5', purging
2023-05-28 07:32:15,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z20eadz8', purging
2023-05-28 07:32:15,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j83o2hi4', purging
2023-05-28 07:32:15,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:15,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:15,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:17,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,529 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,589 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,610 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,659 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:17,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:17,965 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:18,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ms8_y0e', purging
2023-05-28 07:32:18,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lh2cxvll', purging
2023-05-28 07:32:18,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shfpppnu', purging
2023-05-28 07:32:18,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idjzafst', purging
2023-05-28 07:32:18,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ghb2s32w', purging
2023-05-28 07:32:18,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgwumd12', purging
2023-05-28 07:32:18,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwe6pmo9', purging
2023-05-28 07:32:18,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gw2dz8x', purging
2023-05-28 07:32:18,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:18,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:19,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:19,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:21,146 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,222 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,251 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,273 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,300 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,320 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:21,342 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:21,620 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:22,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bczltbh5', purging
2023-05-28 07:32:22,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8uidv4ut', purging
2023-05-28 07:32:22,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kgso2v28', purging
2023-05-28 07:32:22,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eal5v_jo', purging
2023-05-28 07:32:22,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cziak722', purging
2023-05-28 07:32:22,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9malu6_p', purging
2023-05-28 07:32:22,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r__qbjiu', purging
2023-05-28 07:32:22,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w8fpsbk', purging
2023-05-28 07:32:22,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:22,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:22,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:23,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:23,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:24,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:24,747 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:24,958 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:24,992 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:25,019 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:25,045 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:25,076 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:25,374 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:26,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yy37y8mo', purging
2023-05-28 07:32:26,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yejlgnt', purging
2023-05-28 07:32:26,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-837p65w6', purging
2023-05-28 07:32:26,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_eu9ili', purging
2023-05-28 07:32:26,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ln_su70e', purging
2023-05-28 07:32:26,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sc7ehja9', purging
2023-05-28 07:32:26,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gyw7clu8', purging
2023-05-28 07:32:26,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td2rmp6s', purging
2023-05-28 07:32:26,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:26,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:26,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:28,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,547 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,572 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,606 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,639 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:28,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:28,977 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:29,931 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8_9269w', purging
2023-05-28 07:32:29,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nen21kq', purging
2023-05-28 07:32:29,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f497yw3e', purging
2023-05-28 07:32:29,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldb8ot8k', purging
2023-05-28 07:32:29,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-teznrbm1', purging
2023-05-28 07:32:29,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6p1yxrks', purging
2023-05-28 07:32:29,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7u0092tx', purging
2023-05-28 07:32:29,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oszirvj6', purging
2023-05-28 07:32:29,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:29,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:30,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:30,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:32,069 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,097 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,152 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,173 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,203 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,229 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:32,255 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:32,548 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:33,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0gebaw5', purging
2023-05-28 07:32:33,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1elsrexv', purging
2023-05-28 07:32:33,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-67nl6f_r', purging
2023-05-28 07:32:33,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmizof9b', purging
2023-05-28 07:32:33,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33n3dr7t', purging
2023-05-28 07:32:33,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1hlcdcl', purging
2023-05-28 07:32:33,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65dzhs1c', purging
2023-05-28 07:32:33,473 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j1w73qy', purging
2023-05-28 07:32:33,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:33,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:33,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:34,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:34,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:35,646 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,672 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,698 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,734 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,771 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:35,834 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:36,112 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:37,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_lq8rz7', purging
2023-05-28 07:32:37,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1cj5ay25', purging
2023-05-28 07:32:37,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6dg8cath', purging
2023-05-28 07:32:37,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-748yr2en', purging
2023-05-28 07:32:37,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8fs8xm8f', purging
2023-05-28 07:32:37,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kuo_7rkl', purging
2023-05-28 07:32:37,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ck7litt', purging
2023-05-28 07:32:37,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un574u29', purging
2023-05-28 07:32:37,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:37,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:37,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:39,311 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:39,393 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:39,419 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:39,443 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:39,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:39,520 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:39,762 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:40,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mb6a28t0', purging
2023-05-28 07:32:40,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lzb5k5c0', purging
2023-05-28 07:32:40,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1pbkake4', purging
2023-05-28 07:32:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ox2m2xhw', purging
2023-05-28 07:32:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmofr1kp', purging
2023-05-28 07:32:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_md8hn0', purging
2023-05-28 07:32:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rw_caapf', purging
2023-05-28 07:32:40,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqrovily', purging
2023-05-28 07:32:40,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:40,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:40,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:40,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:40,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:40,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:40,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:40,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:40,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:40,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:41,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:41,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:41,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:41,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:42,719 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:42,739 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:42,763 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:42,790 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:42,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:42,863 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:43,122 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:44,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7v3dm3l6', purging
2023-05-28 07:32:44,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pu3za8kn', purging
2023-05-28 07:32:44,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4271l8b', purging
2023-05-28 07:32:44,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dek1eeij', purging
2023-05-28 07:32:44,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83bekde9', purging
2023-05-28 07:32:44,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-orw3zho3', purging
2023-05-28 07:32:44,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0kdh3rf', purging
2023-05-28 07:32:44,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:44,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:44,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:46,143 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,209 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,234 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,258 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,279 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,306 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:46,464 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:47,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pp8b2p23', purging
2023-05-28 07:32:47,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m49jqzgi', purging
2023-05-28 07:32:47,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2biy36pt', purging
2023-05-28 07:32:47,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-123on6wt', purging
2023-05-28 07:32:47,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf54i0wn', purging
2023-05-28 07:32:47,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6exx9g_x', purging
2023-05-28 07:32:47,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g2fwknop', purging
2023-05-28 07:32:47,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:47,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:47,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:49,508 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:49,558 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:49,595 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:49,620 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:49,652 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:49,674 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:49,904 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:50,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7hnerunc', purging
2023-05-28 07:32:50,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tl1yd98p', purging
2023-05-28 07:32:50,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-crfbue86', purging
2023-05-28 07:32:50,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7p2d879', purging
2023-05-28 07:32:50,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ehpbg954', purging
2023-05-28 07:32:50,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-54wk5pxu', purging
2023-05-28 07:32:50,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p4_hadb3', purging
2023-05-28 07:32:50,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:50,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:51,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:51,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:52,795 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:52,857 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:52,886 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:52,912 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:52,939 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:52,973 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:53,256 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:54,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gs4dje91', purging
2023-05-28 07:32:54,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2g5k6ck', purging
2023-05-28 07:32:54,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnbihvv7', purging
2023-05-28 07:32:54,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bw3dh_ja', purging
2023-05-28 07:32:54,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrhv3p5r', purging
2023-05-28 07:32:54,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p524nlrg', purging
2023-05-28 07:32:54,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_nk01yw', purging
2023-05-28 07:32:54,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:54,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:54,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:56,261 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:56,337 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:56,361 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:56,388 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:56,414 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:56,437 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:56,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:57,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sktosez1', purging
2023-05-28 07:32:57,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8u9adxw5', purging
2023-05-28 07:32:57,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgmfbtm4', purging
2023-05-28 07:32:57,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzh_nqa3', purging
2023-05-28 07:32:57,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7t7owl1', purging
2023-05-28 07:32:57,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qy91xk71', purging
2023-05-28 07:32:57,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bo25d4re', purging
2023-05-28 07:32:57,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:57,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:57,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:57,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:57,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:57,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:57,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:57,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:57,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:57,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:58,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:58,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:32:58,182 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:32:58,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:59,742 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:32:59,796 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:59,821 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:59,849 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:59,878 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:32:59,904 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:00,061 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:01,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yvpge3o', purging
2023-05-28 07:33:01,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x3yhecje', purging
2023-05-28 07:33:01,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-byhy2dn4', purging
2023-05-28 07:33:01,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uxw23x9g', purging
2023-05-28 07:33:01,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-anpgmo8_', purging
2023-05-28 07:33:01,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8e37o42b', purging
2023-05-28 07:33:01,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gcan27oy', purging
2023-05-28 07:33:01,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:01,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:01,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:03,211 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,235 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,291 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,315 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,339 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,366 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:03,570 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:04,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nixj5zu8', purging
2023-05-28 07:33:04,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5auda0h4', purging
2023-05-28 07:33:04,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98eu4641', purging
2023-05-28 07:33:04,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q88zq9s8', purging
2023-05-28 07:33:04,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57808fna', purging
2023-05-28 07:33:04,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qk16kqs0', purging
2023-05-28 07:33:04,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s333h1ol', purging
2023-05-28 07:33:04,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:04,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:04,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:04,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:04,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:04,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:04,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:05,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:05,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:06,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,710 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,732 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,759 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,784 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:06,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:08,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4z6hw7j', purging
2023-05-28 07:33:08,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2ule0jv', purging
2023-05-28 07:33:08,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qubo7v90', purging
2023-05-28 07:33:08,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e11um7n_', purging
2023-05-28 07:33:08,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4s25aqva', purging
2023-05-28 07:33:08,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkmkuezn', purging
2023-05-28 07:33:08,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02b3f9br', purging
2023-05-28 07:33:08,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:08,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:08,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:09,995 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:09,996 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:10,053 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:10,078 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:10,102 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:10,130 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:10,338 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:11,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vb95h6a6', purging
2023-05-28 07:33:11,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g5r79sqz', purging
2023-05-28 07:33:11,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6b22e4ed', purging
2023-05-28 07:33:11,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p6x51aoi', purging
2023-05-28 07:33:11,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kpl3f5fo', purging
2023-05-28 07:33:11,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dq9qcymf', purging
2023-05-28 07:33:11,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fo2781sz', purging
2023-05-28 07:33:11,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:11,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:11,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:13,470 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,531 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,554 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,580 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,605 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,630 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:13,790 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:14,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40nhw4hp', purging
2023-05-28 07:33:14,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tkmrka98', purging
2023-05-28 07:33:14,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7aw90bz', purging
2023-05-28 07:33:14,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xm78oy6w', purging
2023-05-28 07:33:14,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnli93gd', purging
2023-05-28 07:33:14,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pdasq3x4', purging
2023-05-28 07:33:14,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vv3hj70w', purging
2023-05-28 07:33:14,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:14,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:14,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:14,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:15,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:15,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:15,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:15,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:15,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:15,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:15,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:15,166 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:15,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:15,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:16,901 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,063 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,064 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,076 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,086 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,094 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:17,214 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:18,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qs4qdtfq', purging
2023-05-28 07:33:18,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-445alcp3', purging
2023-05-28 07:33:18,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqss4b61', purging
2023-05-28 07:33:18,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_3s17dh', purging
2023-05-28 07:33:18,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsa175rn', purging
2023-05-28 07:33:18,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4n9sqfn', purging
2023-05-28 07:33:18,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9o4fy6s', purging
2023-05-28 07:33:18,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:18,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:18,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:20,363 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,399 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,428 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,508 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,509 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,521 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:20,661 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:21,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l46pgl5z', purging
2023-05-28 07:33:21,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0p7y_nq', purging
2023-05-28 07:33:21,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-da3cqe6j', purging
2023-05-28 07:33:21,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-477_sn5u', purging
2023-05-28 07:33:21,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uprswxs1', purging
2023-05-28 07:33:21,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hys1o8qu', purging
2023-05-28 07:33:21,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfp7u_o5', purging
2023-05-28 07:33:21,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:21,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:21,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:21,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:21,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:21,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:21,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:21,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:21,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:21,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:22,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:22,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:22,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:22,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:23,830 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:23,896 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:23,925 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:23,942 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:33:24,193 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:25,235 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mki3bic1', purging
2023-05-28 07:33:25,236 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-poqhnl4p', purging
2023-05-28 07:33:25,236 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e61m9l0o', purging
2023-05-28 07:33:25,237 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40_z7e4a', purging
2023-05-28 07:33:25,237 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgq4yf_r', purging
2023-05-28 07:33:25,237 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmtq4f4q', purging
2023-05-28 07:33:25,238 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dvmgb747', purging
2023-05-28 07:33:25,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:25,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:25,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:25,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:25,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:25,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:25,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:25,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:25,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:25,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:26,651 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:26,708 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:26,735 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:26,757 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:27,036 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:28,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6inisds', purging
2023-05-28 07:33:28,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58hr9mp_', purging
2023-05-28 07:33:28,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5gwwmvh1', purging
2023-05-28 07:33:28,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gs8vd094', purging
2023-05-28 07:33:28,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ke2sl1o0', purging
2023-05-28 07:33:28,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:28,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:28,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:28,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:28,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:28,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:28,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:28,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:28,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:28,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:29,610 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:29,660 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:29,683 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:29,711 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:29,950 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:31,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bdsj4u01', purging
2023-05-28 07:33:31,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rezn8j6', purging
2023-05-28 07:33:31,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ohrn8oev', purging
2023-05-28 07:33:31,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfno_97m', purging
2023-05-28 07:33:31,044 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_aubl1w', purging
2023-05-28 07:33:31,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:31,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:31,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:31,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:31,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:31,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:31,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:31,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:31,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:31,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:32,491 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:32,542 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:32,574 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:32,590 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:32,759 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:33,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p3prj6ew', purging
2023-05-28 07:33:33,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5surb2dx', purging
2023-05-28 07:33:33,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xaogm1te', purging
2023-05-28 07:33:33,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0u5qte02', purging
2023-05-28 07:33:33,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ub7db9ku', purging
2023-05-28 07:33:33,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:33,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:33,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:33,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:34,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:34,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:34,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:34,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:34,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:34,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:35,327 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:35,380 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:35,404 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:35,430 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:35,583 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:36,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-znker8l6', purging
2023-05-28 07:33:36,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_1bwpce', purging
2023-05-28 07:33:36,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fazwd_b', purging
2023-05-28 07:33:36,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_upr9_hf', purging
2023-05-28 07:33:36,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3ce8m_u', purging
2023-05-28 07:33:36,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:36,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:36,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:36,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:36,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:36,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:36,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:36,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:37,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:37,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:38,218 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:38,244 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:38,271 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:38,294 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:38,452 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:39,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_nsujnb', purging
2023-05-28 07:33:39,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7zhlcvks', purging
2023-05-28 07:33:39,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f14kgar8', purging
2023-05-28 07:33:39,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-saf0kwhl', purging
2023-05-28 07:33:39,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7s9l4vrp', purging
2023-05-28 07:33:39,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:39,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:39,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:39,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:39,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:39,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:39,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:39,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:39,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:39,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:41,135 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:41,175 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:41,201 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:41,229 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:41,387 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:42,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5uu7weqs', purging
2023-05-28 07:33:42,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_p4aet_', purging
2023-05-28 07:33:42,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s8ywvkky', purging
2023-05-28 07:33:42,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gdcxxsyv', purging
2023-05-28 07:33:42,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akkh77wm', purging
2023-05-28 07:33:42,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:42,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:42,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:42,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:42,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:42,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:42,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:42,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:42,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:42,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:44,072 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:44,104 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:44,130 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:44,154 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:44,329 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:45,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7r8jxcg', purging
2023-05-28 07:33:45,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x050xoxu', purging
2023-05-28 07:33:45,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-11znpjkh', purging
2023-05-28 07:33:45,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7fhwtx9t', purging
2023-05-28 07:33:45,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jduh8s6', purging
2023-05-28 07:33:45,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:45,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:45,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:45,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:45,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:45,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:45,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:45,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:45,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:45,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:47,043 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:47,096 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:47,121 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:47,147 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:47,304 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:48,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uwyev36a', purging
2023-05-28 07:33:48,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ro7caz_6', purging
2023-05-28 07:33:48,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2r9j4bop', purging
2023-05-28 07:33:48,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2w9q49i', purging
2023-05-28 07:33:48,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zcfaevpr', purging
2023-05-28 07:33:48,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:48,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:48,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:48,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:48,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:48,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:48,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:48,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:48,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:48,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:49,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:50,008 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:50,038 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:50,065 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:50,224 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:51,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvn4dmh2', purging
2023-05-28 07:33:51,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oynjrfa7', purging
2023-05-28 07:33:51,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2n26ph88', purging
2023-05-28 07:33:51,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vyq2yemt', purging
2023-05-28 07:33:51,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iw1rmwn4', purging
2023-05-28 07:33:51,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:51,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:51,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:51,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:51,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:51,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:51,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:51,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:51,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:51,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:52,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:52,890 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:52,918 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:52,943 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:53,123 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:54,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa2_suxo', purging
2023-05-28 07:33:54,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7mlpdw6', purging
2023-05-28 07:33:54,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqd99lcu', purging
2023-05-28 07:33:54,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j2jcyok3', purging
2023-05-28 07:33:54,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kj2wbghr', purging
2023-05-28 07:33:54,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:54,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:54,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:54,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:54,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:54,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:54,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:54,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:54,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:54,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:55,783 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:55,836 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:55,859 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:55,887 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:56,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:57,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vx0ftnwi', purging
2023-05-28 07:33:57,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_mjltu9', purging
2023-05-28 07:33:57,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w7ahr63r', purging
2023-05-28 07:33:57,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1ogsaxb', purging
2023-05-28 07:33:57,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6avor_gb', purging
2023-05-28 07:33:57,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:57,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:57,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:57,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:57,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:57,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:57,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:57,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:33:57,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:33:57,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:33:58,712 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:58,767 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:58,789 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:58,813 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:33:58,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:00,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0m8k_qbb', purging
2023-05-28 07:34:00,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1e9_9mk5', purging
2023-05-28 07:34:00,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgqo0q3_', purging
2023-05-28 07:34:00,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s213afrl', purging
2023-05-28 07:34:00,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25zga9cw', purging
2023-05-28 07:34:00,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:00,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:00,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:00,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:00,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:00,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:00,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:00,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:00,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:00,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:01,651 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:01,704 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:01,727 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:01,752 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:01,926 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:03,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uh7a1y_s', purging
2023-05-28 07:34:03,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iduk35u2', purging
2023-05-28 07:34:03,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftmlm5r6', purging
2023-05-28 07:34:03,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rs6k33cy', purging
2023-05-28 07:34:03,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2wja159', purging
2023-05-28 07:34:03,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:03,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:03,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:03,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:03,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:03,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:03,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:03,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:03,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:03,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:04,581 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:04,626 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:04,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:04,678 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:04,845 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:05,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wl4d8e_i', purging
2023-05-28 07:34:05,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dzk8qk0', purging
2023-05-28 07:34:05,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_bbh5ael', purging
2023-05-28 07:34:05,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_ufvlbi', purging
2023-05-28 07:34:05,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s1exo7m_', purging
2023-05-28 07:34:05,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:05,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:06,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:06,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:06,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:06,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:06,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:06,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:06,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:06,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:07,488 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:07,511 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:07,558 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:07,590 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:07,741 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:08,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i99wz2ah', purging
2023-05-28 07:34:08,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obnewv4o', purging
2023-05-28 07:34:08,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v0_m959a', purging
2023-05-28 07:34:08,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qtfsegcf', purging
2023-05-28 07:34:08,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iahuob3r', purging
2023-05-28 07:34:08,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:08,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:08,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:08,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:08,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:08,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:09,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:09,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:09,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:09,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:10,415 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:10,517 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:10,518 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:10,529 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:10,680 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:11,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jo5m3qtm', purging
2023-05-28 07:34:11,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suyzseuw', purging
2023-05-28 07:34:11,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qlbky0df', purging
2023-05-28 07:34:11,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vtq65tk', purging
2023-05-28 07:34:11,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufdu8v9_', purging
2023-05-28 07:34:11,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:11,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:11,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:11,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:11,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:11,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:11,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:11,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:12,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:12,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:13,235 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:13,287 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:13,312 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:13,339 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:13,512 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:14,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwmra145', purging
2023-05-28 07:34:14,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-opqluljr', purging
2023-05-28 07:34:14,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ly42m4ge', purging
2023-05-28 07:34:14,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emm4xn40', purging
2023-05-28 07:34:14,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lveoqa3d', purging
2023-05-28 07:34:14,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:14,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:14,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:14,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:14,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:14,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:14,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:14,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:14,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:14,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:16,121 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:16,145 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:16,196 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:16,218 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:16,371 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:17,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0w4fruqc', purging
2023-05-28 07:34:17,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4t7hy39q', purging
2023-05-28 07:34:17,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gdaotxrw', purging
2023-05-28 07:34:17,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-inybqy72', purging
2023-05-28 07:34:17,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1x1zwtwm', purging
2023-05-28 07:34:17,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:17,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:17,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:17,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:17,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:17,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:17,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:17,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:17,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:17,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:19,034 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:19,059 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:19,089 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:19,112 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:19,270 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:20,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8zen20h', purging
2023-05-28 07:34:20,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5t37tgu', purging
2023-05-28 07:34:20,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dyv2bpwq', purging
2023-05-28 07:34:20,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cddwq1d5', purging
2023-05-28 07:34:20,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjzsk217', purging
2023-05-28 07:34:20,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:20,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:20,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:20,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:20,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:20,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:20,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:20,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:20,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:20,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:22,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:22,033 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:22,068 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:22,080 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:22,251 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:23,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-et126c1k', purging
2023-05-28 07:34:23,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g3r6_moo', purging
2023-05-28 07:34:23,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mp7koqzb', purging
2023-05-28 07:34:23,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aanm8bzm', purging
2023-05-28 07:34:23,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkhc9zsp', purging
2023-05-28 07:34:23,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:23,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:23,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:23,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:23,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:23,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:23,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:23,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:23,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:23,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:24,908 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:24,958 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:24,984 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:25,010 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:25,159 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:26,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iw32l8_e', purging
2023-05-28 07:34:26,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cesijb2q', purging
2023-05-28 07:34:26,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5l9zx42t', purging
2023-05-28 07:34:26,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o2f7fhn7', purging
2023-05-28 07:34:26,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1p9t_cv7', purging
2023-05-28 07:34:26,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:26,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:26,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:26,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:26,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:26,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:26,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:26,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:26,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:26,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:27,892 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:27,928 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:27,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:27,988 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:28,166 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:29,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1t1uixpf', purging
2023-05-28 07:34:29,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eyyvyvva', purging
2023-05-28 07:34:29,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e17ta3e', purging
2023-05-28 07:34:29,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wiacnw7y', purging
2023-05-28 07:34:29,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vcj3dz7u', purging
2023-05-28 07:34:29,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:29,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:29,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:29,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:29,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:29,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:29,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:29,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:29,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:29,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:30,748 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:30,800 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:30,823 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:30,853 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:31,008 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:32,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4q73z9we', purging
2023-05-28 07:34:32,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9anj__zn', purging
2023-05-28 07:34:32,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bso8qrm1', purging
2023-05-28 07:34:32,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0do2zr6w', purging
2023-05-28 07:34:32,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-boonpu89', purging
2023-05-28 07:34:32,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:32,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:32,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:32,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:32,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:32,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:32,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:32,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:32,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:32,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:33,702 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:33,754 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:33,777 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:33,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:33,968 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:35,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t_2iyzsb', purging
2023-05-28 07:34:35,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqhxxojp', purging
2023-05-28 07:34:35,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvx9bf4n', purging
2023-05-28 07:34:35,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7232a2w8', purging
2023-05-28 07:34:35,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x59hug56', purging
2023-05-28 07:34:35,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:35,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:35,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:35,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:35,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:35,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:35,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:35,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:35,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:35,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:36,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:36,698 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:36,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:36,744 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:36,917 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:38,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mk0iack', purging
2023-05-28 07:34:38,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n537hleg', purging
2023-05-28 07:34:38,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wywggxyz', purging
2023-05-28 07:34:38,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5wztz91', purging
2023-05-28 07:34:38,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_26bd6sl', purging
2023-05-28 07:34:38,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:38,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:38,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:38,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:38,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:38,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:38,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:38,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:38,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:38,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:39,556 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:39,584 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:39,636 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:39,648 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:39,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:40,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ljrc4fq', purging
2023-05-28 07:34:40,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6ga9510', purging
2023-05-28 07:34:40,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ogl2s768', purging
2023-05-28 07:34:40,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6zr1jrfq', purging
2023-05-28 07:34:40,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_vc7_98', purging
2023-05-28 07:34:40,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:40,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:40,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:40,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:41,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:41,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:41,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:41,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:41,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:41,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:42,383 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:42,489 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:42,490 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:34:42,643 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:43,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sc27oie2', purging
2023-05-28 07:34:43,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4ds5ni1', purging
2023-05-28 07:34:43,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5m1wf64w', purging
2023-05-28 07:34:43,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6dmj6v7', purging
2023-05-28 07:34:43,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppkf72zo', purging
2023-05-28 07:34:43,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:43,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:43,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:43,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:43,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:43,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:44,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:44,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:45,010 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:45,059 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:45,080 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:45,242 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:46,430 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_swol4x', purging
2023-05-28 07:34:46,430 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xa59mmk', purging
2023-05-28 07:34:46,431 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8qum5gje', purging
2023-05-28 07:34:46,431 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffk3z4yc', purging
2023-05-28 07:34:46,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:46,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:46,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:46,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:46,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:46,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:46,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:46,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:47,709 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:47,742 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:47,765 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:47,938 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:49,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arnnky_4', purging
2023-05-28 07:34:49,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tvv525_e', purging
2023-05-28 07:34:49,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-60vhgvun', purging
2023-05-28 07:34:49,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mo5p_qia', purging
2023-05-28 07:34:49,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:49,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:49,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:49,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:49,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:49,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:49,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:49,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:50,339 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:50,365 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:50,392 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:50,558 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:51,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3nid_ixm', purging
2023-05-28 07:34:51,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76z9_jgn', purging
2023-05-28 07:34:51,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lldbs4j6', purging
2023-05-28 07:34:51,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_d_px4j', purging
2023-05-28 07:34:51,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:51,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:51,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:51,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:51,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:51,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:51,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:51,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:52,980 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:53,007 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:53,038 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:53,213 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:54,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xikvy9i', purging
2023-05-28 07:34:54,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ks1d_qk_', purging
2023-05-28 07:34:54,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7gc5xqir', purging
2023-05-28 07:34:54,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8khzugl2', purging
2023-05-28 07:34:54,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:54,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:54,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:54,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:54,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:54,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:54,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:54,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:55,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:55,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:55,690 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:55,866 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:57,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1xbmocb', purging
2023-05-28 07:34:57,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktqyfo3x', purging
2023-05-28 07:34:57,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxw3g_j8', purging
2023-05-28 07:34:57,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8yn8tgwi', purging
2023-05-28 07:34:57,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:57,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:57,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:57,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:57,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:57,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:57,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:57,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:34:58,294 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:58,326 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:58,353 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:58,524 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:34:59,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_36stlmf', purging
2023-05-28 07:34:59,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-io1kt09d', purging
2023-05-28 07:34:59,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jclwqflb', purging
2023-05-28 07:34:59,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ln3jrr8p', purging
2023-05-28 07:34:59,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:59,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:59,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:59,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:59,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:59,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:34:59,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:34:59,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:00,974 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:01,022 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:01,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:01,205 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:02,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdsdk9yn', purging
2023-05-28 07:35:02,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_5npysee', purging
2023-05-28 07:35:02,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_o9n4jnu', purging
2023-05-28 07:35:02,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ykves6xa', purging
2023-05-28 07:35:02,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:02,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:02,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:02,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:02,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:02,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:02,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:02,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:03,602 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:03,643 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:03,670 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:03,828 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:05,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxrkig9x', purging
2023-05-28 07:35:05,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hfen29us', purging
2023-05-28 07:35:05,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlr8m53w', purging
2023-05-28 07:35:05,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-janjkj_n', purging
2023-05-28 07:35:05,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:05,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:05,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:05,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:05,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:05,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:05,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:05,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:06,316 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:06,348 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:06,362 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:06,519 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:07,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-51bu9065', purging
2023-05-28 07:35:07,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wm5tkkih', purging
2023-05-28 07:35:07,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:07,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j2gc4ej', purging
2023-05-28 07:35:07,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:07,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vupi0sqf', purging
2023-05-28 07:35:07,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:07,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:07,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:07,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:07,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:07,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:08,973 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:09,005 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:09,029 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:09,191 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:10,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jdrwj4ae', purging
2023-05-28 07:35:10,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ervjzx4', purging
2023-05-28 07:35:10,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vyb38amq', purging
2023-05-28 07:35:10,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uslcvc8l', purging
2023-05-28 07:35:10,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:10,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:10,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:10,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:10,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:10,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:10,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:10,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:11,613 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:11,661 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:11,692 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:11,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvvnp_5g', purging
2023-05-28 07:35:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qazngr43', purging
2023-05-28 07:35:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hz5v_i9v', purging
2023-05-28 07:35:12,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fxdkxy6u', purging
2023-05-28 07:35:12,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:12,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:13,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:13,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:13,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:13,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:13,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:13,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:14,232 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:14,276 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:14,305 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:14,463 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:15,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36d9leuq', purging
2023-05-28 07:35:15,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0dhrgexp', purging
2023-05-28 07:35:15,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvtrt4as', purging
2023-05-28 07:35:15,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgvfmhcb', purging
2023-05-28 07:35:15,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:15,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:15,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:15,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:15,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:15,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:15,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:15,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:16,908 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:16,932 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:16,961 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:17,132 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:18,308 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4t7y65i', purging
2023-05-28 07:35:18,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wmqo18uj', purging
2023-05-28 07:35:18,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xw6dyvlb', purging
2023-05-28 07:35:18,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrmha1x1', purging
2023-05-28 07:35:18,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:18,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:18,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:18,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:18,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:18,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:18,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:18,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:19,576 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:19,602 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:19,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:19,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:20,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2kszuyyd', purging
2023-05-28 07:35:20,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15ck3oza', purging
2023-05-28 07:35:20,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7znk2wx', purging
2023-05-28 07:35:20,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8eqatopv', purging
2023-05-28 07:35:20,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:20,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:21,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:21,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:21,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:21,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:21,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:21,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:22,257 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:22,279 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:22,302 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:22,476 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:23,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_dps6j3_', purging
2023-05-28 07:35:23,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r23nukfw', purging
2023-05-28 07:35:23,646 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oxtdkenn', purging
2023-05-28 07:35:23,646 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jyea3zux', purging
2023-05-28 07:35:23,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:23,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:23,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:23,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:23,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:23,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:23,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:23,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:24,916 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:24,978 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:35:25,165 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:26,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0e5uxk9f', purging
2023-05-28 07:35:26,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odrqooml', purging
2023-05-28 07:35:26,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psrj1x2y', purging
2023-05-28 07:35:26,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58yq1xxe', purging
2023-05-28 07:35:26,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:26,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:26,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:26,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:26,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:26,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:27,299 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:27,318 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:27,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:28,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:28,676 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ly8qy4p7', purging
2023-05-28 07:35:28,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:28,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqqfjiqa', purging
2023-05-28 07:35:28,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92t5gils', purging
2023-05-28 07:35:28,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:28,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:28,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:28,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:29,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:29,743 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:29,916 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:31,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ht1fbplz', purging
2023-05-28 07:35:31,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0sc5w4mq', purging
2023-05-28 07:35:31,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7yjygirn', purging
2023-05-28 07:35:31,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:31,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:31,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:31,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:31,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:31,288 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:32,175 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:32,197 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:32,377 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:33,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5aflkpc', purging
2023-05-28 07:35:33,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jk3csd3n', purging
2023-05-28 07:35:33,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzy8u331', purging
2023-05-28 07:35:33,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:33,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:33,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:33,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:33,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:33,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:34,581 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:34,609 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:34,772 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:35,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-54wq4lzp', purging
2023-05-28 07:35:35,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u3vz_4ty', purging
2023-05-28 07:35:35,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bci6k04y', purging
2023-05-28 07:35:35,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:35,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:35,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:35,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:36,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:36,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:37,036 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:37,069 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:37,249 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:38,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w9lixwt7', purging
2023-05-28 07:35:38,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ahuabke', purging
2023-05-28 07:35:38,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_p63gr2', purging
2023-05-28 07:35:38,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:38,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:38,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:38,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:38,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:38,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:39,450 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:39,485 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:39,646 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:40,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akn3ch63', purging
2023-05-28 07:35:40,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2a1i3wri', purging
2023-05-28 07:35:40,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sv8kuv8y', purging
2023-05-28 07:35:40,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:40,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:40,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:40,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:41,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:41,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:41,815 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:41,845 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:42,014 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:43,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-33ojpczi', purging
2023-05-28 07:35:43,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wa7d3q0z', purging
2023-05-28 07:35:43,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3fr66hbe', purging
2023-05-28 07:35:43,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:43,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:43,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:43,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:43,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:43,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:44,246 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:44,270 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:44,435 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:45,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:45,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tw57w1zg', purging
2023-05-28 07:35:45,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:45,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7bcr5ji', purging
2023-05-28 07:35:45,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p9lx3mx3', purging
2023-05-28 07:35:45,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:45,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:45,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:45,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:46,661 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:46,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:46,843 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:48,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:48,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6o02o1v', purging
2023-05-28 07:35:48,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:48,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b5g30djl', purging
2023-05-28 07:35:48,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgr4yq7f', purging
2023-05-28 07:35:48,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:48,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:48,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:48,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:49,087 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:49,112 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:49,272 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:50,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uh_kcldq', purging
2023-05-28 07:35:50,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-afhdixf1', purging
2023-05-28 07:35:50,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwibpxib', purging
2023-05-28 07:35:50,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:50,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:50,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:50,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:50,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:50,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:51,429 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:51,471 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:51,638 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:52,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v3_svqof', purging
2023-05-28 07:35:52,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57xahbvq', purging
2023-05-28 07:35:52,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6hfwim9', purging
2023-05-28 07:35:52,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:52,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:52,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:52,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:52,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:52,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:53,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:53,871 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:54,029 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:55,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4yqyyygq', purging
2023-05-28 07:35:55,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr22ziz9', purging
2023-05-28 07:35:55,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7surjddp', purging
2023-05-28 07:35:55,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:55,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:55,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:55,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:55,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:55,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:56,221 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:56,245 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:56,418 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:57,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8eg3zuh', purging
2023-05-28 07:35:57,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-worubf02', purging
2023-05-28 07:35:57,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rwf7j7u', purging
2023-05-28 07:35:57,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:57,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:57,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:57,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:35:57,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:57,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:35:58,619 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:58,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:58,828 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:35:59,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cyfbvu1a', purging
2023-05-28 07:35:59,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9zfdnbl', purging
2023-05-28 07:35:59,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fumwv2s9', purging
2023-05-28 07:35:59,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:35:59,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:00,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:00,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:00,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:00,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:01,013 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:01,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:01,215 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:02,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0cqb4ym6', purging
2023-05-28 07:36:02,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o61tes1y', purging
2023-05-28 07:36:02,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbrdkiyo', purging
2023-05-28 07:36:02,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:02,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:02,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:02,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:02,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:02,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:03,436 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:03,464 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:03,640 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:04,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv09wn__', purging
2023-05-28 07:36:04,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idg2kjd0', purging
2023-05-28 07:36:04,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2406rph6', purging
2023-05-28 07:36:04,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:04,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:04,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:04,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:05,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:05,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:05,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:05,878 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:06,047 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:07,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40xpzbnu', purging
2023-05-28 07:36:07,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyxs28jm', purging
2023-05-28 07:36:07,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-48071m69', purging
2023-05-28 07:36:07,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:07,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:07,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:07,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:07,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:07,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:08,308 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:08,329 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:08,505 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:09,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbwt6xas', purging
2023-05-28 07:36:09,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o9xn19oy', purging
2023-05-28 07:36:09,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7kvjmeq', purging
2023-05-28 07:36:09,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:09,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:09,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:09,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:09,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:09,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:10,762 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:10,786 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:10,965 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:12,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_kxtmxyf', purging
2023-05-28 07:36:12,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-66z7es1s', purging
2023-05-28 07:36:12,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_mxntyp9', purging
2023-05-28 07:36:12,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:12,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:12,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:12,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:12,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:12,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:13,176 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:13,201 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:13,370 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:14,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka6w8ckz', purging
2023-05-28 07:36:14,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvlj6ldt', purging
2023-05-28 07:36:14,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hy5l9t3b', purging
2023-05-28 07:36:14,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:14,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:14,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:14,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:14,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:14,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:15,622 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:15,657 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:15,811 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:16,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfxyy78_', purging
2023-05-28 07:36:16,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t4pirqdc', purging
2023-05-28 07:36:16,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_upghj9w', purging
2023-05-28 07:36:16,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:16,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:16,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:16,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:17,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:17,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:18,032 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:18,056 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:18,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:19,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-11rr9ivn', purging
2023-05-28 07:36:19,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sm7owy9b', purging
2023-05-28 07:36:19,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mbmaq8fb', purging
2023-05-28 07:36:19,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:19,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:19,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:19,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:19,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:19,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:20,430 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:20,450 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:20,614 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:21,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-040xs050', purging
2023-05-28 07:36:21,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yazyvsf7', purging
2023-05-28 07:36:21,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vuog1roh', purging
2023-05-28 07:36:21,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:21,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:21,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:21,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:21,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:21,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:22,853 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:22,877 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:23,060 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:24,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yo071pm1', purging
2023-05-28 07:36:24,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jbyp4t9', purging
2023-05-28 07:36:24,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2agf6kbg', purging
2023-05-28 07:36:24,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:24,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:24,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:24,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:24,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:24,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:25,277 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:25,311 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:25,475 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:26,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99bg6v00', purging
2023-05-28 07:36:26,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c5anm2x4', purging
2023-05-28 07:36:26,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hub656tn', purging
2023-05-28 07:36:26,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:26,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:26,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:26,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:26,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:26,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:27,725 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:27,748 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:27,911 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:29,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r3z_jkfl', purging
2023-05-28 07:36:29,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qiaiev_d', purging
2023-05-28 07:36:29,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfhv1d38', purging
2023-05-28 07:36:29,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:29,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:29,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:29,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:29,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:29,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:30,141 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:30,171 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:30,348 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:31,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qr14b3mn', purging
2023-05-28 07:36:31,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-016dgov1', purging
2023-05-28 07:36:31,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k2iimt77', purging
2023-05-28 07:36:31,527 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:31,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:31,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:31,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:31,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:31,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:32,603 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:32,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:32,797 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:33,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hzj5u21v', purging
2023-05-28 07:36:33,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lb07ez0m', purging
2023-05-28 07:36:33,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m4_5slz8', purging
2023-05-28 07:36:33,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:33,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:34,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:34,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:34,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:34,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:35,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:35,057 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:35,220 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:36,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:36,432 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wrt6sx88', purging
2023-05-28 07:36:36,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:36,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65fy2j_9', purging
2023-05-28 07:36:36,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2os2deul', purging
2023-05-28 07:36:36,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:36,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:36:36,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:36:36,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:36:37,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:37,524 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:36:37,691 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 831 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
