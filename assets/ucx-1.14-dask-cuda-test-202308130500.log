============================= test session starts ==============================
platform linux -- Python 3.9.17, pytest-7.4.0, pluggy-1.2.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-08-13 05:37:27,546 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:27,550 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36637 instead
  warnings.warn(
2023-08-13 05:37:27,553 - distributed.scheduler - INFO - State start
2023-08-13 05:37:27,572 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:27,573 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-13 05:37:27,573 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36637/status
2023-08-13 05:37:27,664 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46525'
2023-08-13 05:37:27,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33631'
2023-08-13 05:37:27,681 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42127'
2023-08-13 05:37:27,688 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39947'
2023-08-13 05:37:29,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:29,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:29,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:29,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:29,205 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:29,207 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:29,229 - distributed.scheduler - INFO - Receive client connection: Client-7c20a95e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:29,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:29,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:29,242 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:29,242 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42868
2023-08-13 05:37:29,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:29,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:29,290 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-08-13 05:37:29,607 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34929
2023-08-13 05:37:29,607 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34929
2023-08-13 05:37:29,607 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36093
2023-08-13 05:37:29,607 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-13 05:37:29,607 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:29,607 - distributed.worker - INFO -               Threads:                          4
2023-08-13 05:37:29,607 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-13 05:37:29,607 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-576yzjmg
2023-08-13 05:37:29,607 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-421f32ee-e63a-4bb5-b2b1-ff54af5ad12f
2023-08-13 05:37:29,608 - distributed.worker - INFO - Starting Worker plugin PreImport-000b0f9f-d0c0-4e48-a9c1-a99f6c83b5dd
2023-08-13 05:37:29,608 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13ddab8b-8cf5-4e1c-b3e2-68bfbbaf0c99
2023-08-13 05:37:29,608 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:29,623 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34929', status: init, memory: 0, processing: 0>
2023-08-13 05:37:29,624 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34929
2023-08-13 05:37:29,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42878
2023-08-13 05:37:29,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-13 05:37:29,625 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:29,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-13 05:37:30,544 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40337
2023-08-13 05:37:30,544 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42939
2023-08-13 05:37:30,545 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40337
2023-08-13 05:37:30,545 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42939
2023-08-13 05:37:30,545 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45093
2023-08-13 05:37:30,545 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39841
2023-08-13 05:37:30,545 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,545 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,545 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,545 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,545 - distributed.worker - INFO -               Threads:                          4
2023-08-13 05:37:30,545 - distributed.worker - INFO -               Threads:                          4
2023-08-13 05:37:30,545 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-13 05:37:30,545 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-slra6159
2023-08-13 05:37:30,545 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-13 05:37:30,545 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y8sh1jgb
2023-08-13 05:37:30,545 - distributed.worker - INFO - Starting Worker plugin PreImport-1644aadb-71b3-40f1-81c4-28b3c9ec5a6e
2023-08-13 05:37:30,545 - distributed.worker - INFO - Starting Worker plugin PreImport-1846b5f9-07fc-4961-b278-4c0d13c6c646
2023-08-13 05:37:30,546 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23e595b4-4441-4f33-b64b-8f9faa6f9dd0
2023-08-13 05:37:30,546 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aad3cb82-0c1a-4d73-ad34-18f213f3eff1
2023-08-13 05:37:30,546 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e4a188f-dfad-4b40-a7c1-805297aab584
2023-08-13 05:37:30,546 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,546 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d758683d-96c3-4124-bdeb-eb05529074fd
2023-08-13 05:37:30,546 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,568 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40337', status: init, memory: 0, processing: 0>
2023-08-13 05:37:30,569 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40337
2023-08-13 05:37:30,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42888
2023-08-13 05:37:30,569 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,569 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42939', status: init, memory: 0, processing: 0>
2023-08-13 05:37:30,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-13 05:37:30,572 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42939
2023-08-13 05:37:30,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42898
2023-08-13 05:37:30,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,572 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-13 05:37:30,640 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38249
2023-08-13 05:37:30,641 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38249
2023-08-13 05:37:30,641 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43971
2023-08-13 05:37:30,641 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,641 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,641 - distributed.worker - INFO -               Threads:                          4
2023-08-13 05:37:30,641 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-13 05:37:30,641 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k8boixtj
2023-08-13 05:37:30,641 - distributed.worker - INFO - Starting Worker plugin PreImport-131fe12f-d3b4-47e1-be64-1157b5841c48
2023-08-13 05:37:30,642 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b3763877-4a62-4e08-8d96-adafddc97ee9
2023-08-13 05:37:30,642 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4495d7d4-8a9c-4fa7-8e2a-e56e683e18e5
2023-08-13 05:37:30,642 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,665 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38249', status: init, memory: 0, processing: 0>
2023-08-13 05:37:30,666 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38249
2023-08-13 05:37:30,666 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42916
2023-08-13 05:37:30,666 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-13 05:37:30,667 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:30,669 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-13 05:37:30,678 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-13 05:37:30,678 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-13 05:37:30,678 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-13 05:37:30,678 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-13 05:37:30,683 - distributed.scheduler - INFO - Remove client Client-7c20a95e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:30,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42868; closing.
2023-08-13 05:37:30,683 - distributed.scheduler - INFO - Remove client Client-7c20a95e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:30,683 - distributed.scheduler - INFO - Close client connection: Client-7c20a95e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:30,684 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46525'. Reason: nanny-close
2023-08-13 05:37:30,685 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:30,685 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33631'. Reason: nanny-close
2023-08-13 05:37:30,686 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:30,686 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42127'. Reason: nanny-close
2023-08-13 05:37:30,686 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42939. Reason: nanny-close
2023-08-13 05:37:30,686 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:30,687 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40337. Reason: nanny-close
2023-08-13 05:37:30,687 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39947'. Reason: nanny-close
2023-08-13 05:37:30,687 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:30,687 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38249. Reason: nanny-close
2023-08-13 05:37:30,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-13 05:37:30,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42898; closing.
2023-08-13 05:37:30,688 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34929. Reason: nanny-close
2023-08-13 05:37:30,688 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42939', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:30,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-13 05:37:30,688 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42939
2023-08-13 05:37:30,689 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-13 05:37:30,689 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42888; closing.
2023-08-13 05:37:30,689 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:30,689 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:30,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40337', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:30,690 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42939
2023-08-13 05:37:30,690 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40337
2023-08-13 05:37:30,690 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-13 05:37:30,690 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:30,690 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42916; closing.
2023-08-13 05:37:30,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38249', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:30,691 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38249
2023-08-13 05:37:30,691 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42878; closing.
2023-08-13 05:37:30,691 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:30,691 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34929', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:30,692 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34929
2023-08-13 05:37:30,692 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:37:32,201 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:37:32,202 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:37:32,202 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:37:32,203 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-13 05:37:32,203 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-08-13 05:37:34,212 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:34,217 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33603 instead
  warnings.warn(
2023-08-13 05:37:34,221 - distributed.scheduler - INFO - State start
2023-08-13 05:37:34,274 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:34,275 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:37:34,276 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33603/status
2023-08-13 05:37:34,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37515'
2023-08-13 05:37:34,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45239'
2023-08-13 05:37:34,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35747'
2023-08-13 05:37:34,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40379'
2023-08-13 05:37:34,453 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38917'
2023-08-13 05:37:34,465 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45003'
2023-08-13 05:37:34,469 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42803'
2023-08-13 05:37:34,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35217'
2023-08-13 05:37:36,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,142 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,142 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,153 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,170 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,187 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,187 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:36,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:36,216 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,269 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:36,343 - distributed.scheduler - INFO - Receive client connection: Client-7fff0a2e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:36,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42060
2023-08-13 05:37:40,008 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44303
2023-08-13 05:37:40,008 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44303
2023-08-13 05:37:40,008 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40655
2023-08-13 05:37:40,008 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,008 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,008 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,009 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,009 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f683hbng
2023-08-13 05:37:40,009 - distributed.worker - INFO - Starting Worker plugin PreImport-2357f0ae-3db2-4775-81ca-4d8e30707b88
2023-08-13 05:37:40,009 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4b7b763d-c96a-40a5-bbb5-9cf0f31eb403
2023-08-13 05:37:40,009 - distributed.worker - INFO - Starting Worker plugin RMMSetup-492d6fcd-5114-4971-88ef-b4d260b33744
2023-08-13 05:37:40,019 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45613
2023-08-13 05:37:40,020 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45613
2023-08-13 05:37:40,020 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41315
2023-08-13 05:37:40,020 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,020 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,020 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,020 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,020 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ehn69v6s
2023-08-13 05:37:40,020 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46821
2023-08-13 05:37:40,020 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46821
2023-08-13 05:37:40,020 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35037
2023-08-13 05:37:40,020 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33263
2023-08-13 05:37:40,021 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,021 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df73505b-a977-4fb7-bf27-49a981d46087
2023-08-13 05:37:40,021 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33263
2023-08-13 05:37:40,021 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,021 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35991
2023-08-13 05:37:40,021 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,021 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,021 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,021 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nsu2nwy4
2023-08-13 05:37:40,021 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,021 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v5kufj1i
2023-08-13 05:37:40,021 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee155495-0ff5-4ed7-855e-fc9be3870bf1
2023-08-13 05:37:40,021 - distributed.worker - INFO - Starting Worker plugin PreImport-bac7407b-df71-4ba0-b881-1487bd0c476b
2023-08-13 05:37:40,022 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e8e3c836-91d7-4556-b7c8-43a43d106c96
2023-08-13 05:37:40,022 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c1dc46c6-853e-4d4e-8c0f-ce6b0adc9daf
2023-08-13 05:37:40,024 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43453
2023-08-13 05:37:40,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43453
2023-08-13 05:37:40,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46483
2023-08-13 05:37:40,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,025 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,025 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y82d1orc
2023-08-13 05:37:40,025 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d813de4-c121-4ac8-927a-13b379d03249
2023-08-13 05:37:40,027 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38311
2023-08-13 05:37:40,027 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38311
2023-08-13 05:37:40,027 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43563
2023-08-13 05:37:40,028 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,028 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,028 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,028 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,028 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fqe_afbw
2023-08-13 05:37:40,028 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0854932-cea3-45b7-8bc1-73014f59cd90
2023-08-13 05:37:40,450 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,458 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,458 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-794848e2-0587-4041-9946-2549de2c0910
2023-08-13 05:37:40,458 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ac6db477-73a2-4c7d-8fc5-4fb20690b5df
2023-08-13 05:37:40,459 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9f2a2fdf-774e-45e9-ae19-1f9dd6f82a11
2023-08-13 05:37:40,459 - distributed.worker - INFO - Starting Worker plugin PreImport-26e5fadb-e339-49e3-9c8b-c95b41e5af6e
2023-08-13 05:37:40,459 - distributed.worker - INFO - Starting Worker plugin PreImport-ea4af8db-fdaf-42db-b13e-b450254e96cc
2023-08-13 05:37:40,460 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e588d8d-3639-484e-8943-e504726a490a
2023-08-13 05:37:40,460 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,460 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,460 - distributed.worker - INFO - Starting Worker plugin PreImport-6bc41ce9-b8f9-445f-80b0-d7258b45c371
2023-08-13 05:37:40,460 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,463 - distributed.worker - INFO - Starting Worker plugin PreImport-9149be4a-5def-4439-854e-8fc219b5d702
2023-08-13 05:37:40,464 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,488 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33263', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,490 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33263
2023-08-13 05:37:40,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42076
2023-08-13 05:37:40,491 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,491 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44303', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44303
2023-08-13 05:37:40,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42090
2023-08-13 05:37:40,495 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,495 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,496 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43453', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,497 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43453
2023-08-13 05:37:40,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42098
2023-08-13 05:37:40,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,497 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38311', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,504 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38311
2023-08-13 05:37:40,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42102
2023-08-13 05:37:40,504 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,504 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,504 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46821', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,505 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46821
2023-08-13 05:37:40,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42106
2023-08-13 05:37:40,505 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,506 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45613', status: init, memory: 0, processing: 0>
2023-08-13 05:37:40,506 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,506 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45613
2023-08-13 05:37:40,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42100
2023-08-13 05:37:40,507 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,507 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,510 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:40,903 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45083
2023-08-13 05:37:40,904 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45083
2023-08-13 05:37:40,904 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36907
2023-08-13 05:37:40,904 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,904 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,904 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,905 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3dlpqryf
2023-08-13 05:37:40,905 - distributed.worker - INFO - Starting Worker plugin PreImport-5765eab6-d6b4-492a-97d7-dc9f2087378e
2023-08-13 05:37:40,905 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a62d14d0-823e-4750-bdd3-f24645d39e92
2023-08-13 05:37:40,905 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2663459-45f9-4ce6-9b8e-d98308b72c4d
2023-08-13 05:37:40,934 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34113
2023-08-13 05:37:40,935 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34113
2023-08-13 05:37:40,935 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45055
2023-08-13 05:37:40,935 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:40,935 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:40,935 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:40,936 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:40,936 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y7ynf611
2023-08-13 05:37:40,936 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d86357ee-7826-4fee-8a95-664df52d3de7
2023-08-13 05:37:41,064 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:41,068 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a0a6e338-0f77-4c68-bb30-4635d045b5d5
2023-08-13 05:37:41,068 - distributed.worker - INFO - Starting Worker plugin PreImport-4b0723f9-6352-407d-956a-f4d18354d9ec
2023-08-13 05:37:41,069 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:41,089 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45083', status: init, memory: 0, processing: 0>
2023-08-13 05:37:41,090 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45083
2023-08-13 05:37:41,091 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42112
2023-08-13 05:37:41,091 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:41,091 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:41,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:41,115 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34113', status: init, memory: 0, processing: 0>
2023-08-13 05:37:41,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34113
2023-08-13 05:37:41,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42118
2023-08-13 05:37:41,116 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:41,117 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:41,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:41,130 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,130 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,130 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,131 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,131 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,131 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,131 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,131 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:41,135 - distributed.scheduler - INFO - Remove client Client-7fff0a2e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:41,136 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42060; closing.
2023-08-13 05:37:41,136 - distributed.scheduler - INFO - Remove client Client-7fff0a2e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:41,136 - distributed.scheduler - INFO - Close client connection: Client-7fff0a2e-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:41,137 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40379'. Reason: nanny-close
2023-08-13 05:37:41,138 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,138 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37515'. Reason: nanny-close
2023-08-13 05:37:41,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45239'. Reason: nanny-close
2023-08-13 05:37:41,139 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35747'. Reason: nanny-close
2023-08-13 05:37:41,139 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45613. Reason: nanny-close
2023-08-13 05:37:41,140 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,140 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33263. Reason: nanny-close
2023-08-13 05:37:41,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38917'. Reason: nanny-close
2023-08-13 05:37:41,140 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,141 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44303. Reason: nanny-close
2023-08-13 05:37:41,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45003'. Reason: nanny-close
2023-08-13 05:37:41,141 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,141 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46821. Reason: nanny-close
2023-08-13 05:37:41,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42803'. Reason: nanny-close
2023-08-13 05:37:41,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,142 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42100; closing.
2023-08-13 05:37:41,142 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,142 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35217'. Reason: nanny-close
2023-08-13 05:37:41,142 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45613', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,142 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38311. Reason: nanny-close
2023-08-13 05:37:41,142 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45613
2023-08-13 05:37:41,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,142 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,142 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43453. Reason: nanny-close
2023-08-13 05:37:41,143 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42076; closing.
2023-08-13 05:37:41,143 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,143 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,143 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33263', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,143 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33263
2023-08-13 05:37:41,143 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45083. Reason: nanny-close
2023-08-13 05:37:41,144 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,144 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45613
2023-08-13 05:37:41,144 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,144 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45613
2023-08-13 05:37:41,144 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42090; closing.
2023-08-13 05:37:41,145 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,145 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45613
2023-08-13 05:37:41,145 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,146 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,145 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:42076>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-08-13 05:37:41,146 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:41,146 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44303', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,147 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44303
2023-08-13 05:37:41,147 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34113. Reason: nanny-close
2023-08-13 05:37:41,147 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42106; closing.
2023-08-13 05:37:41,147 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,147 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46821', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,147 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46821
2023-08-13 05:37:41,148 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42098; closing.
2023-08-13 05:37:41,148 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42102; closing.
2023-08-13 05:37:41,148 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43453', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,148 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43453
2023-08-13 05:37:41,149 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:41,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38311', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,149 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38311
2023-08-13 05:37:41,149 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42112; closing.
2023-08-13 05:37:41,150 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45083', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,150 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45083
2023-08-13 05:37:41,150 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:41,150 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42118; closing.
2023-08-13 05:37:41,151 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34113', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:41,151 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34113
2023-08-13 05:37:41,151 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:37:42,705 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:37:42,705 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:37:42,706 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:37:42,707 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:37:42,708 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-08-13 05:37:44,682 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:44,686 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36617 instead
  warnings.warn(
2023-08-13 05:37:44,690 - distributed.scheduler - INFO - State start
2023-08-13 05:37:44,709 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:44,710 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:37:44,711 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36617/status
2023-08-13 05:37:44,888 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39671'
2023-08-13 05:37:44,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40687'
2023-08-13 05:37:44,915 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34573'
2023-08-13 05:37:44,917 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44533'
2023-08-13 05:37:44,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44739'
2023-08-13 05:37:44,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41497'
2023-08-13 05:37:44,943 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36115'
2023-08-13 05:37:44,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39827'
2023-08-13 05:37:46,178 - distributed.scheduler - INFO - Receive client connection: Client-8650631f-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:46,191 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39702
2023-08-13 05:37:46,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:46,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:46,696 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:46,700 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:46,868 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:46,872 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:47,061 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:47,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:47,090 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:47,158 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:50,493 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37697
2023-08-13 05:37:50,494 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37697
2023-08-13 05:37:50,494 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35047
2023-08-13 05:37:50,494 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,494 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,494 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,494 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,495 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b1t562it
2023-08-13 05:37:50,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1a4d2d6-0ddb-4f14-a066-4f81913b9ecc
2023-08-13 05:37:50,532 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37285
2023-08-13 05:37:50,533 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37285
2023-08-13 05:37:50,533 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34383
2023-08-13 05:37:50,533 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,533 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,533 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,533 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z20ex9y3
2023-08-13 05:37:50,534 - distributed.worker - INFO - Starting Worker plugin PreImport-22295eb5-df2c-47dd-a235-c095bc517e03
2023-08-13 05:37:50,534 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8c6898f9-ebdf-460c-834f-2a9b642d7f69
2023-08-13 05:37:50,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1547e5c0-1360-4db0-8929-18b9c235d24d
2023-08-13 05:37:50,536 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66bfdd38-086c-4b99-a419-18a4ddc6ef8c
2023-08-13 05:37:50,537 - distributed.worker - INFO - Starting Worker plugin PreImport-15e00c8d-3768-4e58-93a1-b4007025e93b
2023-08-13 05:37:50,537 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,581 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,601 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37697', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,604 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37697
2023-08-13 05:37:50,604 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39714
2023-08-13 05:37:50,605 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,605 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,607 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,623 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37285', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,623 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37285
2023-08-13 05:37:50,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39724
2023-08-13 05:37:50,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,624 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,810 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42613
2023-08-13 05:37:50,811 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42613
2023-08-13 05:37:50,811 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34883
2023-08-13 05:37:50,811 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,811 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,811 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,811 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,811 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-viuepdk3
2023-08-13 05:37:50,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2f926ee-8cc9-418e-9d53-ec3499b01575
2023-08-13 05:37:50,820 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44151
2023-08-13 05:37:50,821 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44151
2023-08-13 05:37:50,821 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40941
2023-08-13 05:37:50,821 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40085
2023-08-13 05:37:50,821 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,821 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40085
2023-08-13 05:37:50,821 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,821 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40105
2023-08-13 05:37:50,822 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,821 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43815
2023-08-13 05:37:50,822 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,821 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,822 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43815
2023-08-13 05:37:50,822 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34593
2023-08-13 05:37:50,822 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,821 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44625
2023-08-13 05:37:50,822 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,822 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,822 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xl523bnj
2023-08-13 05:37:50,822 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44625
2023-08-13 05:37:50,822 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,822 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,822 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45447
2023-08-13 05:37:50,822 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sk_9yo0w
2023-08-13 05:37:50,822 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,822 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,822 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,822 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,822 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-amk6xwmp
2023-08-13 05:37:50,822 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,822 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,822 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8jhptle5
2023-08-13 05:37:50,822 - distributed.worker - INFO - Starting Worker plugin RMMSetup-da767bb4-a0b1-4b92-97b0-a9a4ded116b5
2023-08-13 05:37:50,822 - distributed.worker - INFO - Starting Worker plugin PreImport-141553bc-8f5c-4a1d-93de-9220373c762e
2023-08-13 05:37:50,822 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7834a5ca-1688-4a81-b53e-cc9fe444c692
2023-08-13 05:37:50,822 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ed668bf-0621-4a6c-a06f-bea3bf7f5bff
2023-08-13 05:37:50,823 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26030495-b36e-455e-8b8a-19f3bab022e9
2023-08-13 05:37:50,823 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a743075b-6d05-4f4d-9120-3dd9618ea9d5
2023-08-13 05:37:50,844 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36377
2023-08-13 05:37:50,845 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36377
2023-08-13 05:37:50,845 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37025
2023-08-13 05:37:50,845 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,845 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,845 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:37:50,846 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:37:50,846 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qa7ytb4u
2023-08-13 05:37:50,846 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2b1533b4-719b-4571-86b1-2b7e08008ec2
2023-08-13 05:37:50,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff002bd6-5d44-4481-a68d-54d1ae76290b
2023-08-13 05:37:50,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13236ae7-a18d-4383-ab7a-4da8c5361500
2023-08-13 05:37:50,887 - distributed.worker - INFO - Starting Worker plugin PreImport-084f3b35-40e1-4166-a432-1d2cf65e851d
2023-08-13 05:37:50,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e9babc0-9ccf-4a2a-abbb-638efb0bf351
2023-08-13 05:37:50,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21189a05-b9b6-4f32-b14d-b6a5ddc7e263
2023-08-13 05:37:50,887 - distributed.worker - INFO - Starting Worker plugin PreImport-fdbf3a59-b767-4793-82ac-8f776ce98b6c
2023-08-13 05:37:50,887 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,887 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,889 - distributed.worker - INFO - Starting Worker plugin PreImport-0514a71f-de29-4eeb-8ed5-830a3087a9f6
2023-08-13 05:37:50,889 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,886 - distributed.worker - INFO - Starting Worker plugin PreImport-78c4fa2a-2317-4c99-8ff6-e8b743f883c4
2023-08-13 05:37:50,891 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,891 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,926 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c7b46c28-6751-4a15-a14e-adb849377409
2023-08-13 05:37:50,927 - distributed.worker - INFO - Starting Worker plugin PreImport-fd4d188b-48e9-4552-be12-5370708bcc50
2023-08-13 05:37:50,927 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43815', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,929 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43815
2023-08-13 05:37:50,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39732
2023-08-13 05:37:50,929 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,929 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,930 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44625', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,931 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44625
2023-08-13 05:37:50,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39730
2023-08-13 05:37:50,932 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,932 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,933 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44151', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,933 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44151
2023-08-13 05:37:50,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39758
2023-08-13 05:37:50,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,934 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,934 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,935 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40085', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,936 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40085
2023-08-13 05:37:50,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39764
2023-08-13 05:37:50,936 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,936 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,937 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,937 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42613', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,938 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42613
2023-08-13 05:37:50,938 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39778
2023-08-13 05:37:50,938 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,939 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,939 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,942 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:50,980 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36377', status: init, memory: 0, processing: 0>
2023-08-13 05:37:50,980 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36377
2023-08-13 05:37:50,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39784
2023-08-13 05:37:50,981 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:37:50,981 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:37:50,983 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:37:51,061 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,061 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,062 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:37:51,067 - distributed.scheduler - INFO - Remove client Client-8650631f-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:51,067 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39702; closing.
2023-08-13 05:37:51,067 - distributed.scheduler - INFO - Remove client Client-8650631f-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:51,067 - distributed.scheduler - INFO - Close client connection: Client-8650631f-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:51,068 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44533'. Reason: nanny-close
2023-08-13 05:37:51,069 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39671'. Reason: nanny-close
2023-08-13 05:37:51,070 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,070 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42613. Reason: nanny-close
2023-08-13 05:37:51,070 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40687'. Reason: nanny-close
2023-08-13 05:37:51,070 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,071 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44151. Reason: nanny-close
2023-08-13 05:37:51,071 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34573'. Reason: nanny-close
2023-08-13 05:37:51,071 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,071 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36377. Reason: nanny-close
2023-08-13 05:37:51,071 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44739'. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37697. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41497'. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36115'. Reason: nanny-close
2023-08-13 05:37:51,072 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40085. Reason: nanny-close
2023-08-13 05:37:51,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39778; closing.
2023-08-13 05:37:51,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,073 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,073 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42613', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,073 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39827'. Reason: nanny-close
2023-08-13 05:37:51,073 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37285. Reason: nanny-close
2023-08-13 05:37:51,073 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42613
2023-08-13 05:37:51,073 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:37:51,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,074 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43815. Reason: nanny-close
2023-08-13 05:37:51,074 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39758; closing.
2023-08-13 05:37:51,074 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,074 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,074 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44151', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,074 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44151
2023-08-13 05:37:51,074 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,075 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39784; closing.
2023-08-13 05:37:51,075 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,075 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44625. Reason: nanny-close
2023-08-13 05:37:51,075 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,075 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,075 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,076 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36377', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,076 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36377
2023-08-13 05:37:51,076 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39714; closing.
2023-08-13 05:37:51,076 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,076 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,077 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,077 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42613
2023-08-13 05:37:51,078 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:37:51,077 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39758>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-08-13 05:37:51,078 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37697', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,079 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37697
2023-08-13 05:37:51,079 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39764; closing.
2023-08-13 05:37:51,079 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39732; closing.
2023-08-13 05:37:51,079 - distributed.nanny - INFO - Worker closed
2023-08-13 05:37:51,080 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40085', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,080 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40085
2023-08-13 05:37:51,080 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43815', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,080 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43815
2023-08-13 05:37:51,081 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39724; closing.
2023-08-13 05:37:51,081 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37285', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,081 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37285
2023-08-13 05:37:51,082 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39730; closing.
2023-08-13 05:37:51,082 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44625', status: closing, memory: 0, processing: 0>
2023-08-13 05:37:51,082 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44625
2023-08-13 05:37:51,083 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:37:51,083 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39730>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-08-13 05:37:52,586 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:37:52,586 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:37:52,586 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:37:52,587 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:37:52,588 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-08-13 05:37:54,640 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:54,644 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43527 instead
  warnings.warn(
2023-08-13 05:37:54,648 - distributed.scheduler - INFO - State start
2023-08-13 05:37:55,098 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:37:55,099 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:37:55,100 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43527/status
2023-08-13 05:37:55,242 - distributed.scheduler - INFO - Receive client connection: Client-8c34aa78-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:37:55,254 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51616
2023-08-13 05:37:55,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36973'
2023-08-13 05:37:55,444 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38267'
2023-08-13 05:37:55,446 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39965'
2023-08-13 05:37:55,454 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37039'
2023-08-13 05:37:55,462 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36799'
2023-08-13 05:37:55,471 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34477'
2023-08-13 05:37:55,479 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39363'
2023-08-13 05:37:55,486 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46835'
2023-08-13 05:37:57,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,208 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,208 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,212 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,265 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,270 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,270 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:37:57,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:37:57,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:37:57,401 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:00,131 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46635
2023-08-13 05:38:00,132 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46635
2023-08-13 05:38:00,132 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38651
2023-08-13 05:38:00,132 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,132 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,132 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,132 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,132 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-truyr1a5
2023-08-13 05:38:00,133 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b86edbb-ce80-4f3a-b1c1-283942fd5511
2023-08-13 05:38:00,150 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43063
2023-08-13 05:38:00,151 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43063
2023-08-13 05:38:00,151 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40929
2023-08-13 05:38:00,151 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,151 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,151 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,151 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,151 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-isk1_ag3
2023-08-13 05:38:00,152 - distributed.worker - INFO - Starting Worker plugin PreImport-b4c18bb0-5f92-41d1-b8ec-34440218ccdb
2023-08-13 05:38:00,152 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-422f740c-ec64-4809-9796-ff59085616b8
2023-08-13 05:38:00,152 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f159be83-4278-4882-a43c-300f09d16871
2023-08-13 05:38:00,348 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37001
2023-08-13 05:38:00,349 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37001
2023-08-13 05:38:00,349 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33557
2023-08-13 05:38:00,349 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,349 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,349 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,349 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,349 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k0c0i932
2023-08-13 05:38:00,350 - distributed.worker - INFO - Starting Worker plugin PreImport-de5a0aa9-8f43-4f22-9a11-2c048c54958f
2023-08-13 05:38:00,350 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a0c36dea-71d3-42a7-a2cf-451e06256df0
2023-08-13 05:38:00,350 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d16b96a3-56d0-493b-b780-9aabe0c11eb4
2023-08-13 05:38:00,354 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39687
2023-08-13 05:38:00,355 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39687
2023-08-13 05:38:00,355 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33839
2023-08-13 05:38:00,355 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,355 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,355 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,355 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,355 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-54uaxbuw
2023-08-13 05:38:00,356 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0458ea5b-baff-41e3-aa78-a4beff9a2ff3
2023-08-13 05:38:00,375 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40075
2023-08-13 05:38:00,377 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40075
2023-08-13 05:38:00,377 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36601
2023-08-13 05:38:00,377 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,377 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,377 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,377 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c_sknc4z
2023-08-13 05:38:00,378 - distributed.worker - INFO - Starting Worker plugin RMMSetup-863493e6-12d0-43f6-bfcb-c8febbe32682
2023-08-13 05:38:00,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39865
2023-08-13 05:38:00,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39865
2023-08-13 05:38:00,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35647
2023-08-13 05:38:00,383 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,383 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,383 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,383 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3xca1esm
2023-08-13 05:38:00,383 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbe558f3-5d4e-44c9-925c-7116b93b7ba5
2023-08-13 05:38:00,401 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c0dec73-d9c3-4a7a-94ad-34ac8e896028
2023-08-13 05:38:00,401 - distributed.worker - INFO - Starting Worker plugin PreImport-220ca41e-b9e2-4b6b-998f-306ba101bc6e
2023-08-13 05:38:00,402 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,402 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,429 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43063', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,431 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43063
2023-08-13 05:38:00,431 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51726
2023-08-13 05:38:00,431 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,432 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,434 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,446 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46635', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,446 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46635
2023-08-13 05:38:00,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51730
2023-08-13 05:38:00,447 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,447 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,450 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,487 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39259
2023-08-13 05:38:00,488 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39259
2023-08-13 05:38:00,488 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44217
2023-08-13 05:38:00,488 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,488 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,488 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,488 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,488 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p2w315iv
2023-08-13 05:38:00,489 - distributed.worker - INFO - Starting Worker plugin PreImport-46533fe0-b41b-4ca0-bbce-2b1758bb7463
2023-08-13 05:38:00,489 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b82fd10-0a0a-4e1b-ba04-07b74edb2ac2
2023-08-13 05:38:00,489 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a73e44a9-4157-448f-b0eb-6b3e5af8b4cb
2023-08-13 05:38:00,552 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38463
2023-08-13 05:38:00,553 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38463
2023-08-13 05:38:00,553 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46607
2023-08-13 05:38:00,553 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,553 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,553 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:00,554 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:00,554 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-i6ve76kp
2023-08-13 05:38:00,554 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0a2b514-3d5f-4e76-a467-c0c65711e893
2023-08-13 05:38:00,603 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,613 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73950d63-b250-45e0-91c0-fc04bd871c2e
2023-08-13 05:38:00,614 - distributed.worker - INFO - Starting Worker plugin PreImport-88683562-fded-4736-879f-b2346784538f
2023-08-13 05:38:00,614 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11cc4892-185b-43df-aeac-ae9d5cfb47c7
2023-08-13 05:38:00,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8117cc4d-5ff2-41c4-beb3-c5b0263bf45e
2023-08-13 05:38:00,623 - distributed.worker - INFO - Starting Worker plugin PreImport-2d2f49e7-f78d-450a-9e33-3807bcf05d03
2023-08-13 05:38:00,623 - distributed.worker - INFO - Starting Worker plugin PreImport-097ce21c-c08c-417a-8125-746716da0ff3
2023-08-13 05:38:00,623 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,623 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,629 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37001', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,630 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37001
2023-08-13 05:38:00,630 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51734
2023-08-13 05:38:00,630 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,630 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,637 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,645 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39687', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,646 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39687
2023-08-13 05:38:00,646 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51750
2023-08-13 05:38:00,646 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,646 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,648 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39865', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,649 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39865
2023-08-13 05:38:00,649 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51764
2023-08-13 05:38:00,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,649 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,654 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40075', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,655 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40075
2023-08-13 05:38:00,655 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51770
2023-08-13 05:38:00,655 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,656 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,658 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,660 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39259', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,661 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39259
2023-08-13 05:38:00,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51786
2023-08-13 05:38:00,661 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,661 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,692 - distributed.worker - INFO - Starting Worker plugin PreImport-abe80d91-6708-4ded-99e2-d06df872825f
2023-08-13 05:38:00,692 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9232db3-3677-4772-b875-59dba8434172
2023-08-13 05:38:00,692 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,725 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38463', status: init, memory: 0, processing: 0>
2023-08-13 05:38:00,725 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38463
2023-08-13 05:38:00,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51790
2023-08-13 05:38:00,726 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:00,726 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:00,728 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:00,746 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,746 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,747 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,747 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,747 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,747 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,747 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,748 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:00,757 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,758 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:00,764 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:00,765 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:00,768 - distributed.scheduler - INFO - Remove client Client-8c34aa78-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:00,768 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51616; closing.
2023-08-13 05:38:00,768 - distributed.scheduler - INFO - Remove client Client-8c34aa78-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:00,768 - distributed.scheduler - INFO - Close client connection: Client-8c34aa78-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:00,769 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38267'. Reason: nanny-close
2023-08-13 05:38:00,770 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,770 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36799'. Reason: nanny-close
2023-08-13 05:38:00,771 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,771 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36973'. Reason: nanny-close
2023-08-13 05:38:00,771 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38463. Reason: nanny-close
2023-08-13 05:38:00,771 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,772 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39965'. Reason: nanny-close
2023-08-13 05:38:00,772 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39687. Reason: nanny-close
2023-08-13 05:38:00,772 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,772 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39259. Reason: nanny-close
2023-08-13 05:38:00,772 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37039'. Reason: nanny-close
2023-08-13 05:38:00,773 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,773 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43063. Reason: nanny-close
2023-08-13 05:38:00,773 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34477'. Reason: nanny-close
2023-08-13 05:38:00,773 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,773 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51790; closing.
2023-08-13 05:38:00,773 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,774 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,774 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39363'. Reason: nanny-close
2023-08-13 05:38:00,774 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46635. Reason: nanny-close
2023-08-13 05:38:00,774 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38463', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,774 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38463
2023-08-13 05:38:00,774 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,774 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,774 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40075. Reason: nanny-close
2023-08-13 05:38:00,774 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46835'. Reason: nanny-close
2023-08-13 05:38:00,775 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:00,775 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51750; closing.
2023-08-13 05:38:00,775 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39865. Reason: nanny-close
2023-08-13 05:38:00,775 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,775 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,775 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,775 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,775 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38463
2023-08-13 05:38:00,776 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39687', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,776 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39687
2023-08-13 05:38:00,776 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37001. Reason: nanny-close
2023-08-13 05:38:00,776 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38463
2023-08-13 05:38:00,776 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,776 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51786; closing.
2023-08-13 05:38:00,776 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38463
2023-08-13 05:38:00,776 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38463
2023-08-13 05:38:00,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,777 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39259', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,777 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39259
2023-08-13 05:38:00,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:00,777 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51726; closing.
2023-08-13 05:38:00,777 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,778 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43063', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,778 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43063
2023-08-13 05:38:00,778 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,778 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51730; closing.
2023-08-13 05:38:00,778 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,778 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:00,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51764; closing.
2023-08-13 05:38:00,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51770; closing.
2023-08-13 05:38:00,779 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46635', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,779 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46635
2023-08-13 05:38:00,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39865', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,780 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39865
2023-08-13 05:38:00,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40075', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,781 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40075
2023-08-13 05:38:00,781 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51734; closing.
2023-08-13 05:38:00,782 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37001', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:00,782 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37001
2023-08-13 05:38:00,782 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:02,186 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:02,187 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:02,187 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:02,188 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:02,188 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-08-13 05:38:04,073 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:04,077 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37327 instead
  warnings.warn(
2023-08-13 05:38:04,081 - distributed.scheduler - INFO - State start
2023-08-13 05:38:04,101 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:04,102 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:04,103 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37327/status
2023-08-13 05:38:04,458 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44739'
2023-08-13 05:38:04,479 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35547'
2023-08-13 05:38:04,488 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35193'
2023-08-13 05:38:04,491 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34423'
2023-08-13 05:38:04,499 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35173'
2023-08-13 05:38:04,509 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43785'
2023-08-13 05:38:04,518 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37931'
2023-08-13 05:38:04,527 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45563'
2023-08-13 05:38:05,783 - distributed.scheduler - INFO - Receive client connection: Client-91e2d59d-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:05,797 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52158
2023-08-13 05:38:06,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,164 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,233 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,241 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,244 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:06,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:06,268 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,277 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:06,466 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:08,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44047
2023-08-13 05:38:08,858 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44047
2023-08-13 05:38:08,858 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40565
2023-08-13 05:38:08,858 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:08,858 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:08,858 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:08,858 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:08,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s1mqxqxr
2023-08-13 05:38:08,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eafce321-d8e5-4b55-857d-b7f44d35c568
2023-08-13 05:38:08,979 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae224b61-2e1a-4eae-91ff-cecbff5d6c4d
2023-08-13 05:38:08,982 - distributed.worker - INFO - Starting Worker plugin PreImport-ec16d6db-2b93-4e2d-bb09-344a2aaacc1c
2023-08-13 05:38:08,983 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,021 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44047', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,022 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44047
2023-08-13 05:38:09,022 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52180
2023-08-13 05:38:09,023 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,023 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,025 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,358 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36241
2023-08-13 05:38:09,359 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36241
2023-08-13 05:38:09,359 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40985
2023-08-13 05:38:09,359 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,359 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,359 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,360 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,360 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a1u2_1ou
2023-08-13 05:38:09,360 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2e2725ff-e67b-4391-a440-af210f029846
2023-08-13 05:38:09,365 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42029
2023-08-13 05:38:09,366 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42029
2023-08-13 05:38:09,365 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39585
2023-08-13 05:38:09,366 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34575
2023-08-13 05:38:09,366 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39585
2023-08-13 05:38:09,366 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,366 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,366 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43415
2023-08-13 05:38:09,366 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,366 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,366 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,367 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,366 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,367 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z52j6man
2023-08-13 05:38:09,367 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,367 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t8qq421p
2023-08-13 05:38:09,367 - distributed.worker - INFO - Starting Worker plugin RMMSetup-961a0c9b-3008-4e7f-8da2-ea98ebc74794
2023-08-13 05:38:09,367 - distributed.worker - INFO - Starting Worker plugin PreImport-379b04bc-ad5e-4474-be7d-e9ccd11c3797
2023-08-13 05:38:09,367 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-819ed884-ec6b-4b89-a15f-1bf2575649e1
2023-08-13 05:38:09,367 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b677efd-dc37-4362-98a2-2d54803e3869
2023-08-13 05:38:09,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34997
2023-08-13 05:38:09,369 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34997
2023-08-13 05:38:09,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34821
2023-08-13 05:38:09,369 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,369 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,369 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,369 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lhpbodf4
2023-08-13 05:38:09,370 - distributed.worker - INFO - Starting Worker plugin PreImport-8071d409-6f46-4796-a240-e3ed6aa9928d
2023-08-13 05:38:09,370 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad63bbe0-600d-4a3b-bd1c-9c108a360d7b
2023-08-13 05:38:09,370 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c93035c9-3b2a-4d93-b3a6-99893fb71f4e
2023-08-13 05:38:09,372 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39159
2023-08-13 05:38:09,373 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39159
2023-08-13 05:38:09,373 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43739
2023-08-13 05:38:09,373 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,373 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,373 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,374 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,374 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uhqdufut
2023-08-13 05:38:09,374 - distributed.worker - INFO - Starting Worker plugin RMMSetup-868c0c8a-d566-4a62-be6e-c0117484dc4e
2023-08-13 05:38:09,379 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44193
2023-08-13 05:38:09,380 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44193
2023-08-13 05:38:09,380 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33995
2023-08-13 05:38:09,380 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,380 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,380 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,380 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,380 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-u0eqjwl3
2023-08-13 05:38:09,381 - distributed.worker - INFO - Starting Worker plugin PreImport-78153a4a-ea95-4275-8fe9-615244283bf6
2023-08-13 05:38:09,381 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a362aec3-27e1-42c7-bbff-fd6d7f4e0e3c
2023-08-13 05:38:09,380 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37685
2023-08-13 05:38:09,381 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37685
2023-08-13 05:38:09,381 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34269
2023-08-13 05:38:09,381 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,381 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,381 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f534a7ef-8f84-4c63-b761-9c4cb5996cba
2023-08-13 05:38:09,382 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:09,382 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:09,382 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nccsznz2
2023-08-13 05:38:09,383 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dea6be38-30f8-4c7b-a42d-35b7396557c3
2023-08-13 05:38:09,517 - distributed.worker - INFO - Starting Worker plugin PreImport-bed74d42-9452-4d6a-9864-bc55ea31b534
2023-08-13 05:38:09,518 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-605fdc97-a4af-41f4-a75d-143d2dbf3f29
2023-08-13 05:38:09,518 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,522 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9939290-7ce7-4c5b-8a99-1dd42fb469bf
2023-08-13 05:38:09,522 - distributed.worker - INFO - Starting Worker plugin PreImport-32127ff5-a7be-427a-a931-ef6ebdd57fab
2023-08-13 05:38:09,522 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,522 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f320488-63cd-405e-b111-7e6c28010795
2023-08-13 05:38:09,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,523 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48877fcd-2504-48f3-9fc5-44a5b599a2cd
2023-08-13 05:38:09,523 - distributed.worker - INFO - Starting Worker plugin PreImport-d570d48c-9d37-4479-8d39-10f21db82384
2023-08-13 05:38:09,523 - distributed.worker - INFO - Starting Worker plugin PreImport-0caeada2-c512-4f52-8c4a-4ff7ac60ca23
2023-08-13 05:38:09,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,523 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,545 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36241', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,546 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36241
2023-08-13 05:38:09,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52186
2023-08-13 05:38:09,547 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,547 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,549 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,552 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34997', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,552 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34997
2023-08-13 05:38:09,552 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52202
2023-08-13 05:38:09,553 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,553 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,553 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37685', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,554 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37685
2023-08-13 05:38:09,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52220
2023-08-13 05:38:09,554 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,555 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,556 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,556 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44193', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,556 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,556 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44193
2023-08-13 05:38:09,557 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52242
2023-08-13 05:38:09,557 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,557 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,558 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39159', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,558 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39159
2023-08-13 05:38:09,558 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52210
2023-08-13 05:38:09,559 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,559 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,560 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,563 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42029', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,563 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42029
2023-08-13 05:38:09,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52236
2023-08-13 05:38:09,564 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,564 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,564 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39585', status: init, memory: 0, processing: 0>
2023-08-13 05:38:09,564 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39585
2023-08-13 05:38:09,564 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52248
2023-08-13 05:38:09,565 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:09,565 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:09,566 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,659 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,659 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:09,663 - distributed.scheduler - INFO - Remove client Client-91e2d59d-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:09,663 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52158; closing.
2023-08-13 05:38:09,663 - distributed.scheduler - INFO - Remove client Client-91e2d59d-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:09,664 - distributed.scheduler - INFO - Close client connection: Client-91e2d59d-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:09,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34423'. Reason: nanny-close
2023-08-13 05:38:09,665 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,665 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44739'. Reason: nanny-close
2023-08-13 05:38:09,666 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,666 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36241. Reason: nanny-close
2023-08-13 05:38:09,666 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35547'. Reason: nanny-close
2023-08-13 05:38:09,667 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,667 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39159. Reason: nanny-close
2023-08-13 05:38:09,667 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35193'. Reason: nanny-close
2023-08-13 05:38:09,667 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39585. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35173'. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52186; closing.
2023-08-13 05:38:09,668 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43785'. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36241', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,668 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34997. Reason: nanny-close
2023-08-13 05:38:09,668 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,668 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,669 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,669 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37685. Reason: nanny-close
2023-08-13 05:38:09,669 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37931'. Reason: nanny-close
2023-08-13 05:38:09,669 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,669 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,669 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44047. Reason: nanny-close
2023-08-13 05:38:09,669 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45563'. Reason: nanny-close
2023-08-13 05:38:09,670 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,670 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:09,670 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,670 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52210; closing.
2023-08-13 05:38:09,670 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,670 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,670 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,671 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39159', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,671 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39159
2023-08-13 05:38:09,671 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,671 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42029. Reason: nanny-close
2023-08-13 05:38:09,671 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,671 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44193. Reason: nanny-close
2023-08-13 05:38:09,671 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,671 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52248; closing.
2023-08-13 05:38:09,671 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36241
2023-08-13 05:38:09,671 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52202; closing.
2023-08-13 05:38:09,672 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39585', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,672 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39585
2023-08-13 05:38:09,672 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,672 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,672 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34997', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,673 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34997
2023-08-13 05:38:09,673 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,673 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52220; closing.
2023-08-13 05:38:09,673 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,673 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:09,673 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37685', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,673 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37685
2023-08-13 05:38:09,673 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,674 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52180; closing.
2023-08-13 05:38:09,674 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,674 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:09,674 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44047', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,674 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44047
2023-08-13 05:38:09,675 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52236; closing.
2023-08-13 05:38:09,675 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52242; closing.
2023-08-13 05:38:09,675 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42029', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,676 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42029
2023-08-13 05:38:09,676 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44193', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:09,676 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44193
2023-08-13 05:38:09,676 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:11,332 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:11,332 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:11,333 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:11,333 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:11,334 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-08-13 05:38:13,498 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:13,504 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43407 instead
  warnings.warn(
2023-08-13 05:38:13,508 - distributed.scheduler - INFO - State start
2023-08-13 05:38:13,531 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:13,532 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:13,533 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43407/status
2023-08-13 05:38:13,540 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35209'
2023-08-13 05:38:14,142 - distributed.scheduler - INFO - Receive client connection: Client-975a9be7-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:14,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52400
2023-08-13 05:38:14,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:14,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-13 05:38:15,595 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:17,294 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40933
2023-08-13 05:38:17,294 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40933
2023-08-13 05:38:17,295 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-08-13 05:38:17,295 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:17,295 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:17,295 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:17,295 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-13 05:38:17,295 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yqg156_t
2023-08-13 05:38:17,295 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dcb741d3-1401-48e9-968b-16f55a155545
2023-08-13 05:38:17,295 - distributed.worker - INFO - Starting Worker plugin PreImport-73a4f4cb-9fe5-44f4-a4f4-2b6d212c0453
2023-08-13 05:38:17,296 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21df945f-0513-4480-afe8-27f34a807e28
2023-08-13 05:38:17,296 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:17,328 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40933', status: init, memory: 0, processing: 0>
2023-08-13 05:38:17,330 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40933
2023-08-13 05:38:17,330 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49200
2023-08-13 05:38:17,331 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:17,331 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:17,335 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:17,337 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:17,341 - distributed.scheduler - INFO - Remove client Client-975a9be7-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:17,341 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52400; closing.
2023-08-13 05:38:17,341 - distributed.scheduler - INFO - Remove client Client-975a9be7-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:17,341 - distributed.scheduler - INFO - Close client connection: Client-975a9be7-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:17,343 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35209'. Reason: nanny-close
2023-08-13 05:38:17,376 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:17,377 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40933. Reason: nanny-close
2023-08-13 05:38:17,379 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49200; closing.
2023-08-13 05:38:17,379 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:17,379 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40933', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:17,380 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40933
2023-08-13 05:38:17,380 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:17,381 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:18,710 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:18,710 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:18,711 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:18,711 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:18,712 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-08-13 05:38:22,510 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:22,514 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33733 instead
  warnings.warn(
2023-08-13 05:38:22,518 - distributed.scheduler - INFO - State start
2023-08-13 05:38:22,539 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:22,539 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:22,540 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33733/status
2023-08-13 05:38:22,549 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43507'
2023-08-13 05:38:23,137 - distributed.scheduler - INFO - Receive client connection: Client-9cc8470c-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:23,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49350
2023-08-13 05:38:24,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:24,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-13 05:38:24,728 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:27,111 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43187
2023-08-13 05:38:27,111 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43187
2023-08-13 05:38:27,111 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43341
2023-08-13 05:38:27,112 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:27,112 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:27,112 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:27,112 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-13 05:38:27,112 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ia7q129c
2023-08-13 05:38:27,113 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53412dda-45d4-4c8e-b339-ab4614eae588
2023-08-13 05:38:27,113 - distributed.worker - INFO - Starting Worker plugin PreImport-733c5e37-a8f6-4cc2-b257-37a339fd052d
2023-08-13 05:38:27,114 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f10af21-f126-4eb8-8168-33cb138239a8
2023-08-13 05:38:27,114 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:27,160 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43187', status: init, memory: 0, processing: 0>
2023-08-13 05:38:27,163 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43187
2023-08-13 05:38:27,163 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59832
2023-08-13 05:38:27,164 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:27,164 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:27,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:27,175 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:27,179 - distributed.scheduler - INFO - Remove client Client-9cc8470c-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:27,179 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49350; closing.
2023-08-13 05:38:27,179 - distributed.scheduler - INFO - Remove client Client-9cc8470c-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:27,180 - distributed.scheduler - INFO - Close client connection: Client-9cc8470c-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:27,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43507'. Reason: nanny-close
2023-08-13 05:38:27,195 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:27,196 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43187. Reason: nanny-close
2023-08-13 05:38:27,199 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:27,199 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59832; closing.
2023-08-13 05:38:27,200 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43187', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:27,200 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43187
2023-08-13 05:38:27,200 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:27,200 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:28,398 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:28,399 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:28,400 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:28,401 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:28,401 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-08-13 05:38:30,348 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:30,352 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33201 instead
  warnings.warn(
2023-08-13 05:38:30,355 - distributed.scheduler - INFO - State start
2023-08-13 05:38:30,401 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:30,402 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:30,402 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33201/status
2023-08-13 05:38:33,997 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:33,998 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:33,998 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:33,999 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:33,999 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-08-13 05:38:35,883 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:35,887 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44753 instead
  warnings.warn(
2023-08-13 05:38:35,890 - distributed.scheduler - INFO - State start
2023-08-13 05:38:35,909 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:35,910 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-13 05:38:35,910 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44753/status
2023-08-13 05:38:35,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40103'
2023-08-13 05:38:36,237 - distributed.scheduler - INFO - Receive client connection: Client-a4d41bdf-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:36,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36376
2023-08-13 05:38:37,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:37,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:37,327 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:37,995 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36243
2023-08-13 05:38:37,996 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36243
2023-08-13 05:38:37,996 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33115
2023-08-13 05:38:37,996 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-13 05:38:37,996 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:37,996 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:37,996 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-13 05:38:37,996 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pq8xgfey
2023-08-13 05:38:37,996 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c352fa3c-4f95-450b-91bf-97858f2e6dd0
2023-08-13 05:38:37,996 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-25f3b3fd-f17d-4186-8f4f-d773e16b526a
2023-08-13 05:38:37,997 - distributed.worker - INFO - Starting Worker plugin PreImport-13193a40-db40-4f25-b642-6590b90f8400
2023-08-13 05:38:37,997 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:38,021 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36243', status: init, memory: 0, processing: 0>
2023-08-13 05:38:38,022 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36243
2023-08-13 05:38:38,022 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36394
2023-08-13 05:38:38,023 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-13 05:38:38,023 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:38,025 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-13 05:38:38,127 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:38,129 - distributed.scheduler - INFO - Remove client Client-a4d41bdf-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:38,129 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36376; closing.
2023-08-13 05:38:38,130 - distributed.scheduler - INFO - Remove client Client-a4d41bdf-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:38,130 - distributed.scheduler - INFO - Close client connection: Client-a4d41bdf-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:38,131 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40103'. Reason: nanny-close
2023-08-13 05:38:38,131 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:38,132 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36243. Reason: nanny-close
2023-08-13 05:38:38,134 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36394; closing.
2023-08-13 05:38:38,134 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-13 05:38:38,134 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36243', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:38,134 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36243
2023-08-13 05:38:38,134 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:38,135 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:39,047 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:39,047 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:39,047 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:39,048 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-13 05:38:39,048 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-08-13 05:38:40,976 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:40,980 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41305 instead
  warnings.warn(
2023-08-13 05:38:40,984 - distributed.scheduler - INFO - State start
2023-08-13 05:38:41,003 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:41,004 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:41,005 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41305/status
2023-08-13 05:38:41,115 - distributed.scheduler - INFO - Receive client connection: Client-a7e3d7bd-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:41,126 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35450
2023-08-13 05:38:41,196 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45341'
2023-08-13 05:38:41,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41095'
2023-08-13 05:38:41,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37759'
2023-08-13 05:38:41,221 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43127'
2023-08-13 05:38:41,228 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43487'
2023-08-13 05:38:41,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35499'
2023-08-13 05:38:41,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41205'
2023-08-13 05:38:41,255 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35275'
2023-08-13 05:38:42,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,926 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,926 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,926 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,960 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,963 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:42,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:42,969 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:42,979 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:43,006 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:46,069 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39531
2023-08-13 05:38:46,069 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39531
2023-08-13 05:38:46,070 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35543
2023-08-13 05:38:46,070 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,070 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,070 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,070 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,070 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0_al8b34
2023-08-13 05:38:46,070 - distributed.worker - INFO - Starting Worker plugin PreImport-d366cfc4-1f2c-4170-8883-c53a5857fdeb
2023-08-13 05:38:46,070 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d77cefff-ad00-494c-9884-2f818a4a5786
2023-08-13 05:38:46,071 - distributed.worker - INFO - Starting Worker plugin RMMSetup-17460df9-c353-4aae-9fb9-ab27eb43cd76
2023-08-13 05:38:46,072 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36187
2023-08-13 05:38:46,073 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36187
2023-08-13 05:38:46,073 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36255
2023-08-13 05:38:46,073 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,073 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,073 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,073 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,073 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4f4wbipm
2023-08-13 05:38:46,074 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f08fde13-9312-43c6-8208-d3067d8bbc4e
2023-08-13 05:38:46,234 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41837
2023-08-13 05:38:46,235 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41837
2023-08-13 05:38:46,235 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43121
2023-08-13 05:38:46,235 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,235 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,235 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,235 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,235 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jolo2p5z
2023-08-13 05:38:46,236 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7607b9a7-0662-4539-83f0-25300e8ed3db
2023-08-13 05:38:46,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38669
2023-08-13 05:38:46,238 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38669
2023-08-13 05:38:46,238 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40057
2023-08-13 05:38:46,238 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,239 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,239 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,239 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-847dn1_9
2023-08-13 05:38:46,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5fba408-ccf8-4fc2-b8ac-43e771c2bb3f
2023-08-13 05:38:46,239 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35721
2023-08-13 05:38:46,240 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35721
2023-08-13 05:38:46,240 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34793
2023-08-13 05:38:46,240 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,240 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,240 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,240 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,240 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hm6bylg9
2023-08-13 05:38:46,241 - distributed.worker - INFO - Starting Worker plugin RMMSetup-662d3707-cbd8-4efc-9fab-594cb9f435e7
2023-08-13 05:38:46,242 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44147
2023-08-13 05:38:46,242 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44147
2023-08-13 05:38:46,242 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41667
2023-08-13 05:38:46,242 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,242 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,243 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,243 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,243 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lwkfm7te
2023-08-13 05:38:46,243 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e472e299-b15b-4f31-99d4-c1fea79efac4
2023-08-13 05:38:46,253 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46783
2023-08-13 05:38:46,255 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46783
2023-08-13 05:38:46,255 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36669
2023-08-13 05:38:46,255 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,255 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,255 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,255 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,255 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pve4tbqd
2023-08-13 05:38:46,256 - distributed.worker - INFO - Starting Worker plugin PreImport-40e3676b-797c-4566-a353-aaae1f8836d9
2023-08-13 05:38:46,256 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6da44993-9265-4387-81e1-e3a41556c5a1
2023-08-13 05:38:46,256 - distributed.worker - INFO - Starting Worker plugin RMMSetup-190d4bc9-d5fb-4131-8123-aa271561c4a1
2023-08-13 05:38:46,257 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46039
2023-08-13 05:38:46,257 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46039
2023-08-13 05:38:46,258 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43877
2023-08-13 05:38:46,258 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,258 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,258 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:46,258 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-13 05:38:46,258 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z01rqmdo
2023-08-13 05:38:46,258 - distributed.worker - INFO - Starting Worker plugin PreImport-83f14074-1d3f-4500-928c-150d52d0cc50
2023-08-13 05:38:46,258 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f116e23-a6bf-4fba-9bb8-6c95eecaacae
2023-08-13 05:38:46,259 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7e7b5b7-98c4-4878-ae1f-799a46123b72
2023-08-13 05:38:46,277 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,312 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39531', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,313 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39531
2023-08-13 05:38:46,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48852
2023-08-13 05:38:46,313 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,314 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,335 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed278a6f-f8d4-44c6-b602-d08b4823dd06
2023-08-13 05:38:46,335 - distributed.worker - INFO - Starting Worker plugin PreImport-4ec40cee-d9aa-4efe-bc8a-dd5e91658790
2023-08-13 05:38:46,335 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,365 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36187', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,366 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36187
2023-08-13 05:38:46,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48866
2023-08-13 05:38:46,366 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,367 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,371 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,414 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15249be0-a1be-4f8f-89cb-bf4cabf01c9b
2023-08-13 05:38:46,414 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61d954a3-647b-4fd7-8ae3-6a9f97cb84d1
2023-08-13 05:38:46,414 - distributed.worker - INFO - Starting Worker plugin PreImport-0ef285e4-bca0-4fda-9ce5-aa4a425bd4b9
2023-08-13 05:38:46,415 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-44fa11ca-fbcd-4d49-9a7a-af6a50eb02af
2023-08-13 05:38:46,415 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,415 - distributed.worker - INFO - Starting Worker plugin PreImport-4b70609e-80f7-4932-8567-72c1e70865ea
2023-08-13 05:38:46,415 - distributed.worker - INFO - Starting Worker plugin PreImport-0459fd57-7d99-4bde-af04-718b5057abcb
2023-08-13 05:38:46,415 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,415 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,415 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8d2a771a-2bf1-4f8c-a226-4f1751eda65f
2023-08-13 05:38:46,415 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,416 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,416 - distributed.worker - INFO - Starting Worker plugin PreImport-51a6adf1-2c5b-4ab9-8072-3b31f9669a8b
2023-08-13 05:38:46,417 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,441 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46039', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,442 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46039
2023-08-13 05:38:46,442 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48878
2023-08-13 05:38:46,442 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,443 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,443 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38669', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,444 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38669
2023-08-13 05:38:46,444 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48880
2023-08-13 05:38:46,444 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,445 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,445 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,449 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46783', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,450 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46783
2023-08-13 05:38:46,450 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48896
2023-08-13 05:38:46,450 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,450 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,450 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44147', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,451 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44147
2023-08-13 05:38:46,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48912
2023-08-13 05:38:46,452 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,452 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,454 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35721', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,455 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35721
2023-08-13 05:38:46,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48918
2023-08-13 05:38:46,455 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,456 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41837', status: init, memory: 0, processing: 0>
2023-08-13 05:38:46,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41837
2023-08-13 05:38:46,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48920
2023-08-13 05:38:46,457 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:46,457 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:46,458 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,460 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:46,503 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,504 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,519 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:46,522 - distributed.scheduler - INFO - Remove client Client-a7e3d7bd-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:46,522 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35450; closing.
2023-08-13 05:38:46,523 - distributed.scheduler - INFO - Remove client Client-a7e3d7bd-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:46,523 - distributed.scheduler - INFO - Close client connection: Client-a7e3d7bd-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:46,524 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43127'. Reason: nanny-close
2023-08-13 05:38:46,524 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,525 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45341'. Reason: nanny-close
2023-08-13 05:38:46,526 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,526 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35721. Reason: nanny-close
2023-08-13 05:38:46,526 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41095'. Reason: nanny-close
2023-08-13 05:38:46,526 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,527 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44147. Reason: nanny-close
2023-08-13 05:38:46,527 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37759'. Reason: nanny-close
2023-08-13 05:38:46,527 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,527 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46039. Reason: nanny-close
2023-08-13 05:38:46,527 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43487'. Reason: nanny-close
2023-08-13 05:38:46,528 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,528 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39531. Reason: nanny-close
2023-08-13 05:38:46,528 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35499'. Reason: nanny-close
2023-08-13 05:38:46,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48918; closing.
2023-08-13 05:38:46,528 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,528 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,528 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35721', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,529 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-08-13 05:38:46,529 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41205'. Reason: nanny-close
2023-08-13 05:38:46,529 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36187. Reason: nanny-close
2023-08-13 05:38:46,529 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,529 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,529 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,529 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35275'. Reason: nanny-close
2023-08-13 05:38:46,529 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41837. Reason: nanny-close
2023-08-13 05:38:46,529 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:46,530 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,530 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38669. Reason: nanny-close
2023-08-13 05:38:46,530 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,530 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,530 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48912; closing.
2023-08-13 05:38:46,530 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-08-13 05:38:46,530 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48878; closing.
2023-08-13 05:38:46,530 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,531 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,531 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46783. Reason: nanny-close
2023-08-13 05:38:46,531 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-08-13 05:38:46,531 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-08-13 05:38:46,531 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44147', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,531 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44147
2023-08-13 05:38:46,531 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46039', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,532 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-08-13 05:38:46,532 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,532 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46039
2023-08-13 05:38:46,532 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,532 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48852; closing.
2023-08-13 05:38:46,532 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,532 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39531', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,532 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39531
2023-08-13 05:38:46,533 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:46,533 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,533 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48866; closing.
2023-08-13 05:38:46,533 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,533 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48880; closing.
2023-08-13 05:38:46,534 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48920; closing.
2023-08-13 05:38:46,534 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,534 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36187', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,534 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:46,534 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36187
2023-08-13 05:38:46,534 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38669', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,534 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38669
2023-08-13 05:38:46,535 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41837', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,535 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41837
2023-08-13 05:38:46,535 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48896; closing.
2023-08-13 05:38:46,536 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46783', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:46,536 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46783
2023-08-13 05:38:46,536 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:47,891 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:47,892 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:47,892 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:47,893 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:47,893 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-08-13 05:38:49,898 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:49,902 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46153 instead
  warnings.warn(
2023-08-13 05:38:49,905 - distributed.scheduler - INFO - State start
2023-08-13 05:38:49,924 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:49,925 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:49,925 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46153/status
2023-08-13 05:38:50,119 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39261'
2023-08-13 05:38:50,184 - distributed.scheduler - INFO - Receive client connection: Client-ad321174-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:50,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48990
2023-08-13 05:38:51,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:51,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:51,554 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:52,307 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46469
2023-08-13 05:38:52,307 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46469
2023-08-13 05:38:52,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41065
2023-08-13 05:38:52,307 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:52,307 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:52,307 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:52,307 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-13 05:38:52,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b4ej6s6i
2023-08-13 05:38:52,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44ef0565-476c-4f6f-9e3d-07501fb0f03e
2023-08-13 05:38:52,401 - distributed.worker - INFO - Starting Worker plugin PreImport-8303e241-cfda-4294-8883-2d7b373a90cf
2023-08-13 05:38:52,402 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4b084cb0-64ba-4b86-9b03-82431e4cca11
2023-08-13 05:38:52,402 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:52,434 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46469', status: init, memory: 0, processing: 0>
2023-08-13 05:38:52,435 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46469
2023-08-13 05:38:52,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49006
2023-08-13 05:38:52,436 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:52,436 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:52,438 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:52,536 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:52,540 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:52,541 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:52,543 - distributed.scheduler - INFO - Remove client Client-ad321174-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:52,543 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48990; closing.
2023-08-13 05:38:52,544 - distributed.scheduler - INFO - Remove client Client-ad321174-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:52,544 - distributed.scheduler - INFO - Close client connection: Client-ad321174-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:52,545 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39261'. Reason: nanny-close
2023-08-13 05:38:52,545 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:52,547 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46469. Reason: nanny-close
2023-08-13 05:38:52,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49006; closing.
2023-08-13 05:38:52,548 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:52,549 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46469', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:52,549 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46469
2023-08-13 05:38:52,549 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:52,549 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:53,611 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:53,612 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:53,612 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:53,613 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:53,613 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-08-13 05:38:55,613 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:55,617 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46171 instead
  warnings.warn(
2023-08-13 05:38:55,621 - distributed.scheduler - INFO - State start
2023-08-13 05:38:55,642 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-13 05:38:55,643 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-13 05:38:55,643 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46171/status
2023-08-13 05:38:55,852 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33433'
2023-08-13 05:38:56,156 - distributed.scheduler - INFO - Receive client connection: Client-b0897837-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:56,169 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39178
2023-08-13 05:38:57,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:38:57,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:38:57,255 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-13 05:38:58,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45913
2023-08-13 05:38:58,031 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45913
2023-08-13 05:38:58,031 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36509
2023-08-13 05:38:58,031 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-13 05:38:58,031 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:58,031 - distributed.worker - INFO -               Threads:                          1
2023-08-13 05:38:58,031 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-13 05:38:58,031 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rhlcf4ob
2023-08-13 05:38:58,031 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61eeac4c-2c00-417a-a05f-16a09072a257
2023-08-13 05:38:58,123 - distributed.worker - INFO - Starting Worker plugin PreImport-31499219-cfc9-4486-88bf-c5d8b9a26438
2023-08-13 05:38:58,123 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c84a63da-363e-4bee-90a1-719ec1bfc7b6
2023-08-13 05:38:58,123 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:58,156 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45913', status: init, memory: 0, processing: 0>
2023-08-13 05:38:58,157 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45913
2023-08-13 05:38:58,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39186
2023-08-13 05:38:58,158 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-13 05:38:58,158 - distributed.worker - INFO - -------------------------------------------------
2023-08-13 05:38:58,160 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-13 05:38:58,207 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-08-13 05:38:58,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-13 05:38:58,215 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:58,217 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-13 05:38:58,219 - distributed.scheduler - INFO - Remove client Client-b0897837-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:58,219 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39178; closing.
2023-08-13 05:38:58,219 - distributed.scheduler - INFO - Remove client Client-b0897837-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:58,220 - distributed.scheduler - INFO - Close client connection: Client-b0897837-399b-11ee-8a1b-d8c49764f6bb
2023-08-13 05:38:58,220 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33433'. Reason: nanny-close
2023-08-13 05:38:58,221 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-13 05:38:58,222 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45913. Reason: nanny-close
2023-08-13 05:38:58,224 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39186; closing.
2023-08-13 05:38:58,224 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-13 05:38:58,224 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45913', status: closing, memory: 0, processing: 0>
2023-08-13 05:38:58,224 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45913
2023-08-13 05:38:58,224 - distributed.scheduler - INFO - Lost all workers
2023-08-13 05:38:58,225 - distributed.nanny - INFO - Worker closed
2023-08-13 05:38:59,336 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-13 05:38:59,337 - distributed.scheduler - INFO - Scheduler closing...
2023-08-13 05:38:59,337 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-13 05:38:59,338 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-13 05:38:59,338 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33519 instead
  warnings.warn(
2023-08-13 05:39:08,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:08,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:08,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43757 instead
  warnings.warn(
2023-08-13 05:39:17,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:17,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:17,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41891 instead
  warnings.warn(
2023-08-13 05:39:25,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:25,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:25,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33725 instead
  warnings.warn(
2023-08-13 05:39:34,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:34,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:34,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:34,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:34,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:34,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:34,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:34,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:35,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:35,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:35,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:35,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:35,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:35,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:35,043 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:35,043 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:39,078 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1262, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
Task exception was never retrieved
future: <Task finished name='Task-1317' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37453 instead
  warnings.warn(
2023-08-13 05:39:45,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:45,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:45,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33149 instead
  warnings.warn(
2023-08-13 05:39:54,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:54,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:39:55,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:39:55,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33167 instead
  warnings.warn(
2023-08-13 05:40:06,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:06,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:06,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45739 instead
  warnings.warn(
2023-08-13 05:40:16,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-13 05:40:16,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-13 05:40:16,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44937 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39861 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38115 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41155 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41703 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40921 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42615 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40493 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42509 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41363 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40927 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39491 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40633 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36167 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40553 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41805 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38255 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42943 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38245 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46709 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34253 instead
  warnings.warn(
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,150 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,152 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,153 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,158 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,160 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fbfd90acf70>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,161 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f5f98e58f70>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,162 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f58dd7a2f70>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:15,166 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f496ee0cf70>>, <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-6' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 254, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 61, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-13 05:45:17,163 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-13 05:45:17,164 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-13 05:45:17,165 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-13 05:45:17,169 - distributed.nanny - ERROR - Worker process died unexpectedly
