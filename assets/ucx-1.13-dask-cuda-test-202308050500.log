============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.4.0, pluggy-1.2.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-08-05 05:38:13,812 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:13,816 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41299 instead
  warnings.warn(
2023-08-05 05:38:13,820 - distributed.scheduler - INFO - State start
2023-08-05 05:38:13,839 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:13,840 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-05 05:38:13,840 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41299/status
2023-08-05 05:38:13,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44367'
2023-08-05 05:38:13,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39583'
2023-08-05 05:38:13,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39361'
2023-08-05 05:38:13,970 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43779'
2023-08-05 05:38:15,088 - distributed.scheduler - INFO - Receive client connection: Client-445de530-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:15,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36458
2023-08-05 05:38:15,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:15,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:15,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:15,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:15,415 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:15,417 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:15,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:15,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:15,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:15,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:15,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:15,508 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-08-05 05:38:15,801 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41793
2023-08-05 05:38:15,801 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41793
2023-08-05 05:38:15,801 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43341
2023-08-05 05:38:15,801 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-05 05:38:15,802 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:15,802 - distributed.worker - INFO -               Threads:                          4
2023-08-05 05:38:15,802 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-05 05:38:15,802 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3c_0xy0s
2023-08-05 05:38:15,802 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cd7ad0da-cedd-4772-bb58-f97b48d72060
2023-08-05 05:38:15,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66d87602-6f88-43d4-a053-736ecf8f0fec
2023-08-05 05:38:15,802 - distributed.worker - INFO - Starting Worker plugin PreImport-8ec7cbfb-71fe-4fb5-ab4a-98527dec4f7a
2023-08-05 05:38:15,803 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:15,819 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41793', status: init, memory: 0, processing: 0>
2023-08-05 05:38:15,820 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41793
2023-08-05 05:38:15,820 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36484
2023-08-05 05:38:15,821 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-05 05:38:15,821 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:15,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-05 05:38:16,632 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34123
2023-08-05 05:38:16,633 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34123
2023-08-05 05:38:16,633 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45611
2023-08-05 05:38:16,633 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,633 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,633 - distributed.worker - INFO -               Threads:                          4
2023-08-05 05:38:16,633 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-05 05:38:16,633 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x78txtga
2023-08-05 05:38:16,633 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7ef11716-463f-4e1d-9fd5-ec875d2ef4fb
2023-08-05 05:38:16,633 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8286e45b-b8aa-4039-b704-f8dfee2e56e1
2023-08-05 05:38:16,634 - distributed.worker - INFO - Starting Worker plugin PreImport-3f539a9d-86c7-4063-85b4-fce0ef3b107b
2023-08-05 05:38:16,634 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,635 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45155
2023-08-05 05:38:16,636 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45155
2023-08-05 05:38:16,636 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39957
2023-08-05 05:38:16,636 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,636 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,636 - distributed.worker - INFO -               Threads:                          4
2023-08-05 05:38:16,636 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-05 05:38:16,636 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hme69aes
2023-08-05 05:38:16,636 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28b96801-6c40-49ed-9ab5-be77bf4b76fe
2023-08-05 05:38:16,637 - distributed.worker - INFO - Starting Worker plugin PreImport-d2f9b662-74da-4a10-9bca-3d567f6c1027
2023-08-05 05:38:16,637 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c7b6dcd-db99-4928-a8d1-9a76dc41763f
2023-08-05 05:38:16,637 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,659 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45155', status: init, memory: 0, processing: 0>
2023-08-05 05:38:16,661 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45155
2023-08-05 05:38:16,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36506
2023-08-05 05:38:16,661 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,661 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-05 05:38:16,668 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34123', status: init, memory: 0, processing: 0>
2023-08-05 05:38:16,668 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34123
2023-08-05 05:38:16,669 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36496
2023-08-05 05:38:16,669 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,669 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,672 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34853
2023-08-05 05:38:16,672 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34853
2023-08-05 05:38:16,673 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35105
2023-08-05 05:38:16,673 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,673 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,673 - distributed.worker - INFO -               Threads:                          4
2023-08-05 05:38:16,673 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-05 05:38:16,673 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-08-05 05:38:16,673 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-npmkw4tf
2023-08-05 05:38:16,674 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a36d705b-03c9-476e-b276-82a6f6d52a4c
2023-08-05 05:38:16,674 - distributed.worker - INFO - Starting Worker plugin PreImport-aff4ccdd-743f-435e-b63a-ba2f166de406
2023-08-05 05:38:16,674 - distributed.worker - INFO - Starting Worker plugin RMMSetup-43e75688-3a9b-4972-a442-e716af89afcd
2023-08-05 05:38:16,674 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,691 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34853', status: init, memory: 0, processing: 0>
2023-08-05 05:38:16,692 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34853
2023-08-05 05:38:16,692 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36514
2023-08-05 05:38:16,692 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-05 05:38:16,693 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:16,695 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-05 05:38:16,742 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-05 05:38:16,743 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-05 05:38:16,742 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-05 05:38:16,743 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-08-05 05:38:16,748 - distributed.scheduler - INFO - Remove client Client-445de530-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:16,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36458; closing.
2023-08-05 05:38:16,749 - distributed.scheduler - INFO - Remove client Client-445de530-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:16,750 - distributed.scheduler - INFO - Close client connection: Client-445de530-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:16,750 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44367'. Reason: nanny-close
2023-08-05 05:38:16,751 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:16,751 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39583'. Reason: nanny-close
2023-08-05 05:38:16,752 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:16,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39361'. Reason: nanny-close
2023-08-05 05:38:16,752 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34853. Reason: nanny-close
2023-08-05 05:38:16,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:16,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45155. Reason: nanny-close
2023-08-05 05:38:16,753 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43779'. Reason: nanny-close
2023-08-05 05:38:16,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:16,754 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34123. Reason: nanny-close
2023-08-05 05:38:16,754 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41793. Reason: nanny-close
2023-08-05 05:38:16,754 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36514; closing.
2023-08-05 05:38:16,754 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-05 05:38:16,754 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-05 05:38:16,755 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34853', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:16,755 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34853
2023-08-05 05:38:16,756 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:16,756 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-05 05:38:16,756 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-05 05:38:16,756 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:16,756 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36506; closing.
2023-08-05 05:38:16,757 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:16,757 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45155', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:16,757 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45155
2023-08-05 05:38:16,758 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:16,758 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36496; closing.
2023-08-05 05:38:16,759 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34123', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:16,759 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34123
2023-08-05 05:38:16,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36484; closing.
2023-08-05 05:38:16,760 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41793', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:16,760 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41793
2023-08-05 05:38:16,760 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:17,967 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:17,967 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:17,968 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:17,968 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-05 05:38:17,969 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-08-05 05:38:19,818 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:19,822 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40507 instead
  warnings.warn(
2023-08-05 05:38:19,825 - distributed.scheduler - INFO - State start
2023-08-05 05:38:19,844 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:19,844 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:38:19,845 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40507/status
2023-08-05 05:38:20,020 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35903'
2023-08-05 05:38:20,043 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42101'
2023-08-05 05:38:20,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43263'
2023-08-05 05:38:20,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42563'
2023-08-05 05:38:20,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42593'
2023-08-05 05:38:20,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43333'
2023-08-05 05:38:20,079 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33227'
2023-08-05 05:38:20,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38293'
2023-08-05 05:38:20,225 - distributed.scheduler - INFO - Receive client connection: Client-47f86969-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:20,243 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51612
2023-08-05 05:38:21,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,659 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,660 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,709 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:21,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:21,754 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:21,789 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:24,309 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46317
2023-08-05 05:38:24,310 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46317
2023-08-05 05:38:24,310 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40477
2023-08-05 05:38:24,311 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,311 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,311 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,311 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,311 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c5hd9qhh
2023-08-05 05:38:24,312 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f89e92f2-3102-4b12-9157-06dae0207ac3
2023-08-05 05:38:24,374 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39313
2023-08-05 05:38:24,375 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39313
2023-08-05 05:38:24,375 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40949
2023-08-05 05:38:24,375 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,375 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,375 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,375 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,375 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-n76ylblr
2023-08-05 05:38:24,376 - distributed.worker - INFO - Starting Worker plugin PreImport-d78b2893-9cfc-4066-a907-b85b71c9d05e
2023-08-05 05:38:24,376 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2d27ce1-24bb-4d68-a779-dc0d4c466cee
2023-08-05 05:38:24,376 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a1147031-84e4-4caa-a2b6-60ea859aeee0
2023-08-05 05:38:24,446 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5592c4c-1042-42e4-a80c-c3e822fb73a7
2023-08-05 05:38:24,446 - distributed.worker - INFO - Starting Worker plugin PreImport-21e0e72f-b558-4a07-8ee5-dd8d04e4537b
2023-08-05 05:38:24,447 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,484 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46317', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46317
2023-08-05 05:38:24,487 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51628
2023-08-05 05:38:24,487 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,488 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,515 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,538 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38157
2023-08-05 05:38:24,539 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38157
2023-08-05 05:38:24,539 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37383
2023-08-05 05:38:24,540 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,540 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,540 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,540 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,540 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vfofgomp
2023-08-05 05:38:24,540 - distributed.worker - INFO - Starting Worker plugin PreImport-e8b5859c-0c20-4093-90e2-d123ed354bcf
2023-08-05 05:38:24,541 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-770b4ac1-85b0-4c10-8c46-b5090791fc83
2023-08-05 05:38:24,541 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ac774519-0ad2-40fe-9b71-f2502fe9a818
2023-08-05 05:38:24,542 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39349
2023-08-05 05:38:24,543 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39349
2023-08-05 05:38:24,543 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46639
2023-08-05 05:38:24,544 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,544 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,544 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,544 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,544 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4kp52y1l
2023-08-05 05:38:24,545 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ea9e8ee8-5aa5-4b9e-a98b-a7842b714680
2023-08-05 05:38:24,554 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39313', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,555 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39313
2023-08-05 05:38:24,555 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51640
2023-08-05 05:38:24,556 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,556 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,593 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39071
2023-08-05 05:38:24,594 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39071
2023-08-05 05:38:24,594 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42465
2023-08-05 05:38:24,594 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,594 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,594 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,594 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,594 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vsh5w8h_
2023-08-05 05:38:24,595 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-911ec56d-95f1-44fd-a816-59434a5995fb
2023-08-05 05:38:24,595 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0df8a246-aca5-4829-9fd8-eb3083eb23b0
2023-08-05 05:38:24,597 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40791
2023-08-05 05:38:24,597 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40791
2023-08-05 05:38:24,598 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36689
2023-08-05 05:38:24,598 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,598 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,598 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,598 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,598 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-72ad_mbt
2023-08-05 05:38:24,598 - distributed.worker - INFO - Starting Worker plugin RMMSetup-12a2e49b-d37d-4dcd-9a02-cd6b3ca75cad
2023-08-05 05:38:24,597 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45477
2023-08-05 05:38:24,599 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45477
2023-08-05 05:38:24,599 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39323
2023-08-05 05:38:24,599 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,599 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,599 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,600 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,600 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gqa_ipw5
2023-08-05 05:38:24,600 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a982a282-f74c-4302-afb2-90c4840d6c58
2023-08-05 05:38:24,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46427
2023-08-05 05:38:24,604 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46427
2023-08-05 05:38:24,605 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35083
2023-08-05 05:38:24,605 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,605 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,605 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:24,605 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:24,605 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8g_x5jg7
2023-08-05 05:38:24,605 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53e111e4-de37-41ef-a3d6-59daf4eb2011
2023-08-05 05:38:24,720 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,722 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9055a108-4154-41a1-a55b-277edd20082c
2023-08-05 05:38:24,722 - distributed.worker - INFO - Starting Worker plugin PreImport-40485912-a6ab-4958-9087-54f9bc82b460
2023-08-05 05:38:24,723 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68959f67-d60a-42aa-979d-0d2f67e3a181
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin PreImport-086d061f-d660-4536-aa57-ec8e11ac6944
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin PreImport-c13bf245-fe60-4a16-b6d6-50a5ec4323c5
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-92aaab01-8d96-4a1f-9448-760d2422f004
2023-08-05 05:38:24,733 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8a77d04-b479-435f-9ea7-2a7cd31cd36a
2023-08-05 05:38:24,733 - distributed.worker - INFO - Starting Worker plugin PreImport-f16a3c1a-d673-4f3e-86f3-1b609e477837
2023-08-05 05:38:24,733 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,733 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,734 - distributed.worker - INFO - Starting Worker plugin PreImport-a33ebb26-6028-477d-bb3f-5270abff58b0
2023-08-05 05:38:24,734 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,755 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39349', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,756 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39349
2023-08-05 05:38:24,756 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51656
2023-08-05 05:38:24,756 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,756 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,757 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38157', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,757 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38157
2023-08-05 05:38:24,757 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51642
2023-08-05 05:38:24,758 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,758 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,759 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,761 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,763 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46427', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,764 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46427
2023-08-05 05:38:24,764 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51672
2023-08-05 05:38:24,765 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,765 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,766 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45477', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,766 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45477
2023-08-05 05:38:24,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51686
2023-08-05 05:38:24,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,767 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,767 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,767 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39071', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,768 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39071
2023-08-05 05:38:24,768 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51674
2023-08-05 05:38:24,769 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,769 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40791', status: init, memory: 0, processing: 0>
2023-08-05 05:38:24,770 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40791
2023-08-05 05:38:24,770 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51688
2023-08-05 05:38:24,770 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:24,770 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:24,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,773 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:24,780 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,780 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,780 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,781 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,781 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,781 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,781 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,781 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:24,785 - distributed.scheduler - INFO - Remove client Client-47f86969-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:24,786 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51612; closing.
2023-08-05 05:38:24,786 - distributed.scheduler - INFO - Remove client Client-47f86969-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:24,786 - distributed.scheduler - INFO - Close client connection: Client-47f86969-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:24,787 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42563'. Reason: nanny-close
2023-08-05 05:38:24,787 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,788 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42593'. Reason: nanny-close
2023-08-05 05:38:24,788 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,789 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35903'. Reason: nanny-close
2023-08-05 05:38:24,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39071. Reason: nanny-close
2023-08-05 05:38:24,789 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40791. Reason: nanny-close
2023-08-05 05:38:24,789 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42101'. Reason: nanny-close
2023-08-05 05:38:24,790 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,790 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39349. Reason: nanny-close
2023-08-05 05:38:24,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43263'. Reason: nanny-close
2023-08-05 05:38:24,790 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,791 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43333'. Reason: nanny-close
2023-08-05 05:38:24,791 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38157. Reason: nanny-close
2023-08-05 05:38:24,791 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51674; closing.
2023-08-05 05:38:24,791 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,791 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,791 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39071', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,791 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,791 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33227'. Reason: nanny-close
2023-08-05 05:38:24,791 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,791 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39313. Reason: nanny-close
2023-08-05 05:38:24,792 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38293'. Reason: nanny-close
2023-08-05 05:38:24,792 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46317. Reason: nanny-close
2023-08-05 05:38:24,792 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,792 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:24,792 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,792 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45477. Reason: nanny-close
2023-08-05 05:38:24,793 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,793 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,793 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51688; closing.
2023-08-05 05:38:24,793 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,793 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51656; closing.
2023-08-05 05:38:24,793 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,793 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,794 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,794 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46427. Reason: nanny-close
2023-08-05 05:38:24,794 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,794 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40791', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,794 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40791
2023-08-05 05:38:24,794 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39071
2023-08-05 05:38:24,794 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,794 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,794 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39349', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,794 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39349
2023-08-05 05:38:24,794 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,795 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51642; closing.
2023-08-05 05:38:24,795 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:24,795 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38157', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,795 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,795 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38157
2023-08-05 05:38:24,795 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,796 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51640; closing.
2023-08-05 05:38:24,796 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,796 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51628; closing.
2023-08-05 05:38:24,796 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51686; closing.
2023-08-05 05:38:24,796 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:24,797 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39313', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,797 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39313
2023-08-05 05:38:24,797 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46317', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,797 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46317
2023-08-05 05:38:24,798 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45477', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,798 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45477
2023-08-05 05:38:24,798 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51672; closing.
2023-08-05 05:38:24,799 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46427', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:24,799 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46427
2023-08-05 05:38:24,799 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:26,305 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:26,305 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:26,306 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:26,307 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:38:26,307 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-08-05 05:38:28,326 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:28,330 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43771 instead
  warnings.warn(
2023-08-05 05:38:28,334 - distributed.scheduler - INFO - State start
2023-08-05 05:38:28,354 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:28,355 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:38:28,355 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43771/status
2023-08-05 05:38:28,404 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36783'
2023-08-05 05:38:28,424 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34027'
2023-08-05 05:38:28,425 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36477'
2023-08-05 05:38:28,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36413'
2023-08-05 05:38:28,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41709'
2023-08-05 05:38:28,450 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44215'
2023-08-05 05:38:28,458 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37717'
2023-08-05 05:38:28,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37979'
2023-08-05 05:38:28,469 - distributed.scheduler - INFO - Receive client connection: Client-4cfbf514-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:28,481 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38024
2023-08-05 05:38:30,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,106 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:30,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:30,131 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,131 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,143 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,154 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:30,155 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:32,969 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43001
2023-08-05 05:38:32,969 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43001
2023-08-05 05:38:32,969 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44907
2023-08-05 05:38:32,969 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,970 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,970 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,970 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,970 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_3as48xt
2023-08-05 05:38:32,970 - distributed.worker - INFO - Starting Worker plugin PreImport-c238dd3d-a085-4f18-8700-ea5e93b0b6f5
2023-08-05 05:38:32,970 - distributed.worker - INFO - Starting Worker plugin RMMSetup-27554405-c3b0-474b-b8fe-48c25d6d3e92
2023-08-05 05:38:32,970 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37733
2023-08-05 05:38:32,971 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37733
2023-08-05 05:38:32,971 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34047
2023-08-05 05:38:32,971 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,971 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,971 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,971 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,971 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-n7vdfu7x
2023-08-05 05:38:32,972 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fd629528-0593-4add-baaa-e555a2a5331d
2023-08-05 05:38:32,972 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38549
2023-08-05 05:38:32,972 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38549
2023-08-05 05:38:32,972 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38831
2023-08-05 05:38:32,973 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,973 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,973 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,973 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,973 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s963q9ss
2023-08-05 05:38:32,973 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15d71607-41e1-4fb6-ac85-3c7161d6ca76
2023-08-05 05:38:32,973 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3004189d-7ed0-4256-8bbe-a809ccb9a54a
2023-08-05 05:38:32,975 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45213
2023-08-05 05:38:32,976 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45213
2023-08-05 05:38:32,976 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35631
2023-08-05 05:38:32,976 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,976 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,976 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,976 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,976 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-67qjr8dw
2023-08-05 05:38:32,977 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-60202802-e898-4906-90e6-edcce47f9c37
2023-08-05 05:38:32,977 - distributed.worker - INFO - Starting Worker plugin RMMSetup-efe3c2e9-1de3-47a2-90a8-bc22ac8e80a3
2023-08-05 05:38:32,977 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42151
2023-08-05 05:38:32,978 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42151
2023-08-05 05:38:32,978 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46603
2023-08-05 05:38:32,978 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,978 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,978 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,978 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,978 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l204a5gw
2023-08-05 05:38:32,979 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd773c6c-d804-4a6c-82bb-b62e7efa8fe0
2023-08-05 05:38:32,979 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43731
2023-08-05 05:38:32,980 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43731
2023-08-05 05:38:32,980 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36609
2023-08-05 05:38:32,980 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,980 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,980 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,980 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,980 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2r651vsv
2023-08-05 05:38:32,981 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a5984180-440c-4b13-8afd-f7e5d2ed14aa
2023-08-05 05:38:32,982 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39617
2023-08-05 05:38:32,983 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39617
2023-08-05 05:38:32,983 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36277
2023-08-05 05:38:32,983 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,983 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,983 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,984 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,984 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-twnt5pfg
2023-08-05 05:38:32,984 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-faa105e5-d8b9-4ff2-a502-2969a50e9ff3
2023-08-05 05:38:32,984 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8dee8711-4ec4-467b-a901-bcb07afe16a3
2023-08-05 05:38:32,985 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36547
2023-08-05 05:38:32,986 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36547
2023-08-05 05:38:32,986 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40331
2023-08-05 05:38:32,986 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:32,986 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:32,986 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:32,986 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:32,986 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p2ls7vj5
2023-08-05 05:38:32,987 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66c470b1-fb12-476b-8b49-4fe3e7d4b9c7
2023-08-05 05:38:32,987 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c08f3d48-1a7e-44b7-a649-bb51351700f8
2023-08-05 05:38:33,012 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cf3a0a74-049a-48e0-940e-08ab32b49759
2023-08-05 05:38:33,012 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-85a1b541-7729-48e4-b669-35d4b1926664
2023-08-05 05:38:33,012 - distributed.worker - INFO - Starting Worker plugin PreImport-3db92a66-ac0b-4063-bee3-3662e45c9d38
2023-08-05 05:38:33,013 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,013 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,013 - distributed.worker - INFO - Starting Worker plugin PreImport-185516ba-4cba-407a-95a4-2f43dfb47086
2023-08-05 05:38:33,013 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,014 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f2704efe-fef8-4286-9089-2a59be227619
2023-08-05 05:38:33,014 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d8f9d61e-a1ce-434b-9755-bb37eb46e52b
2023-08-05 05:38:33,014 - distributed.worker - INFO - Starting Worker plugin PreImport-4dc75db7-25d5-40fb-a402-b38c8b946f21
2023-08-05 05:38:33,015 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,014 - distributed.worker - INFO - Starting Worker plugin PreImport-f8644b22-f2a1-4c1e-9452-6e895e539a60
2023-08-05 05:38:33,015 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,015 - distributed.worker - INFO - Starting Worker plugin PreImport-18597b04-e83a-431b-a907-5b6e64f3ec59
2023-08-05 05:38:33,015 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,016 - distributed.worker - INFO - Starting Worker plugin PreImport-5be18881-7425-4377-962d-16507b21b3d2
2023-08-05 05:38:33,016 - distributed.worker - INFO - Starting Worker plugin PreImport-8aa2d61d-b767-4a70-bfd0-3b332584a224
2023-08-05 05:38:33,016 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,017 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,037 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45213', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,038 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45213
2023-08-05 05:38:33,038 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38056
2023-08-05 05:38:33,038 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,039 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,039 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37733', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,039 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37733
2023-08-05 05:38:33,039 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38048
2023-08-05 05:38:33,040 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,040 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,040 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39617', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,041 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39617
2023-08-05 05:38:33,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38080
2023-08-05 05:38:33,041 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,042 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,042 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,043 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,044 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38549', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,045 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38549
2023-08-05 05:38:33,045 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38098
2023-08-05 05:38:33,045 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,045 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,046 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42151', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,046 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42151
2023-08-05 05:38:33,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38086
2023-08-05 05:38:33,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,047 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,047 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,051 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43731', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,052 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43731
2023-08-05 05:38:33,052 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38096
2023-08-05 05:38:33,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43001', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,052 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,052 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43001
2023-08-05 05:38:33,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38072
2023-08-05 05:38:33,053 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,054 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,054 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36547', status: init, memory: 0, processing: 0>
2023-08-05 05:38:33,054 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36547
2023-08-05 05:38:33,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38110
2023-08-05 05:38:33,055 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:33,055 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:33,056 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,056 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,058 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,146 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,147 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:33,151 - distributed.scheduler - INFO - Remove client Client-4cfbf514-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:33,151 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38024; closing.
2023-08-05 05:38:33,151 - distributed.scheduler - INFO - Remove client Client-4cfbf514-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:33,151 - distributed.scheduler - INFO - Close client connection: Client-4cfbf514-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:33,153 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36477'. Reason: nanny-close
2023-08-05 05:38:33,153 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,153 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36783'. Reason: nanny-close
2023-08-05 05:38:33,154 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,154 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34027'. Reason: nanny-close
2023-08-05 05:38:33,154 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43001. Reason: nanny-close
2023-08-05 05:38:33,154 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,155 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43731. Reason: nanny-close
2023-08-05 05:38:33,155 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36413'. Reason: nanny-close
2023-08-05 05:38:33,155 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,155 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38549. Reason: nanny-close
2023-08-05 05:38:33,156 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41709'. Reason: nanny-close
2023-08-05 05:38:33,156 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,156 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37733. Reason: nanny-close
2023-08-05 05:38:33,156 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44215'. Reason: nanny-close
2023-08-05 05:38:33,157 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,157 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38072; closing.
2023-08-05 05:38:33,157 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37717'. Reason: nanny-close
2023-08-05 05:38:33,157 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42151. Reason: nanny-close
2023-08-05 05:38:33,157 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43001', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,157 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43001
2023-08-05 05:38:33,157 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,157 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37979'. Reason: nanny-close
2023-08-05 05:38:33,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36547. Reason: nanny-close
2023-08-05 05:38:33,158 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:33,158 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39617. Reason: nanny-close
2023-08-05 05:38:33,158 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38098; closing.
2023-08-05 05:38:33,158 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,158 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45213. Reason: nanny-close
2023-08-05 05:38:33,159 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,159 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38549', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,159 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38549
2023-08-05 05:38:33,159 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43001
2023-08-05 05:38:33,160 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38096; closing.
2023-08-05 05:38:33,160 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43001
2023-08-05 05:38:33,160 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,160 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,160 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38048; closing.
2023-08-05 05:38:33,160 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,160 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43001
2023-08-05 05:38:33,160 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43001
2023-08-05 05:38:33,161 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43731', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,161 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43731
2023-08-05 05:38:33,161 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37733', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,161 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37733
2023-08-05 05:38:33,161 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,161 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:33,162 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38086; closing.
2023-08-05 05:38:33,162 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38080; closing.
2023-08-05 05:38:33,162 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,162 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42151', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,162 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42151
2023-08-05 05:38:33,163 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39617', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,163 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39617
2023-08-05 05:38:33,163 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:33,163 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38110; closing.
2023-08-05 05:38:33,164 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38056; closing.
2023-08-05 05:38:33,164 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36547', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,164 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36547
2023-08-05 05:38:33,164 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45213', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:33,165 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45213
2023-08-05 05:38:33,165 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:34,519 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:34,520 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:34,520 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:34,521 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:38:34,521 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-08-05 05:38:36,328 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:36,332 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35977 instead
  warnings.warn(
2023-08-05 05:38:36,336 - distributed.scheduler - INFO - State start
2023-08-05 05:38:36,394 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:36,395 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:38:36,395 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35977/status
2023-08-05 05:38:36,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44911'
2023-08-05 05:38:36,585 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37599'
2023-08-05 05:38:36,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42237'
2023-08-05 05:38:36,597 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35151'
2023-08-05 05:38:36,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46811'
2023-08-05 05:38:36,615 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43649'
2023-08-05 05:38:36,624 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39835'
2023-08-05 05:38:36,633 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43307'
2023-08-05 05:38:37,605 - distributed.scheduler - INFO - Receive client connection: Client-51d18689-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:37,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43160
2023-08-05 05:38:38,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,294 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,311 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,323 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:38,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:38,358 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,359 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,404 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:38,408 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:40,944 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33325
2023-08-05 05:38:40,944 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33325
2023-08-05 05:38:40,944 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41897
2023-08-05 05:38:40,945 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:40,945 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:40,945 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:40,945 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:40,945 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ud00t683
2023-08-05 05:38:40,945 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ad43e34-b949-47ae-8177-e6820bbddec7
2023-08-05 05:38:40,948 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42611
2023-08-05 05:38:40,949 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42611
2023-08-05 05:38:40,949 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35519
2023-08-05 05:38:40,949 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:40,949 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:40,949 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:40,949 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:40,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ohc0_lw8
2023-08-05 05:38:40,950 - distributed.worker - INFO - Starting Worker plugin PreImport-eb3134f9-9d6c-4296-9f3a-8e563d745fe6
2023-08-05 05:38:40,950 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9bb76baf-193b-4423-903f-d1eb9519c821
2023-08-05 05:38:40,950 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e304e995-baeb-4647-8870-e5655f027579
2023-08-05 05:38:40,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45089
2023-08-05 05:38:40,958 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45089
2023-08-05 05:38:40,958 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41663
2023-08-05 05:38:40,958 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:40,958 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:40,959 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:40,959 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:40,959 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qrgstlcb
2023-08-05 05:38:40,959 - distributed.worker - INFO - Starting Worker plugin PreImport-04ec6ae8-c835-42f5-aacc-909292d94ed9
2023-08-05 05:38:40,959 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc388e21-4ed8-4538-bc21-aeb9aa24f75d
2023-08-05 05:38:40,960 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1df03fd-1662-47d1-9353-3e2d60bef130
2023-08-05 05:38:41,018 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36519
2023-08-05 05:38:41,018 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36519
2023-08-05 05:38:41,018 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45111
2023-08-05 05:38:41,018 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,019 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,019 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:41,019 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:41,019 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nz0atcam
2023-08-05 05:38:41,018 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41805
2023-08-05 05:38:41,019 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41805
2023-08-05 05:38:41,019 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7cf3012-e759-433c-8b17-40ee27dcc546
2023-08-05 05:38:41,019 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37267
2023-08-05 05:38:41,019 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,020 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,020 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:41,020 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:41,020 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hbtfzbe7
2023-08-05 05:38:41,020 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9bd9f4c8-372d-418d-a90f-6b700562688e
2023-08-05 05:38:41,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37799
2023-08-05 05:38:41,031 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37799
2023-08-05 05:38:41,031 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41243
2023-08-05 05:38:41,031 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,031 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,031 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:41,031 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:41,031 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4d0au5kw
2023-08-05 05:38:41,032 - distributed.worker - INFO - Starting Worker plugin RMMSetup-db49360c-716b-4732-a94f-f44a0c2ddc3f
2023-08-05 05:38:41,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42443
2023-08-05 05:38:41,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42443
2023-08-05 05:38:41,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32893
2023-08-05 05:38:41,035 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,035 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,035 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:41,035 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:41,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uz9nh619
2023-08-05 05:38:41,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5bfe04d1-db2b-4e23-93e6-5dda60434cd0
2023-08-05 05:38:41,035 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46641
2023-08-05 05:38:41,037 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46641
2023-08-05 05:38:41,037 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39781
2023-08-05 05:38:41,038 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,038 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,038 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:41,038 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:41,038 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l0loxxku
2023-08-05 05:38:41,039 - distributed.worker - INFO - Starting Worker plugin RMMSetup-47ef7739-b036-4cd7-b88e-dea21f5ba63b
2023-08-05 05:38:41,194 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99641f98-1c6b-47d2-bf46-72ca79ed3af0
2023-08-05 05:38:41,195 - distributed.worker - INFO - Starting Worker plugin PreImport-51a36359-27e9-4726-9919-19c4301184c9
2023-08-05 05:38:41,195 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,203 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,208 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,231 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33325', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,233 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33325
2023-08-05 05:38:41,233 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43182
2023-08-05 05:38:41,233 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,234 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,236 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,240 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42611', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,241 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42611
2023-08-05 05:38:41,241 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43190
2023-08-05 05:38:41,241 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7801d87b-57fc-435d-9ae1-281d7b09da62
2023-08-05 05:38:41,241 - distributed.worker - INFO - Starting Worker plugin PreImport-d2a8e8e2-bef0-4a10-8fb3-b9506ec662b2
2023-08-05 05:38:41,242 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,242 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,242 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,244 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dfe38da7-f23a-44dd-a26f-31541ac09ab6
2023-08-05 05:38:41,245 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,245 - distributed.worker - INFO - Starting Worker plugin PreImport-c7ae59d6-f27f-4696-ad7f-0add4b0c5d71
2023-08-05 05:38:41,245 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,246 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ecf79da2-37a8-4d7f-a2d5-3623b5623513
2023-08-05 05:38:41,246 - distributed.worker - INFO - Starting Worker plugin PreImport-87e287cf-78ac-41bd-a9f4-166d7962263c
2023-08-05 05:38:41,246 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,247 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45089', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,247 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45089
2023-08-05 05:38:41,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43200
2023-08-05 05:38:41,248 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5afb26a-e30e-41db-8d6d-1aa8cc01b52a
2023-08-05 05:38:41,248 - distributed.worker - INFO - Starting Worker plugin PreImport-c0aa77f1-ef0a-4d77-baba-bb0556972f59
2023-08-05 05:38:41,248 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,248 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4b518575-7426-4728-8285-6175552f11a0
2023-08-05 05:38:41,248 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,248 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,248 - distributed.worker - INFO - Starting Worker plugin PreImport-2477129c-8d40-4292-800c-cc238af85233
2023-08-05 05:38:41,249 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,253 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,268 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36519', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,269 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36519
2023-08-05 05:38:41,269 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43202
2023-08-05 05:38:41,269 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,269 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,272 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46641', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,273 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46641
2023-08-05 05:38:41,273 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43228
2023-08-05 05:38:41,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,274 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,274 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41805', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,275 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41805
2023-08-05 05:38:41,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43214
2023-08-05 05:38:41,275 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,275 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,277 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37799', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,278 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,278 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37799
2023-08-05 05:38:41,278 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43240
2023-08-05 05:38:41,278 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,278 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,279 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42443', status: init, memory: 0, processing: 0>
2023-08-05 05:38:41,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,279 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42443
2023-08-05 05:38:41,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43244
2023-08-05 05:38:41,280 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:41,280 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:41,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,282 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,319 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,323 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:41,332 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,332 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,333 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:38:41,339 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:38:41,340 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:38:41,342 - distributed.scheduler - INFO - Remove client Client-51d18689-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:41,343 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43160; closing.
2023-08-05 05:38:41,343 - distributed.scheduler - INFO - Remove client Client-51d18689-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:41,343 - distributed.scheduler - INFO - Close client connection: Client-51d18689-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:41,344 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42237'. Reason: nanny-close
2023-08-05 05:38:41,345 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,345 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35151'. Reason: nanny-close
2023-08-05 05:38:41,346 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,346 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39835'. Reason: nanny-close
2023-08-05 05:38:41,346 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45089. Reason: nanny-close
2023-08-05 05:38:41,347 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,347 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42611. Reason: nanny-close
2023-08-05 05:38:41,347 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44911'. Reason: nanny-close
2023-08-05 05:38:41,348 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,348 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36519. Reason: nanny-close
2023-08-05 05:38:41,348 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37599'. Reason: nanny-close
2023-08-05 05:38:41,348 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,349 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46811'. Reason: nanny-close
2023-08-05 05:38:41,349 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41805. Reason: nanny-close
2023-08-05 05:38:41,349 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43200; closing.
2023-08-05 05:38:41,349 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,349 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,349 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46641. Reason: nanny-close
2023-08-05 05:38:41,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45089', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,349 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43649'. Reason: nanny-close
2023-08-05 05:38:41,350 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45089
2023-08-05 05:38:41,350 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,350 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,350 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,350 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43307'. Reason: nanny-close
2023-08-05 05:38:41,350 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33325. Reason: nanny-close
2023-08-05 05:38:41,350 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:41,350 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,351 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37799. Reason: nanny-close
2023-08-05 05:38:41,351 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,351 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,351 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45089
2023-08-05 05:38:41,351 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,351 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43190; closing.
2023-08-05 05:38:41,351 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43202; closing.
2023-08-05 05:38:41,351 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45089
2023-08-05 05:38:41,352 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,352 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42443. Reason: nanny-close
2023-08-05 05:38:41,352 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45089
2023-08-05 05:38:41,352 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42611', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,352 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42611
2023-08-05 05:38:41,352 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36519', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,352 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36519
2023-08-05 05:38:41,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,353 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45089
2023-08-05 05:38:41,353 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43214; closing.
2023-08-05 05:38:41,353 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,353 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41805', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,353 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41805
2023-08-05 05:38:41,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:41,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43228; closing.
2023-08-05 05:38:41,354 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,354 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46641', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,354 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46641
2023-08-05 05:38:41,355 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43240; closing.
2023-08-05 05:38:41,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43182; closing.
2023-08-05 05:38:41,355 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:41,355 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37799', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,356 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37799
2023-08-05 05:38:41,356 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33325', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,356 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33325
2023-08-05 05:38:41,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43244; closing.
2023-08-05 05:38:41,357 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42443', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:41,357 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42443
2023-08-05 05:38:41,357 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:42,812 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:42,812 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:42,813 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:42,813 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:38:42,814 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-08-05 05:38:44,678 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:44,682 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33585 instead
  warnings.warn(
2023-08-05 05:38:44,686 - distributed.scheduler - INFO - State start
2023-08-05 05:38:44,705 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:44,706 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:38:44,707 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33585/status
2023-08-05 05:38:44,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43475'
2023-08-05 05:38:44,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45059'
2023-08-05 05:38:44,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43831'
2023-08-05 05:38:44,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37893'
2023-08-05 05:38:44,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46407'
2023-08-05 05:38:44,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42077'
2023-08-05 05:38:44,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45471'
2023-08-05 05:38:44,929 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38727'
2023-08-05 05:38:45,421 - distributed.scheduler - INFO - Receive client connection: Client-56c2b433-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:45,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52540
2023-08-05 05:38:46,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,519 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,527 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,555 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,556 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,557 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,580 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,584 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,592 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:46,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:46,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:46,651 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:49,486 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43057
2023-08-05 05:38:49,488 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43057
2023-08-05 05:38:49,488 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45103
2023-08-05 05:38:49,488 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,488 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,488 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,488 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,488 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z8gm5kdq
2023-08-05 05:38:49,489 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36622748-fc32-4726-9b75-a462662f6970
2023-08-05 05:38:49,605 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c14f4014-7676-4ae9-8f1b-41b5b3de3500
2023-08-05 05:38:49,606 - distributed.worker - INFO - Starting Worker plugin PreImport-1aa17120-3572-4730-8ab3-ec289f510e45
2023-08-05 05:38:49,606 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,648 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43057', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43057
2023-08-05 05:38:49,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52558
2023-08-05 05:38:49,650 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,651 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,653 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:49,759 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45023
2023-08-05 05:38:49,759 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45023
2023-08-05 05:38:49,759 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45747
2023-08-05 05:38:49,760 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,760 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,760 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,760 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,760 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-njw5055g
2023-08-05 05:38:49,760 - distributed.worker - INFO - Starting Worker plugin RMMSetup-12bdfa74-0648-408c-acaa-04ecbaa5fff8
2023-08-05 05:38:49,765 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39963
2023-08-05 05:38:49,766 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39963
2023-08-05 05:38:49,766 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36455
2023-08-05 05:38:49,766 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,766 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,766 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,766 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,766 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mg6trdn8
2023-08-05 05:38:49,767 - distributed.worker - INFO - Starting Worker plugin PreImport-44a824f0-4f58-4ecc-bb96-de352d48e497
2023-08-05 05:38:49,767 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-90651801-fbe2-45c0-8b66-ed3a55c0d209
2023-08-05 05:38:49,767 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ad201cf-06e9-4168-af02-d82d7a960590
2023-08-05 05:38:49,768 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39657
2023-08-05 05:38:49,768 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39657
2023-08-05 05:38:49,768 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33403
2023-08-05 05:38:49,768 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,769 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,769 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,769 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,769 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6dsdi_q1
2023-08-05 05:38:49,769 - distributed.worker - INFO - Starting Worker plugin PreImport-989da60e-703a-442b-a3c0-770d4c8ad83f
2023-08-05 05:38:49,769 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-db80848b-521f-4a48-9c2a-e1435d64d4e7
2023-08-05 05:38:49,770 - distributed.worker - INFO - Starting Worker plugin RMMSetup-505dc458-5a8f-4644-b6e7-193dfdc6600a
2023-08-05 05:38:49,772 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43193
2023-08-05 05:38:49,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43193
2023-08-05 05:38:49,773 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34797
2023-08-05 05:38:49,773 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,773 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,773 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,773 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-opudaijf
2023-08-05 05:38:49,773 - distributed.worker - INFO - Starting Worker plugin RMMSetup-71e9fb47-6dd6-4b94-bff6-9ab6f8c16660
2023-08-05 05:38:49,774 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38953
2023-08-05 05:38:49,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38953
2023-08-05 05:38:49,775 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42215
2023-08-05 05:38:49,775 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,775 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,775 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,775 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,775 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d7792twv
2023-08-05 05:38:49,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-badc7217-5052-4eeb-a6fa-378c986ca1e2
2023-08-05 05:38:49,777 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36179
2023-08-05 05:38:49,777 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36179
2023-08-05 05:38:49,778 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41889
2023-08-05 05:38:49,778 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,778 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,778 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,778 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,778 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g_bw4np8
2023-08-05 05:38:49,778 - distributed.worker - INFO - Starting Worker plugin RMMSetup-da80f58f-25a7-4313-8447-9dc09762e6cb
2023-08-05 05:38:49,778 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40061
2023-08-05 05:38:49,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40061
2023-08-05 05:38:49,780 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41803
2023-08-05 05:38:49,780 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,780 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,780 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:49,780 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-08-05 05:38:49,780 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0f7xa7oi
2023-08-05 05:38:49,781 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1628e6ab-60dd-4fc8-a381-8ff159ae1f79
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a48f6d71-31cc-4447-849a-376f3ae2fcc1
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cada4cdf-d133-4612-8ab8-50062334fc16
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-102b3518-0da9-446f-8699-177a4f6dda6a
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin PreImport-39b13b00-6f53-4e42-9dca-1e1d42bda92c
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5594445-8b12-4d68-8961-33dc8380a8bb
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin PreImport-48f86738-d3a9-4246-99a8-7f9e3ac691c2
2023-08-05 05:38:49,942 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-632c9e1a-3fd1-4d17-9ec0-394002432ed7
2023-08-05 05:38:49,942 - distributed.worker - INFO - Starting Worker plugin PreImport-cf74571e-d0f0-40ff-a9c1-2de66a22f32c
2023-08-05 05:38:49,942 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,942 - distributed.worker - INFO - Starting Worker plugin PreImport-12edcc37-14fe-4135-a7fd-f5fa23f26656
2023-08-05 05:38:49,942 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,942 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,942 - distributed.worker - INFO - Starting Worker plugin PreImport-3ff180c1-dd8e-4006-9e51-8314e7adff04
2023-08-05 05:38:49,942 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,967 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,967 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,969 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36179', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,970 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36179
2023-08-05 05:38:49,970 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52568
2023-08-05 05:38:49,970 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,971 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,972 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43193', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,972 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43193
2023-08-05 05:38:49,972 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52566
2023-08-05 05:38:49,973 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,973 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,973 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40061', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,974 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40061
2023-08-05 05:38:49,974 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52578
2023-08-05 05:38:49,975 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,975 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:49,975 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,975 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:49,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:49,980 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45023', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,981 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45023
2023-08-05 05:38:49,981 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52594
2023-08-05 05:38:49,981 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,982 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38953', status: init, memory: 0, processing: 0>
2023-08-05 05:38:49,982 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,982 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38953
2023-08-05 05:38:49,982 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52590
2023-08-05 05:38:49,983 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:49,983 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:49,986 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:49,988 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:50,002 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39657', status: init, memory: 0, processing: 0>
2023-08-05 05:38:50,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39657
2023-08-05 05:38:50,002 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52606
2023-08-05 05:38:50,003 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:50,003 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:50,003 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39963', status: init, memory: 0, processing: 0>
2023-08-05 05:38:50,004 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39963
2023-08-05 05:38:50,004 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52618
2023-08-05 05:38:50,004 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:50,005 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:50,007 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:50,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:50,033 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,034 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,035 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-08-05 05:38:50,039 - distributed.scheduler - INFO - Remove client Client-56c2b433-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:50,039 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52540; closing.
2023-08-05 05:38:50,039 - distributed.scheduler - INFO - Remove client Client-56c2b433-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:50,040 - distributed.scheduler - INFO - Close client connection: Client-56c2b433-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:50,040 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43475'. Reason: nanny-close
2023-08-05 05:38:50,041 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,041 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45059'. Reason: nanny-close
2023-08-05 05:38:50,042 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,042 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43831'. Reason: nanny-close
2023-08-05 05:38:50,042 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39963. Reason: nanny-close
2023-08-05 05:38:50,043 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,043 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39657. Reason: nanny-close
2023-08-05 05:38:50,043 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37893'. Reason: nanny-close
2023-08-05 05:38:50,043 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,044 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43057. Reason: nanny-close
2023-08-05 05:38:50,044 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46407'. Reason: nanny-close
2023-08-05 05:38:50,044 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,044 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43193. Reason: nanny-close
2023-08-05 05:38:50,044 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42077'. Reason: nanny-close
2023-08-05 05:38:50,045 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52618; closing.
2023-08-05 05:38:50,045 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,045 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,045 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39963', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,045 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39963
2023-08-05 05:38:50,045 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45471'. Reason: nanny-close
2023-08-05 05:38:50,045 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38953. Reason: nanny-close
2023-08-05 05:38:50,045 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,045 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,046 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,046 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38727'. Reason: nanny-close
2023-08-05 05:38:50,046 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45023. Reason: nanny-close
2023-08-05 05:38:50,046 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,046 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:50,046 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,046 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39963
2023-08-05 05:38:50,046 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39963
2023-08-05 05:38:50,047 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52606; closing.
2023-08-05 05:38:50,047 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,047 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52558; closing.
2023-08-05 05:38:50,047 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36179. Reason: nanny-close
2023-08-05 05:38:50,047 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39963
2023-08-05 05:38:50,047 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,047 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,047 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39657', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,047 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40061. Reason: nanny-close
2023-08-05 05:38:50,047 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39657
2023-08-05 05:38:50,048 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,048 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39963
2023-08-05 05:38:50,048 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43057', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,048 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43057
2023-08-05 05:38:50,048 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52566; closing.
2023-08-05 05:38:50,048 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,048 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,049 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43193', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,049 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43193
2023-08-05 05:38:50,049 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:50,049 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,049 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52590; closing.
2023-08-05 05:38:50,050 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38953', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,050 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,050 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,050 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38953
2023-08-05 05:38:50,050 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52594; closing.
2023-08-05 05:38:50,050 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:50,050 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52568; closing.
2023-08-05 05:38:50,051 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45023', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,051 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45023
2023-08-05 05:38:50,051 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36179', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,051 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36179
2023-08-05 05:38:50,051 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52578; closing.
2023-08-05 05:38:50,052 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40061', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:50,052 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40061
2023-08-05 05:38:50,052 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:51,508 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:51,509 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:51,510 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:51,511 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:38:51,512 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-08-05 05:38:53,469 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:53,474 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46373 instead
  warnings.warn(
2023-08-05 05:38:53,478 - distributed.scheduler - INFO - State start
2023-08-05 05:38:53,497 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:38:53,498 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:38:53,499 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46373/status
2023-08-05 05:38:53,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37889'
2023-08-05 05:38:55,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:38:55,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:38:55,638 - distributed.scheduler - INFO - Receive client connection: Client-5c06316b-3352-11ee-886c-d8c49764f6bb
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-05 05:38:55,643 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:38:55,649 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54652
2023-08-05 05:38:56,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44457
2023-08-05 05:38:56,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44457
2023-08-05 05:38:56,503 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-08-05 05:38:56,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:38:56,503 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:56,503 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:38:56,504 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-05 05:38:56,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wrlxtcrp
2023-08-05 05:38:56,504 - distributed.worker - INFO - Starting Worker plugin PreImport-d7db0a4b-c571-4a39-9874-9345a5e65871
2023-08-05 05:38:56,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a30edd4d-5b1a-4ce5-adb9-43658b444f14
2023-08-05 05:38:56,504 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5064a56-9693-4df2-b571-a5daabe97910
2023-08-05 05:38:56,504 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:56,529 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44457', status: init, memory: 0, processing: 0>
2023-08-05 05:38:56,530 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44457
2023-08-05 05:38:56,530 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54668
2023-08-05 05:38:56,531 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:38:56,531 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:38:56,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:38:56,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:38:56,574 - distributed.scheduler - INFO - Remove client Client-5c06316b-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:56,574 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54652; closing.
2023-08-05 05:38:56,574 - distributed.scheduler - INFO - Remove client Client-5c06316b-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:56,575 - distributed.scheduler - INFO - Close client connection: Client-5c06316b-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:38:56,576 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37889'. Reason: nanny-close
2023-08-05 05:38:56,577 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:38:56,578 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44457. Reason: nanny-close
2023-08-05 05:38:56,579 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54668; closing.
2023-08-05 05:38:56,579 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:38:56,580 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44457', status: closing, memory: 0, processing: 0>
2023-08-05 05:38:56,580 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44457
2023-08-05 05:38:56,580 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:38:56,580 - distributed.nanny - INFO - Worker closed
2023-08-05 05:38:57,592 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:38:57,592 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:38:57,593 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:38:57,594 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:38:57,594 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-08-05 05:39:01,208 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:01,213 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39129 instead
  warnings.warn(
2023-08-05 05:39:01,217 - distributed.scheduler - INFO - State start
2023-08-05 05:39:01,239 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:01,240 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:39:01,240 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:39:01,241 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-08-05 05:39:01,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36833'
2023-08-05 05:39:02,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:02,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-08-05 05:39:03,615 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:39:05,636 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36833'. Reason: nanny-close
2023-08-05 05:39:06,359 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45755
2023-08-05 05:39:06,360 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45755
2023-08-05 05:39:06,360 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33715
2023-08-05 05:39:06,360 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:39:06,360 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:06,360 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:39:06,360 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-05 05:39:06,360 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-db_5d9tf
2023-08-05 05:39:06,361 - distributed.worker - INFO - Starting Worker plugin PreImport-d062dd4d-e3e2-4086-913f-1a8a6a96118d
2023-08-05 05:39:06,362 - distributed.worker - INFO - Starting Worker plugin RMMSetup-639714da-a962-4aca-b752-1d7609a426cd
2023-08-05 05:39:06,363 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ce73d43-2701-4fb5-b410-7f456f8d8adf
2023-08-05 05:39:06,363 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:06,386 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:39:06,386 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:06,388 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:39:06,398 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:39:06,399 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45755. Reason: nanny-close
2023-08-05 05:39:06,401 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:39:06,402 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-08-05 05:39:09,393 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:09,398 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45699 instead
  warnings.warn(
2023-08-05 05:39:09,401 - distributed.scheduler - INFO - State start
2023-08-05 05:39:09,423 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:09,424 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:39:09,425 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45699/status
2023-08-05 05:39:09,748 - distributed.scheduler - INFO - Receive client connection: Client-65c4fe3c-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:09,763 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54254
2023-08-05 05:39:14,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45259', status: init, memory: 0, processing: 0>
2023-08-05 05:39:14,684 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45259
2023-08-05 05:39:14,684 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54334
2023-08-05 05:39:14,887 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45701', status: init, memory: 0, processing: 0>
2023-08-05 05:39:14,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45701
2023-08-05 05:39:14,888 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56188
2023-08-05 05:39:15,094 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34719', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,095 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34719
2023-08-05 05:39:15,095 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56196
2023-08-05 05:39:15,100 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33303', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,100 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33303
2023-08-05 05:39:15,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56214
2023-08-05 05:39:15,104 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46321', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,104 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46321
2023-08-05 05:39:15,104 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56240
2023-08-05 05:39:15,105 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36055', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,106 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36055
2023-08-05 05:39:15,106 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56202
2023-08-05 05:39:15,110 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38939', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,110 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38939
2023-08-05 05:39:15,110 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56226
2023-08-05 05:39:15,117 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33089', status: init, memory: 0, processing: 0>
2023-08-05 05:39:15,118 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33089
2023-08-05 05:39:15,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56250
2023-08-05 05:39:15,199 - distributed.scheduler - INFO - Remove client Client-65c4fe3c-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:15,199 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54254; closing.
2023-08-05 05:39:15,200 - distributed.scheduler - INFO - Remove client Client-65c4fe3c-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:15,201 - distributed.scheduler - INFO - Close client connection: Client-65c4fe3c-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:15,205 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56202; closing.
2023-08-05 05:39:15,206 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36055', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,206 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36055
2023-08-05 05:39:15,207 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56226; closing.
2023-08-05 05:39:15,208 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38939', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,208 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38939
2023-08-05 05:39:15,208 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56214; closing.
2023-08-05 05:39:15,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56240; closing.
2023-08-05 05:39:15,209 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33303', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,209 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33303
2023-08-05 05:39:15,210 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46321', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,210 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46321
2023-08-05 05:39:15,211 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56188; closing.
2023-08-05 05:39:15,211 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56250; closing.
2023-08-05 05:39:15,212 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54334; closing.
2023-08-05 05:39:15,212 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45701', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,212 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45701
2023-08-05 05:39:15,213 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33089', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,213 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33089
2023-08-05 05:39:15,213 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45259', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,214 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45259
2023-08-05 05:39:15,214 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56196; closing.
2023-08-05 05:39:15,214 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34719', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:15,215 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34719
2023-08-05 05:39:15,215 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:39:15,958 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:39:15,958 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:39:15,961 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:39:15,964 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:39:15,964 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-08-05 05:39:18,139 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:18,143 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45771 instead
  warnings.warn(
2023-08-05 05:39:18,147 - distributed.scheduler - INFO - State start
2023-08-05 05:39:18,167 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:18,168 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-08-05 05:39:18,169 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45771/status
2023-08-05 05:39:18,273 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37113'
2023-08-05 05:39:19,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:19,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:19,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:39:20,122 - distributed.scheduler - INFO - Receive client connection: Client-6aa9f31f-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:20,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34102
2023-08-05 05:39:21,281 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40781
2023-08-05 05:39:21,281 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40781
2023-08-05 05:39:21,281 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39339
2023-08-05 05:39:21,281 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-08-05 05:39:21,281 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:21,281 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:39:21,282 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-05 05:39:21,282 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bqfpq9l_
2023-08-05 05:39:21,282 - distributed.worker - INFO - Starting Worker plugin RMMSetup-948b4ff8-0786-4607-8f4f-69454db0ad9c
2023-08-05 05:39:21,282 - distributed.worker - INFO - Starting Worker plugin PreImport-793b28ff-dcb7-4cf1-9445-0210deed4e60
2023-08-05 05:39:21,282 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8c0b32cc-5370-4c95-83a9-1188d029fc9b
2023-08-05 05:39:21,282 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:21,630 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40781', status: init, memory: 0, processing: 0>
2023-08-05 05:39:21,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40781
2023-08-05 05:39:21,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34124
2023-08-05 05:39:21,632 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-08-05 05:39:21,633 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:21,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-08-05 05:39:21,759 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:21,762 - distributed.scheduler - INFO - Remove client Client-6aa9f31f-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:21,762 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34102; closing.
2023-08-05 05:39:21,762 - distributed.scheduler - INFO - Remove client Client-6aa9f31f-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:21,763 - distributed.scheduler - INFO - Close client connection: Client-6aa9f31f-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:21,763 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37113'. Reason: nanny-close
2023-08-05 05:39:21,764 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:39:21,765 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40781. Reason: nanny-close
2023-08-05 05:39:21,767 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-08-05 05:39:21,767 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34124; closing.
2023-08-05 05:39:21,767 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40781', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:21,768 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40781
2023-08-05 05:39:21,768 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:39:21,768 - distributed.nanny - INFO - Worker closed
2023-08-05 05:39:22,930 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:39:22,930 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:39:22,931 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:39:22,932 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-08-05 05:39:22,932 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 79, in run_cli
    _register_command_ep(cli, ep)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 56, in _register_command_ep
    command = entry_point.load()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 209, in load
    module = import_module(match.group('module'))
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/__init__.py", line 4, in <module>
    from distributed import config  # load distributed configuration first
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/config.py", line 22, in <module>
    defaults = yaml.safe_load(f)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/__init__.py", line 125, in safe_load
    return load(stream, SafeLoader)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 36, in get_single_node
    document = self.compose_document()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 55, in compose_document
    node = self.compose_node(None, None)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 84, in compose_node
    node = self.compose_mapping_node(anchor)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 133, in compose_mapping_node
    item_value = self.compose_node(node, item_key)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 84, in compose_node
    node = self.compose_mapping_node(anchor)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 133, in compose_mapping_node
    item_value = self.compose_node(node, item_key)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 84, in compose_node
    node = self.compose_mapping_node(anchor)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 133, in compose_mapping_node
    item_value = self.compose_node(node, item_key)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 84, in compose_node
    node = self.compose_mapping_node(anchor)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 133, in compose_mapping_node
    item_value = self.compose_node(node, item_key)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 82, in compose_node
    node = self.compose_sequence_node(anchor)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 111, in compose_sequence_node
    node.value.append(self.compose_node(node, index))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/yaml/composer.py", line 80, in compose_node
    node = self.compose_scalar_node(anchor)
KeyboardInterrupt
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 79, in run_cli
    _register_command_ep(cli, ep)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 56, in _register_command_ep
    command = entry_point.load()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 209, in load
    module = import_module(match.group('module'))
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/__init__.py", line 22, in <module>
    from distributed.actor import Actor, ActorFuture, BaseActorFuture
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/actor.py", line 14, in <module>
    from distributed.client import Future
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/client.py", line 49, in <module>
    from distributed.core import ErrorMessage
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 27, in <module>
    from distributed.comm import (
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/__init__.py", line 16, in <module>
    from distributed.comm.utils import get_tcp_server_address, get_tcp_server_addresses
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 29, in <module>
    import numpy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numpy/__init__.py", line 144, in <module>
    from . import lib
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numpy/lib/__init__.py", line 35, in <module>
    from . import utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numpy/lib/utils.py", line 756, in <module>
    _function_signature_re = re.compile(r"[a-z0-9_]+\(.*[,=].*\)", re.I)
  File "/opt/conda/envs/gdf/lib/python3.9/re.py", line 252, in compile
    return _compile(pattern, flags)
  File "/opt/conda/envs/gdf/lib/python3.9/re.py", line 304, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/opt/conda/envs/gdf/lib/python3.9/sre_compile.py", line 792, in compile
    code = _code(p, flags)
  File "/opt/conda/envs/gdf/lib/python3.9/sre_compile.py", line 631, in _code
    _compile(code, p.data, flags)
  File "/opt/conda/envs/gdf/lib/python3.9/sre_compile.py", line 156, in _compile
    if _simple(av[2]):
  File "/opt/conda/envs/gdf/lib/python3.9/sre_compile.py", line 449, in _simple
    if len(p) != 1:
  File "/opt/conda/envs/gdf/lib/python3.9/sre_parse.py", line 162, in __len__
    return len(self.data)
KeyboardInterrupt
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-08-05 05:39:25,713 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:25,717 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40977 instead
  warnings.warn(
2023-08-05 05:39:25,721 - distributed.scheduler - INFO - State start
2023-08-05 05:39:25,740 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:25,741 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:39:25,741 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40977/status
2023-08-05 05:39:25,762 - distributed.scheduler - INFO - Receive client connection: Client-70279f23-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:25,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35978
2023-08-05 05:39:25,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38571'
2023-08-05 05:39:26,621 - distributed.scheduler - INFO - Receive client connection: Client-6f3622c8-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:26,622 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36008
2023-08-05 05:39:27,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:27,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:27,333 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:39:28,108 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38993
2023-08-05 05:39:28,108 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38993
2023-08-05 05:39:28,108 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40843
2023-08-05 05:39:28,108 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:39:28,108 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:28,108 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:39:28,108 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-05 05:39:28,109 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h7bnr4sk
2023-08-05 05:39:28,109 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b8672828-b2eb-4423-9d43-05a7f55c8f98
2023-08-05 05:39:28,109 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0d70c46-a0d3-41f9-8520-bc51a67de4bc
2023-08-05 05:39:28,248 - distributed.worker - INFO - Starting Worker plugin PreImport-5b2aff87-6d88-4251-ac0a-3465175bf4d9
2023-08-05 05:39:28,248 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:28,276 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38993', status: init, memory: 0, processing: 0>
2023-08-05 05:39:28,277 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38993
2023-08-05 05:39:28,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36094
2023-08-05 05:39:28,277 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:39:28,277 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:28,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:39:28,354 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:39:28,358 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:28,360 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:28,362 - distributed.scheduler - INFO - Remove client Client-6f3622c8-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:28,362 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36008; closing.
2023-08-05 05:39:28,363 - distributed.scheduler - INFO - Remove client Client-6f3622c8-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:28,363 - distributed.scheduler - INFO - Close client connection: Client-6f3622c8-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:28,364 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38571'. Reason: nanny-close
2023-08-05 05:39:28,364 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:39:28,365 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38993. Reason: nanny-close
2023-08-05 05:39:28,367 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:39:28,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36094; closing.
2023-08-05 05:39:28,367 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38993', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:28,368 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38993
2023-08-05 05:39:28,368 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:39:28,368 - distributed.nanny - INFO - Worker closed
2023-08-05 05:39:29,431 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:39:29,431 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:39:29,432 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:39:29,433 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:39:29,434 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-08-05 05:39:31,441 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:31,445 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46223 instead
  warnings.warn(
2023-08-05 05:39:31,449 - distributed.scheduler - INFO - State start
2023-08-05 05:39:31,580 - distributed.scheduler - INFO - -----------------------------------------------
2023-08-05 05:39:31,581 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-08-05 05:39:31,582 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46223/status
2023-08-05 05:39:31,712 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37933'
2023-08-05 05:39:32,316 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38641', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,330 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38641
2023-08-05 05:39:32,330 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36432
2023-08-05 05:39:32,553 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40417', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,553 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40417
2023-08-05 05:39:32,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36434
2023-08-05 05:39:32,561 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35187', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,562 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35187
2023-08-05 05:39:32,562 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36462
2023-08-05 05:39:32,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37801', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,571 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37801
2023-08-05 05:39:32,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36484
2023-08-05 05:39:32,572 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34027', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,573 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34027
2023-08-05 05:39:32,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36476
2023-08-05 05:39:32,576 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44555', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,576 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44555
2023-08-05 05:39:32,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36496
2023-08-05 05:39:32,580 - distributed.scheduler - INFO - Receive client connection: Client-7297b3dd-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:32,581 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36512
2023-08-05 05:39:32,596 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36467', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,596 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36467
2023-08-05 05:39:32,596 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36498
2023-08-05 05:39:32,600 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44689', status: init, memory: 0, processing: 0>
2023-08-05 05:39:32,601 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44689
2023-08-05 05:39:32,601 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36506
2023-08-05 05:39:32,943 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36462; closing.
2023-08-05 05:39:32,944 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35187', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,944 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35187
2023-08-05 05:39:32,946 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36434; closing.
2023-08-05 05:39:32,946 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36476; closing.
2023-08-05 05:39:32,947 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40417', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,947 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40417
2023-08-05 05:39:32,948 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34027', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,948 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34027
2023-08-05 05:39:32,949 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36506; closing.
2023-08-05 05:39:32,950 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44689', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,950 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44689
2023-08-05 05:39:32,950 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36432; closing.
2023-08-05 05:39:32,951 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36484; closing.
2023-08-05 05:39:32,951 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36498; closing.
2023-08-05 05:39:32,951 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36496; closing.
2023-08-05 05:39:32,952 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38641', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,952 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38641
2023-08-05 05:39:32,953 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37801', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,953 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37801
2023-08-05 05:39:32,954 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36467', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,954 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36467
2023-08-05 05:39:32,954 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44555', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:32,954 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44555
2023-08-05 05:39:32,954 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:39:33,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:33,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:33,453 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-08-05 05:39:34,570 - distributed.scheduler - INFO - Receive client connection: Client-756f82e9-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:34,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36542
2023-08-05 05:39:34,634 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40003
2023-08-05 05:39:34,635 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40003
2023-08-05 05:39:34,635 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42701
2023-08-05 05:39:34,635 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-08-05 05:39:34,635 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:34,635 - distributed.worker - INFO -               Threads:                          1
2023-08-05 05:39:34,635 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-08-05 05:39:34,635 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kza0aery
2023-08-05 05:39:34,635 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7cb59326-3b28-4c28-bb13-5662d742fdb7
2023-08-05 05:39:34,636 - distributed.worker - INFO - Starting Worker plugin RMMSetup-af0f24a2-4c3a-4324-9b6d-a446ce24062d
2023-08-05 05:39:34,742 - distributed.worker - INFO - Starting Worker plugin PreImport-9c879d72-a9bb-46a8-9840-2a293b6c6f32
2023-08-05 05:39:34,742 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:34,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40003', status: init, memory: 0, processing: 0>
2023-08-05 05:39:34,769 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40003
2023-08-05 05:39:34,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36556
2023-08-05 05:39:34,770 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-08-05 05:39:34,770 - distributed.worker - INFO - -------------------------------------------------
2023-08-05 05:39:34,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-08-05 05:39:34,780 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:34,783 - distributed.scheduler - INFO - Remove client Client-756f82e9-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:34,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36542; closing.
2023-08-05 05:39:34,783 - distributed.scheduler - INFO - Remove client Client-756f82e9-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:34,783 - distributed.scheduler - INFO - Close client connection: Client-756f82e9-3352-11ee-89fb-d8c49764f6bb
2023-08-05 05:39:34,873 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-08-05 05:39:34,878 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-08-05 05:39:34,882 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:34,883 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-08-05 05:39:34,886 - distributed.scheduler - INFO - Remove client Client-7297b3dd-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:34,886 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36512; closing.
2023-08-05 05:39:34,886 - distributed.scheduler - INFO - Remove client Client-7297b3dd-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:34,886 - distributed.scheduler - INFO - Close client connection: Client-7297b3dd-3352-11ee-886c-d8c49764f6bb
2023-08-05 05:39:34,888 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37933'. Reason: nanny-close
2023-08-05 05:39:34,889 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-08-05 05:39:34,890 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40003. Reason: nanny-close
2023-08-05 05:39:34,892 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36556; closing.
2023-08-05 05:39:34,892 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-08-05 05:39:34,892 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40003', status: closing, memory: 0, processing: 0>
2023-08-05 05:39:34,892 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40003
2023-08-05 05:39:34,892 - distributed.scheduler - INFO - Lost all workers
2023-08-05 05:39:34,893 - distributed.nanny - INFO - Worker closed
2023-08-05 05:39:35,903 - distributed._signals - INFO - Received signal SIGINT (2)
2023-08-05 05:39:35,903 - distributed.scheduler - INFO - Scheduler closing...
2023-08-05 05:39:35,904 - distributed.scheduler - INFO - Scheduler closing all comms
2023-08-05 05:39:35,905 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-08-05 05:39:35,905 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37213 instead
  warnings.warn(
2023-08-05 05:39:44,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:44,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:44,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:45,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:45,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43381 instead
  warnings.warn(
2023-08-05 05:39:54,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:39:54,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:39:54,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39257 instead
  warnings.warn(
2023-08-05 05:40:04,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:04,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:04,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39379 instead
  warnings.warn(
2023-08-05 05:40:13,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:13,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:13,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37187 instead
  warnings.warn(
2023-08-05 05:40:24,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:24,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:24,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41993 instead
  warnings.warn(
2023-08-05 05:40:36,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:36,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:36,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42103 instead
  warnings.warn(
2023-08-05 05:40:49,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:40:49,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:40:49,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39047 instead
  warnings.warn(
2023-08-05 05:41:03,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,288 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-05 05:41:03,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-05 05:41:03,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39743 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35293 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37389 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37205 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33409 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46261 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42151 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36407 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45399 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37593 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41689 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46701 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46721 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44047 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37841 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36701 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46831 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37919 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45607 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46673 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41467 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37351 instead
  warnings.warn(
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-810' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39989 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40129 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41601 instead
  warnings.warn(
2023-08-05 05:47:31,677 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-531f4f75-efd1-4871-b3e1-766a7eaf0bad
Function:  _run_coroutine_on_worker
args:      (31516723617346675975602307423444901278, <function shuffle_task at 0x7f22d85585e0>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0)", "('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)"}, 1: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)"}, 2: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)"}, 3: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)"}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-08-05 05:47:31,680 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-6c9ac08b-c1a6-4893-9329-d1975fa09a3c
Function:  _run_coroutine_on_worker
args:      (31516723617346675975602307423444901278, <function shuffle_task at 0x7fee3a762a60>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)", "('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0)"}, 1: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)"}, 2: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)"}, 3: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)"}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-08-05 05:47:31,687 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-dbf99d64-c346-4617-9d0e-7774b8802f61
Function:  _run_coroutine_on_worker
args:      (31516723617346675975602307423444901278, <function shuffle_task at 0x7f6d3f550c10>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)", "('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0)"}, 1: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)"}, 2: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)"}, 3: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)"}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-08-05 05:47:31,689 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-c4083f3c-ff99-4e53-b3a7-ab78f899d22f
Function:  _run_coroutine_on_worker
args:      (31516723617346675975602307423444901278, <function shuffle_task at 0x7f491134b550>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0)", "('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)"}, 1: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)"}, 2: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)"}, 3: {"('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)"}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-08-05 05:47:31,842 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,849 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,856 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,865 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,887 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fef0f483b80>>, <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,888 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f6e14090b50>>, <Task finished name='Task-15' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-15' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,889 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f49e5e7cc70>>, <Task finished name='Task-16' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-16' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:31,890 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2338ae7a90>>, <Task finished name='Task-16' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-16' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-08-05 05:47:33,890 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-05 05:47:33,891 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-05 05:47:33,892 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-08-05 05:47:33,892 - distributed.nanny - ERROR - Worker process died unexpectedly
