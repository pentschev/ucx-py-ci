============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-18 05:37:49,007 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:37:49,013 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36763 instead
  warnings.warn(
2023-10-18 05:37:49,017 - distributed.scheduler - INFO - State start
2023-10-18 05:37:49,041 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:37:49,043 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-18 05:37:49,043 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36763/status
2023-10-18 05:37:49,044 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:37:49,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35465'
2023-10-18 05:37:49,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38511'
2023-10-18 05:37:49,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37379'
2023-10-18 05:37:49,081 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33625'
2023-10-18 05:37:49,707 - distributed.scheduler - INFO - Receive client connection: Client-780a4302-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:37:49,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42036
2023-10-18 05:37:50,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:50,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:50,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:50,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:50,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:50,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:50,710 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:50,710 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:50,712 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:50,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:50,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:50,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-18 05:37:50,724 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39409
2023-10-18 05:37:50,724 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39409
2023-10-18 05:37:50,724 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45101
2023-10-18 05:37:50,725 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-18 05:37:50,725 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:50,725 - distributed.worker - INFO -               Threads:                          4
2023-10-18 05:37:50,725 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-18 05:37:50,725 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-6kiiny_2
2023-10-18 05:37:50,725 - distributed.worker - INFO - Starting Worker plugin PreImport-894a984b-f7a0-4097-96e7-d158b8501456
2023-10-18 05:37:50,725 - distributed.worker - INFO - Starting Worker plugin RMMSetup-788c9540-7f97-4930-bf44-2c4b5c0f9f6a
2023-10-18 05:37:50,725 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-063e7b5d-f218-4333-853a-acde4a7a5288
2023-10-18 05:37:50,726 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:51,003 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39409', status: init, memory: 0, processing: 0>
2023-10-18 05:37:51,004 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39409
2023-10-18 05:37:51,004 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49438
2023-10-18 05:37:51,005 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:37:51,006 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-18 05:37:51,006 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:51,007 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-18 05:37:52,177 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33437
2023-10-18 05:37:52,178 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33437
2023-10-18 05:37:52,179 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38341
2023-10-18 05:37:52,179 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,179 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,179 - distributed.worker - INFO -               Threads:                          4
2023-10-18 05:37:52,179 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-18 05:37:52,179 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-wfbd1q57
2023-10-18 05:37:52,180 - distributed.worker - INFO - Starting Worker plugin PreImport-109a3a2d-b313-4e23-b824-b81847c06231
2023-10-18 05:37:52,180 - distributed.worker - INFO - Starting Worker plugin RMMSetup-15ba7d5c-71ad-4c1b-8760-fcb55eb92e24
2023-10-18 05:37:52,181 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14227708-c11e-41d2-8f23-bf2078d068e5
2023-10-18 05:37:52,180 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44031
2023-10-18 05:37:52,181 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44031
2023-10-18 05:37:52,181 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,181 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45423
2023-10-18 05:37:52,181 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,181 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,181 - distributed.worker - INFO -               Threads:                          4
2023-10-18 05:37:52,182 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-18 05:37:52,182 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-0ye9do88
2023-10-18 05:37:52,182 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3683cb6-652b-402e-8042-77aed84f2ae5
2023-10-18 05:37:52,183 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5bb3cbfd-2233-41c2-ae2e-ce590a77f372
2023-10-18 05:37:52,183 - distributed.worker - INFO - Starting Worker plugin PreImport-e004cdcb-e006-4a2b-9a49-f6dd008ee6dd
2023-10-18 05:37:52,185 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36861
2023-10-18 05:37:52,186 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36861
2023-10-18 05:37:52,186 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41011
2023-10-18 05:37:52,186 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,186 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,186 - distributed.worker - INFO -               Threads:                          4
2023-10-18 05:37:52,187 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-18 05:37:52,187 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-qum2izq5
2023-10-18 05:37:52,188 - distributed.worker - INFO - Starting Worker plugin PreImport-13af75e0-2f66-4004-8db0-8931b5d6bd00
2023-10-18 05:37:52,188 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5230f85c-d873-490a-9bf6-b39f90ba84f8
2023-10-18 05:37:52,188 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b06d7c3-99cb-42a3-9d32-441d082374d9
2023-10-18 05:37:52,188 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,188 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,206 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33437', status: init, memory: 0, processing: 0>
2023-10-18 05:37:52,207 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33437
2023-10-18 05:37:52,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49456
2023-10-18 05:37:52,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:37:52,209 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,209 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,211 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36861', status: init, memory: 0, processing: 0>
2023-10-18 05:37:52,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-18 05:37:52,212 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36861
2023-10-18 05:37:52,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49464
2023-10-18 05:37:52,213 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:37:52,214 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,214 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,215 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-18 05:37:52,224 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44031', status: init, memory: 0, processing: 0>
2023-10-18 05:37:52,225 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44031
2023-10-18 05:37:52,225 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49476
2023-10-18 05:37:52,226 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:37:52,227 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-18 05:37:52,228 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:37:52,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-18 05:37:52,275 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-18 05:37:52,276 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-18 05:37:52,276 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-18 05:37:52,276 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-18 05:37:52,281 - distributed.scheduler - INFO - Remove client Client-780a4302-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:37:52,281 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42036; closing.
2023-10-18 05:37:52,281 - distributed.scheduler - INFO - Remove client Client-780a4302-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:37:52,281 - distributed.scheduler - INFO - Close client connection: Client-780a4302-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:37:52,282 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35465'. Reason: nanny-close
2023-10-18 05:37:52,283 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:37:52,284 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38511'. Reason: nanny-close
2023-10-18 05:37:52,284 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:37:52,284 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44031. Reason: nanny-close
2023-10-18 05:37:52,284 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37379'. Reason: nanny-close
2023-10-18 05:37:52,285 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:37:52,285 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36861. Reason: nanny-close
2023-10-18 05:37:52,285 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33625'. Reason: nanny-close
2023-10-18 05:37:52,285 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:37:52,285 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33437. Reason: nanny-close
2023-10-18 05:37:52,286 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39409. Reason: nanny-close
2023-10-18 05:37:52,287 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49476; closing.
2023-10-18 05:37:52,287 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-18 05:37:52,287 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-18 05:37:52,287 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607472.2874773')
2023-10-18 05:37:52,287 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-18 05:37:52,288 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-18 05:37:52,288 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49438; closing.
2023-10-18 05:37:52,288 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49464; closing.
2023-10-18 05:37:52,288 - distributed.nanny - INFO - Worker closed
2023-10-18 05:37:52,289 - distributed.nanny - INFO - Worker closed
2023-10-18 05:37:52,289 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39409', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607472.2893639')
2023-10-18 05:37:52,289 - distributed.nanny - INFO - Worker closed
2023-10-18 05:37:52,289 - distributed.nanny - INFO - Worker closed
2023-10-18 05:37:52,289 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36861', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607472.2897973')
2023-10-18 05:37:52,290 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49456; closing.
2023-10-18 05:37:52,290 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:49438>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:49438>: Stream is closed
2023-10-18 05:37:52,292 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33437', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607472.2928925')
2023-10-18 05:37:52,293 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:37:53,499 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:37:53,500 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:37:53,500 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:37:53,501 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-18 05:37:53,502 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-18 05:37:55,574 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:37:55,578 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-18 05:37:55,581 - distributed.scheduler - INFO - State start
2023-10-18 05:37:55,600 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:37:55,601 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:37:55,602 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-18 05:37:55,602 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:37:55,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42865'
2023-10-18 05:37:55,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42885'
2023-10-18 05:37:55,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40369'
2023-10-18 05:37:55,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37903'
2023-10-18 05:37:55,974 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35067'
2023-10-18 05:37:55,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37755'
2023-10-18 05:37:55,991 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39405'
2023-10-18 05:37:56,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33413'
2023-10-18 05:37:56,111 - distributed.scheduler - INFO - Receive client connection: Client-7c0d1086-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:37:56,124 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50996
2023-10-18 05:37:57,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:57,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:57,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:57,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:57,804 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:57,804 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:57,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:57,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:57,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:57,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:57,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:57,820 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:57,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:57,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:57,825 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:58,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:58,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:58,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:58,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:58,023 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:58,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:37:58,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:37:58,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:37:58,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:00,765 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46239
2023-10-18 05:38:00,766 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46239
2023-10-18 05:38:00,766 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46105
2023-10-18 05:38:00,766 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,766 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,766 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,766 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,766 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5u196ejf
2023-10-18 05:38:00,767 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33cc71d0-a978-4f32-8777-f2876a9c9621
2023-10-18 05:38:00,772 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33931
2023-10-18 05:38:00,773 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33931
2023-10-18 05:38:00,773 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39805
2023-10-18 05:38:00,773 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,774 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,774 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,774 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,774 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q5u95jpz
2023-10-18 05:38:00,774 - distributed.worker - INFO - Starting Worker plugin RMMSetup-245f200f-0e2b-4d90-9421-7f4912a5e4db
2023-10-18 05:38:00,778 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40061
2023-10-18 05:38:00,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40061
2023-10-18 05:38:00,779 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37615
2023-10-18 05:38:00,779 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,779 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,779 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,779 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,779 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-659sp6_g
2023-10-18 05:38:00,780 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69d439c7-63ab-40bc-94dc-7ef91dd47cb2
2023-10-18 05:38:00,780 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7e044954-ad45-4e1f-ba00-36be0694dd85
2023-10-18 05:38:00,909 - distributed.worker - INFO - Starting Worker plugin PreImport-9d857aaf-7a3a-4f89-b906-cf646d20c18d
2023-10-18 05:38:00,909 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,912 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15205a3d-b638-4ca5-a3e1-66c31510ff80
2023-10-18 05:38:00,912 - distributed.worker - INFO - Starting Worker plugin PreImport-74245ff2-94d1-4d41-b482-612aff874457
2023-10-18 05:38:00,912 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,920 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9e81bf13-52db-482b-9abe-c8eb0e2154f2
2023-10-18 05:38:00,923 - distributed.worker - INFO - Starting Worker plugin PreImport-f7d9e6f3-f4f5-4038-bc79-f709abdb86d4
2023-10-18 05:38:00,924 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,942 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46239', status: init, memory: 0, processing: 0>
2023-10-18 05:38:00,943 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46239
2023-10-18 05:38:00,943 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60904
2023-10-18 05:38:00,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:00,945 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40061', status: init, memory: 0, processing: 0>
2023-10-18 05:38:00,945 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,945 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,945 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40061
2023-10-18 05:38:00,945 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60898
2023-10-18 05:38:00,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:00,946 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:00,948 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,948 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,950 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:00,955 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34013
2023-10-18 05:38:00,956 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34013
2023-10-18 05:38:00,956 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39599
2023-10-18 05:38:00,956 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,956 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,956 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,956 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,956 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s9p0vf1c
2023-10-18 05:38:00,957 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e48de7e5-8a80-4c41-855d-57daf587525d
2023-10-18 05:38:00,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40197
2023-10-18 05:38:00,958 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40197
2023-10-18 05:38:00,958 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41773
2023-10-18 05:38:00,958 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,958 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,958 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,959 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,959 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y8stio16
2023-10-18 05:38:00,959 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e596feb-987f-4822-a79c-e89642ef4e19
2023-10-18 05:38:00,959 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46727
2023-10-18 05:38:00,960 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46727
2023-10-18 05:38:00,960 - distributed.worker - INFO - Starting Worker plugin PreImport-0d6855bd-1dfc-4570-a165-8557df450843
2023-10-18 05:38:00,960 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43051
2023-10-18 05:38:00,960 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,960 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,960 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a34bb591-3a5e-4e30-abab-b89bbb961009
2023-10-18 05:38:00,960 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,960 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,960 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5qvbo4sw
2023-10-18 05:38:00,961 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6bfce461-3086-49d7-9f28-4865bb2b6254
2023-10-18 05:38:00,960 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39371
2023-10-18 05:38:00,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39371
2023-10-18 05:38:00,961 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36099
2023-10-18 05:38:00,961 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,961 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33931', status: init, memory: 0, processing: 0>
2023-10-18 05:38:00,961 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,961 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,962 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z3n9li62
2023-10-18 05:38:00,962 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33931
2023-10-18 05:38:00,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60906
2023-10-18 05:38:00,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45913
2023-10-18 05:38:00,962 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45913
2023-10-18 05:38:00,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0481c1ae-4e41-4d21-9cd2-9a8bef228186
2023-10-18 05:38:00,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41741
2023-10-18 05:38:00,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,962 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,962 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:00,963 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:00,963 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ixo3eitm
2023-10-18 05:38:00,963 - distributed.worker - INFO - Starting Worker plugin RMMSetup-76dd6b05-56a2-48da-8a0a-37cd41a51395
2023-10-18 05:38:00,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:00,964 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:00,964 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:00,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,238 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,246 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cf916e28-49a1-4b2b-a4df-19ec536b799c
2023-10-18 05:38:01,246 - distributed.worker - INFO - Starting Worker plugin PreImport-ae297b04-2988-4a1e-8cbb-4b0bf69139ff
2023-10-18 05:38:01,246 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,251 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df98e848-4163-40b9-944b-86dab7ddcdaa
2023-10-18 05:38:01,252 - distributed.worker - INFO - Starting Worker plugin PreImport-5cc7e3e2-b01b-479c-be8c-1d85a11b3e29
2023-10-18 05:38:01,252 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,255 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b5695b37-1dee-4731-857e-9498156fc035
2023-10-18 05:38:01,255 - distributed.worker - INFO - Starting Worker plugin PreImport-48c49358-1e0c-4e81-bf37-dfc1d5dd80d7
2023-10-18 05:38:01,256 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,260 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e205a87b-10e5-40d4-88f8-869d8c90cd15
2023-10-18 05:38:01,260 - distributed.worker - INFO - Starting Worker plugin PreImport-56dc221d-7165-444e-8477-0df67d6da168
2023-10-18 05:38:01,261 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,266 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40197', status: init, memory: 0, processing: 0>
2023-10-18 05:38:01,266 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40197
2023-10-18 05:38:01,266 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60914
2023-10-18 05:38:01,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:01,269 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:01,269 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,271 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,272 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46727', status: init, memory: 0, processing: 0>
2023-10-18 05:38:01,273 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46727
2023-10-18 05:38:01,273 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60926
2023-10-18 05:38:01,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:01,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:01,274 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,276 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34013', status: init, memory: 0, processing: 0>
2023-10-18 05:38:01,276 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,277 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34013
2023-10-18 05:38:01,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60934
2023-10-18 05:38:01,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:01,279 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:01,279 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,284 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39371', status: init, memory: 0, processing: 0>
2023-10-18 05:38:01,285 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39371
2023-10-18 05:38:01,285 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60950
2023-10-18 05:38:01,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:01,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:01,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,288 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,289 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45913', status: init, memory: 0, processing: 0>
2023-10-18 05:38:01,290 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45913
2023-10-18 05:38:01,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60942
2023-10-18 05:38:01,291 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:01,292 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:01,292 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:01,294 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:01,366 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,366 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,366 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,367 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,367 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,367 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,367 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,367 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:01,371 - distributed.scheduler - INFO - Remove client Client-7c0d1086-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:01,371 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50996; closing.
2023-10-18 05:38:01,372 - distributed.scheduler - INFO - Remove client Client-7c0d1086-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:01,372 - distributed.scheduler - INFO - Close client connection: Client-7c0d1086-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:01,373 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42865'. Reason: nanny-close
2023-10-18 05:38:01,373 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,374 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42885'. Reason: nanny-close
2023-10-18 05:38:01,374 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,375 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40197. Reason: nanny-close
2023-10-18 05:38:01,375 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40369'. Reason: nanny-close
2023-10-18 05:38:01,375 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,376 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33931. Reason: nanny-close
2023-10-18 05:38:01,376 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37903'. Reason: nanny-close
2023-10-18 05:38:01,376 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,376 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46239. Reason: nanny-close
2023-10-18 05:38:01,377 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35067'. Reason: nanny-close
2023-10-18 05:38:01,377 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,377 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46727. Reason: nanny-close
2023-10-18 05:38:01,377 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,378 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37755'. Reason: nanny-close
2023-10-18 05:38:01,378 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,378 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60914; closing.
2023-10-18 05:38:01,378 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,378 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40061. Reason: nanny-close
2023-10-18 05:38:01,378 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,378 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40197', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.3788638')
2023-10-18 05:38:01,379 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39405'. Reason: nanny-close
2023-10-18 05:38:01,379 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45913. Reason: nanny-close
2023-10-18 05:38:01,379 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,379 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33413'. Reason: nanny-close
2023-10-18 05:38:01,380 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39371. Reason: nanny-close
2023-10-18 05:38:01,380 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:01,380 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60906; closing.
2023-10-18 05:38:01,380 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,380 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,380 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,381 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,381 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34013. Reason: nanny-close
2023-10-18 05:38:01,381 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60926; closing.
2023-10-18 05:38:01,381 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33931', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.381863')
2023-10-18 05:38:01,382 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60904; closing.
2023-10-18 05:38:01,382 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,382 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,382 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,383 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46727', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.3830354')
2023-10-18 05:38:01,383 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:01,383 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.383663')
2023-10-18 05:38:01,384 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,384 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60898; closing.
2023-10-18 05:38:01,384 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,384 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60942; closing.
2023-10-18 05:38:01,385 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,385 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:01,385 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40061', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.3855064')
2023-10-18 05:38:01,385 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45913', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.385932')
2023-10-18 05:38:01,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60950; closing.
2023-10-18 05:38:01,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60934; closing.
2023-10-18 05:38:01,387 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39371', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.3870444')
2023-10-18 05:38:01,387 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34013', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607481.3875086')
2023-10-18 05:38:01,387 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:02,890 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:02,891 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:02,891 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:02,892 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:02,893 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-18 05:38:04,893 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:04,897 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-18 05:38:04,901 - distributed.scheduler - INFO - State start
2023-10-18 05:38:05,072 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:05,073 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:05,074 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-18 05:38:05,074 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:05,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40511'
2023-10-18 05:38:05,212 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45379'
2023-10-18 05:38:05,221 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40125'
2023-10-18 05:38:05,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32915'
2023-10-18 05:38:05,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33863'
2023-10-18 05:38:05,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38691'
2023-10-18 05:38:05,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40177'
2023-10-18 05:38:05,264 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35277'
2023-10-18 05:38:05,807 - distributed.scheduler - INFO - Receive client connection: Client-81981184-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:05,819 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32882
2023-10-18 05:38:07,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,082 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,083 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,083 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,118 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,119 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,129 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:07,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:07,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:07,146 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:10,062 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33875
2023-10-18 05:38:10,063 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33875
2023-10-18 05:38:10,063 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45085
2023-10-18 05:38:10,063 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,063 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,063 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,063 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,063 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h_e27ce0
2023-10-18 05:38:10,064 - distributed.worker - INFO - Starting Worker plugin RMMSetup-27575de9-1405-40fd-9502-0fede06c8316
2023-10-18 05:38:10,069 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43507
2023-10-18 05:38:10,069 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43507
2023-10-18 05:38:10,069 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41709
2023-10-18 05:38:10,070 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,070 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,070 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,070 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,070 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5sm3eib5
2023-10-18 05:38:10,070 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3340dc1b-da48-41d0-911d-334a1ab48a91
2023-10-18 05:38:10,071 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a5f9a88d-c004-4346-ac25-c87fe60d513f
2023-10-18 05:38:10,147 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44361
2023-10-18 05:38:10,148 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44361
2023-10-18 05:38:10,148 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42401
2023-10-18 05:38:10,148 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,148 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,148 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,148 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,149 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a4s3mwyr
2023-10-18 05:38:10,149 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-096fe510-a7ed-4b9d-aecc-644b7a16943c
2023-10-18 05:38:10,149 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb04a5db-6236-4aa9-b67d-c16ec02df3d0
2023-10-18 05:38:10,178 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43801
2023-10-18 05:38:10,179 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43801
2023-10-18 05:38:10,179 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34381
2023-10-18 05:38:10,179 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,179 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,179 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,179 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,179 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ou9cu8ks
2023-10-18 05:38:10,180 - distributed.worker - INFO - Starting Worker plugin PreImport-99e778bf-70ba-447a-9294-6025931992b8
2023-10-18 05:38:10,180 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ca195fd-b0a5-47c8-bfa8-50438ad4bc83
2023-10-18 05:38:10,180 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f671f7fa-bb50-477b-9cb2-148ee5f109c3
2023-10-18 05:38:10,189 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45131
2023-10-18 05:38:10,190 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45131
2023-10-18 05:38:10,190 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34509
2023-10-18 05:38:10,190 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,190 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,190 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,190 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,190 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gj56og1t
2023-10-18 05:38:10,191 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba85edaa-0e96-4086-8c3c-ce96659dc58c
2023-10-18 05:38:10,191 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa06ef48-75ac-4135-8d07-d10d60141fc7
2023-10-18 05:38:10,193 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36239
2023-10-18 05:38:10,194 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36239
2023-10-18 05:38:10,194 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38641
2023-10-18 05:38:10,194 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,194 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,194 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,194 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,194 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sujgbgb7
2023-10-18 05:38:10,195 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b66c0950-5bae-4c0c-a865-bb6af8a63976
2023-10-18 05:38:10,194 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32981
2023-10-18 05:38:10,195 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32981
2023-10-18 05:38:10,195 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b3ba0c82-519c-4512-89fd-0c4195421677
2023-10-18 05:38:10,195 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45963
2023-10-18 05:38:10,195 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,195 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,195 - distributed.worker - INFO - Starting Worker plugin PreImport-482beb25-cd5d-4b23-9119-3b27a7b4fd80
2023-10-18 05:38:10,195 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,195 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,195 - distributed.worker - INFO - Starting Worker plugin PreImport-d0c79572-2d8f-4f47-a0c8-32959927c17d
2023-10-18 05:38:10,195 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-exqj51oh
2023-10-18 05:38:10,195 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,196 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dbb73a89-b96b-4345-bc50-75ab51e3efee
2023-10-18 05:38:10,196 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a306c164-6895-429d-9dbd-c24ea507fcf4
2023-10-18 05:38:10,197 - distributed.worker - INFO - Starting Worker plugin RMMSetup-27fe0f45-66a0-4663-bebe-5b1fc73bbde2
2023-10-18 05:38:10,197 - distributed.worker - INFO - Starting Worker plugin PreImport-bb264783-78e8-4e78-a247-42ce57a80ffa
2023-10-18 05:38:10,198 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,201 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33755
2023-10-18 05:38:10,202 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33755
2023-10-18 05:38:10,202 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46621
2023-10-18 05:38:10,203 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,203 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,203 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:10,203 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:10,203 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qome0s91
2023-10-18 05:38:10,204 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f5fa46f-70f6-473a-a28b-91410375ad72
2023-10-18 05:38:10,216 - distributed.worker - INFO - Starting Worker plugin PreImport-c078d666-03b8-4428-a152-5200b19f71a2
2023-10-18 05:38:10,216 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,220 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,221 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33875', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,223 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33875
2023-10-18 05:38:10,223 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33742
2023-10-18 05:38:10,223 - distributed.worker - INFO - Starting Worker plugin PreImport-3d9c0473-dd01-4749-8304-fdce63ec0daa
2023-10-18 05:38:10,223 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,224 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,225 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,225 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,226 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,227 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,227 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43507', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,227 - distributed.worker - INFO - Starting Worker plugin PreImport-ff8b39b2-b608-421d-baa5-a47e66e922ea
2023-10-18 05:38:10,228 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,228 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43507
2023-10-18 05:38:10,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33758
2023-10-18 05:38:10,228 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dacfa7be-ebf2-4256-ad85-c60555ef1f03
2023-10-18 05:38:10,229 - distributed.worker - INFO - Starting Worker plugin PreImport-d2fafdff-a24f-4ece-97dc-8e510a028a39
2023-10-18 05:38:10,229 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,230 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,231 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,231 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,233 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,240 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44361', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,241 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44361
2023-10-18 05:38:10,241 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33772
2023-10-18 05:38:10,242 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,243 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,243 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,245 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,245 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43801', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,246 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43801
2023-10-18 05:38:10,246 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33778
2023-10-18 05:38:10,247 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45131', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,248 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45131
2023-10-18 05:38:10,248 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33786
2023-10-18 05:38:10,248 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,248 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,249 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,249 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,249 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,250 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,258 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32981', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,258 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32981
2023-10-18 05:38:10,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33818
2023-10-18 05:38:10,259 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36239', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,260 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36239
2023-10-18 05:38:10,260 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33802
2023-10-18 05:38:10,260 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,261 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,261 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,261 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,262 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,262 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,263 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33755', status: init, memory: 0, processing: 0>
2023-10-18 05:38:10,263 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,263 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33755
2023-10-18 05:38:10,263 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33834
2023-10-18 05:38:10,264 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:10,266 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:10,266 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:10,268 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:10,317 - distributed.scheduler - INFO - Remove client Client-81981184-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:10,317 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32882; closing.
2023-10-18 05:38:10,318 - distributed.scheduler - INFO - Remove client Client-81981184-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:10,318 - distributed.scheduler - INFO - Close client connection: Client-81981184-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:10,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40511'. Reason: nanny-close
2023-10-18 05:38:10,319 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,320 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45379'. Reason: nanny-close
2023-10-18 05:38:10,320 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,321 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36239. Reason: nanny-close
2023-10-18 05:38:10,321 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40125'. Reason: nanny-close
2023-10-18 05:38:10,321 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,321 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43507. Reason: nanny-close
2023-10-18 05:38:10,321 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32915'. Reason: nanny-close
2023-10-18 05:38:10,322 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33875. Reason: nanny-close
2023-10-18 05:38:10,322 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33863'. Reason: nanny-close
2023-10-18 05:38:10,322 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43801. Reason: nanny-close
2023-10-18 05:38:10,323 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,323 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38691'. Reason: nanny-close
2023-10-18 05:38:10,323 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,323 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33802; closing.
2023-10-18 05:38:10,323 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33755. Reason: nanny-close
2023-10-18 05:38:10,323 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40177'. Reason: nanny-close
2023-10-18 05:38:10,323 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,324 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,324 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,324 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3239977')
2023-10-18 05:38:10,324 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32981. Reason: nanny-close
2023-10-18 05:38:10,324 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35277'. Reason: nanny-close
2023-10-18 05:38:10,324 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:10,324 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33742; closing.
2023-10-18 05:38:10,324 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44361. Reason: nanny-close
2023-10-18 05:38:10,325 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,325 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,325 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45131. Reason: nanny-close
2023-10-18 05:38:10,325 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,325 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,325 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.325704')
2023-10-18 05:38:10,325 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,326 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33758; closing.
2023-10-18 05:38:10,326 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,326 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,327 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:10,327 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,327 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43507', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3277693')
2023-10-18 05:38:10,328 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,328 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,328 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33778; closing.
2023-10-18 05:38:10,328 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,328 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:10,329 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:33742>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:10,331 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43801', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3314474')
2023-10-18 05:38:10,332 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33834; closing.
2023-10-18 05:38:10,332 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33755', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3328118')
2023-10-18 05:38:10,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33818; closing.
2023-10-18 05:38:10,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33772; closing.
2023-10-18 05:38:10,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33786; closing.
2023-10-18 05:38:10,334 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32981', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3341076')
2023-10-18 05:38:10,334 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44361', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3346865')
2023-10-18 05:38:10,335 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45131', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607490.3351693')
2023-10-18 05:38:10,335 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:11,736 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:11,736 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:11,737 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:11,738 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:11,738 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-18 05:38:13,636 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:13,640 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33623 instead
  warnings.warn(
2023-10-18 05:38:13,644 - distributed.scheduler - INFO - State start
2023-10-18 05:38:13,670 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:13,671 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:13,671 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33623/status
2023-10-18 05:38:13,672 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:13,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38043'
2023-10-18 05:38:13,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44861'
2023-10-18 05:38:13,997 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38429'
2023-10-18 05:38:14,011 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36067'
2023-10-18 05:38:14,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35233'
2023-10-18 05:38:14,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40011'
2023-10-18 05:38:14,031 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43607'
2023-10-18 05:38:14,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42565'
2023-10-18 05:38:15,124 - distributed.scheduler - INFO - Receive client connection: Client-86d1ddac-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:15,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33998
2023-10-18 05:38:15,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,839 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,839 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,877 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,887 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,888 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:15,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:15,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:15,931 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:18,218 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44225
2023-10-18 05:38:18,219 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44225
2023-10-18 05:38:18,219 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36059
2023-10-18 05:38:18,219 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,219 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,219 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,220 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,220 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9mj362g8
2023-10-18 05:38:18,220 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0633079-eeef-43f9-acc2-b44504ad0fbf
2023-10-18 05:38:18,361 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee331c16-86c7-4578-9992-6d4d1a845d7d
2023-10-18 05:38:18,361 - distributed.worker - INFO - Starting Worker plugin PreImport-ac4361ed-cbc1-4c77-ae25-123c415d5c92
2023-10-18 05:38:18,361 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,385 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44225', status: init, memory: 0, processing: 0>
2023-10-18 05:38:18,386 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44225
2023-10-18 05:38:18,386 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34020
2023-10-18 05:38:18,387 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:18,387 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,387 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,389 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:18,432 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37913
2023-10-18 05:38:18,433 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37913
2023-10-18 05:38:18,433 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37005
2023-10-18 05:38:18,433 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,433 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,433 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,434 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,434 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dvysewi2
2023-10-18 05:38:18,434 - distributed.worker - INFO - Starting Worker plugin PreImport-564bd81b-502b-4707-b64a-de2a6c048a92
2023-10-18 05:38:18,434 - distributed.worker - INFO - Starting Worker plugin RMMSetup-15068907-bb00-4e80-a78e-4157da983260
2023-10-18 05:38:18,751 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39219
2023-10-18 05:38:18,752 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39219
2023-10-18 05:38:18,752 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41675
2023-10-18 05:38:18,752 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,752 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,753 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sjebnp6i
2023-10-18 05:38:18,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45639
2023-10-18 05:38:18,753 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45639
2023-10-18 05:38:18,753 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34287
2023-10-18 05:38:18,753 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,753 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3bce61fd-fdc2-4aaf-890b-3b1124a24347
2023-10-18 05:38:18,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ikchim47
2023-10-18 05:38:18,754 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5e52408-0c48-4306-8820-9e176cc0fe71
2023-10-18 05:38:18,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44721
2023-10-18 05:38:18,762 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44721
2023-10-18 05:38:18,762 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43137
2023-10-18 05:38:18,762 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,762 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,762 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,762 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,762 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uududdua
2023-10-18 05:38:18,763 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff3b461b-bb34-4a8e-bb8e-44a235d06510
2023-10-18 05:38:18,770 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40935
2023-10-18 05:38:18,771 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40935
2023-10-18 05:38:18,771 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34077
2023-10-18 05:38:18,771 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,771 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,771 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,771 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,771 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xsqx0shc
2023-10-18 05:38:18,772 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2402a52f-e6d2-46c3-a128-3619556c4111
2023-10-18 05:38:18,772 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cdd93826-7642-4c84-80e7-4112a734cc0a
2023-10-18 05:38:18,778 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37753
2023-10-18 05:38:18,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37753
2023-10-18 05:38:18,779 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36379
2023-10-18 05:38:18,779 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,779 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,780 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,780 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,780 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f2sxofmo
2023-10-18 05:38:18,780 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd2c117f-d0a6-4c26-ba65-e49f2a98994c
2023-10-18 05:38:18,780 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36065
2023-10-18 05:38:18,781 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36065
2023-10-18 05:38:18,781 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37857
2023-10-18 05:38:18,781 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,781 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,781 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:18,782 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:18,782 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6t7p40hs
2023-10-18 05:38:18,782 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4e91bd7f-6ab4-4726-a972-74f622f4f270
2023-10-18 05:38:18,826 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a311af2-700d-435e-a25d-ee281148e5a7
2023-10-18 05:38:18,828 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,868 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37913', status: init, memory: 0, processing: 0>
2023-10-18 05:38:18,869 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37913
2023-10-18 05:38:18,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34024
2023-10-18 05:38:18,871 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:18,872 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:18,872 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:18,990 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-abbeff61-e66f-40d2-80bb-f82b6ae72630
2023-10-18 05:38:18,991 - distributed.worker - INFO - Starting Worker plugin PreImport-1d2aab7a-0a1f-4d85-b141-d47bfdff008a
2023-10-18 05:38:18,992 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,995 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-280acfa3-62d7-4fba-979b-89d99d91d460
2023-10-18 05:38:18,995 - distributed.worker - INFO - Starting Worker plugin PreImport-3cf3df3a-fb2f-471e-8d57-863a6e284ab5
2023-10-18 05:38:18,995 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:18,998 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-415067a1-bb12-4617-9d0d-d64b458996ea
2023-10-18 05:38:18,999 - distributed.worker - INFO - Starting Worker plugin PreImport-10a11d03-ee3e-4757-a8fc-df6224d6e369
2023-10-18 05:38:18,999 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,004 - distributed.worker - INFO - Starting Worker plugin PreImport-7d9a4a0b-eb17-4d66-b2d6-c87fdd80c457
2023-10-18 05:38:19,005 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,007 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71e48586-5e06-42d1-8e9f-c26644650814
2023-10-18 05:38:19,007 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a809d70f-6c77-4112-ae84-c1dd5f246d25
2023-10-18 05:38:19,007 - distributed.worker - INFO - Starting Worker plugin PreImport-8f36f9c6-c040-44fc-b8e9-295b83c049a5
2023-10-18 05:38:19,007 - distributed.worker - INFO - Starting Worker plugin PreImport-b14a21ca-9519-4158-9a12-a075a251e9c7
2023-10-18 05:38:19,007 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,008 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,020 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45639', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,020 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45639
2023-10-18 05:38:19,020 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34044
2023-10-18 05:38:19,021 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,023 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,023 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,023 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44721', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,024 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44721
2023-10-18 05:38:19,024 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34058
2023-10-18 05:38:19,024 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,025 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,026 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,026 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,027 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,028 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39219', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,029 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39219
2023-10-18 05:38:19,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34036
2023-10-18 05:38:19,030 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,031 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37753', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,032 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,032 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,034 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,035 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37753
2023-10-18 05:38:19,035 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,035 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34070
2023-10-18 05:38:19,036 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,036 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,038 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,039 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40935', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,040 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40935
2023-10-18 05:38:19,040 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34066
2023-10-18 05:38:19,042 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,043 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36065', status: init, memory: 0, processing: 0>
2023-10-18 05:38:19,043 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,043 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,043 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36065
2023-10-18 05:38:19,044 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34086
2023-10-18 05:38:19,045 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:19,046 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,046 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:19,046 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:19,048 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:19,157 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,157 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,157 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,158 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,158 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,158 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,158 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,158 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:19,171 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,171 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,171 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,171 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,171 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,172 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,172 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,172 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:19,182 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:19,184 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:19,187 - distributed.scheduler - INFO - Remove client Client-86d1ddac-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:19,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33998; closing.
2023-10-18 05:38:19,188 - distributed.scheduler - INFO - Remove client Client-86d1ddac-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:19,188 - distributed.scheduler - INFO - Close client connection: Client-86d1ddac-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:19,189 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38043'. Reason: nanny-close
2023-10-18 05:38:19,190 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,191 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44861'. Reason: nanny-close
2023-10-18 05:38:19,191 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,191 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37913. Reason: nanny-close
2023-10-18 05:38:19,191 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38429'. Reason: nanny-close
2023-10-18 05:38:19,192 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,192 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39219. Reason: nanny-close
2023-10-18 05:38:19,192 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36067'. Reason: nanny-close
2023-10-18 05:38:19,192 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,192 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44225. Reason: nanny-close
2023-10-18 05:38:19,193 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35233'. Reason: nanny-close
2023-10-18 05:38:19,193 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37753. Reason: nanny-close
2023-10-18 05:38:19,193 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,193 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40011'. Reason: nanny-close
2023-10-18 05:38:19,194 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,194 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,194 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34024; closing.
2023-10-18 05:38:19,194 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43607'. Reason: nanny-close
2023-10-18 05:38:19,194 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40935. Reason: nanny-close
2023-10-18 05:38:19,194 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,194 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,194 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37913', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.1946857')
2023-10-18 05:38:19,194 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,195 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42565'. Reason: nanny-close
2023-10-18 05:38:19,195 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36065. Reason: nanny-close
2023-10-18 05:38:19,195 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:19,195 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,195 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44721. Reason: nanny-close
2023-10-18 05:38:19,195 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45639. Reason: nanny-close
2023-10-18 05:38:19,196 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,196 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,196 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,197 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,197 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,197 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34070; closing.
2023-10-18 05:38:19,197 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,197 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34020; closing.
2023-10-18 05:38:19,198 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34036; closing.
2023-10-18 05:38:19,198 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,198 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,198 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:19,199 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,199 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37753', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.1993763')
2023-10-18 05:38:19,199 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44225', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.1998484')
2023-10-18 05:38:19,200 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39219', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.2003632')
2023-10-18 05:38:19,201 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,201 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:19,201 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34066; closing.
2023-10-18 05:38:19,202 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34058; closing.
2023-10-18 05:38:19,202 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34086; closing.
2023-10-18 05:38:19,203 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40935', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.2031722')
2023-10-18 05:38:19,203 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44721', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.2038')
2023-10-18 05:38:19,204 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36065', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.204424')
2023-10-18 05:38:19,204 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34044; closing.
2023-10-18 05:38:19,205 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45639', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607499.2055538')
2023-10-18 05:38:19,205 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:19,205 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34044>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:21,358 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:21,358 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:21,360 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:21,362 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:21,363 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-18 05:38:23,637 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:23,642 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44835 instead
  warnings.warn(
2023-10-18 05:38:23,646 - distributed.scheduler - INFO - State start
2023-10-18 05:38:23,801 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:23,802 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:23,802 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44835/status
2023-10-18 05:38:23,803 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:23,952 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38255'
2023-10-18 05:38:23,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40827'
2023-10-18 05:38:23,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43757'
2023-10-18 05:38:23,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42089'
2023-10-18 05:38:23,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39679'
2023-10-18 05:38:23,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43139'
2023-10-18 05:38:24,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38257'
2023-10-18 05:38:24,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45455'
2023-10-18 05:38:25,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,815 - distributed.scheduler - INFO - Receive client connection: Client-8cb8bf00-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:25,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,825 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,829 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51268
2023-10-18 05:38:25,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,852 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,852 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:25,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:25,861 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:25,864 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:28,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42551
2023-10-18 05:38:28,752 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42551
2023-10-18 05:38:28,752 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45167
2023-10-18 05:38:28,752 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,753 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u63yfez9
2023-10-18 05:38:28,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-679bb08d-dfe4-4f8b-b01f-37a8ed51dc74
2023-10-18 05:38:28,760 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33119
2023-10-18 05:38:28,761 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33119
2023-10-18 05:38:28,761 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41209
2023-10-18 05:38:28,761 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,761 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,761 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,761 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,761 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0y7vsc74
2023-10-18 05:38:28,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fa84de2c-8ded-43a0-8626-9eb789a15661
2023-10-18 05:38:28,764 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35431
2023-10-18 05:38:28,765 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35431
2023-10-18 05:38:28,765 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37637
2023-10-18 05:38:28,765 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,765 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,765 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,766 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,766 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zgj2dz8g
2023-10-18 05:38:28,766 - distributed.worker - INFO - Starting Worker plugin RMMSetup-549f03c7-8cfb-47a2-9149-d7b65eebe8c2
2023-10-18 05:38:28,823 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35765
2023-10-18 05:38:28,824 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35765
2023-10-18 05:38:28,825 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33707
2023-10-18 05:38:28,825 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,825 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,825 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,825 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,825 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1855_yeu
2023-10-18 05:38:28,826 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-34ad91d3-3b98-4260-b410-3e35333d3f13
2023-10-18 05:38:28,826 - distributed.worker - INFO - Starting Worker plugin RMMSetup-75e49cb9-f68e-49bc-97f0-54fc170b81bb
2023-10-18 05:38:28,833 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45113
2023-10-18 05:38:28,834 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45113
2023-10-18 05:38:28,834 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33805
2023-10-18 05:38:28,834 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,834 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,834 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,834 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,834 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vx0cs4p0
2023-10-18 05:38:28,835 - distributed.worker - INFO - Starting Worker plugin RMMSetup-03d24271-4c85-4b92-beba-edaccbaa0826
2023-10-18 05:38:28,835 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34951
2023-10-18 05:38:28,836 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34951
2023-10-18 05:38:28,836 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41837
2023-10-18 05:38:28,836 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,836 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,837 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,837 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,837 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4xrylj8e
2023-10-18 05:38:28,838 - distributed.worker - INFO - Starting Worker plugin RMMSetup-086d1822-213c-4975-aef7-582257a87af2
2023-10-18 05:38:28,843 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33775
2023-10-18 05:38:28,844 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33775
2023-10-18 05:38:28,844 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39025
2023-10-18 05:38:28,845 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,845 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,845 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,845 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,845 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6b9qflzi
2023-10-18 05:38:28,845 - distributed.worker - INFO - Starting Worker plugin RMMSetup-98c904a5-e4a6-4535-b566-020ca81d4984
2023-10-18 05:38:28,845 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34975
2023-10-18 05:38:28,846 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34975
2023-10-18 05:38:28,846 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37275
2023-10-18 05:38:28,846 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:28,847 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:28,847 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:28,847 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:28,847 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b7knlufw
2023-10-18 05:38:28,847 - distributed.worker - INFO - Starting Worker plugin PreImport-ac5d6c2a-69bb-4113-83b9-c4a7f5d0a851
2023-10-18 05:38:28,847 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ebd02483-02d5-40d5-bd3a-049e1c885af4
2023-10-18 05:38:28,972 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-31efa3fd-5433-42c3-86d6-4dbf753a7ff5
2023-10-18 05:38:28,972 - distributed.worker - INFO - Starting Worker plugin PreImport-da8ce28c-f02f-426a-b778-275b043e1e8c
2023-10-18 05:38:28,973 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,003 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42551', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,004 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42551
2023-10-18 05:38:29,005 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51296
2023-10-18 05:38:29,005 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,007 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,007 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,008 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,017 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-10efe112-191a-4df7-8c49-c46e19343db7
2023-10-18 05:38:29,017 - distributed.worker - INFO - Starting Worker plugin PreImport-aaa47ccc-6853-4120-ad11-294a76831c74
2023-10-18 05:38:29,018 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11e13f9e-97f0-4f65-a5f5-449a7157dcce
2023-10-18 05:38:29,034 - distributed.worker - INFO - Starting Worker plugin PreImport-8fb4ac05-5543-4cbd-b2fe-ce73e4a69830
2023-10-18 05:38:29,034 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,048 - distributed.worker - INFO - Starting Worker plugin PreImport-158c96a0-7a9f-4973-9d89-67f1ab3717e6
2023-10-18 05:38:29,048 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35431', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35431
2023-10-18 05:38:29,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51310
2023-10-18 05:38:29,054 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,056 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,056 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,060 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33119', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,061 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33119
2023-10-18 05:38:29,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51316
2023-10-18 05:38:29,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,063 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,063 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,064 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77c0b41c-5e2e-40f8-aa02-9be5c8af1226
2023-10-18 05:38:29,064 - distributed.worker - INFO - Starting Worker plugin PreImport-b8ee8cb5-83bd-4b8b-af33-3ec76650a454
2023-10-18 05:38:29,064 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,064 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,077 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-934728c1-6c70-44e7-a165-9445a6851229
2023-10-18 05:38:29,077 - distributed.worker - INFO - Starting Worker plugin PreImport-969418e4-6a8c-470e-b767-95ca876c5d2b
2023-10-18 05:38:29,078 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,080 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d0f00c1b-4046-4968-b340-7cd7a731aaed
2023-10-18 05:38:29,080 - distributed.worker - INFO - Starting Worker plugin PreImport-fc24135a-62d0-4b0b-a73a-42cc6d64b71b
2023-10-18 05:38:29,081 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,081 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35765', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,081 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38a026c3-c05e-40af-8788-795513cce816
2023-10-18 05:38:29,082 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35765
2023-10-18 05:38:29,082 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51332
2023-10-18 05:38:29,082 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,083 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,084 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,084 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,093 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34951', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,094 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34951
2023-10-18 05:38:29,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51348
2023-10-18 05:38:29,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,097 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,097 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,106 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33775', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,107 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33775
2023-10-18 05:38:29,107 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51358
2023-10-18 05:38:29,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,109 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,109 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,111 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,113 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45113', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,113 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45113
2023-10-18 05:38:29,113 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51354
2023-10-18 05:38:29,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,115 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,115 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,116 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34975', status: init, memory: 0, processing: 0>
2023-10-18 05:38:29,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34975
2023-10-18 05:38:29,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51372
2023-10-18 05:38:29,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:29,119 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:29,119 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:29,121 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:29,129 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,130 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,142 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,143 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,143 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,143 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:38:29,149 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,150 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:29,153 - distributed.scheduler - INFO - Remove client Client-8cb8bf00-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:29,153 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51268; closing.
2023-10-18 05:38:29,153 - distributed.scheduler - INFO - Remove client Client-8cb8bf00-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:29,153 - distributed.scheduler - INFO - Close client connection: Client-8cb8bf00-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:29,154 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38255'. Reason: nanny-close
2023-10-18 05:38:29,155 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,156 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40827'. Reason: nanny-close
2023-10-18 05:38:29,156 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,156 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34975. Reason: nanny-close
2023-10-18 05:38:29,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43757'. Reason: nanny-close
2023-10-18 05:38:29,157 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,157 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45113. Reason: nanny-close
2023-10-18 05:38:29,157 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42089'. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42551. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39679'. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33775. Reason: nanny-close
2023-10-18 05:38:29,158 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,158 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43139'. Reason: nanny-close
2023-10-18 05:38:29,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,159 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51372; closing.
2023-10-18 05:38:29,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35765. Reason: nanny-close
2023-10-18 05:38:29,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38257'. Reason: nanny-close
2023-10-18 05:38:29,159 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1597023')
2023-10-18 05:38:29,159 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,159 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35431. Reason: nanny-close
2023-10-18 05:38:29,160 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,160 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45455'. Reason: nanny-close
2023-10-18 05:38:29,160 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:29,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33119. Reason: nanny-close
2023-10-18 05:38:29,160 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,161 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51296; closing.
2023-10-18 05:38:29,161 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34951. Reason: nanny-close
2023-10-18 05:38:29,161 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,161 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,161 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,162 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1627584')
2023-10-18 05:38:29,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,163 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51354; closing.
2023-10-18 05:38:29,163 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,163 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,163 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:29,164 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,164 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,165 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:29,164 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51296>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51296>: Stream is closed
2023-10-18 05:38:29,167 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45113', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1671486')
2023-10-18 05:38:29,167 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51358; closing.
2023-10-18 05:38:29,168 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51332; closing.
2023-10-18 05:38:29,168 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33775', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1688046')
2023-10-18 05:38:29,169 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35765', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.169303')
2023-10-18 05:38:29,169 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51310; closing.
2023-10-18 05:38:29,169 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51316; closing.
2023-10-18 05:38:29,170 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35431', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1705694')
2023-10-18 05:38:29,171 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33119', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1710196')
2023-10-18 05:38:29,171 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51348; closing.
2023-10-18 05:38:29,172 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607509.1720994')
2023-10-18 05:38:29,172 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:29,172 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51348>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:30,622 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:30,622 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:30,623 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:30,624 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:30,625 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-18 05:38:32,705 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:32,709 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43175 instead
  warnings.warn(
2023-10-18 05:38:32,713 - distributed.scheduler - INFO - State start
2023-10-18 05:38:32,735 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:32,736 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:32,736 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43175/status
2023-10-18 05:38:32,737 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:32,756 - distributed.scheduler - INFO - Receive client connection: Client-921b46c2-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:32,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36728
2023-10-18 05:38:32,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36837'
2023-10-18 05:38:32,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39865'
2023-10-18 05:38:32,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41925'
2023-10-18 05:38:32,914 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33129'
2023-10-18 05:38:32,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42603'
2023-10-18 05:38:32,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37217'
2023-10-18 05:38:32,933 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46381'
2023-10-18 05:38:32,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38917'
2023-10-18 05:38:34,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,783 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,785 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,807 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,808 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,831 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,869 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:34,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:34,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:34,875 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:37,597 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37101
2023-10-18 05:38:37,597 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37101
2023-10-18 05:38:37,597 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38783
2023-10-18 05:38:37,597 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,598 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,598 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,598 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,598 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o5eeum1q
2023-10-18 05:38:37,598 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2d491893-45df-41a7-b0b7-71e590d35030
2023-10-18 05:38:37,618 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43825
2023-10-18 05:38:37,619 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43825
2023-10-18 05:38:37,619 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39641
2023-10-18 05:38:37,619 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,619 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,619 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,619 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b10edjg1
2023-10-18 05:38:37,620 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d0b32a12-2b3f-4388-9c17-19bec1784439
2023-10-18 05:38:37,620 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01b2a658-4e69-4155-bf10-71617266fb91
2023-10-18 05:38:37,626 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42029
2023-10-18 05:38:37,627 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42029
2023-10-18 05:38:37,627 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33121
2023-10-18 05:38:37,627 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,628 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-siq4ehw4
2023-10-18 05:38:37,628 - distributed.worker - INFO - Starting Worker plugin PreImport-2f9c5a30-4761-4870-8008-5d0dffe19ba8
2023-10-18 05:38:37,628 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ad8b5de-6dc2-4225-a2f2-4cc35a81d3a6
2023-10-18 05:38:37,723 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34099
2023-10-18 05:38:37,725 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34099
2023-10-18 05:38:37,725 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34209
2023-10-18 05:38:37,725 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,725 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,725 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,725 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,725 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-81l898l9
2023-10-18 05:38:37,726 - distributed.worker - INFO - Starting Worker plugin RMMSetup-629d14c8-9e3f-415c-a2c2-1b196bce55b0
2023-10-18 05:38:37,727 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40847
2023-10-18 05:38:37,728 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40847
2023-10-18 05:38:37,728 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35031
2023-10-18 05:38:37,727 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40535
2023-10-18 05:38:37,728 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,728 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40535
2023-10-18 05:38:37,728 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,728 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42345
2023-10-18 05:38:37,728 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,728 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,728 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,728 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,728 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mtwjwakj
2023-10-18 05:38:37,728 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,728 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,729 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j0uoxten
2023-10-18 05:38:37,729 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ee0fa64-6f49-4c3e-886f-5f16aeea21e5
2023-10-18 05:38:37,729 - distributed.worker - INFO - Starting Worker plugin RMMSetup-73c59f7b-e321-4c5b-a947-282cebe008f1
2023-10-18 05:38:37,729 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39977
2023-10-18 05:38:37,730 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39977
2023-10-18 05:38:37,730 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40155
2023-10-18 05:38:37,730 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,730 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,730 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,730 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,730 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q8mg6ayx
2023-10-18 05:38:37,731 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef19fb7b-9b95-4116-8782-8015ad06ba93
2023-10-18 05:38:37,731 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41339
2023-10-18 05:38:37,732 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41339
2023-10-18 05:38:37,732 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42905
2023-10-18 05:38:37,732 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,732 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,733 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:37,733 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:38:37,733 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d39dplv6
2023-10-18 05:38:37,733 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e8418d83-26a3-46e7-9f0d-b4d00044f68e
2023-10-18 05:38:37,844 - distributed.worker - INFO - Starting Worker plugin PreImport-00d1e683-a4d6-4c6a-938d-1050d47f0c75
2023-10-18 05:38:37,844 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,853 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4f5e16d0-7247-46e3-9093-3cc82fcc7dcc
2023-10-18 05:38:37,853 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c93e62ec-3e19-4f2b-9825-3fb7932009e5
2023-10-18 05:38:37,853 - distributed.worker - INFO - Starting Worker plugin PreImport-b990c88d-5f5a-4798-bad0-6d9a533b182c
2023-10-18 05:38:37,854 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,860 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,885 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b6b89d3-cc9b-4195-a20a-74e0ec752e78
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin PreImport-78125ce4-549e-470f-acf2-91797d457729
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42ec5b17-6d32-4f1f-9dfe-6b5b990383ba
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-20c09654-74be-4fc5-8f37-64eede726022
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin PreImport-c258479e-eecd-46c5-99cb-75612a6a816b
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin PreImport-befa29d6-371e-484e-b6cd-887a1a823661
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dd068ca4-753d-4f1e-95e4-cbdfb59272c4
2023-10-18 05:38:37,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c53ec7cd-c405-4398-884c-4418110664c1
2023-10-18 05:38:37,886 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,886 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,886 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,887 - distributed.worker - INFO - Starting Worker plugin PreImport-8e2d873b-db35-4a18-a394-c7fb69a0ce5a
2023-10-18 05:38:37,887 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,887 - distributed.worker - INFO - Starting Worker plugin PreImport-27dcb6d1-8239-4b60-aa5a-14a4db5c9437
2023-10-18 05:38:37,888 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,888 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43825', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,890 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43825
2023-10-18 05:38:37,890 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36790
2023-10-18 05:38:37,890 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37101', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,891 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37101
2023-10-18 05:38:37,891 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36798
2023-10-18 05:38:37,891 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,893 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,893 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,893 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,893 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,895 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,895 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,896 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42029', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,897 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42029
2023-10-18 05:38:37,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36810
2023-10-18 05:38:37,898 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,900 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,900 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,919 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39977', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,920 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39977
2023-10-18 05:38:37,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36822
2023-10-18 05:38:37,921 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40847', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,921 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40847
2023-10-18 05:38:37,921 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36820
2023-10-18 05:38:37,922 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,922 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,922 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41339', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,922 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41339
2023-10-18 05:38:37,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36844
2023-10-18 05:38:37,923 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40535', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,924 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,924 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,924 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40535
2023-10-18 05:38:37,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36854
2023-10-18 05:38:37,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,925 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34099', status: init, memory: 0, processing: 0>
2023-10-18 05:38:37,925 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,926 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,926 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,926 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34099
2023-10-18 05:38:37,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36840
2023-10-18 05:38:37,927 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,927 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,927 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:37,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,928 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:37,928 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:37,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:37,930 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:38,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:38:38,027 - distributed.scheduler - INFO - Remove client Client-921b46c2-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:38,028 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36728; closing.
2023-10-18 05:38:38,028 - distributed.scheduler - INFO - Remove client Client-921b46c2-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:38,028 - distributed.scheduler - INFO - Close client connection: Client-921b46c2-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:38,029 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36837'. Reason: nanny-close
2023-10-18 05:38:38,030 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39865'. Reason: nanny-close
2023-10-18 05:38:38,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,031 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42029. Reason: nanny-close
2023-10-18 05:38:38,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41925'. Reason: nanny-close
2023-10-18 05:38:38,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41339. Reason: nanny-close
2023-10-18 05:38:38,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33129'. Reason: nanny-close
2023-10-18 05:38:38,032 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37101. Reason: nanny-close
2023-10-18 05:38:38,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42603'. Reason: nanny-close
2023-10-18 05:38:38,033 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34099. Reason: nanny-close
2023-10-18 05:38:38,033 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37217'. Reason: nanny-close
2023-10-18 05:38:38,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,033 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36810; closing.
2023-10-18 05:38:38,033 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,034 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43825. Reason: nanny-close
2023-10-18 05:38:38,034 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42029', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0339978')
2023-10-18 05:38:38,034 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,034 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46381'. Reason: nanny-close
2023-10-18 05:38:38,034 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,034 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,034 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40535. Reason: nanny-close
2023-10-18 05:38:38,034 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36798; closing.
2023-10-18 05:38:38,034 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38917'. Reason: nanny-close
2023-10-18 05:38:38,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,035 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:38,035 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37101', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0351472')
2023-10-18 05:38:38,035 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40847. Reason: nanny-close
2023-10-18 05:38:38,035 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,035 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39977. Reason: nanny-close
2023-10-18 05:38:38,036 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,036 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,036 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36844; closing.
2023-10-18 05:38:38,036 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,036 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,037 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,037 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,038 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:38,036 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36798>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:38,038 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,038 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41339', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0388448')
2023-10-18 05:38:38,039 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36840; closing.
2023-10-18 05:38:38,039 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,039 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,039 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:38,040 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34099', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0401235')
2023-10-18 05:38:38,040 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36790; closing.
2023-10-18 05:38:38,040 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36854; closing.
2023-10-18 05:38:38,041 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43825', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0414464')
2023-10-18 05:38:38,041 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40535', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0418177')
2023-10-18 05:38:38,042 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36820; closing.
2023-10-18 05:38:38,042 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36822; closing.
2023-10-18 05:38:38,043 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.043031')
2023-10-18 05:38:38,043 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39977', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607518.0434477')
2023-10-18 05:38:38,043 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:38,043 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36822>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:38,044 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36820>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-18 05:38:39,547 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:39,547 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:39,548 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:39,549 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:39,550 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-18 05:38:41,485 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:41,489 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40635 instead
  warnings.warn(
2023-10-18 05:38:41,493 - distributed.scheduler - INFO - State start
2023-10-18 05:38:41,513 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:41,514 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:41,514 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40635/status
2023-10-18 05:38:41,515 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:41,773 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36409'
2023-10-18 05:38:43,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:43,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:43,620 - distributed.scheduler - INFO - Receive client connection: Client-976c2325-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:43,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43708
2023-10-18 05:38:44,017 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:44,893 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43601
2023-10-18 05:38:44,894 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43601
2023-10-18 05:38:44,894 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-18 05:38:44,894 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:44,894 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:44,894 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:44,894 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-18 05:38:44,894 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0wiv6l9_
2023-10-18 05:38:44,894 - distributed.worker - INFO - Starting Worker plugin RMMSetup-189ffd8e-37fc-4889-9ddb-974664840158
2023-10-18 05:38:44,895 - distributed.worker - INFO - Starting Worker plugin PreImport-c39fd2fd-b94d-4a95-9f91-f57955042da6
2023-10-18 05:38:44,895 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-faff0322-b7b2-47f8-82aa-1f92ec16b762
2023-10-18 05:38:44,901 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:44,944 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43601', status: init, memory: 0, processing: 0>
2023-10-18 05:38:44,946 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43601
2023-10-18 05:38:44,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43724
2023-10-18 05:38:44,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:44,948 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:44,949 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:44,950 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:44,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:44,967 - distributed.scheduler - INFO - Remove client Client-976c2325-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:44,967 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43708; closing.
2023-10-18 05:38:44,968 - distributed.scheduler - INFO - Remove client Client-976c2325-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:44,968 - distributed.scheduler - INFO - Close client connection: Client-976c2325-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:44,969 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36409'. Reason: nanny-close
2023-10-18 05:38:44,969 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:44,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43601. Reason: nanny-close
2023-10-18 05:38:44,973 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43724; closing.
2023-10-18 05:38:44,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:44,974 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43601', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607524.9741266')
2023-10-18 05:38:44,974 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:44,975 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:46,135 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:46,136 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:46,136 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:46,137 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:46,138 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-18 05:38:50,214 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:50,222 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-18 05:38:50,227 - distributed.scheduler - INFO - State start
2023-10-18 05:38:50,303 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:50,304 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:50,306 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-18 05:38:50,306 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:38:50,375 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40179'
2023-10-18 05:38:50,718 - distributed.scheduler - INFO - Receive client connection: Client-9c8b6c10-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:50,734 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40428
2023-10-18 05:38:52,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:38:52,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:38:52,502 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:38:53,271 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34573
2023-10-18 05:38:53,272 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34573
2023-10-18 05:38:53,272 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43369
2023-10-18 05:38:53,272 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:38:53,272 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:53,272 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:38:53,272 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-18 05:38:53,272 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4wrx0f5p
2023-10-18 05:38:53,272 - distributed.worker - INFO - Starting Worker plugin RMMSetup-edc33b96-6825-4332-9d0d-c5b85580617d
2023-10-18 05:38:53,273 - distributed.worker - INFO - Starting Worker plugin PreImport-91ad6634-d495-4c6c-97bb-5fbf2a98573b
2023-10-18 05:38:53,274 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-75b40608-669b-41a3-8258-35e7fc2edac7
2023-10-18 05:38:53,275 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:53,305 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34573', status: init, memory: 0, processing: 0>
2023-10-18 05:38:53,307 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34573
2023-10-18 05:38:53,307 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40454
2023-10-18 05:38:53,307 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:38:53,308 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:38:53,308 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:38:53,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:38:53,385 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:38:53,388 - distributed.scheduler - INFO - Remove client Client-9c8b6c10-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:53,388 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40428; closing.
2023-10-18 05:38:53,388 - distributed.scheduler - INFO - Remove client Client-9c8b6c10-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:53,388 - distributed.scheduler - INFO - Close client connection: Client-9c8b6c10-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:38:53,389 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40179'. Reason: nanny-close
2023-10-18 05:38:53,390 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:38:53,391 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34573. Reason: nanny-close
2023-10-18 05:38:53,393 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40454; closing.
2023-10-18 05:38:53,393 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:38:53,393 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34573', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607533.393309')
2023-10-18 05:38:53,393 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:38:53,394 - distributed.nanny - INFO - Worker closed
2023-10-18 05:38:54,505 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:38:54,506 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:38:54,507 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:38:54,508 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:38:54,508 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-18 05:38:56,628 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:56,632 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33425 instead
  warnings.warn(
2023-10-18 05:38:56,637 - distributed.scheduler - INFO - State start
2023-10-18 05:38:56,659 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:38:56,660 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:38:56,661 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33425/status
2023-10-18 05:38:56,661 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:39:00,305 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:40462'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:40462>: Stream is closed
2023-10-18 05:39:00,539 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:39:00,539 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:39:00,539 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:39:00,540 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:39:00,540 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-18 05:39:02,581 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:02,585 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42695 instead
  warnings.warn(
2023-10-18 05:39:02,589 - distributed.scheduler - INFO - State start
2023-10-18 05:39:02,701 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:02,702 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-18 05:39:02,703 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42695/status
2023-10-18 05:39:02,703 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:39:02,789 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41411'
2023-10-18 05:39:04,176 - distributed.scheduler - INFO - Receive client connection: Client-a3f10b95-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:04,186 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43224
2023-10-18 05:39:04,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:04,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:04,467 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:05,216 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40689
2023-10-18 05:39:05,216 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40689
2023-10-18 05:39:05,217 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35361
2023-10-18 05:39:05,217 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-18 05:39:05,217 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:05,217 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:05,217 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-18 05:39:05,217 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-e70mlguk
2023-10-18 05:39:05,218 - distributed.worker - INFO - Starting Worker plugin PreImport-8eb91068-a4f5-4ba4-a864-f901e4a686cb
2023-10-18 05:39:05,218 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a696206c-af73-4667-ae14-0f3946f6c4ed
2023-10-18 05:39:05,218 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99ee1268-9096-42e1-912f-5b965f2939e2
2023-10-18 05:39:05,218 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:05,242 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40689', status: init, memory: 0, processing: 0>
2023-10-18 05:39:05,243 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40689
2023-10-18 05:39:05,243 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43238
2023-10-18 05:39:05,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:05,244 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-18 05:39:05,245 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:05,246 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-18 05:39:05,309 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:05,311 - distributed.scheduler - INFO - Remove client Client-a3f10b95-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:05,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43224; closing.
2023-10-18 05:39:05,312 - distributed.scheduler - INFO - Remove client Client-a3f10b95-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:05,313 - distributed.scheduler - INFO - Close client connection: Client-a3f10b95-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:05,313 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41411'. Reason: nanny-close
2023-10-18 05:39:05,314 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:05,315 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40689. Reason: nanny-close
2023-10-18 05:39:05,316 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-18 05:39:05,316 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43238; closing.
2023-10-18 05:39:05,317 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607545.3170795')
2023-10-18 05:39:05,317 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:39:05,318 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:06,280 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:39:06,280 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:39:06,280 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:39:06,281 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-18 05:39:06,282 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-18 05:39:08,335 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:08,340 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43885 instead
  warnings.warn(
2023-10-18 05:39:08,344 - distributed.scheduler - INFO - State start
2023-10-18 05:39:08,366 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:08,367 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:39:08,368 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43885/status
2023-10-18 05:39:08,368 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:39:08,476 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36653'
2023-10-18 05:39:08,491 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38925'
2023-10-18 05:39:08,504 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41363'
2023-10-18 05:39:08,515 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35625'
2023-10-18 05:39:08,517 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37685'
2023-10-18 05:39:08,528 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37319'
2023-10-18 05:39:08,537 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42421'
2023-10-18 05:39:08,549 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36427'
2023-10-18 05:39:10,291 - distributed.scheduler - INFO - Receive client connection: Client-a75f6a98-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:10,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54294
2023-10-18 05:39:10,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,358 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,377 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,398 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,420 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,433 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,433 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:10,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:10,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:10,447 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:13,219 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39833
2023-10-18 05:39:13,219 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39833
2023-10-18 05:39:13,220 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41709
2023-10-18 05:39:13,220 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,220 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,220 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,220 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,220 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pm3c59nt
2023-10-18 05:39:13,220 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb827383-d306-4591-a5f3-5b405c8a71cc
2023-10-18 05:39:13,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38873
2023-10-18 05:39:13,228 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38873
2023-10-18 05:39:13,228 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46689
2023-10-18 05:39:13,228 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,228 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,228 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,229 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,229 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bmomfek0
2023-10-18 05:39:13,229 - distributed.worker - INFO - Starting Worker plugin PreImport-a6620c7c-d426-4eb9-87ac-9c374d3deae7
2023-10-18 05:39:13,229 - distributed.worker - INFO - Starting Worker plugin RMMSetup-618b6039-3371-4293-9806-fd7dd8897ecb
2023-10-18 05:39:13,245 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33859
2023-10-18 05:39:13,246 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33859
2023-10-18 05:39:13,246 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33521
2023-10-18 05:39:13,246 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,246 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,246 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,246 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,246 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rwtms4xv
2023-10-18 05:39:13,247 - distributed.worker - INFO - Starting Worker plugin RMMSetup-43898bb0-d3e2-4e56-a6bd-61b0c97c0326
2023-10-18 05:39:13,327 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42831
2023-10-18 05:39:13,328 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42831
2023-10-18 05:39:13,328 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37849
2023-10-18 05:39:13,328 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,328 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,328 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,328 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,328 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0y53722i
2023-10-18 05:39:13,329 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1eeefc5f-5d4c-43c0-bfb1-c4fb4622917f
2023-10-18 05:39:13,331 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43189
2023-10-18 05:39:13,332 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43189
2023-10-18 05:39:13,332 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41069
2023-10-18 05:39:13,332 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,332 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,332 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,332 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,332 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kgy1vuqe
2023-10-18 05:39:13,333 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d91d142e-b24b-4107-b311-062d2301a3cf
2023-10-18 05:39:13,331 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33851
2023-10-18 05:39:13,333 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33851
2023-10-18 05:39:13,333 - distributed.worker - INFO - Starting Worker plugin RMMSetup-73b2981e-b9f8-4007-a9fa-31863ad851d8
2023-10-18 05:39:13,334 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43477
2023-10-18 05:39:13,334 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,334 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,334 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,334 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,334 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-x_6f_kvv
2023-10-18 05:39:13,335 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5f2f4b3-c6cc-49ab-9140-12462331d851
2023-10-18 05:39:13,336 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45745
2023-10-18 05:39:13,337 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45745
2023-10-18 05:39:13,337 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44857
2023-10-18 05:39:13,337 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,338 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,338 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,338 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,338 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6zyu6gce
2023-10-18 05:39:13,338 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8ebc67d6-fa68-4c38-8d1e-7bcdaf6476be
2023-10-18 05:39:13,338 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36983
2023-10-18 05:39:13,339 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36983
2023-10-18 05:39:13,339 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46839
2023-10-18 05:39:13,339 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,339 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,339 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:13,339 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-18 05:39:13,340 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ej8lqcov
2023-10-18 05:39:13,340 - distributed.worker - INFO - Starting Worker plugin RMMSetup-94f3649a-e06f-43b7-8b18-261a0ab9c62d
2023-10-18 05:39:13,454 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef25193c-fe0d-464e-b9d3-8b2792468215
2023-10-18 05:39:13,456 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,457 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-499d746d-c021-4260-a5de-d86a8feb425a
2023-10-18 05:39:13,458 - distributed.worker - INFO - Starting Worker plugin PreImport-33d24188-9e4c-4589-9a97-5d72b3125aa9
2023-10-18 05:39:13,458 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,458 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-650cd9ce-6bf8-4c5e-a605-29975de9f2a6
2023-10-18 05:39:13,459 - distributed.worker - INFO - Starting Worker plugin PreImport-5624ff1b-974d-425b-8fc1-8ec819d43129
2023-10-18 05:39:13,459 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0f7b825-ba38-49da-b18f-79a926c29b18
2023-10-18 05:39:13,465 - distributed.worker - INFO - Starting Worker plugin PreImport-7f2ec213-74dd-4ebb-bce8-41fd526c9a5e
2023-10-18 05:39:13,465 - distributed.worker - INFO - Starting Worker plugin PreImport-c9785d97-c269-49a6-ba9f-bec513204795
2023-10-18 05:39:13,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,474 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8173f59e-fca6-4633-ac37-bd302937260e
2023-10-18 05:39:13,474 - distributed.worker - INFO - Starting Worker plugin PreImport-0bf24311-e200-4bff-a028-1f40a029eb9b
2023-10-18 05:39:13,474 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,481 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba2d8e92-c843-4a26-9d61-bc9d33716de3
2023-10-18 05:39:13,482 - distributed.worker - INFO - Starting Worker plugin PreImport-831d1815-da56-4028-8cb2-7ae4f736b44b
2023-10-18 05:39:13,482 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,486 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dbd8dd22-7ee3-4a3a-86da-da9bcc730222
2023-10-18 05:39:13,487 - distributed.worker - INFO - Starting Worker plugin PreImport-dba4539c-6688-40ae-bf2c-6ab348eef6ab
2023-10-18 05:39:13,487 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,488 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33859', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,489 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33859
2023-10-18 05:39:13,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54338
2023-10-18 05:39:13,491 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,491 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39833', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,491 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39833
2023-10-18 05:39:13,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54344
2023-10-18 05:39:13,492 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,492 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,492 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38873', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,493 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38873
2023-10-18 05:39:13,493 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54322
2023-10-18 05:39:13,494 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42831', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,494 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,494 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42831
2023-10-18 05:39:13,495 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54354
2023-10-18 05:39:13,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,496 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,496 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,496 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,497 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,498 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,498 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,500 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43189', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,501 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43189
2023-10-18 05:39:13,501 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54358
2023-10-18 05:39:13,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,504 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,504 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,506 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45745', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,506 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45745
2023-10-18 05:39:13,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54386
2023-10-18 05:39:13,507 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33851', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,508 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33851
2023-10-18 05:39:13,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54374
2023-10-18 05:39:13,509 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,509 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,509 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,510 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,510 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,510 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,511 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36983', status: init, memory: 0, processing: 0>
2023-10-18 05:39:13,512 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36983
2023-10-18 05:39:13,512 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54394
2023-10-18 05:39:13,512 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:13,514 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:13,514 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:13,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,585 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,586 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,586 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:13,590 - distributed.scheduler - INFO - Remove client Client-a75f6a98-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:13,590 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54294; closing.
2023-10-18 05:39:13,591 - distributed.scheduler - INFO - Remove client Client-a75f6a98-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:13,591 - distributed.scheduler - INFO - Close client connection: Client-a75f6a98-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:13,592 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36653'. Reason: nanny-close
2023-10-18 05:39:13,592 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,593 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38925'. Reason: nanny-close
2023-10-18 05:39:13,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,594 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38873. Reason: nanny-close
2023-10-18 05:39:13,594 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41363'. Reason: nanny-close
2023-10-18 05:39:13,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,595 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33851. Reason: nanny-close
2023-10-18 05:39:13,595 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35625'. Reason: nanny-close
2023-10-18 05:39:13,595 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,595 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33859. Reason: nanny-close
2023-10-18 05:39:13,595 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37685'. Reason: nanny-close
2023-10-18 05:39:13,596 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,596 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36983. Reason: nanny-close
2023-10-18 05:39:13,596 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37319'. Reason: nanny-close
2023-10-18 05:39:13,596 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,596 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,596 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54322; closing.
2023-10-18 05:39:13,596 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43189. Reason: nanny-close
2023-10-18 05:39:13,597 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38873', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.5971973')
2023-10-18 05:39:13,597 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42421'. Reason: nanny-close
2023-10-18 05:39:13,597 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,597 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,597 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,597 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36427'. Reason: nanny-close
2023-10-18 05:39:13,597 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39833. Reason: nanny-close
2023-10-18 05:39:13,598 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:13,598 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,598 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42831. Reason: nanny-close
2023-10-18 05:39:13,598 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45745. Reason: nanny-close
2023-10-18 05:39:13,598 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,598 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54394; closing.
2023-10-18 05:39:13,599 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54374; closing.
2023-10-18 05:39:13,599 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,599 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,599 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54338; closing.
2023-10-18 05:39:13,599 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,599 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,599 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36983', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.5998924')
2023-10-18 05:39:13,600 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33851', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6002522')
2023-10-18 05:39:13,600 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,600 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33859', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6005929')
2023-10-18 05:39:13,600 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,600 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:13,601 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,601 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54358; closing.
2023-10-18 05:39:13,602 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43189', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6020684')
2023-10-18 05:39:13,602 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,602 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,602 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:13,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54344; closing.
2023-10-18 05:39:13,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54354; closing.
2023-10-18 05:39:13,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54386; closing.
2023-10-18 05:39:13,603 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6030557')
2023-10-18 05:39:13,603 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42831', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6034117')
2023-10-18 05:39:13,603 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45745', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607553.6037831')
2023-10-18 05:39:13,603 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:39:15,159 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:39:15,160 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:39:15,160 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:39:15,161 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:39:15,162 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-18 05:39:17,130 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:17,134 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39621 instead
  warnings.warn(
2023-10-18 05:39:17,138 - distributed.scheduler - INFO - State start
2023-10-18 05:39:17,161 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:17,162 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:39:17,163 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39621/status
2023-10-18 05:39:17,163 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:39:17,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34023'
2023-10-18 05:39:17,553 - distributed.scheduler - INFO - Receive client connection: Client-ac9cb833-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:17,564 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54480
2023-10-18 05:39:18,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:18,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:18,949 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:19,786 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39729
2023-10-18 05:39:19,786 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39729
2023-10-18 05:39:19,786 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45591
2023-10-18 05:39:19,786 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:19,787 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:19,787 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:19,787 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-18 05:39:19,787 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2hqjyd1g
2023-10-18 05:39:19,787 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3452519-3a84-452d-b577-34752aa3c276
2023-10-18 05:39:19,788 - distributed.worker - INFO - Starting Worker plugin PreImport-4c79bb5a-f70c-4421-ada9-4a5696c3f5f0
2023-10-18 05:39:19,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6c7f905a-b454-460a-80e4-8fc6ec400e47
2023-10-18 05:39:19,894 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:19,922 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39729', status: init, memory: 0, processing: 0>
2023-10-18 05:39:19,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39729
2023-10-18 05:39:19,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54498
2023-10-18 05:39:19,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:19,925 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:19,925 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:19,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:19,943 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:39:19,947 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:19,949 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:19,951 - distributed.scheduler - INFO - Remove client Client-ac9cb833-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:19,951 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54480; closing.
2023-10-18 05:39:19,952 - distributed.scheduler - INFO - Remove client Client-ac9cb833-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:19,952 - distributed.scheduler - INFO - Close client connection: Client-ac9cb833-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:19,953 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34023'. Reason: nanny-close
2023-10-18 05:39:19,956 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:19,957 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39729. Reason: nanny-close
2023-10-18 05:39:19,959 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54498; closing.
2023-10-18 05:39:19,959 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:19,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39729', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607559.9594908')
2023-10-18 05:39:19,959 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:39:19,960 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:20,969 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:39:20,969 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:39:20,970 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:39:20,971 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:39:20,971 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-18 05:39:22,943 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:22,947 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34227 instead
  warnings.warn(
2023-10-18 05:39:22,951 - distributed.scheduler - INFO - State start
2023-10-18 05:39:23,108 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-18 05:39:23,109 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-18 05:39:23,110 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34227/status
2023-10-18 05:39:23,110 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-18 05:39:23,191 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33721'
2023-10-18 05:39:23,615 - distributed.scheduler - INFO - Receive client connection: Client-b01bc021-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:23,630 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53290
2023-10-18 05:39:24,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-18 05:39:24,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-18 05:39:24,947 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-18 05:39:25,826 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44173
2023-10-18 05:39:25,826 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44173
2023-10-18 05:39:25,827 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39835
2023-10-18 05:39:25,827 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-18 05:39:25,827 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:25,827 - distributed.worker - INFO -               Threads:                          1
2023-10-18 05:39:25,827 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-18 05:39:25,827 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3yi2erzp
2023-10-18 05:39:25,827 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a55f1789-f39d-4c25-a927-4bab6170c759
2023-10-18 05:39:25,828 - distributed.worker - INFO - Starting Worker plugin PreImport-e2232870-f9eb-42f4-b24c-9fff12f0ad00
2023-10-18 05:39:25,828 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a100a520-6afd-4e21-b9eb-e1b407bc28fb
2023-10-18 05:39:25,927 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:25,953 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44173', status: init, memory: 0, processing: 0>
2023-10-18 05:39:25,955 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44173
2023-10-18 05:39:25,955 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53308
2023-10-18 05:39:25,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-18 05:39:25,957 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-18 05:39:25,957 - distributed.worker - INFO - -------------------------------------------------
2023-10-18 05:39:25,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-18 05:39:25,988 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-18 05:39:25,993 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-18 05:39:25,996 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:25,998 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-18 05:39:26,000 - distributed.scheduler - INFO - Remove client Client-b01bc021-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:26,001 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53290; closing.
2023-10-18 05:39:26,001 - distributed.scheduler - INFO - Remove client Client-b01bc021-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:26,002 - distributed.scheduler - INFO - Close client connection: Client-b01bc021-6d78-11ee-b192-d8c49764f6bb
2023-10-18 05:39:26,002 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33721'. Reason: nanny-close
2023-10-18 05:39:26,003 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-18 05:39:26,004 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44173. Reason: nanny-close
2023-10-18 05:39:26,006 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-18 05:39:26,006 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53308; closing.
2023-10-18 05:39:26,006 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44173', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697607566.0066543')
2023-10-18 05:39:26,007 - distributed.scheduler - INFO - Lost all workers
2023-10-18 05:39:26,008 - distributed.nanny - INFO - Worker closed
2023-10-18 05:39:27,069 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-18 05:39:27,069 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-18 05:39:27,070 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-18 05:39:27,071 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-18 05:39:27,071 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39135 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35179 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44859 instead
  warnings.warn(
2023-10-18 05:40:24,723 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-18 05:40:24,725 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:53475', name: 6, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40925 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45725 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35655 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41071 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39067 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40427 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46515 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44591 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43615 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46219 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33581 instead
  warnings.warn(
[1697607857.877083] [dgx13:70570:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:39742) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36369 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39793 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42739 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35003 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46069 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34047 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38709 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44867 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35479 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43495 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39621 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33675 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39069 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36843 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37145 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46867 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45159 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44065 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36091 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43509 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35957 instead
  warnings.warn(
2023-10-18 05:50:43,943 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,946 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,947 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,953 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:40471'.
2023-10-18 05:50:43,953 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:59096 remote=tcp://127.0.0.1:46145>: Stream is closed
2023-10-18 05:50:43,955 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:45845'.
2023-10-18 05:50:43,955 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:45845'. Shutting down.
2023-10-18 05:50:43,956 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:42515'.
2023-10-18 05:50:43,956 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f3f12c32400>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,956 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:59110 remote=tcp://127.0.0.1:46145>: Stream is closed
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,958 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8746e6a400>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,959 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f5b0b5ae400>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,967 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:43,976 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:41681'.
2023-10-18 05:50:43,977 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:41681'. Shutting down.
2023-10-18 05:50:43,979 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fe148ed9400>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-18 05:50:45,958 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-18 05:50:45,960 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-18 05:50:45,962 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-18 05:50:45,982 - distributed.nanny - ERROR - Worker process died unexpectedly
