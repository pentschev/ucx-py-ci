============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-11 05:38:36,683 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:36,687 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33597 instead
  warnings.warn(
2023-10-11 05:38:36,690 - distributed.scheduler - INFO - State start
2023-10-11 05:38:36,711 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:36,712 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-11 05:38:36,713 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33597/status
2023-10-11 05:38:36,713 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:38:36,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43973'
2023-10-11 05:38:36,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45549'
2023-10-11 05:38:36,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45767'
2023-10-11 05:38:36,927 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43673'
2023-10-11 05:38:37,247 - distributed.scheduler - INFO - Receive client connection: Client-6b9183e4-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:37,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53314
2023-10-11 05:38:38,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:38,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:38,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:38,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:38,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:38,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:38,659 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:38,659 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:38,660 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:38,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:38,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:38,674 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-11 05:38:38,678 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32789
2023-10-11 05:38:38,678 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32789
2023-10-11 05:38:38,678 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41481
2023-10-11 05:38:38,678 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-11 05:38:38,678 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:38,678 - distributed.worker - INFO -               Threads:                          4
2023-10-11 05:38:38,678 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-11 05:38:38,678 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-g501akwf
2023-10-11 05:38:38,679 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0a581a1-4756-4374-a348-079f5e2c1e94
2023-10-11 05:38:38,679 - distributed.worker - INFO - Starting Worker plugin PreImport-e1e1dbad-d262-4c17-b954-83dd655249e6
2023-10-11 05:38:38,679 - distributed.worker - INFO - Starting Worker plugin RMMSetup-97577bc4-a578-4fc8-984a-0068fc0d6fa9
2023-10-11 05:38:38,679 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:39,154 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32789', status: init, memory: 0, processing: 0>
2023-10-11 05:38:39,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32789
2023-10-11 05:38:39,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53318
2023-10-11 05:38:39,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:39,157 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-11 05:38:39,157 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:39,158 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-11 05:38:40,105 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40951
2023-10-11 05:38:40,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40951
2023-10-11 05:38:40,105 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38689
2023-10-11 05:38:40,105 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38459
2023-10-11 05:38:40,105 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38459
2023-10-11 05:38:40,105 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,105 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39831
2023-10-11 05:38:40,106 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,106 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,106 - distributed.worker - INFO -               Threads:                          4
2023-10-11 05:38:40,106 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-11 05:38:40,106 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ta08gpa9
2023-10-11 05:38:40,106 - distributed.worker - INFO -               Threads:                          4
2023-10-11 05:38:40,106 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-11 05:38:40,106 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-p6xxdkfr
2023-10-11 05:38:40,106 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d09e227f-d3df-48b5-ae9a-e9d586d2c635
2023-10-11 05:38:40,106 - distributed.worker - INFO - Starting Worker plugin PreImport-dc9d978c-5220-4f50-87f5-1cfab5fc7ee2
2023-10-11 05:38:40,106 - distributed.worker - INFO - Starting Worker plugin PreImport-2f9b99e3-1379-46de-86a5-6f572bbce66b
2023-10-11 05:38:40,107 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c9005b08-0edc-495c-912d-1465dc79874e
2023-10-11 05:38:40,107 - distributed.worker - INFO - Starting Worker plugin RMMSetup-905db604-2844-4258-9d0f-804e1d08a61e
2023-10-11 05:38:40,107 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,106 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32813
2023-10-11 05:38:40,107 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d98fca1b-f230-4b6d-b9af-59946dc0b326
2023-10-11 05:38:40,107 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32813
2023-10-11 05:38:40,107 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41073
2023-10-11 05:38:40,107 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,107 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,107 - distributed.worker - INFO -               Threads:                          4
2023-10-11 05:38:40,107 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-11 05:38:40,107 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-d9ou0mld
2023-10-11 05:38:40,107 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,108 - distributed.worker - INFO - Starting Worker plugin PreImport-82cab951-c726-4c39-8f30-569496bb9e17
2023-10-11 05:38:40,108 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a3441e6-f299-4450-95bf-01286e3b3afe
2023-10-11 05:38:40,108 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9fa95188-e823-44a7-bda9-588ab8c81374
2023-10-11 05:38:40,109 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,284 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38459', status: init, memory: 0, processing: 0>
2023-10-11 05:38:40,284 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38459
2023-10-11 05:38:40,284 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43098
2023-10-11 05:38:40,285 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40951', status: init, memory: 0, processing: 0>
2023-10-11 05:38:40,286 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40951
2023-10-11 05:38:40,286 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43084
2023-10-11 05:38:40,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:40,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:40,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,289 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32813', status: init, memory: 0, processing: 0>
2023-10-11 05:38:40,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-11 05:38:40,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-11 05:38:40,289 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32813
2023-10-11 05:38:40,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43100
2023-10-11 05:38:40,291 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:40,293 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-11 05:38:40,293 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:40,296 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-11 05:38:40,391 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-11 05:38:40,391 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-11 05:38:40,392 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-11 05:38:41,203 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-11 05:38:41,208 - distributed.scheduler - INFO - Remove client Client-6b9183e4-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:41,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53314; closing.
2023-10-11 05:38:41,209 - distributed.scheduler - INFO - Remove client Client-6b9183e4-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:41,209 - distributed.scheduler - INFO - Close client connection: Client-6b9183e4-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:41,210 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43973'. Reason: nanny-close
2023-10-11 05:38:41,211 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:41,212 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45549'. Reason: nanny-close
2023-10-11 05:38:41,212 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:41,212 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32813. Reason: nanny-close
2023-10-11 05:38:41,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45767'. Reason: nanny-close
2023-10-11 05:38:41,213 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:41,213 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40951. Reason: nanny-close
2023-10-11 05:38:41,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43673'. Reason: nanny-close
2023-10-11 05:38:41,213 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:41,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32789. Reason: nanny-close
2023-10-11 05:38:41,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38459. Reason: nanny-close
2023-10-11 05:38:41,215 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-11 05:38:41,215 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-11 05:38:41,216 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-11 05:38:41,216 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43084; closing.
2023-10-11 05:38:41,216 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:41,217 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002721.2173526')
2023-10-11 05:38:41,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-11 05:38:41,217 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43100; closing.
2023-10-11 05:38:41,217 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:41,218 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:41,218 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32813', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002721.218616')
2023-10-11 05:38:41,219 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53318; closing.
2023-10-11 05:38:41,219 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43098; closing.
2023-10-11 05:38:41,219 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:41,219 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32789', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002721.2197437')
2023-10-11 05:38:41,220 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38459', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002721.2200572')
2023-10-11 05:38:41,220 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:38:41,220 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:43100>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-11 05:38:41,221 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:43098>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:43098>: Stream is closed
2023-10-11 05:38:42,427 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:38:42,427 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:38:42,428 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:38:42,429 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-11 05:38:42,429 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-11 05:38:44,612 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:44,617 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35125 instead
  warnings.warn(
2023-10-11 05:38:44,620 - distributed.scheduler - INFO - State start
2023-10-11 05:38:44,640 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:44,641 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:38:44,642 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35125/status
2023-10-11 05:38:44,642 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:38:44,690 - distributed.scheduler - INFO - Receive client connection: Client-7053b230-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:44,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51490
2023-10-11 05:38:44,824 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37173'
2023-10-11 05:38:44,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43405'
2023-10-11 05:38:44,848 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44307'
2023-10-11 05:38:44,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36457'
2023-10-11 05:38:44,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42245'
2023-10-11 05:38:44,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34915'
2023-10-11 05:38:44,884 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35393'
2023-10-11 05:38:44,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44407'
2023-10-11 05:38:46,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,635 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,675 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,676 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,714 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,716 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,729 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:46,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:46,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:46,739 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:49,104 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40475
2023-10-11 05:38:49,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40475
2023-10-11 05:38:49,106 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37493
2023-10-11 05:38:49,106 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,106 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,106 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,106 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,106 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-or0cu_hu
2023-10-11 05:38:49,107 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0024935a-2a19-4b67-bc38-e42925a57d6d
2023-10-11 05:38:49,217 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5affb691-dd49-49a6-9deb-dacf13fa6d2c
2023-10-11 05:38:49,218 - distributed.worker - INFO - Starting Worker plugin PreImport-2a1dc731-d88a-42a8-b0ab-b8770bbc8f01
2023-10-11 05:38:49,218 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,256 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40475', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,257 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40475
2023-10-11 05:38:49,257 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51582
2023-10-11 05:38:49,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,260 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,260 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,262 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,389 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38549
2023-10-11 05:38:49,390 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38549
2023-10-11 05:38:49,390 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36267
2023-10-11 05:38:49,390 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,390 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,390 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,390 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,390 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w8d_nwpv
2023-10-11 05:38:49,391 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65fe42ec-ab39-43df-bc67-612e3dfd871c
2023-10-11 05:38:49,406 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43963
2023-10-11 05:38:49,407 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43963
2023-10-11 05:38:49,407 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38509
2023-10-11 05:38:49,407 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,407 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,407 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,407 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,407 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o6_14ng_
2023-10-11 05:38:49,408 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ebb82cd-5081-42ae-87b3-d45da47bb589
2023-10-11 05:38:49,410 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42305
2023-10-11 05:38:49,411 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42305
2023-10-11 05:38:49,411 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45245
2023-10-11 05:38:49,411 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,411 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,411 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,411 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,411 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-41qcnsh8
2023-10-11 05:38:49,412 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb5e273b-b5c1-441d-914f-d09b3799fe41
2023-10-11 05:38:49,450 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36493
2023-10-11 05:38:49,451 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36493
2023-10-11 05:38:49,452 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38513
2023-10-11 05:38:49,452 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,452 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,452 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,452 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,452 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9fu0dp0c
2023-10-11 05:38:49,453 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad8a28d8-259f-436f-9957-5dcdbf7c84ab
2023-10-11 05:38:49,463 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36597
2023-10-11 05:38:49,464 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36597
2023-10-11 05:38:49,464 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38267
2023-10-11 05:38:49,464 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,464 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,464 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,465 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,465 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dnm4m3gd
2023-10-11 05:38:49,465 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13fda237-6e69-4efe-b961-52bbadf0c829
2023-10-11 05:38:49,466 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40097
2023-10-11 05:38:49,467 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40097
2023-10-11 05:38:49,467 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41765
2023-10-11 05:38:49,467 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,467 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,467 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,467 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,467 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lme_3kso
2023-10-11 05:38:49,468 - distributed.worker - INFO - Starting Worker plugin RMMSetup-315eaac2-46ca-4deb-9f52-17ec2337afe6
2023-10-11 05:38:49,467 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40505
2023-10-11 05:38:49,468 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40505
2023-10-11 05:38:49,468 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36149
2023-10-11 05:38:49,468 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,468 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,468 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:49,468 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:49,468 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jovtc87_
2023-10-11 05:38:49,469 - distributed.worker - INFO - Starting Worker plugin PreImport-72fbe3e8-cf8f-4ecd-b556-1b10a53e68f7
2023-10-11 05:38:49,469 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ca4cb074-6eff-4a5d-bc6a-226bccc1768e
2023-10-11 05:38:49,469 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd63cd94-3bd4-45d6-a1bd-caf22ce7c0c9
2023-10-11 05:38:49,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-20d403d3-58a2-41c6-b5cf-f149174ac1af
2023-10-11 05:38:49,579 - distributed.worker - INFO - Starting Worker plugin PreImport-49309f47-3dfa-4827-8b33-5c8b52958982
2023-10-11 05:38:49,579 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,581 - distributed.worker - INFO - Starting Worker plugin PreImport-c85350a7-6256-4b15-9ea0-802add4cf991
2023-10-11 05:38:49,582 - distributed.worker - INFO - Starting Worker plugin PreImport-8279a5aa-c727-45ff-9606-e2fab5fdde3c
2023-10-11 05:38:49,582 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d287f58e-b3ad-4121-b888-3a26c4cddff0
2023-10-11 05:38:49,582 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-124c54e3-9c0d-4e6b-b1fb-3c3e08beb9da
2023-10-11 05:38:49,583 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,584 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,601 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5dc706e8-6bef-4381-b195-a03e7c81b245
2023-10-11 05:38:49,601 - distributed.worker - INFO - Starting Worker plugin PreImport-022c1c5b-bd85-4123-8dc4-ab859989083a
2023-10-11 05:38:49,601 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9b2b8a8b-e77e-4dba-a6ac-b054cebf94cf
2023-10-11 05:38:49,601 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,601 - distributed.worker - INFO - Starting Worker plugin PreImport-c130f593-7450-440f-9305-fcbce5386599
2023-10-11 05:38:49,602 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,606 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,606 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b04b36d-70ab-4848-9db9-8c412b86e3b4
2023-10-11 05:38:49,607 - distributed.worker - INFO - Starting Worker plugin PreImport-d2ab4fdc-3a36-4530-9c30-72b3fb4d0722
2023-10-11 05:38:49,607 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,609 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38549', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,610 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38549
2023-10-11 05:38:49,610 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51598
2023-10-11 05:38:49,611 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42305', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,611 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,612 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42305
2023-10-11 05:38:49,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51608
2023-10-11 05:38:49,612 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,612 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,613 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43963', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,613 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43963
2023-10-11 05:38:49,613 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51618
2023-10-11 05:38:49,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,614 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,614 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,616 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,616 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,618 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,624 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40097', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,625 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40097
2023-10-11 05:38:49,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51622
2023-10-11 05:38:49,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,628 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40505', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,629 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40505
2023-10-11 05:38:49,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51644
2023-10-11 05:38:49,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,631 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36597', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,631 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,631 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,631 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36597
2023-10-11 05:38:49,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51656
2023-10-11 05:38:49,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,633 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,633 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,634 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36493', status: init, memory: 0, processing: 0>
2023-10-11 05:38:49,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,634 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36493
2023-10-11 05:38:49,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51634
2023-10-11 05:38:49,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:49,637 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:49,637 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:49,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,657 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,658 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:49,662 - distributed.scheduler - INFO - Remove client Client-7053b230-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:49,662 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51490; closing.
2023-10-11 05:38:49,662 - distributed.scheduler - INFO - Remove client Client-7053b230-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:49,663 - distributed.scheduler - INFO - Close client connection: Client-7053b230-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:49,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37173'. Reason: nanny-close
2023-10-11 05:38:49,664 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,665 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43405'. Reason: nanny-close
2023-10-11 05:38:49,665 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,665 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42305. Reason: nanny-close
2023-10-11 05:38:49,666 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44307'. Reason: nanny-close
2023-10-11 05:38:49,666 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,666 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43963. Reason: nanny-close
2023-10-11 05:38:49,666 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36457'. Reason: nanny-close
2023-10-11 05:38:49,666 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,667 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40475. Reason: nanny-close
2023-10-11 05:38:49,667 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42245'. Reason: nanny-close
2023-10-11 05:38:49,667 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,667 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40505. Reason: nanny-close
2023-10-11 05:38:49,667 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34915'. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35393'. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,668 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38549. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51608; closing.
2023-10-11 05:38:49,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44407'. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42305', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6685925')
2023-10-11 05:38:49,668 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,668 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,668 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36597. Reason: nanny-close
2023-10-11 05:38:49,669 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,669 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,669 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40097. Reason: nanny-close
2023-10-11 05:38:49,670 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51644; closing.
2023-10-11 05:38:49,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51618; closing.
2023-10-11 05:38:49,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51582; closing.
2023-10-11 05:38:49,670 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,670 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,670 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,670 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,671 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,671 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40505', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6712887')
2023-10-11 05:38:49,671 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,671 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43963', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6716714')
2023-10-11 05:38:49,672 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40475', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6720264')
2023-10-11 05:38:49,672 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,672 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,672 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51598; closing.
2023-10-11 05:38:49,673 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:49,673 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38549', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.673397')
2023-10-11 05:38:49,673 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51656; closing.
2023-10-11 05:38:49,673 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51622; closing.
2023-10-11 05:38:49,674 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36597', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6742322')
2023-10-11 05:38:49,674 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40097', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.6747174')
2023-10-11 05:38:49,689 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:49,690 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36493. Reason: nanny-close
2023-10-11 05:38:49,692 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51634; closing.
2023-10-11 05:38:49,692 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:49,692 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36493', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002729.692886')
2023-10-11 05:38:49,693 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:38:49,694 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:51,181 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:38:51,182 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:38:51,182 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:38:51,183 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:38:51,184 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-11 05:38:53,324 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:53,328 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33133 instead
  warnings.warn(
2023-10-11 05:38:53,332 - distributed.scheduler - INFO - State start
2023-10-11 05:38:53,353 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:38:53,353 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:38:53,354 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33133/status
2023-10-11 05:38:53,354 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:38:53,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42057'
2023-10-11 05:38:53,869 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45935'
2023-10-11 05:38:53,878 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38245'
2023-10-11 05:38:53,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42897'
2023-10-11 05:38:53,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34305'
2023-10-11 05:38:53,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42005'
2023-10-11 05:38:53,911 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41975'
2023-10-11 05:38:53,919 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39427'
2023-10-11 05:38:55,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,636 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:38:55,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:38:55,758 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,758 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:38:55,811 - distributed.scheduler - INFO - Receive client connection: Client-7584e228-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:55,822 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57214
2023-10-11 05:38:57,585 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34721
2023-10-11 05:38:57,586 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34721
2023-10-11 05:38:57,586 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46259
2023-10-11 05:38:57,586 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:57,586 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:57,586 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:57,586 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:57,587 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_02j69rs
2023-10-11 05:38:57,587 - distributed.worker - INFO - Starting Worker plugin PreImport-e0cf5115-d3bd-4855-84d6-ad3d72e48193
2023-10-11 05:38:57,587 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6dc50287-774c-447e-add8-924d11aa9d1d
2023-10-11 05:38:57,587 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c26eddf7-8eed-4388-9bfe-91913dccae99
2023-10-11 05:38:57,708 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:57,737 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34721', status: init, memory: 0, processing: 0>
2023-10-11 05:38:57,738 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34721
2023-10-11 05:38:57,738 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57226
2023-10-11 05:38:57,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:57,741 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:57,741 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:57,743 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,594 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41083
2023-10-11 05:38:58,595 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41083
2023-10-11 05:38:58,595 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40109
2023-10-11 05:38:58,595 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,595 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,593 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45209
2023-10-11 05:38:58,596 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,596 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45209
2023-10-11 05:38:58,596 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,596 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-loos1cd6
2023-10-11 05:38:58,596 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39805
2023-10-11 05:38:58,596 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,596 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,596 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,596 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a879e3a2-9c79-454d-85cf-debb27230f93
2023-10-11 05:38:58,596 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,596 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6ifmf0vf
2023-10-11 05:38:58,597 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cf29b4d-acda-429c-8617-4fd1de8ca699
2023-10-11 05:38:58,627 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83e68f56-40d1-4ff0-aa76-9a0a2f2cdc8e
2023-10-11 05:38:58,627 - distributed.worker - INFO - Starting Worker plugin PreImport-97ceaa94-30a9-4d95-826e-a252b97457d6
2023-10-11 05:38:58,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,656 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41083', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,657 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41083
2023-10-11 05:38:58,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57230
2023-10-11 05:38:58,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,659 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,659 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,660 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,679 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d842efa1-e3b4-480f-ba5c-3a5abb7cbdde
2023-10-11 05:38:58,680 - distributed.worker - INFO - Starting Worker plugin PreImport-47c406ab-e1cb-4327-8490-2416e0425afe
2023-10-11 05:38:58,680 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,713 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41391
2023-10-11 05:38:58,713 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41391
2023-10-11 05:38:58,714 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39245
2023-10-11 05:38:58,714 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,714 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,714 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,714 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,714 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45209', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,714 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yvi71h7_
2023-10-11 05:38:58,715 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45209
2023-10-11 05:38:58,715 - distributed.worker - INFO - Starting Worker plugin PreImport-f0197b78-0f6d-489c-a128-cf1caeff00c6
2023-10-11 05:38:58,715 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57234
2023-10-11 05:38:58,715 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e91d9015-3cdc-49cd-adfc-7f79d5f15913
2023-10-11 05:38:58,715 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79da21ff-0e38-418b-8f23-2fdf12bacde7
2023-10-11 05:38:58,714 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37167
2023-10-11 05:38:58,715 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37167
2023-10-11 05:38:58,715 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36055
2023-10-11 05:38:58,715 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,716 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,716 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,716 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,716 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,716 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0oiw8k2g
2023-10-11 05:38:58,716 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed528b5c-918f-4e9b-8d7b-6d2471d28eee
2023-10-11 05:38:58,716 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,716 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,716 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46563
2023-10-11 05:38:58,717 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46563
2023-10-11 05:38:58,717 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41627
2023-10-11 05:38:58,717 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,717 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,717 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,718 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,718 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bfb0d_2t
2023-10-11 05:38:58,718 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4012f3e3-98da-4242-8e22-f46774e87d42
2023-10-11 05:38:58,718 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,723 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42515
2023-10-11 05:38:58,724 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42515
2023-10-11 05:38:58,724 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39491
2023-10-11 05:38:58,724 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,724 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,724 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,724 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,724 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1jkv2y5p
2023-10-11 05:38:58,725 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aeefee03-a2ec-4d48-96d0-beacb44fd060
2023-10-11 05:38:58,728 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33037
2023-10-11 05:38:58,730 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33037
2023-10-11 05:38:58,730 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33945
2023-10-11 05:38:58,730 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,730 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,730 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:38:58,731 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:38:58,731 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1v25pgi7
2023-10-11 05:38:58,732 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f333965a-b612-4108-8ca8-f211289c675a
2023-10-11 05:38:58,751 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-56b867a4-18e9-4653-87af-9f91bb9e3161
2023-10-11 05:38:58,751 - distributed.worker - INFO - Starting Worker plugin PreImport-c04cc525-0608-4d56-bbed-f3de9d226802
2023-10-11 05:38:58,751 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,752 - distributed.worker - INFO - Starting Worker plugin PreImport-87f63c1e-43aa-41f6-bb21-0d13674c6b23
2023-10-11 05:38:58,752 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce072ca0-d059-4e7d-8feb-53c754218436
2023-10-11 05:38:58,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,755 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-948eacab-f572-43a1-bf9d-b367e974f24a
2023-10-11 05:38:58,755 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a8b8c501-c811-4fd8-b0c9-871eefa4ac19
2023-10-11 05:38:58,755 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,755 - distributed.worker - INFO - Starting Worker plugin PreImport-dcc1067e-ceb1-490f-b983-ff3b166fabd2
2023-10-11 05:38:58,756 - distributed.worker - INFO - Starting Worker plugin PreImport-617a033f-c16a-44a6-92cd-df1d85932956
2023-10-11 05:38:58,756 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,756 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,772 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46563', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,773 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46563
2023-10-11 05:38:58,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57250
2023-10-11 05:38:58,775 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,775 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41391', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,776 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,776 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,776 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41391
2023-10-11 05:38:58,776 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57262
2023-10-11 05:38:58,777 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,778 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,778 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,778 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,780 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,784 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33037', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,784 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33037
2023-10-11 05:38:58,785 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57270
2023-10-11 05:38:58,785 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37167', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,786 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37167
2023-10-11 05:38:58,786 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57254
2023-10-11 05:38:58,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,786 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42515', status: init, memory: 0, processing: 0>
2023-10-11 05:38:58,787 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42515
2023-10-11 05:38:58,787 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,787 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57276
2023-10-11 05:38:58,787 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,787 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,788 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,788 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:38:58,789 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,790 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:38:58,790 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:38:58,790 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,792 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,831 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,832 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,832 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:38:58,837 - distributed.scheduler - INFO - Remove client Client-7584e228-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:58,837 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57214; closing.
2023-10-11 05:38:58,837 - distributed.scheduler - INFO - Remove client Client-7584e228-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:58,838 - distributed.scheduler - INFO - Close client connection: Client-7584e228-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:38:58,839 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42057'. Reason: nanny-close
2023-10-11 05:38:58,839 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,840 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45935'. Reason: nanny-close
2023-10-11 05:38:58,841 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,841 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37167. Reason: nanny-close
2023-10-11 05:38:58,841 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38245'. Reason: nanny-close
2023-10-11 05:38:58,841 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,842 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42515. Reason: nanny-close
2023-10-11 05:38:58,842 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42897'. Reason: nanny-close
2023-10-11 05:38:58,842 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,842 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45209. Reason: nanny-close
2023-10-11 05:38:58,842 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34305'. Reason: nanny-close
2023-10-11 05:38:58,843 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,843 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46563. Reason: nanny-close
2023-10-11 05:38:58,843 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42005'. Reason: nanny-close
2023-10-11 05:38:58,843 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,843 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,843 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57254; closing.
2023-10-11 05:38:58,844 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33037. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41975'. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37167', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8442235')
2023-10-11 05:38:58,844 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,844 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,844 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34721. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39427'. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41391. Reason: nanny-close
2023-10-11 05:38:58,844 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:38:58,845 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,845 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,845 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41083. Reason: nanny-close
2023-10-11 05:38:58,845 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,846 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57250; closing.
2023-10-11 05:38:58,846 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57234; closing.
2023-10-11 05:38:58,846 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,846 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57276; closing.
2023-10-11 05:38:58,846 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,846 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,846 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,847 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,847 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.847075')
2023-10-11 05:38:58,847 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45209', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8474433')
2023-10-11 05:38:58,847 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:38:58,847 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42515', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8478408')
2023-10-11 05:38:58,848 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,848 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,848 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,848 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57270; closing.
2023-10-11 05:38:58,849 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57226; closing.
2023-10-11 05:38:58,849 - distributed.nanny - INFO - Worker closed
2023-10-11 05:38:58,849 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33037', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8497655')
2023-10-11 05:38:58,850 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34721', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8502152')
2023-10-11 05:38:58,850 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57262; closing.
2023-10-11 05:38:58,850 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57230; closing.
2023-10-11 05:38:58,851 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41391', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8513355')
2023-10-11 05:38:58,851 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41083', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002738.8517997')
2023-10-11 05:38:58,851 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:00,357 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:00,358 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:00,358 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:00,359 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:00,360 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-11 05:39:02,511 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:02,516 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33515 instead
  warnings.warn(
2023-10-11 05:39:02,520 - distributed.scheduler - INFO - State start
2023-10-11 05:39:02,542 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:02,543 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:02,544 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33515/status
2023-10-11 05:39:02,544 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:02,644 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35119'
2023-10-11 05:39:02,662 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35857'
2023-10-11 05:39:02,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40369'
2023-10-11 05:39:02,687 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34527'
2023-10-11 05:39:02,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34621'
2023-10-11 05:39:02,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40053'
2023-10-11 05:39:02,710 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33399'
2023-10-11 05:39:02,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39851'
2023-10-11 05:39:03,919 - distributed.scheduler - INFO - Receive client connection: Client-7af53dc3-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:03,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32776
2023-10-11 05:39:04,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,541 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,541 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,541 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,604 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,605 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:04,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:04,609 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:04,611 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:07,323 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45575
2023-10-11 05:39:07,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45575
2023-10-11 05:39:07,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37307
2023-10-11 05:39:07,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,325 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,325 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,325 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,325 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ccmk3yb6
2023-10-11 05:39:07,325 - distributed.worker - INFO - Starting Worker plugin PreImport-6a009cd9-122e-4bcf-999a-1243f42e3eba
2023-10-11 05:39:07,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ea5b928c-9b14-48bd-9ae8-49aea44eaf18
2023-10-11 05:39:07,326 - distributed.worker - INFO - Starting Worker plugin RMMSetup-46e5fa89-c231-42ad-b641-08290ed09c10
2023-10-11 05:39:07,465 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37419
2023-10-11 05:39:07,466 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37419
2023-10-11 05:39:07,466 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36871
2023-10-11 05:39:07,466 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,466 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,466 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,466 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,466 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k9z95j73
2023-10-11 05:39:07,467 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a3b549ec-4d44-455c-922d-251f81639c54
2023-10-11 05:39:07,476 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34983
2023-10-11 05:39:07,476 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34983
2023-10-11 05:39:07,477 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39777
2023-10-11 05:39:07,477 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,477 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,477 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,477 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,477 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sc7q5lnc
2023-10-11 05:39:07,477 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0072173e-ea34-46b6-b497-4c1e3ffb606e
2023-10-11 05:39:07,480 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33791
2023-10-11 05:39:07,481 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33791
2023-10-11 05:39:07,481 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35723
2023-10-11 05:39:07,481 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,482 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,482 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,482 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,482 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-siiacxh3
2023-10-11 05:39:07,482 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e60b687a-7b2c-4a4b-aa87-df2e5debc473
2023-10-11 05:39:07,486 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38997
2023-10-11 05:39:07,487 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38997
2023-10-11 05:39:07,487 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46745
2023-10-11 05:39:07,487 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,487 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,488 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,488 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,488 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z0pmnj74
2023-10-11 05:39:07,488 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0a2593bb-e1df-44d7-b0d8-56a0a93752df
2023-10-11 05:39:07,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33595
2023-10-11 05:39:07,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33143
2023-10-11 05:39:07,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33595
2023-10-11 05:39:07,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33143
2023-10-11 05:39:07,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41505
2023-10-11 05:39:07,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37045
2023-10-11 05:39:07,503 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,503 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,503 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,503 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gjjwgzj6
2023-10-11 05:39:07,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3xmyu6oo
2023-10-11 05:39:07,503 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35625
2023-10-11 05:39:07,504 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35625
2023-10-11 05:39:07,504 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38043
2023-10-11 05:39:07,504 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,504 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-981ea985-12d0-4917-a573-42fd9dd51f0a
2023-10-11 05:39:07,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0d59b75-27b2-4336-847c-d3895dd53e82
2023-10-11 05:39:07,504 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:07,504 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:07,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ulsrl1bc
2023-10-11 05:39:07,505 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e304da23-9a9a-4c82-9175-d6013e201541
2023-10-11 05:39:07,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1575aae6-b82e-414a-80a6-944ebd7c9122
2023-10-11 05:39:07,540 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,582 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45575', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,584 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45575
2023-10-11 05:39:07,584 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32782
2023-10-11 05:39:07,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,587 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,587 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,762 - distributed.worker - INFO - Starting Worker plugin PreImport-52ccd6c1-abd7-40a9-a76c-6da97c701128
2023-10-11 05:39:07,762 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,766 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-34b756c0-faf8-4c79-9d10-74b3c4b74bb8
2023-10-11 05:39:07,766 - distributed.worker - INFO - Starting Worker plugin PreImport-fc5c4972-c7a6-48c8-93ec-4e98c0a3a7d5
2023-10-11 05:39:07,767 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,774 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7011b781-5573-4b3e-b61e-2ebce43c9f30
2023-10-11 05:39:07,774 - distributed.worker - INFO - Starting Worker plugin PreImport-7b3ec84e-ab14-4623-bc59-b7b3a506fcdd
2023-10-11 05:39:07,775 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,777 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dec9f110-7b41-4004-b6b9-506276818534
2023-10-11 05:39:07,778 - distributed.worker - INFO - Starting Worker plugin PreImport-99b71dbd-492e-47ea-b3c2-ea4e9ba24b03
2023-10-11 05:39:07,778 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2377025a-6594-4c31-8619-b5e80bd1ed64
2023-10-11 05:39:07,778 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,779 - distributed.worker - INFO - Starting Worker plugin PreImport-90f3061b-3c32-4514-bf07-42bc254983d2
2023-10-11 05:39:07,780 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,780 - distributed.worker - INFO - Starting Worker plugin PreImport-62d1c7c7-deed-47ee-a223-41fbcdcae129
2023-10-11 05:39:07,780 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6d689604-a3df-4c1f-ac30-294f71d105ab
2023-10-11 05:39:07,781 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,781 - distributed.worker - INFO - Starting Worker plugin PreImport-48bf6177-df72-452d-9d5e-d76e95bc3ed8
2023-10-11 05:39:07,781 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f7a83a82-8720-45af-adfe-5a58d9a5d5dc
2023-10-11 05:39:07,781 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,793 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35625', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,794 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35625
2023-10-11 05:39:07,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32786
2023-10-11 05:39:07,795 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37419', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37419
2023-10-11 05:39:07,796 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,796 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32796
2023-10-11 05:39:07,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,797 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,797 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,798 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,799 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,799 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,800 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,806 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34983', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,806 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34983
2023-10-11 05:39:07,806 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32812
2023-10-11 05:39:07,807 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33143', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,807 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,808 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33143
2023-10-11 05:39:07,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32814
2023-10-11 05:39:07,808 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,808 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,809 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33791', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,809 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,809 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33791
2023-10-11 05:39:07,809 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32802
2023-10-11 05:39:07,810 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33595', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,810 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,810 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,810 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33595
2023-10-11 05:39:07,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32832
2023-10-11 05:39:07,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,811 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,812 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38997', status: init, memory: 0, processing: 0>
2023-10-11 05:39:07,812 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,812 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,812 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38997
2023-10-11 05:39:07,812 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32818
2023-10-11 05:39:07,813 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,813 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,814 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:07,814 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,815 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:07,815 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:07,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:07,882 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,884 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,884 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,895 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,896 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:07,902 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:07,904 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:07,906 - distributed.scheduler - INFO - Remove client Client-7af53dc3-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:07,906 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32776; closing.
2023-10-11 05:39:07,906 - distributed.scheduler - INFO - Remove client Client-7af53dc3-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:07,907 - distributed.scheduler - INFO - Close client connection: Client-7af53dc3-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:07,908 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35119'. Reason: nanny-close
2023-10-11 05:39:07,908 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,909 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35857'. Reason: nanny-close
2023-10-11 05:39:07,909 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,909 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33143. Reason: nanny-close
2023-10-11 05:39:07,910 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40369'. Reason: nanny-close
2023-10-11 05:39:07,910 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,910 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33595. Reason: nanny-close
2023-10-11 05:39:07,910 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34527'. Reason: nanny-close
2023-10-11 05:39:07,911 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,911 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38997. Reason: nanny-close
2023-10-11 05:39:07,911 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34621'. Reason: nanny-close
2023-10-11 05:39:07,911 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,911 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32814; closing.
2023-10-11 05:39:07,911 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,912 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45575. Reason: nanny-close
2023-10-11 05:39:07,912 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33143', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.912104')
2023-10-11 05:39:07,912 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40053'. Reason: nanny-close
2023-10-11 05:39:07,912 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,912 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34983. Reason: nanny-close
2023-10-11 05:39:07,912 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,913 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33399'. Reason: nanny-close
2023-10-11 05:39:07,913 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,913 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,913 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37419. Reason: nanny-close
2023-10-11 05:39:07,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39851'. Reason: nanny-close
2023-10-11 05:39:07,914 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:07,914 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,914 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,914 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32818; closing.
2023-10-11 05:39:07,914 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35625. Reason: nanny-close
2023-10-11 05:39:07,914 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33791. Reason: nanny-close
2023-10-11 05:39:07,915 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32832; closing.
2023-10-11 05:39:07,915 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,915 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,915 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38997', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9154992')
2023-10-11 05:39:07,916 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,916 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33595', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9160318')
2023-10-11 05:39:07,916 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,917 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,917 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:07,917 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32782; closing.
2023-10-11 05:39:07,917 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32812; closing.
2023-10-11 05:39:07,917 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,918 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,918 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45575', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9183383')
2023-10-11 05:39:07,918 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,919 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34983', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9189243')
2023-10-11 05:39:07,919 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:07,919 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32796; closing.
2023-10-11 05:39:07,920 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37419', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9204733')
2023-10-11 05:39:07,921 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32802; closing.
2023-10-11 05:39:07,921 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32786; closing.
2023-10-11 05:39:07,921 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33791', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9217703')
2023-10-11 05:39:07,922 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35625', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002747.9222026')
2023-10-11 05:39:07,922 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:07,922 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:32802>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-11 05:39:07,924 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:32786>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-11 05:39:09,475 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:09,476 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:09,476 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:09,477 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:09,478 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-11 05:39:11,796 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:11,800 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45961 instead
  warnings.warn(
2023-10-11 05:39:11,804 - distributed.scheduler - INFO - State start
2023-10-11 05:39:11,825 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:11,826 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:11,826 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45961/status
2023-10-11 05:39:11,826 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:11,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39149'
2023-10-11 05:39:11,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35993'
2023-10-11 05:39:11,990 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37879'
2023-10-11 05:39:12,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40347'
2023-10-11 05:39:12,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37911'
2023-10-11 05:39:12,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44595'
2023-10-11 05:39:12,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40013'
2023-10-11 05:39:12,035 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35379'
2023-10-11 05:39:13,006 - distributed.scheduler - INFO - Receive client connection: Client-80812b98-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:13,020 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59032
2023-10-11 05:39:13,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,837 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,838 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,842 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,866 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,880 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,882 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:13,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:13,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:13,907 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:16,607 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36591
2023-10-11 05:39:16,608 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36591
2023-10-11 05:39:16,608 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45629
2023-10-11 05:39:16,608 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,608 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,608 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,608 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,608 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aswi2ezo
2023-10-11 05:39:16,609 - distributed.worker - INFO - Starting Worker plugin RMMSetup-875b18da-f1fd-4ba8-aa4b-84c1ee93ba7c
2023-10-11 05:39:16,627 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46627
2023-10-11 05:39:16,628 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46627
2023-10-11 05:39:16,628 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39759
2023-10-11 05:39:16,628 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,628 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,628 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nmbi5cys
2023-10-11 05:39:16,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6deac715-50ab-47ae-ab2f-46222f29bef0
2023-10-11 05:39:16,646 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39775
2023-10-11 05:39:16,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39775
2023-10-11 05:39:16,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32923
2023-10-11 05:39:16,647 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,647 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,647 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,647 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,647 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q2njjo22
2023-10-11 05:39:16,648 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ba412dbe-04ce-43ed-ba25-25818ff0f2e5
2023-10-11 05:39:16,660 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38051
2023-10-11 05:39:16,660 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38051
2023-10-11 05:39:16,661 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42333
2023-10-11 05:39:16,661 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,661 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,661 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,661 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,661 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g4w9j5xp
2023-10-11 05:39:16,661 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1eec4c9-3c62-48f9-839e-6e74b53773da
2023-10-11 05:39:16,687 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35439
2023-10-11 05:39:16,689 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35439
2023-10-11 05:39:16,689 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37665
2023-10-11 05:39:16,689 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,689 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,689 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,689 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,689 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xw6cm0lx
2023-10-11 05:39:16,690 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ffd2c006-f311-480f-be5e-8a9d062c7e84
2023-10-11 05:39:16,692 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39263
2023-10-11 05:39:16,693 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39263
2023-10-11 05:39:16,693 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46351
2023-10-11 05:39:16,694 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,694 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,694 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,694 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,694 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ebrqbg7a
2023-10-11 05:39:16,693 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39611
2023-10-11 05:39:16,694 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39611
2023-10-11 05:39:16,694 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43533
2023-10-11 05:39:16,694 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,694 - distributed.worker - INFO - Starting Worker plugin PreImport-363682eb-ac07-4351-82d6-0d7694a05a45
2023-10-11 05:39:16,694 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,695 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-276603c2-602b-49d4-b975-ad19cdec44df
2023-10-11 05:39:16,695 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,695 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,695 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2e9b9ba4-bcc4-4432-9041-295c00c990c6
2023-10-11 05:39:16,695 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6qk6a4kg
2023-10-11 05:39:16,694 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45457
2023-10-11 05:39:16,695 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45457
2023-10-11 05:39:16,695 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46573
2023-10-11 05:39:16,695 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,695 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,696 - distributed.worker - INFO - Starting Worker plugin RMMSetup-491b1b54-a2c3-4f96-84d6-c557ad12fc54
2023-10-11 05:39:16,696 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:16,696 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:16,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g3o7spsg
2023-10-11 05:39:16,696 - distributed.worker - INFO - Starting Worker plugin RMMSetup-17336d96-6ee1-4af0-8d81-c42aa3db2670
2023-10-11 05:39:16,791 - distributed.worker - INFO - Starting Worker plugin PreImport-7d567122-5257-4348-be5b-6f7f6402fedb
2023-10-11 05:39:16,791 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b402b65f-ed52-4154-b1ab-1b31072ab2f3
2023-10-11 05:39:16,792 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,824 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36591', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,825 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36591
2023-10-11 05:39:16,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59052
2023-10-11 05:39:16,827 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,828 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,828 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,842 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6d2b178b-5c3b-4f94-a54a-9e081268187c
2023-10-11 05:39:16,843 - distributed.worker - INFO - Starting Worker plugin PreImport-1aa77335-75dc-41ee-8545-0f58078dfef7
2023-10-11 05:39:16,843 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,872 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46627', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,873 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46627
2023-10-11 05:39:16,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59056
2023-10-11 05:39:16,874 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,874 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d16c468f-55db-4198-99fd-4c31f7656b8e
2023-10-11 05:39:16,875 - distributed.worker - INFO - Starting Worker plugin PreImport-cf07209a-d9bb-45cf-8c9d-d178e7af7673
2023-10-11 05:39:16,875 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,875 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,876 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,877 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,889 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,894 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-781ff645-2e0b-4fd8-af32-7640f6a3cba6
2023-10-11 05:39:16,894 - distributed.worker - INFO - Starting Worker plugin PreImport-08b1f685-7f6b-483d-8268-06e21e2a7715
2023-10-11 05:39:16,895 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,897 - distributed.worker - INFO - Starting Worker plugin PreImport-406c6045-6ba7-4e8f-983b-8021cdc4f11e
2023-10-11 05:39:16,898 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f4a01168-e786-48e5-8ee4-82c43ee3df87
2023-10-11 05:39:16,898 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,899 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e252fee0-8ac7-4723-b3a9-70f65993d2fc
2023-10-11 05:39:16,900 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39775', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,900 - distributed.worker - INFO - Starting Worker plugin PreImport-c873aba0-0b1b-4cb3-b315-3f59246b1385
2023-10-11 05:39:16,901 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,901 - distributed.worker - INFO - Starting Worker plugin PreImport-68deb6cb-dfa3-485c-a536-64b93ff67bb5
2023-10-11 05:39:16,901 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39775
2023-10-11 05:39:16,901 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f1d7862-fb58-49d8-a8d5-abd19379ff94
2023-10-11 05:39:16,901 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59064
2023-10-11 05:39:16,902 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,902 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,903 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,904 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,905 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,914 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39263', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,915 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39263
2023-10-11 05:39:16,915 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59074
2023-10-11 05:39:16,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,917 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,917 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,925 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45457', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,926 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45457
2023-10-11 05:39:16,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59116
2023-10-11 05:39:16,927 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38051', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,927 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38051
2023-10-11 05:39:16,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59086
2023-10-11 05:39:16,927 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,928 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,928 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,929 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,929 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35439', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,930 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35439
2023-10-11 05:39:16,930 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59100
2023-10-11 05:39:16,930 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,931 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,932 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,932 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,934 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39611', status: init, memory: 0, processing: 0>
2023-10-11 05:39:16,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:16,935 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39611
2023-10-11 05:39:16,935 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59118
2023-10-11 05:39:16,936 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:16,937 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:16,937 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:16,939 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,045 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,055 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,055 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,055 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,055 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,056 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,056 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,056 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,056 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:39:17,062 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,064 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:17,066 - distributed.scheduler - INFO - Remove client Client-80812b98-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:17,066 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59032; closing.
2023-10-11 05:39:17,066 - distributed.scheduler - INFO - Remove client Client-80812b98-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:17,066 - distributed.scheduler - INFO - Close client connection: Client-80812b98-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:17,067 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39149'. Reason: nanny-close
2023-10-11 05:39:17,068 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35993'. Reason: nanny-close
2023-10-11 05:39:17,069 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,069 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35439. Reason: nanny-close
2023-10-11 05:39:17,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37879'. Reason: nanny-close
2023-10-11 05:39:17,070 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,070 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36591. Reason: nanny-close
2023-10-11 05:39:17,070 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40347'. Reason: nanny-close
2023-10-11 05:39:17,070 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,070 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39775. Reason: nanny-close
2023-10-11 05:39:17,071 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37911'. Reason: nanny-close
2023-10-11 05:39:17,071 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,071 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39263. Reason: nanny-close
2023-10-11 05:39:17,071 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44595'. Reason: nanny-close
2023-10-11 05:39:17,071 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,072 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38051. Reason: nanny-close
2023-10-11 05:39:17,072 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,072 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40013'. Reason: nanny-close
2023-10-11 05:39:17,072 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59100; closing.
2023-10-11 05:39:17,072 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,072 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,072 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46627. Reason: nanny-close
2023-10-11 05:39:17,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35439', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0728312')
2023-10-11 05:39:17,072 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35379'. Reason: nanny-close
2023-10-11 05:39:17,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,073 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:17,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,073 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39611. Reason: nanny-close
2023-10-11 05:39:17,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59074; closing.
2023-10-11 05:39:17,073 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45457. Reason: nanny-close
2023-10-11 05:39:17,074 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39263', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0739686')
2023-10-11 05:39:17,074 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,074 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,074 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59064; closing.
2023-10-11 05:39:17,074 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,074 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,074 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,074 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,075 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39775', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0753589')
2023-10-11 05:39:17,075 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59052; closing.
2023-10-11 05:39:17,075 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,076 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:17,076 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,076 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,077 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,077 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:17,076 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:59074>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-11 05:39:17,078 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36591', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.078306')
2023-10-11 05:39:17,078 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59086; closing.
2023-10-11 05:39:17,079 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38051', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0794928')
2023-10-11 05:39:17,079 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59056; closing.
2023-10-11 05:39:17,080 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59118; closing.
2023-10-11 05:39:17,080 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59116; closing.
2023-10-11 05:39:17,080 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46627', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.080702')
2023-10-11 05:39:17,081 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39611', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0811577')
2023-10-11 05:39:17,081 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45457', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002757.0816453')
2023-10-11 05:39:17,081 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:18,685 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:18,686 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:18,686 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:18,687 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:18,688 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-11 05:39:20,817 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:20,821 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45959 instead
  warnings.warn(
2023-10-11 05:39:20,825 - distributed.scheduler - INFO - State start
2023-10-11 05:39:20,847 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:20,848 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:20,849 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45959/status
2023-10-11 05:39:20,849 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:21,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36353'
2023-10-11 05:39:21,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45593'
2023-10-11 05:39:21,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46561'
2023-10-11 05:39:21,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36989'
2023-10-11 05:39:21,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41071'
2023-10-11 05:39:21,080 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39187'
2023-10-11 05:39:21,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38031'
2023-10-11 05:39:21,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35667'
2023-10-11 05:39:21,529 - distributed.scheduler - INFO - Receive client connection: Client-85db35ba-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:21,542 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59736
2023-10-11 05:39:22,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,911 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:22,912 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:22,949 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,949 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,953 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:22,954 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:22,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:22,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:22,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:22,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:23,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:23,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:23,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:23,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:23,007 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:23,012 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:25,582 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34675
2023-10-11 05:39:25,583 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34675
2023-10-11 05:39:25,583 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34635
2023-10-11 05:39:25,583 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,583 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,583 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,583 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,583 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-416v4scl
2023-10-11 05:39:25,584 - distributed.worker - INFO - Starting Worker plugin RMMSetup-15f17128-c7cd-4599-836f-8aa8aa914ee1
2023-10-11 05:39:25,710 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39273
2023-10-11 05:39:25,711 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39273
2023-10-11 05:39:25,711 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37219
2023-10-11 05:39:25,711 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,711 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,711 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,711 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,711 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vtm3bxy3
2023-10-11 05:39:25,712 - distributed.worker - INFO - Starting Worker plugin PreImport-14d2b69f-96bf-4819-b14e-1b4e8e900978
2023-10-11 05:39:25,712 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-650cd14b-62b7-461d-951a-fb13cd5465c6
2023-10-11 05:39:25,712 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4d78c1d4-22df-46a3-9294-30a115759444
2023-10-11 05:39:25,717 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e76c7db8-a9b6-405c-b8e4-ce8f2b236df5
2023-10-11 05:39:25,717 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46011
2023-10-11 05:39:25,718 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46011
2023-10-11 05:39:25,718 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36699
2023-10-11 05:39:25,718 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,718 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,718 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,718 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,718 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_y7botf9
2023-10-11 05:39:25,719 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2cbc370b-ec34-49ff-9972-f452b62e0868
2023-10-11 05:39:25,720 - distributed.worker - INFO - Starting Worker plugin PreImport-441aeaa4-07fd-4952-b559-b0a13bbc4586
2023-10-11 05:39:25,720 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,754 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34675', status: init, memory: 0, processing: 0>
2023-10-11 05:39:25,756 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34675
2023-10-11 05:39:25,756 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59750
2023-10-11 05:39:25,758 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:25,759 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,759 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,762 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:25,868 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,872 - distributed.worker - INFO - Starting Worker plugin PreImport-9fdfe2ac-5ba3-42ca-badc-d947758ee3c3
2023-10-11 05:39:25,872 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-41f89bb7-69d3-4af0-b231-c2dce10e8b45
2023-10-11 05:39:25,873 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,886 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46217
2023-10-11 05:39:25,887 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46217
2023-10-11 05:39:25,887 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34423
2023-10-11 05:39:25,887 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,887 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,887 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,887 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,887 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zt_6mslt
2023-10-11 05:39:25,888 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83b1bb86-f481-417d-a902-fddb5984af17
2023-10-11 05:39:25,888 - distributed.worker - INFO - Starting Worker plugin PreImport-9b6b8d30-2088-462c-b8bb-cc4f4576b13a
2023-10-11 05:39:25,888 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e2d3e2d4-b768-468b-836b-261aaae6f4bf
2023-10-11 05:39:25,896 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44409
2023-10-11 05:39:25,896 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44409
2023-10-11 05:39:25,897 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37247
2023-10-11 05:39:25,897 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,897 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,897 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,897 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,897 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8el6cnvp
2023-10-11 05:39:25,897 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58a0b91c-d938-4d11-b599-62ce6877784e
2023-10-11 05:39:25,898 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39273', status: init, memory: 0, processing: 0>
2023-10-11 05:39:25,898 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39273
2023-10-11 05:39:25,898 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59758
2023-10-11 05:39:25,898 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33635
2023-10-11 05:39:25,899 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33635
2023-10-11 05:39:25,899 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34413
2023-10-11 05:39:25,899 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46011', status: init, memory: 0, processing: 0>
2023-10-11 05:39:25,899 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,899 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,899 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,899 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,900 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zrii99dh
2023-10-11 05:39:25,900 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:25,900 - distributed.worker - INFO - Starting Worker plugin RMMSetup-848f7976-c41a-4dc3-a745-96cc922bfc27
2023-10-11 05:39:25,900 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46011
2023-10-11 05:39:25,900 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59760
2023-10-11 05:39:25,901 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,901 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,901 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:25,901 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40539
2023-10-11 05:39:25,902 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40539
2023-10-11 05:39:25,902 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,902 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44439
2023-10-11 05:39:25,902 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,902 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,902 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,902 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,902 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,902 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_erv21he
2023-10-11 05:39:25,903 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:25,903 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f480b600-e827-4fbf-abc2-746ff4dd0340
2023-10-11 05:39:25,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:25,908 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34243
2023-10-11 05:39:25,909 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34243
2023-10-11 05:39:25,909 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37361
2023-10-11 05:39:25,909 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:25,909 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:25,909 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:25,910 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:39:25,910 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qh5uczco
2023-10-11 05:39:25,910 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dbfeb264-fa65-4b17-9590-2a21dd0e1541
2023-10-11 05:39:26,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3e28beca-0bc6-4450-ae1d-adbe2b84c0be
2023-10-11 05:39:26,035 - distributed.worker - INFO - Starting Worker plugin PreImport-ca58e743-805b-43be-836d-d8fd334cc3cb
2023-10-11 05:39:26,036 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,037 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-efed7ba7-817a-42e5-9b87-03c523e53f18
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin PreImport-ed10dae3-e01a-47bb-897a-c35eb79939d7
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin PreImport-5ae412c8-2eb8-40e4-8bce-13394d74d786
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38483c51-f7e6-44c2-bb13-78d6e517e88a
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24e460e3-5e5d-406c-82ee-bc0c46055ec0
2023-10-11 05:39:26,038 - distributed.worker - INFO - Starting Worker plugin PreImport-734e81cd-ebdf-44e6-8a90-bfc05d2fedc4
2023-10-11 05:39:26,038 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,039 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,039 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,061 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33635', status: init, memory: 0, processing: 0>
2023-10-11 05:39:26,061 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33635
2023-10-11 05:39:26,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59768
2023-10-11 05:39:26,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40539', status: init, memory: 0, processing: 0>
2023-10-11 05:39:26,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:26,062 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40539
2023-10-11 05:39:26,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59800
2023-10-11 05:39:26,063 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:26,063 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46217', status: init, memory: 0, processing: 0>
2023-10-11 05:39:26,063 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:26,064 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46217
2023-10-11 05:39:26,064 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59784
2023-10-11 05:39:26,065 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:26,065 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:26,065 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:26,066 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34243', status: init, memory: 0, processing: 0>
2023-10-11 05:39:26,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:26,066 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:26,066 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,066 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34243
2023-10-11 05:39:26,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59804
2023-10-11 05:39:26,067 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44409', status: init, memory: 0, processing: 0>
2023-10-11 05:39:26,067 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:26,068 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:26,068 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44409
2023-10-11 05:39:26,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59806
2023-10-11 05:39:26,069 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:26,069 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,069 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:26,071 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:26,071 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:26,071 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:26,072 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:26,171 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,171 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,172 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:39:26,176 - distributed.scheduler - INFO - Remove client Client-85db35ba-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:26,177 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59736; closing.
2023-10-11 05:39:26,177 - distributed.scheduler - INFO - Remove client Client-85db35ba-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:26,177 - distributed.scheduler - INFO - Close client connection: Client-85db35ba-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:26,178 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36353'. Reason: nanny-close
2023-10-11 05:39:26,179 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,180 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45593'. Reason: nanny-close
2023-10-11 05:39:26,180 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,180 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40539. Reason: nanny-close
2023-10-11 05:39:26,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46561'. Reason: nanny-close
2023-10-11 05:39:26,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,181 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46011. Reason: nanny-close
2023-10-11 05:39:26,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36989'. Reason: nanny-close
2023-10-11 05:39:26,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,182 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34675. Reason: nanny-close
2023-10-11 05:39:26,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41071'. Reason: nanny-close
2023-10-11 05:39:26,182 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,182 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59800; closing.
2023-10-11 05:39:26,182 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,182 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40539', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1828887')
2023-10-11 05:39:26,183 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39187'. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39273. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33635. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38031'. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46217. Reason: nanny-close
2023-10-11 05:39:26,184 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,184 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35667'. Reason: nanny-close
2023-10-11 05:39:26,184 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:26,184 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59760; closing.
2023-10-11 05:39:26,184 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44409. Reason: nanny-close
2023-10-11 05:39:26,184 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,185 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46011', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1851096')
2023-10-11 05:39:26,185 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34243. Reason: nanny-close
2023-10-11 05:39:26,185 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,186 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59750; closing.
2023-10-11 05:39:26,186 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,186 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,186 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,186 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34675', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1867623')
2023-10-11 05:39:26,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59758; closing.
2023-10-11 05:39:26,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59768; closing.
2023-10-11 05:39:26,187 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:26,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59784; closing.
2023-10-11 05:39:26,187 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,188 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39273', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1880066')
2023-10-11 05:39:26,188 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33635', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1883888')
2023-10-11 05:39:26,188 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46217', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.188702')
2023-10-11 05:39:26,188 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,189 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,189 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,189 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:26,189 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59804; closing.
2023-10-11 05:39:26,189 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59806; closing.
2023-10-11 05:39:26,190 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34243', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1900177')
2023-10-11 05:39:26,190 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44409', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002766.1904798')
2023-10-11 05:39:26,190 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:27,796 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:27,797 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:27,797 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:27,798 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:27,799 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-11 05:39:30,052 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:30,057 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43127 instead
  warnings.warn(
2023-10-11 05:39:30,061 - distributed.scheduler - INFO - State start
2023-10-11 05:39:30,091 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:30,092 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:30,093 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43127/status
2023-10-11 05:39:30,093 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:30,198 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34647'
2023-10-11 05:39:30,684 - distributed.scheduler - INFO - Receive client connection: Client-8b504610-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:30,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54790
2023-10-11 05:39:32,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:32,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:32,657 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:33,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40693
2023-10-11 05:39:33,761 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40693
2023-10-11 05:39:33,761 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-11 05:39:33,762 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:33,762 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:33,762 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:33,762 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-11 05:39:33,762 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tkhfqtb0
2023-10-11 05:39:33,762 - distributed.worker - INFO - Starting Worker plugin RMMSetup-59439187-5dd4-490d-8734-de419575bc77
2023-10-11 05:39:33,763 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83d2442b-a573-4de5-b7a8-080d92c0121b
2023-10-11 05:39:33,763 - distributed.worker - INFO - Starting Worker plugin PreImport-9295663e-ca1e-49e1-b59c-64b38d42310e
2023-10-11 05:39:33,763 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:33,784 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40693', status: init, memory: 0, processing: 0>
2023-10-11 05:39:33,786 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40693
2023-10-11 05:39:33,786 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54798
2023-10-11 05:39:33,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:33,787 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:33,787 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:33,789 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:33,864 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:33,867 - distributed.scheduler - INFO - Remove client Client-8b504610-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:33,867 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54790; closing.
2023-10-11 05:39:33,867 - distributed.scheduler - INFO - Remove client Client-8b504610-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:33,868 - distributed.scheduler - INFO - Close client connection: Client-8b504610-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:33,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34647'. Reason: nanny-close
2023-10-11 05:39:33,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:33,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40693. Reason: nanny-close
2023-10-11 05:39:33,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54798; closing.
2023-10-11 05:39:33,872 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:33,872 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40693', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002773.8722985')
2023-10-11 05:39:33,872 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:33,873 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:34,935 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:34,935 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:34,936 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:34,937 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:34,937 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-11 05:39:39,105 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:39,109 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34647 instead
  warnings.warn(
2023-10-11 05:39:39,112 - distributed.scheduler - INFO - State start
2023-10-11 05:39:39,134 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:39,136 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:39,136 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34647/status
2023-10-11 05:39:39,136 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:39,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35987'
2023-10-11 05:39:40,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:40,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:41,497 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:42,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33207
2023-10-11 05:39:42,299 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33207
2023-10-11 05:39:42,299 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37211
2023-10-11 05:39:42,299 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:39:42,299 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:42,299 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:42,299 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-11 05:39:42,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_afg5wiq
2023-10-11 05:39:42,300 - distributed.worker - INFO - Starting Worker plugin PreImport-5d36655f-e23f-4be0-b8e8-108290f04b5c
2023-10-11 05:39:42,301 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5fbaf2f-6c3d-4d2f-b551-45ac34ffab2b
2023-10-11 05:39:42,301 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ddb9025b-a547-44c6-aeba-13a791e13817
2023-10-11 05:39:42,302 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:42,329 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33207', status: init, memory: 0, processing: 0>
2023-10-11 05:39:42,341 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33207
2023-10-11 05:39:42,341 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60058
2023-10-11 05:39:42,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:42,342 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:39:42,342 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:42,344 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:39:44,330 - distributed.scheduler - INFO - Receive client connection: Client-90caeba5-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:44,331 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60064
2023-10-11 05:39:44,338 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:44,343 - distributed.scheduler - INFO - Remove client Client-90caeba5-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:44,343 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60064; closing.
2023-10-11 05:39:44,343 - distributed.scheduler - INFO - Remove client Client-90caeba5-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:44,344 - distributed.scheduler - INFO - Close client connection: Client-90caeba5-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:44,344 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35987'. Reason: nanny-close
2023-10-11 05:39:44,345 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:44,346 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33207. Reason: nanny-close
2023-10-11 05:39:44,349 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-11 05:39:44,351 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60058; closing.
2023-10-11 05:39:44,352 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:39:44,352 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33207', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002784.3521516')
2023-10-11 05:39:44,352 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:44,354 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:44,354 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:33207', status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-11 05:39:45,411 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:45,411 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:45,411 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:45,412 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:45,412 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-11 05:39:47,570 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:47,577 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35165 instead
  warnings.warn(
2023-10-11 05:39:47,581 - distributed.scheduler - INFO - State start
2023-10-11 05:39:47,604 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:47,605 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:47,606 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35165/status
2023-10-11 05:39:47,606 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:51,305 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:60074'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60074>: Stream is closed
2023-10-11 05:39:51,622 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:51,622 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:51,622 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:51,623 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:39:51,623 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-11 05:39:53,668 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:53,673 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35071 instead
  warnings.warn(
2023-10-11 05:39:53,677 - distributed.scheduler - INFO - State start
2023-10-11 05:39:53,699 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:53,700 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-11 05:39:53,701 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35071/status
2023-10-11 05:39:53,701 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:53,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38757'
2023-10-11 05:39:53,928 - distributed.scheduler - INFO - Receive client connection: Client-997f49e6-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:53,940 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33158
2023-10-11 05:39:55,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:39:55,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:39:55,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:39:56,086 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43171
2023-10-11 05:39:56,087 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43171
2023-10-11 05:39:56,087 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41563
2023-10-11 05:39:56,087 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-11 05:39:56,087 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:56,087 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:39:56,087 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-11 05:39:56,087 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zc65fhuo
2023-10-11 05:39:56,088 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f40792de-2102-4e58-90f4-067226405cfc
2023-10-11 05:39:56,088 - distributed.worker - INFO - Starting Worker plugin PreImport-d1d8eb1c-fbb8-4f50-a761-724f90592bbc
2023-10-11 05:39:56,088 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-727147f0-40a5-4d1f-afde-b494fae0e49f
2023-10-11 05:39:56,088 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:56,110 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43171', status: init, memory: 0, processing: 0>
2023-10-11 05:39:56,111 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43171
2023-10-11 05:39:56,112 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33172
2023-10-11 05:39:56,112 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:39:56,113 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-11 05:39:56,113 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:39:56,115 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-11 05:39:56,184 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:39:56,186 - distributed.scheduler - INFO - Remove client Client-997f49e6-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:56,187 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33158; closing.
2023-10-11 05:39:56,187 - distributed.scheduler - INFO - Remove client Client-997f49e6-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:56,187 - distributed.scheduler - INFO - Close client connection: Client-997f49e6-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:39:56,188 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38757'. Reason: nanny-close
2023-10-11 05:39:56,188 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:39:56,190 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43171. Reason: nanny-close
2023-10-11 05:39:56,191 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33172; closing.
2023-10-11 05:39:56,191 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-11 05:39:56,192 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43171', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002796.1921384')
2023-10-11 05:39:56,192 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:39:56,193 - distributed.nanny - INFO - Worker closed
2023-10-11 05:39:57,154 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:39:57,155 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:39:57,155 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:39:57,156 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-11 05:39:57,157 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-11 05:39:59,144 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:59,148 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39379 instead
  warnings.warn(
2023-10-11 05:39:59,152 - distributed.scheduler - INFO - State start
2023-10-11 05:39:59,172 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:39:59,173 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:39:59,173 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39379/status
2023-10-11 05:39:59,173 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:39:59,474 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46853'
2023-10-11 05:39:59,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39259'
2023-10-11 05:39:59,496 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40377'
2023-10-11 05:39:59,510 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33483'
2023-10-11 05:39:59,512 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44837'
2023-10-11 05:39:59,520 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35295'
2023-10-11 05:39:59,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35649'
2023-10-11 05:39:59,537 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36761'
2023-10-11 05:40:01,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,308 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,310 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,310 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,330 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,332 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,343 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,429 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:01,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:01,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:01,458 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:03,673 - distributed.scheduler - INFO - Receive client connection: Client-9ccaf2d0-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:03,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56478
2023-10-11 05:40:03,935 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37577
2023-10-11 05:40:03,936 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37577
2023-10-11 05:40:03,936 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35055
2023-10-11 05:40:03,936 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:03,936 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:03,936 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:03,936 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:03,936 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-itz9bscb
2023-10-11 05:40:03,937 - distributed.worker - INFO - Starting Worker plugin PreImport-5e6449a5-6cfc-4db1-accd-082d7da76d16
2023-10-11 05:40:03,937 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef6cf99c-0dbc-4bb9-9d2d-c25979380427
2023-10-11 05:40:03,937 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c050c747-e197-4f13-9d3f-cdb00cce698b
2023-10-11 05:40:03,938 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34103
2023-10-11 05:40:03,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34103
2023-10-11 05:40:03,939 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35717
2023-10-11 05:40:03,939 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:03,939 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:03,939 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:03,939 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:03,939 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-48j_alzo
2023-10-11 05:40:03,939 - distributed.worker - INFO - Starting Worker plugin RMMSetup-587d6a15-c302-4833-af32-0ca288cd4cb4
2023-10-11 05:40:03,971 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43723
2023-10-11 05:40:03,972 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43723
2023-10-11 05:40:03,972 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38129
2023-10-11 05:40:03,972 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:03,972 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:03,972 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:03,972 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:03,973 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-20xw6np_
2023-10-11 05:40:03,973 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e406656c-5d3f-44d0-bcd8-9e62bb1b146a
2023-10-11 05:40:04,069 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37505
2023-10-11 05:40:04,071 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37505
2023-10-11 05:40:04,071 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38533
2023-10-11 05:40:04,071 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,071 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,071 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:04,071 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:04,071 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s6g5j65t
2023-10-11 05:40:04,072 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f565b6c1-277c-43fc-8ce8-bc69ff2a18b7
2023-10-11 05:40:04,075 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33285
2023-10-11 05:40:04,076 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33285
2023-10-11 05:40:04,076 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36843
2023-10-11 05:40:04,076 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,076 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,076 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:04,076 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:04,076 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-egvhrpqg
2023-10-11 05:40:04,077 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1d0b3c9f-f1ee-4fb3-93ce-3cb8c5baa0b8
2023-10-11 05:40:04,078 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38841
2023-10-11 05:40:04,079 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38841
2023-10-11 05:40:04,079 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39173
2023-10-11 05:40:04,079 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,079 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:04,079 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:04,079 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qs65fnzm
2023-10-11 05:40:04,080 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ebeaff49-a0dd-4cac-9da8-4ec38f985cac
2023-10-11 05:40:04,080 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44763
2023-10-11 05:40:04,081 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44763
2023-10-11 05:40:04,081 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45899
2023-10-11 05:40:04,081 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,081 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,081 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:04,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:04,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oeaiv4jc
2023-10-11 05:40:04,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-73b83cb0-c439-4610-b570-5713a703d35c
2023-10-11 05:40:04,083 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33575
2023-10-11 05:40:04,084 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33575
2023-10-11 05:40:04,085 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43523
2023-10-11 05:40:04,085 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,085 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,085 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:04,085 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-11 05:40:04,085 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1us4fsn0
2023-10-11 05:40:04,086 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d4985aca-a1ea-4fe3-aba9-a0aabe5f2dd2
2023-10-11 05:40:04,223 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,223 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-605080d8-0136-4307-85c7-972c95849d1d
2023-10-11 05:40:04,223 - distributed.worker - INFO - Starting Worker plugin PreImport-c9e3d3dd-8a09-4d4f-ae68-c1f2bc03740b
2023-10-11 05:40:04,224 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1352ad2-c2c5-48b2-90c5-a8f6197eebbf
2023-10-11 05:40:04,233 - distributed.worker - INFO - Starting Worker plugin PreImport-3a510950-566e-4f54-ade9-1e26e2bb6777
2023-10-11 05:40:04,233 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,238 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5443bdbf-ebbe-4b51-8377-23b6a6724af9
2023-10-11 05:40:04,239 - distributed.worker - INFO - Starting Worker plugin PreImport-6fb22072-25d7-44ae-b8f5-dc0b3b2ae93c
2023-10-11 05:40:04,239 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,250 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37577', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,251 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37577
2023-10-11 05:40:04,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56504
2023-10-11 05:40:04,252 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34103', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,252 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,253 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34103
2023-10-11 05:40:04,253 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56510
2023-10-11 05:40:04,253 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,253 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,254 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,254 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,254 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,255 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,256 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,258 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43723', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,258 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43723
2023-10-11 05:40:04,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56516
2023-10-11 05:40:04,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,260 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,260 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,262 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-50d81395-b1fb-4ce3-9a5f-2512bd3b7f92
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin PreImport-6d9ff6ab-e8ed-4baa-9d2d-63245a12cd48
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin PreImport-8f5c9d4f-d38f-4a19-a271-a144e94c8edd
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c6bd6a01-418b-4247-a7fc-ad5fa05a5efa
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin PreImport-00e0f25b-c532-4c1a-8f12-515ebfc99c47
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin PreImport-4ce1cf4a-92ac-4e83-a6ae-1132438c796a
2023-10-11 05:40:04,278 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-75d275e4-bdac-425a-a475-e726e6ca73b4
2023-10-11 05:40:04,278 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-045b2cf6-40e1-4541-b77c-faf542439662
2023-10-11 05:40:04,278 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,279 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,279 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,280 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38841', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,281 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38841
2023-10-11 05:40:04,281 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56532
2023-10-11 05:40:04,282 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,283 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,283 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,286 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,302 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44763', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,303 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44763
2023-10-11 05:40:04,303 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56542
2023-10-11 05:40:04,304 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,304 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,305 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,306 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,309 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33575', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,310 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33575
2023-10-11 05:40:04,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56552
2023-10-11 05:40:04,311 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33285', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,311 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33285
2023-10-11 05:40:04,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56560
2023-10-11 05:40:04,312 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,312 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,312 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37505', status: init, memory: 0, processing: 0>
2023-10-11 05:40:04,313 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37505
2023-10-11 05:40:04,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56548
2023-10-11 05:40:04,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,314 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,314 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,314 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:04,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,315 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:04,315 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:04,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,317 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:04,416 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,416 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,416 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,416 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,417 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,417 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,417 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,417 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-11 05:40:04,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:04,434 - distributed.scheduler - INFO - Remove client Client-9ccaf2d0-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:04,434 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56478; closing.
2023-10-11 05:40:04,435 - distributed.scheduler - INFO - Remove client Client-9ccaf2d0-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:04,435 - distributed.scheduler - INFO - Close client connection: Client-9ccaf2d0-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:04,436 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46853'. Reason: nanny-close
2023-10-11 05:40:04,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,438 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39259'. Reason: nanny-close
2023-10-11 05:40:04,438 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,439 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33575. Reason: nanny-close
2023-10-11 05:40:04,439 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40377'. Reason: nanny-close
2023-10-11 05:40:04,440 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,440 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33285. Reason: nanny-close
2023-10-11 05:40:04,440 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33483'. Reason: nanny-close
2023-10-11 05:40:04,440 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,441 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56552; closing.
2023-10-11 05:40:04,441 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34103. Reason: nanny-close
2023-10-11 05:40:04,441 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,441 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33575', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4413764')
2023-10-11 05:40:04,441 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44837'. Reason: nanny-close
2023-10-11 05:40:04,442 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37577. Reason: nanny-close
2023-10-11 05:40:04,442 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,442 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,442 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,442 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,443 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35295'. Reason: nanny-close
2023-10-11 05:40:04,443 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38841. Reason: nanny-close
2023-10-11 05:40:04,443 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56560; closing.
2023-10-11 05:40:04,443 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,444 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,444 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,444 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35649'. Reason: nanny-close
2023-10-11 05:40:04,444 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,444 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33285', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.444568')
2023-10-11 05:40:04,444 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,444 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37505. Reason: nanny-close
2023-10-11 05:40:04,445 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56510; closing.
2023-10-11 05:40:04,445 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34103', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4454117')
2023-10-11 05:40:04,445 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36761'. Reason: nanny-close
2023-10-11 05:40:04,445 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,445 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43723. Reason: nanny-close
2023-10-11 05:40:04,445 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:04,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56504; closing.
2023-10-11 05:40:04,446 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,446 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44763. Reason: nanny-close
2023-10-11 05:40:04,446 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37577', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4465933')
2023-10-11 05:40:04,446 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56532; closing.
2023-10-11 05:40:04,447 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,447 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38841', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4474797')
2023-10-11 05:40:04,447 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56548; closing.
2023-10-11 05:40:04,448 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,448 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:04,448 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37505', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4483259')
2023-10-11 05:40:04,448 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56516; closing.
2023-10-11 05:40:04,448 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,448 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,449 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43723', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.4491825')
2023-10-11 05:40:04,449 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56542; closing.
2023-10-11 05:40:04,449 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:04,450 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44763', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002804.44994')
2023-10-11 05:40:04,450 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:40:04,450 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:56516>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-11 05:40:05,953 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:40:05,954 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:40:05,954 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:40:05,955 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:40:05,956 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-11 05:40:08,054 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:40:08,058 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37631 instead
  warnings.warn(
2023-10-11 05:40:08,062 - distributed.scheduler - INFO - State start
2023-10-11 05:40:08,085 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:40:08,086 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:40:08,087 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37631/status
2023-10-11 05:40:08,087 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:40:08,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40173'
2023-10-11 05:40:08,830 - distributed.scheduler - INFO - Receive client connection: Client-a20ad2a8-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:08,842 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56652
2023-10-11 05:40:09,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:09,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:09,912 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:10,704 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39587
2023-10-11 05:40:10,705 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39587
2023-10-11 05:40:10,705 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34093
2023-10-11 05:40:10,705 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:10,705 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:10,705 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:10,705 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-11 05:40:10,705 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_ghv9cij
2023-10-11 05:40:10,706 - distributed.worker - INFO - Starting Worker plugin RMMSetup-daf7a646-1ace-440d-9e24-0e19c9cb093f
2023-10-11 05:40:10,809 - distributed.worker - INFO - Starting Worker plugin PreImport-b14a41cb-a03e-40a1-879f-4a160995f5ed
2023-10-11 05:40:10,809 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5963f477-8d13-4cc0-8af1-4aa8878be716
2023-10-11 05:40:10,809 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:10,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39587', status: init, memory: 0, processing: 0>
2023-10-11 05:40:10,837 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39587
2023-10-11 05:40:10,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43028
2023-10-11 05:40:10,838 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:10,839 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:10,839 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:10,841 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:10,883 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:40:10,887 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:10,889 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:10,891 - distributed.scheduler - INFO - Remove client Client-a20ad2a8-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:10,891 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56652; closing.
2023-10-11 05:40:10,892 - distributed.scheduler - INFO - Remove client Client-a20ad2a8-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:10,892 - distributed.scheduler - INFO - Close client connection: Client-a20ad2a8-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:10,893 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40173'. Reason: nanny-close
2023-10-11 05:40:10,893 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:10,894 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39587. Reason: nanny-close
2023-10-11 05:40:10,896 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43028; closing.
2023-10-11 05:40:10,896 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:10,897 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39587', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002810.8971653')
2023-10-11 05:40:10,897 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:40:10,898 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:12,360 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:40:12,361 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:40:12,361 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:40:12,362 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:40:12,363 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-11 05:40:14,553 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:40:14,558 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45597 instead
  warnings.warn(
2023-10-11 05:40:14,562 - distributed.scheduler - INFO - State start
2023-10-11 05:40:14,585 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-11 05:40:14,586 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-11 05:40:14,587 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45597/status
2023-10-11 05:40:14,587 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-11 05:40:14,589 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41569'
2023-10-11 05:40:15,460 - distributed.scheduler - INFO - Receive client connection: Client-a5db3655-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:15,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43122
2023-10-11 05:40:16,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-11 05:40:16,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-11 05:40:16,527 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-11 05:40:18,778 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37395
2023-10-11 05:40:18,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37395
2023-10-11 05:40:18,779 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34037
2023-10-11 05:40:18,779 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-11 05:40:18,779 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:18,779 - distributed.worker - INFO -               Threads:                          1
2023-10-11 05:40:18,779 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-11 05:40:18,779 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sv4_yg98
2023-10-11 05:40:18,780 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc44edb9-7a82-44ed-9c50-976f8248efcd
2023-10-11 05:40:18,883 - distributed.worker - INFO - Starting Worker plugin PreImport-6e9e8c44-bf9f-4108-8eb3-72bfa5fd3741
2023-10-11 05:40:18,884 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bfcd6597-3996-48cb-a24a-951aaa277d7d
2023-10-11 05:40:18,884 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:18,917 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37395', status: init, memory: 0, processing: 0>
2023-10-11 05:40:18,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37395
2023-10-11 05:40:18,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43132
2023-10-11 05:40:18,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-11 05:40:18,922 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-11 05:40:18,922 - distributed.worker - INFO - -------------------------------------------------
2023-10-11 05:40:18,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-11 05:40:18,972 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-11 05:40:18,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-11 05:40:18,980 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:18,982 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-11 05:40:18,984 - distributed.scheduler - INFO - Remove client Client-a5db3655-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:18,984 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43122; closing.
2023-10-11 05:40:18,985 - distributed.scheduler - INFO - Remove client Client-a5db3655-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:18,985 - distributed.scheduler - INFO - Close client connection: Client-a5db3655-67f8-11ee-b14b-d8c49764f6bb
2023-10-11 05:40:18,986 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41569'. Reason: nanny-close
2023-10-11 05:40:18,986 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-11 05:40:18,988 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37395. Reason: nanny-close
2023-10-11 05:40:18,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43132; closing.
2023-10-11 05:40:18,990 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-11 05:40:18,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37395', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697002818.9907928')
2023-10-11 05:40:18,991 - distributed.scheduler - INFO - Lost all workers
2023-10-11 05:40:18,992 - distributed.nanny - INFO - Worker closed
2023-10-11 05:40:20,052 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-11 05:40:20,053 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-11 05:40:20,053 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-11 05:40:20,054 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-11 05:40:20,055 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42843 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46869 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37427 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45605 instead
  warnings.warn(
2023-10-11 05:41:05,057 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
Task exception was never retrieved
future: <Task finished name='Task-1201' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38353 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40465 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45003 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39959 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34621 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45561 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34657 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37273 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43179 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40675 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45495 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33483 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35001 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40371 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42831 instead
  warnings.warn(
[1697003094.725433] [dgx13:70160:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:49437) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33941 instead
  warnings.warn(
[1697003113.321758] [dgx13:70489:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:60734) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33913 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43301 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38153 instead
  warnings.warn(
[1697003178.674668] [dgx13:71729:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:59270) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42939 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36787 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38837 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42483 instead
  warnings.warn(
2023-10-11 05:48:03,273 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60474 remote=tcp://127.0.0.1:33223>: Stream is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36727 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35851 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38531 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44391 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44635 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45741 instead
  warnings.warn(
2023-10-11 05:50:22,345 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-11 05:50:22,555 - distributed.core - ERROR - [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-11 05:50:22,577 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'ucx://127.0.0.1:41459'.
2023-10-11 05:50:22,578 - distributed.worker - ERROR - Scheduler was unaware of this worker 'ucx://127.0.0.1:41459'. Shutting down.
2023-10-11 05:50:22,603 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f46ce94f7c0>>, <Task finished name='Task-13' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-13' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-11 05:50:24,606 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
