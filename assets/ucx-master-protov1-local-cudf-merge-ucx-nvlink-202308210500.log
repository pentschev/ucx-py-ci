/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41313 instead
  warnings.warn(
[dgx13:79024:0:79024] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79024) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f1b03c4dced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f1b03c4dee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f1b03c4e0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f1baa28f420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f1b03ccd6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f1b03cf5c59]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2050f) [0x7f1b03c0750f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x235f8) [0x7f1b03c0a5f8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f1b03c57439]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f1b03c0970d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f1b03cca52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7f1b03d8baaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55bec08963d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55bec08a23f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55bec0945612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f1b2ae0f1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55bec089a67c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55bec085548b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55bec08996f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55bec08976e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55bec08a23f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55bec0893022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55bec08af88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55bec08b000c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55bec097373e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55bec089a67c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55bec08963d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55bec08af96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55bec08963d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55bec08a23f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55bec08924c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55bec08a26a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55bec0892212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55bec08a23f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55bec0893022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55bec0890f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55bec0890c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55bec0890c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55bec093e20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55bec096b5fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55bec0967983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55bec095f79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55bec095f68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55bec095e8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55bec0932047]
=================================
[dgx13:79013:0:79013] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79013) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fde002ccced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fde002ccee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fde002cd0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fdea0911420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fde0034c6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fde00374c59]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2050f) [0x7fde0028650f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x235f8) [0x7fde002895f8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fde002d6439]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fde0028870d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fde0034952a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fde0040aaaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ed813123d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed8131e3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
16  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
17  /opt/conda/envs/gdf/bin/python(+0x14ca43) [0x55ed8132ba43]
18  /opt/conda/envs/gdf/bin/python(+0x2580fc) [0x55ed814370fc]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55ed812d148b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55ed813156f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55ed813136e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed8131e3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ed8130f022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55ed8132b88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ed8132c00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55ed813ef73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ed8131667c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ed813123d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55ed8132b96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55ed813123d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed8131e3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed8130e4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55ed8131e6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ed8130e212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed8131e3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55ed8130f022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55ed8130cf94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ed8130cc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ed8130cc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ed813ba20b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55ed813e75fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55ed813e3983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ed813db79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ed813db68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ed813da8c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ed813ae047]
=================================
[dgx13:79021:0:79021] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79021) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe518616ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fe518616ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fe5186170aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe5aac85420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe5186966f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe5186bec59]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2050f) [0x7fe5185d050f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x235f8) [0x7fe5185d35f8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe518620439]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe5185d270d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe51869352a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fe518754aaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56457e4013d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56457e40d3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x56457e4b0612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fe52b8031e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56457e40567c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x56457e3c048b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x56457e4046f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x56457e4026e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56457e40d3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56457e3fe022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x56457e41a88b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56457e41b00c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x56457e4de73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56457e40567c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56457e4013d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x56457e41a96c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56457e4013d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56457e40d3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56457e3fd4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x56457e40d6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56457e3fd212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56457e40d3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56457e3fe022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x56457e3fbf94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56457e3fbc68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56457e3fbc19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56457e4a920b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x56457e4d65fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x56457e4d2983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x56457e4ca79a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x56457e4ca68c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x56457e4c98c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x56457e49d047]
=================================
[dgx13:79018:0:79018] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79018) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fafa16ecced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fafa16ecee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fafa16ed0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb045d56420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fafa176c6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fafa1794c59]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2050f) [0x7fafa16a650f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x235f8) [0x7fafa16a95f8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fafa16f6439]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fafa16a870d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fafa176952a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x37aaa) [0x7fafa182aaaa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55b87f17e3d6]
13  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b87f18a3f9]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e2612) [0x55b87f22d612]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fafc68d21e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b87f18267c]
19  /opt/conda/envs/gdf/bin/python(+0xf248b) [0x55b87f13d48b]
20  /opt/conda/envs/gdf/bin/python(+0x1366f3) [0x55b87f1816f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x58b4) [0x55b87f17f6e4]
22  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
24  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
26  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
28  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
30  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b87f18a3f9]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55b87f17b022]
33  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
34  /opt/conda/envs/gdf/bin/python(+0x14c88b) [0x55b87f19788b]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b87f19800c]
36  /opt/conda/envs/gdf/bin/python(+0x21073e) [0x55b87f25b73e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b87f18267c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55b87f17e3d6]
39  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
40  /opt/conda/envs/gdf/bin/python(+0x14c96c) [0x55b87f19796c]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55b87f17e3d6]
42  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
44  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b87f18a3f9]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b87f17a4c6]
47  /opt/conda/envs/gdf/bin/python(+0x13f6a2) [0x55b87f18a6a2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b87f17a212]
49  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b87f18a3f9]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55b87f17b022]
52  /opt/conda/envs/gdf/bin/python(+0x12df94) [0x55b87f178f94]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b87f178c68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b87f178c19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b87f22620b]
56  /opt/conda/envs/gdf/bin/python(+0x2085fa) [0x55b87f2535fa]
57  /opt/conda/envs/gdf/bin/python(+0x204983) [0x55b87f24f983]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b87f24779a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b87f24768c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b87f2468c7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b87f21a047]
=================================
2023-08-21 05:50:57,392 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33679 -> ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f703d229440, tag: 0xb4f7b7a45579856a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,392 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f6b48d62180, tag: 0x92e333e2a592532a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f6b48d62180, tag: 0x92e333e2a592532a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-21 05:50:57,393 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f703d229240, tag: 0xe5cc8a37f876e2a0, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f703d229240, tag: 0xe5cc8a37f876e2a0, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,392 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fb653284180, tag: 0xcc8bbc53f21d54e8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fb653284180, tag: 0xcc8bbc53f21d54e8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-21 05:50:57,393 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39011 -> ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b48d62400, tag: 0xef98dfe435896933, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,393 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f703d229180, tag: 0xe2c4629531ff985a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f703d229180, tag: 0xe2c4629531ff985a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,392 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7efc00768240, tag: 0x3fa5663960cf9cf8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7efc00768240, tag: 0x3fa5663960cf9cf8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,394 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39011 -> ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b48d623c0, tag: 0xb98e87a7eeacb845, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,394 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7efc00768180, tag: 0x6ab62ebf8aad70a7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7efc00768180, tag: 0x6ab62ebf8aad70a7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 05:50:57,394 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6b48d622c0, tag: 0x5d346509d7fa8a53, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6b48d622c0, tag: 0x5d346509d7fa8a53, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,394 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fb653284200, tag: 0x39a9d9d6c94b3873, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fb653284200, tag: 0x39a9d9d6c94b3873, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,396 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fb653284140, tag: 0xe486242bb524eacf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fb653284140, tag: 0xe486242bb524eacf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-21 05:50:57,396 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f703d229280, tag: 0xefad63df343901ff, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f703d229280, tag: 0xefad63df343901ff, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,396 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f6b48d621c0, tag: 0x50d19d6a4db7e077, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f6b48d621c0, tag: 0x50d19d6a4db7e077, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 05:50:57,396 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33679 -> ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f703d2293c0, tag: 0x907d1d5e1d27c972, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,396 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40601 -> ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7efc00768300, tag: 0x96ed6173a0a19a2c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50799 -> ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb653284400, tag: 0xc83d57ceac0b9b0b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40601 -> ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7efc00768380, tag: 0x9652a5fdafd7f4d0, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50799 -> ucx://127.0.0.1:55815
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb6532843c0, tag: 0x6c00a37c94274384, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,397 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40601 -> ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7efc00768340, tag: 0xcaa3848840f9f08c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,398 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50799 -> ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb653284340, tag: 0xa6bb7aedb9ae4290, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,398 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7efc00768280, tag: 0x9b48b78a10925ddc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7efc00768280, tag: 0x9b48b78a10925ddc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-21 05:50:57,440 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39011 -> ucx://127.0.0.1:38503
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #009] ep: 0x7f6b48d62440, tag: 0x452cee7821284443, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,440 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33679 -> ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f703d229340, tag: 0xa91c00f74785f1a6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,448 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39011 -> ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6b48d62340, tag: 0xf5cb413ba51c2108, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,457 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f703d229140, tag: 0x81af3874a1563d05, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f703d229140, tag: 0x81af3874a1563d05, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-21 05:50:57,466 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33679 -> ucx://127.0.0.1:36865
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f703d229400, tag: 0x2ee28c8a952be51a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:57,466 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f6b48d62240, tag: 0xa6238cf70cbcd48f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f6b48d62240, tag: 0xa6238cf70cbcd48f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,520 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7efc007682c0, tag: 0xe6487033ee26373a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7efc007682c0, tag: 0xe6487033ee26373a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-21 05:50:57,522 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53485
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7fb653284100, tag: 0x933a2ce2189c3bfc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7fb653284100, tag: 0x933a2ce2189c3bfc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-21 05:50:57,569 - distributed.nanny - WARNING - Restarting worker
2023-08-21 05:50:57,571 - distributed.nanny - WARNING - Restarting worker
2023-08-21 05:50:57,664 - distributed.nanny - WARNING - Restarting worker
2023-08-21 05:50:57,692 - distributed.nanny - WARNING - Restarting worker
2023-08-21 05:50:59,315 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 2)
Function:  _concat
args:      ([                key   payload
39584     825580225  37797774
39588     840535916  81295159
39593     809956180  90266409
39599     206568973  75699498
80389     412424028  41137617
...             ...       ...
99982292  822366982  12135684
99995011  409398727  15282267
99995022  821938337  44569010
99995034  832282838  77703058
99995039  819746089  69119949

[12503879 rows x 2 columns],                 key   payload
72705     910898480  17750165
72713     114575098  64791829
72723     315358605  99967626
72725      20013316  11904426
11366     960162340  66599419
...             ...       ...
99999180  920453255  72172693
99999185  624304044   4466638
99999189  926771772  24880874
99999190  933429839  15734511
99999198  907605513  44622046

[12499576 rows x 2 columns],                  key   payload
125032    1048306459  29093309
125035      27044626  57476566
125037    1052149704  75225365
125042    1034701629  27589816
125046    1025584391  70626567
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-21 05:50:59,458 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  _concat
args:      ([                key   payload
39587     848182252   7096110
39590     835843362  89345503
39592     814118060  11721886
39597     867077260  17732770
11360     407678083  26424789
...             ...       ...
99995009  831486387  94392488
99995019  850989285  62155120
99995020    9665795  21028678
99995024  202910929  83025883
99995027  602801218  48711012

[12497796 rows x 2 columns],                 key   payload
72712     951304898  23958880
72714     946274574  60465707
72721     722373175  42393357
11386     909432709  21649426
11388     923911333   3711081
...             ...       ...
99999177   16594759  31095048
99999181  424400730  52157083
99999192  948912090  21717024
99999193  959292689  50061947
99999194  713554908  12705076

[12497151 rows x 2 columns],                  key   payload
125024    1016270019  56398621
125025     326154066  85628011
125026    1038049535  45189460
125030    1056742202  86281883
125048    1003941895  34329559
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-21 05:50:59,535 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:50:59,535 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:50:59,539 - distributed.worker - ERROR - tuple indices must be integers or slices, not str
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2915, in get_data_from_worker
    status = response["status"]
TypeError: tuple indices must be integers or slices, not str
2023-08-21 05:50:59,549 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 930, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1099, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {"('split-simple-shuffle-054f65580a5efedc40c26858beb83d02', 7, 4)"}, 'who': 'ucx://127.0.0.1:33679', 'max_connections': None, 'reply': True}
2023-08-21 05:50:59,759 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40601
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #083] ep: 0x7f703d229100, tag: 0x5dfc5812fe8c1140, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #083] ep: 0x7f703d229100, tag: 0x5dfc5812fe8c1140, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-08-21 05:50:59,770 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40601 -> ucx://127.0.0.1:33679
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 320, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7efc00768100 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1777, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-21 05:50:59,886 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 1)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           114238  38915225
0            30751  57144317
0            72892  20167261
0           541707  28002111
0            15167  94485381
...            ...       ...
0        799967427  45616778
0        799823206  88885595
0        799868365  41749439
0        799715583  78174762
0        799898426  73888568

[12497508 rows x 2 columns],                key   payload
shuffle                     
1            44633    159937
1           300320  80513716
1           162548  14807669
1           611521  16416857
1           738032  17181025
...            ...       ...
1        799997661  37660825
1        799984690  47754248
1        799979686   1841914
1        799967912  82516463
1        799979697  27652447

[12503907 rows x 2 columns],                key   payload
shuffle                     
2           171996  88908401
2           139057  55980236
2           209880  58000508
2           139533  82722605
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-21 05:50:59,996 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:50:59,996 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:51:00,016 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-f1e9396f54451b9cde4495a9a287c08c', 0)
Function:  subgraph_callable-a377c50c-a14e-4eee-8c23-0b89a7c5
args:      (               key   payload
shuffle                     
0             6734  87919413
0           122598  47245250
0            23183  48522252
0           331215  70222547
0           236531  86990865
...            ...       ...
7        799922652  57569627
7        799948722  22117774
7        799915421  78748418
7        799911465  67608561
7        799889599  47390125

[99999977 rows x 2 columns],                  key   payload
39600      811154700  81461087
39605      864484935  77988816
11364      848733317  46815590
11365      803137889  90812872
11368      825410529  49683112
...              ...       ...
99992498  1519017188   1058487
99992505  1546914539  90242658
99992357  1509714580  62140267
99992362  1550920020  60292080
99992382  1521501818  92224848

[100005446 rows x 2 columns], 'simple-shuffle-054f65580a5efedc40c26858beb83d02', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-21 05:51:00,369 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:51:00,370 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:51:00,399 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:51:00,399 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2051, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2905, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1136, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-21 05:51:00,652 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  _concat
args:      ([                key   payload
39598     854336539  90625077
39611     851120564  14615484
11377     700949034   8065694
11384       5077366  29264377
11390     830684791  70281152
...             ...       ...
99995018  606756492  83352800
99995023  867961446  19184372
99995026  800731076  16917636
99995037  815900208  35797767
99995038  866508492  17793736

[12500893 rows x 2 columns],                 key   payload
72708     416639643  31346385
72717     955977912  27422668
72722     614058014  64867133
72730     722947726  18302029
11361     618592337   8659668
...             ...       ...
99999108  617311231  89175787
99999109  915750173  40355297
99999119  939265524  70905377
99999122  930563351  46964679
99999128  524420999  48727492

[12495890 rows x 2 columns],                  key   payload
125040    1059107376  47197018
125041     329296451  76259111
43139     1063795389  53943126
41476     1047717826  65274430
52353     1014139877  70618183
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
