[dgx13:79960:0:79960] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79960) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe0f89fee8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7fe0f89ff084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7fe0f89ff24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe18b169420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fe0f8a80317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fe0f8aa8a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7fe0f89b784f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7fe0f89baa28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe0f8a085d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe0f89b9b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe0f8a7d21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fe0f8b435fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5619777226fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56197772f519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x5619777d2162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fe10bc1a1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56197772777c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x5619776d9d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x5619777267f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x561977724929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56197772f519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x561977720128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x56197773cccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56197773d44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x56197780010e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56197772777c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5619777226fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x56197773cdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5619777226fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56197772f519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56197771f5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56197772f7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56197771f312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56197772f519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x561977720128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56197771e094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56197771dd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56197771dd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5619777cb07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x5619777f7fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x5619777f4353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x5619777ec16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x5619777ec05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x5619777eb297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x5619777bef07]
=================================
[dgx13:79949:0:79949] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
[dgx13:79969:0:79969] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79949) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd590c47e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7fd590c48084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7fd590c4824a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fd6313bc420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fd590cc9317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fd590cf1a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7fd590c0084f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7fd590c03a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fd590c515d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fd590c02b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fd590cc621a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fd590d8c5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55fadbc526fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55fadbc5f519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55fadbd02162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fd6241df1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55fadbc5777c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55fadbc09d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55fadbc567f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55fadbc54929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55fadbc5f519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55fadbc50128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55fadbc6cccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55fadbc6d44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55fadbd3010e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55fadbc5777c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55fadbc526fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55fadbc6cdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55fadbc526fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55fadbc5f519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55fadbc4f5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55fadbc5f7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55fadbc4f312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55fadbc5f519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55fadbc50128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55fadbc4e094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55fadbc4dd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55fadbc4dd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55fadbcfb07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55fadbd27fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55fadbd24353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55fadbd1c16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55fadbd1c05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55fadbd1b297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55fadbceef07]
=================================
==== backtrace (tid:  79969) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f2678e7be8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f2678e7c084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f2678e7c24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f27195fc420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f2678efd317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f2678f25a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f2678e3484f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f2678e37a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f2678e855d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f2678e36b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f2678efa21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f2678fc05fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1b45a96fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b1b45b6519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55b1b45c3e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55b1b46ceb2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55b1b4560d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55b1b45ad7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55b1b45ab929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b1b45b6519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b1b45a7128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55b1b45c3ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b1b45c444c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55b1b468710e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b1b45ae77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1b45a96fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55b1b45c3dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1b45a96fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b1b45b6519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1b45a65c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1b45b67c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b1b45a6312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b1b45b6519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b1b45a7128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b1b45a5094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b1b45a4d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b1b45a4d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b1b465207b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55b1b467efca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55b1b467b353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b1b467316a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b1b467305c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b1b4672297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b1b4645f07]
=================================
[dgx13:79966:0:79966] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79966) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0dfc95ce8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f0dfc95d084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f0dfc95d24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f0e9cf5a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f0dfc9de317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f0dfca06a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f0dfc91584f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f0dfc918a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0dfc9665d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f0dfc917b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0dfc9db21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f0dfcaa15fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x560e212696fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560e21276519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x560e21319162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f0e1da031e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x560e2126e77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x560e21220d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x560e2126d7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x560e2126b929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560e21276519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x560e21267128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x560e21283ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x560e2128444c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x560e2134710e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x560e2126e77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x560e212696fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x560e21283dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x560e212696fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560e21276519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560e212665c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x560e212767c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x560e21266312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560e21276519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x560e21267128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x560e21265094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x560e21264d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x560e21264d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x560e2131207b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x560e2133efca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x560e2133b353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x560e2133316a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x560e2133305c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x560e21332297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x560e21305f07]
=================================
[dgx13:79957:0:79957] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
[dgx13:79945:0:79945] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79957) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f163309de8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f163309e084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f163309e24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f16d37fc420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f163311f317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f1633147a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f163305684f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f1633059a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f16330a75d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f1633058b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f163311c21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f16331e25fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55580f5d26fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55580f5df519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55580f682162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f16542ab1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55580f5d777c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55580f589d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55580f5d67f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55580f5d4929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55580f5df519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55580f5d0128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55580f5ecccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55580f5ed44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55580f6b010e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55580f5d777c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55580f5d26fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55580f5ecdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55580f5d26fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55580f5df519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55580f5cf5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55580f5df7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55580f5cf312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55580f5df519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55580f5d0128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55580f5ce094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55580f5cdd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55580f5cdd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55580f67b07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55580f6a7fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55580f6a4353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55580f69c16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55580f69c05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55580f69b297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55580f66ef07]
=================================
==== backtrace (tid:  79945) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fdc9d5d4e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7fdc9d5d5084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7fdc9d5d524a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fdd41d3b420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fdc9d656317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fdc9d67ea1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7fdc9d58d84f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7fdc9d590a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fdc9d5de5d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fdc9d58fb3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fdc9d65321a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fdc9d7195fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559b5e9d66fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559b5e9e3519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559b5ea86162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fdcc27e71e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559b5e9db77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x559b5e98dd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x559b5e9da7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x559b5e9d8929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559b5e9e3519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559b5e9d4128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x559b5e9f0ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559b5e9f144c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x559b5eab410e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559b5e9db77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559b5e9d66fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x559b5e9f0dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559b5e9d66fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559b5e9e3519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559b5e9d35c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559b5e9e37c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x559b5e9d3312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559b5e9e3519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559b5e9d4128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559b5e9d2094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x559b5e9d1d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559b5e9d1d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559b5ea7f07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x559b5eaabfca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x559b5eaa8353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x559b5eaa016a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x559b5eaa005c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x559b5ea9f297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x559b5ea72f07]
=================================
[dgx13:79963:0:79963] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
[dgx13:79954:0:79954] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  79963) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f7168c47e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f7168c48084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f7168c4824a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f72093a2420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f7168cc9317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f7168cf1a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f7168c0084f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f7168c03a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f7168c515d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f7168c02b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f7168cc621a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f7168d8c5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a7fecfb6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7fed08519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55a7fed15e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55a7fee20b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55a7fecb2d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55a7fecff7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55a7fecfd929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7fed08519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55a7fecf9128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55a7fed15ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55a7fed1644c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55a7fedd910e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55a7fed0077c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a7fecfb6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55a7fed15dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55a7fecfb6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7fed08519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55a7fecf85c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55a7fed087c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55a7fecf8312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55a7fed08519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55a7fecf9128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55a7fecf7094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55a7fecf6d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a7fecf6d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a7feda407b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55a7fedd0fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55a7fedcd353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55a7fedc516a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55a7fedc505c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55a7fedc4297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55a7fed97f07]
=================================
==== backtrace (tid:  79954) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f19f0f11e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f19f0f12084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f19f0f1224a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f1a91693420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f19f0f93317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f19f0fbba1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f19f0eca84f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f19f0ecda28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f19f0f1b5d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f19f0eccb3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f19f0f9021a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f19f10565fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ed5574f6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed5575c519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55ed55769e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55ed55874b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55ed55706d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55ed557537f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55ed55751929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed5575c519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ed5574d128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55ed55769ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ed5576a44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55ed5582d10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ed5575477c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ed5574f6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55ed55769dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ed5574f6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed5575c519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ed5574c5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ed5575c7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ed5574c312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ed5575c519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ed5574d128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ed5574b094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ed5574ad68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ed5574ad19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ed557f807b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55ed55824fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55ed55821353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ed5581916a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ed5581905c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ed55818297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ed557ebf07]
=================================
2023-09-20 07:28:46,989 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,050 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,375 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,431 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,435 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,464 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,493 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:47,565 - distributed.nanny - WARNING - Restarting worker
[dgx13:80123:0:80123] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80123) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f3a548a8e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f3a548a9084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f3a548a924a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f3af4e8e420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f3a5492a317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f3a54952a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f3a5486184f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f3a54864a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f3a548b25d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f3a54863b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f3a5492721a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f3a549ed5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56033e04f6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56033e05c519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x56033e0ff162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f3ae80241e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56033e05477c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x56033e006d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x56033e0537f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x56033e051929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56033e05c519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56033e04d128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x56033e069ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56033e06a44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x56033e12d10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56033e05477c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56033e04f6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x56033e069dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56033e04f6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56033e05c519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56033e04c5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56033e05c7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56033e04c312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56033e05c519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56033e04d128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56033e04b094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56033e04ad68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56033e04ad19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56033e0f807b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x56033e124fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x56033e121353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x56033e11916a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x56033e11905c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x56033e118297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x56033e0ebf07]
=================================
[dgx13:80126:0:80126] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80126) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f126059ee8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f126059f084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f126059f24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f12f2b94420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f1260620317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f1260648a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f126055784f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f126055aa28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f12605a85d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f1260559b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f126061d21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f12606e35fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1231776fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b123184519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55b123191e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55b12329cb2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55b12312ed05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55b12317b7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55b123179929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b123184519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b123175128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55b123191ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b12319244c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55b12325510e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b12317c77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1231776fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55b123191dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b1231776fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b123184519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b1231745c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b1231847c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b123174312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b123184519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b123175128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b123173094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b123172d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b123172d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b12322007b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55b12324cfca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55b123249353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b12324116a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b12324105c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b123240297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b123213f07]
=================================
2023-09-20 07:28:54,600 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:38579
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd689bc4100, tag: 0xf59f0b64543dfb8d, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:54,698 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:54,735 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:38311
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb361924100, tag: 0x4a539c4eb14acc2, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:54,826 - distributed.nanny - WARNING - Restarting worker
[dgx13:80140:0:80140] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80140) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f771d467e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f771d468084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f771d46824a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f77c1bce420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f771d4e9317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f771d511a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f771d42084f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f771d423a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f771d4715d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f771d422b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f771d4e621a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f771d5ac5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ad547566fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ad54763519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55ad54770e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55ad5487bb2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55ad5470dd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55ad5475a7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55ad54758929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ad54763519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ad54754128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55ad54770ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55ad5477144c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55ad5483410e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55ad5475b77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ad547566fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55ad54770dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55ad547566fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ad54763519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55ad547535c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55ad547637c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55ad54753312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55ad54763519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55ad54754128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55ad54752094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55ad54751d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55ad54751d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55ad547ff07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55ad5482bfca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55ad54828353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55ad5482016a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55ad5482005c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55ad5481f297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55ad547f2f07]
=================================
[dgx13:80134:0:80134] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80134) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f5f0767ee8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7f5f0767f084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7f5f0767f24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f5fabde4420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f5f07700317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f5f07728a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7f5f0763784f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7f5f0763aa28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f5f076885d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f5f07639b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f5f076fd21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f5f077c35fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0b5ebb6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0b5ec8519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55c0b5f6b162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f5f2c88e1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55c0b5ec077c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55c0b5e72d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55c0b5ebf7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55c0b5ebd929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0b5ec8519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55c0b5eb9128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55c0b5ed5ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55c0b5ed644c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55c0b5f9910e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55c0b5ec077c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0b5ebb6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55c0b5ed5dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0b5ebb6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0b5ec8519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0b5eb85c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0b5ec87c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55c0b5eb8312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0b5ec8519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55c0b5eb9128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0b5eb7094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55c0b5eb6d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55c0b5eb6d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55c0b5f6407b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55c0b5f90fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55c0b5f8d353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55c0b5f8516a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55c0b5f8505c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55c0b5f84297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55c0b5f57f07]
=================================
2023-09-20 07:28:55,774 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fb361924140, tag: 0xbc0f58d5ef3db04d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fb361924140, tag: 0xbc0f58d5ef3db04d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-20 07:28:55,774 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fd689bc41c0, tag: 0x4b7cf1003586e650, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fd689bc41c0, tag: 0x4b7cf1003586e650, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-09-20 07:28:55,774 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f68349b0240, tag: 0x3d34746bdfee731f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:55,775 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fb361924240, tag: 0xca066e66af42558a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:55,775 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd689bc4280, tag: 0x6f1c0ae33e53d21d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:55,776 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56973
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f68349b0140, tag: 0xf5220daed0cf2e13, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f68349b0140, tag: 0xf5220daed0cf2e13, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-09-20 07:28:55,828 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:37989
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb361924280, tag: 0x1443e2111c466f5e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:55,828 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:37989
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f68349b0280, tag: 0xed3c786c3c495355, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:55,845 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:55,911 - distributed.nanny - WARNING - Restarting worker
[dgx13:80291:0:80291] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80291) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd0b8185e8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7fd0b8186084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7fd0b818624a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fd15877b420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fd0b8207317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fd0b822fa1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7fd0b813e84f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7fd0b8141a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fd0b818f5d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fd0b8140b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fd0b820421a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fd0b82ca5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d0bdb5e6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d0bdb6b519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55d0bdb78e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55d0bdc83b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55d0bdb15d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55d0bdb627f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55d0bdb60929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d0bdb6b519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d0bdb5c128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55d0bdb78ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55d0bdb7944c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55d0bdc3c10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55d0bdb6377c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d0bdb5e6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55d0bdb78dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55d0bdb5e6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d0bdb6b519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55d0bdb5b5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55d0bdb6b7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55d0bdb5b312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55d0bdb6b519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55d0bdb5c128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55d0bdb5a094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55d0bdb59d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55d0bdb59d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55d0bdc0707b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55d0bdc33fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55d0bdc30353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55d0bdc2816a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55d0bdc2805c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55d0bdc27297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55d0bdbfaf07]
=================================
2023-09-20 07:28:57,880 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:44807
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd689bc4280, tag: 0x87bbf92217f3f0d0, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,037 - distributed.nanny - WARNING - Restarting worker
[dgx13:80295:0:80295] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80295) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff36cadae8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7ff36cadb084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7ff36cadb24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff40d0e6420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7ff36cb5c317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7ff36cb84a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7ff36ca9384f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7ff36ca96a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7ff36cae45d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7ff36ca95b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7ff36cb5921a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7ff36cc1f5fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b98c1736fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b98c180519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55b98c18de83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55b98c298b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55b98c12ad05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55b98c1777f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55b98c175929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b98c180519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b98c171128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55b98c18dccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b98c18e44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55b98c25110e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b98c17877c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b98c1736fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55b98c18ddac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b98c1736fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b98c180519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b98c1705c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b98c1807c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b98c170312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b98c180519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b98c171128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b98c16f094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b98c16ed68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b98c16ed19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b98c21c07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55b98c248fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55b98c245353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b98c23d16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b98c23d05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b98c23c297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b98c20ff07]
=================================
2023-09-20 07:28:58,620 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,621 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,634 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,634 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,637 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 0, 2)}, 'who': 'ucx://127.0.0.1:40095', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 0, 2)}, 'who': 'ucx://127.0.0.1:40095', 'reply': True})
2023-09-20 07:28:58,642 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 0, 2)}, 'who': 'ucx://127.0.0.1:40095', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 0, 2)}, 'who': 'ucx://127.0.0.1:40095', 'reply': True})
2023-09-20 07:28:58,654 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 2, 0)}, 'who': 'ucx://127.0.0.1:59939', 'reply': True}
2023-09-20 07:28:58,660 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,660 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,680 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,680 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,685 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3, 1)}, 'who': 'ucx://127.0.0.1:44809', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3, 1)}, 'who': 'ucx://127.0.0.1:44809', 'reply': True})
2023-09-20 07:28:58,690 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3, 1)}, 'who': 'ucx://127.0.0.1:44809', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3, 1)}, 'who': 'ucx://127.0.0.1:44809', 'reply': True})
2023-09-20 07:28:58,693 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 4, 3)}, 'who': 'ucx://127.0.0.1:40095', 'reply': True}
2023-09-20 07:28:58,762 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:58,856 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33191
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #064] ep: 0x7fd689bc4140, tag: 0xe615a07264526776, nbytes: 1152, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #064] ep: 0x7fd689bc4140, tag: 0xe615a07264526776, nbytes: 1152, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:58,859 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:37131
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f68349b0240, tag: 0xd2f4228632e89f7f, nbytes: 100001608, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,860 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 320, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f68349b0200 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,864 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #063] ep: 0x7fd689bc4180, tag: 0x8840ab7ae453d8be, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #063] ep: 0x7fd689bc4180, tag: 0x8840ab7ae453d8be, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
[dgx13:80303:0:80303] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80303) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa0f421be8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7fa0f421c084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7fa0f421c24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fa1867f9420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fa0f429d317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fa0f42c5a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7fa0f41d484f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7fa0f41d7a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fa0f42255d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fa0f41d6b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fa0f429a21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fa0f43605fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55678f1776fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55678f184519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55678f191e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55678f29cb2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55678f12ed05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55678f17b7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55678f179929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55678f184519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55678f175128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55678f191ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55678f19244c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55678f25510e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55678f17c77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55678f1776fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55678f191dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55678f1776fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55678f184519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55678f1745c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55678f1847c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55678f174312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55678f184519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55678f175128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55678f173094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55678f172d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55678f172d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55678f22007b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55678f24cfca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55678f249353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55678f24116a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55678f24105c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55678f240297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55678f213f07]
=================================
2023-09-20 07:28:58,900 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44809
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #059] ep: 0x7fb361924280, tag: 0x9c2720a13bd63b86, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #059] ep: 0x7fb361924280, tag: 0x9c2720a13bd63b86, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:58,900 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:37131
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feb2d8862c0, tag: 0x8f29e1733c6de8e4, nbytes: 100012536, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,901 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:37131
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb3619242c0, tag: 0x3092d1233223e260, nbytes: 99989056, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,904 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #064] ep: 0x7fb361924200, tag: 0x8840ab7ae453d8be, nbytes: 99977344, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,904 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #046] ep: 0x7fb361924180, tag: 0x4389ea0add1bd6b0, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #046] ep: 0x7fb361924180, tag: 0x4389ea0add1bd6b0, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:58,905 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #047] ep: 0x7fd689bc4200, tag: 0x4389ea0add1bd6b0, nbytes: 99998536, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,906 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 320, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7feb2d886200 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,922 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,923 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,933 - distributed.worker - ERROR - ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 6, 6)}, 'who': 'ucx://127.0.0.1:33191', 'reply': True})
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
KeyError: 'status'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2863, in get_data_from_worker
    raise ValueError("Unexpected response", response)
ValueError: ('Unexpected response', {'op': 'get_data', 'keys': {('split-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 6, 6)}, 'who': 'ucx://127.0.0.1:33191', 'reply': True})
2023-09-20 07:28:58,941 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0, 4)}, 'who': 'ucx://127.0.0.1:59939', 'reply': True}
2023-09-20 07:28:58,944 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44809
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #039] ep: 0x7fd689bc42c0, tag: 0x39ffa803bfc58755, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #039] ep: 0x7fd689bc42c0, tag: 0x39ffa803bfc58755, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:58,945 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 320, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7feb2d886240 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:58,983 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,983 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:58,986 - distributed.worker - ERROR - tuple indices must be integers or slices, not str
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
TypeError: tuple indices must be integers or slices, not str
2023-09-20 07:28:59,011 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,011 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx13:80306:0:80306] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  80306) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7efe353abe8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c084) [0x7efe353ac084]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c24a) [0x7efe353ac24a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7efed99ae420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7efe3542d317]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7efe35455a1d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2084f) [0x7efe3536484f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a28) [0x7efe35367a28]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7efe353b55d9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7efe35366b3d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7efe3542a21a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7efe354f05fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55f3e422a6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f3e4237519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55f3e42da162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7efe5a4581e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f3e422f77c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55f3e41e1d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55f3e422e7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55f3e422c929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f3e4237519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55f3e4228128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55f3e4244ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55f3e424544c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55f3e430810e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55f3e422f77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55f3e422a6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55f3e4244dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55f3e422a6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f3e4237519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55f3e42275c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55f3e42377c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55f3e4227312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55f3e4237519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55f3e4228128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55f3e4226094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55f3e4225d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f3e4225d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f3e42d307b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55f3e42fffca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55f3e42fc353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55f3e42f416a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55f3e42f405c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55f3e42f3297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55f3e42c6f07]
=================================
2023-09-20 07:28:59,111 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:49857
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd689bc41c0, tag: 0x299abfbcd30dcd2e, nbytes: 99961104, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,116 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:49857
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feb2d886300, tag: 0x7289798ad480ef40, nbytes: 99981272, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,164 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:59,168 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,169 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,171 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 6)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           633333   8308368
0           528688  11971113
0           895124  94466891
0           890094  40966262
0           668486  82846875
...            ...       ...
0        799934862  51552294
0        799945995  89274298
0        799835737  94080408
0        799963643  41859212
0        799848540   1621721

[12498811 rows x 2 columns],                key   payload
shuffle                     
1           632492   1678019
1           233002  19318524
1           482395  96093444
1          1281442   5102575
1           113430  51212148
...            ...       ...
1        799856651  99524170
1        799842357  22106071
1        799956411  38005761
1        799842360  25657850
1        799957499  89353811

[12498510 rows x 2 columns],                key   payload
shuffle                     
2           118265  56713707
2           356403  35594460
2            85807  18487666
2           762905  49061420
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-09-20 07:28:59,183 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,184 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,186 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:49857
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f68349b02c0, tag: 0x85425b95a12782dc, nbytes: 99954360, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,192 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44809
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 358, in read
    raise CommClosedError("Connection closed by writer")
distributed.comm.core.CommClosedError: Connection closed by writer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('Connection closed by writer')
2023-09-20 07:28:59,192 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feb2d886300, tag: 0x9bf8d00ca4f7e69a, nbytes: 99963296, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,193 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #008] ep: 0x7fb361924300, tag: 0xecd0610a184be338, nbytes: 99, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #008] ep: 0x7fb361924300, tag: 0xecd0610a184be338, nbytes: 99, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:59,193 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #009] ep: 0x7fd689bc41c0, tag: 0xecd0610a184be338, nbytes: 100007192, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,222 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,223 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,226 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 358, in read
    raise CommClosedError("Connection closed by writer")
distributed.comm.core.CommClosedError: Connection closed by writer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('Connection closed by writer')
2023-09-20 07:28:59,226 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:44809
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #101] ep: 0x7fd689bc4100, tag: 0xe2c2d1d66af65b4b, nbytes: 99961104, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,304 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:46303
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb361924200, tag: 0xf3e59de642635b43, nbytes: 100025496, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,304 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59939 -> ucx://127.0.0.1:46303
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fd689bc4200, tag: 0x9ddbe9a6d1062e53, nbytes: 99999016, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,305 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44809 -> ucx://127.0.0.1:46303
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7feb2d886200, tag: 0x3b57b39c3fde7046, nbytes: 100015992, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,319 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,319 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,322 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1069, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1784, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': {('split-simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6, 0)}, 'who': 'ucx://127.0.0.1:59939', 'reply': True}
2023-09-20 07:28:59,349 - distributed.nanny - WARNING - Restarting worker
2023-09-20 07:28:59,418 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 7)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           635658  15174754
0           637651  74776719
0           837375  36527912
0           714046  45893216
0           639877  70250947
...            ...       ...
0        799856173  48524387
0        799994646  82499186
0        799996271   2989445
0        799968199  91801035
0        799871695  24191488

[12498151 rows x 2 columns],                key   payload
shuffle                     
1           447487  12085548
1           299742  74720457
1           403073  33962301
1          1281466  77072865
1           235343  25598391
...            ...       ...
1        799957496  17050520
1        799861947   4591595
1        799879877  76407496
1        799939858  21206413
1        799932721  36089478

[12498591 rows x 2 columns],                key   payload
shuffle                     
2           155529  77462328
2           300542  26175729
2            98198  97648767
2           756371  40902723
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-09-20 07:28:59,420 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:46303
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f68349b0200, tag: 0x5485fc56f613447d, nbytes: 100016008, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,422 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:33191
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 358, in read
    raise CommClosedError("Connection closed by writer")
distributed.comm.core.CommClosedError: Connection closed by writer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('Connection closed by writer')
2023-09-20 07:28:59,424 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33191 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7f68349b0240, tag: 0x1fb2d2a45355d27d, nbytes: 100048904, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,426 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 364, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #009] ep: 0x7fd689bc42c0, tag: 0xb2ad5cbf5d90de77, nbytes: 24, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #009] ep: 0x7fd689bc42c0, tag: 0xb2ad5cbf5d90de77, nbytes: 24, type: <class 'numpy.ndarray'>>: Message truncated")
2023-09-20 07:28:59,426 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #021] ep: 0x7fb3619242c0, tag: 0xb2ad5cbf5d90de77, nbytes: 100059872, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,476 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,477 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,488 - distributed.core - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 381, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
2023-09-20 07:28:59,488 - distributed.worker - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 381, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
2023-09-20 07:28:59,498 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40095
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 358, in read
    raise CommClosedError("Connection closed by writer")
distributed.comm.core.CommClosedError: Connection closed by writer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('Connection closed by writer')
2023-09-20 07:28:59,498 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40095 -> ucx://127.0.0.1:59939
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fb3619242c0, tag: 0xa10361f780c97cd1, nbytes: 100059872, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-20 07:28:59,521 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,522 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,541 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,542 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:28:59,767 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  _concat
args:      ([                key   payload
32334     821080402  94173022
23142     869398573  87491448
25796     850077652  48187587
123522    607590136   2637526
18946     841904117  56130154
...             ...       ...
99996988  844100109  83532197
99997123  860949573  61585734
99997135  815795281  43661817
99997142  105310587  84921610
99997143  500085153  22003078

[12498923 rows x 2 columns],                 key   payload
114312    419164321  80245327
105025    217831506  80654335
110790    926951770  31016391
26348     969158452  63713728
111656    962367610  75720935
...             ...       ...
99991920  900994318  27945994
99991927  903527893  21107716
99991928  940090323  14461270
99991930  953391229  27809493
99991933  917276692  41455525

[12501128 rows x 2 columns],                  key   payload
15558       29274097  55558750
64614     1013849231  70429740
11915     1055739578  57599926
94435     1056089916   4793708
5283      1035578171  79974591
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-09-20 07:29:00,001 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:29:00,001 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-09-20 07:29:01,274 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 2)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           644980  38481088
0           506222  97905634
0           844428  87270621
0           627695  32011625
0           479200   7203372
...            ...       ...
0        799899788  14483789
0        799964995  86913068
0        799824023  91731545
0        799956452  80606723
0        799955204   1765667

[12497244 rows x 2 columns],                key   payload
shuffle                     
1           401342  53705900
1           292428  44499489
1           566893   5889397
1          1256372  97096083
1           126410  74222231
...            ...       ...
1        799958527  23948834
1        799985623  31846492
1        799884863  42648409
1        799863979  97756727
1        799848523  41951291

[12500558 rows x 2 columns],                key   payload
shuffle                     
2            93592  40055944
2           331284  50385945
2            67923  45397251
2           738976  70405989
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
