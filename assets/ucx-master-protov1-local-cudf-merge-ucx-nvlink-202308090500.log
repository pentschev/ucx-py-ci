2023-08-09 05:52:25,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:25,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:25,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:68676:0:68676] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68676) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe6a4d25ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fe6a4d25ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fe6a4d260aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe7365a8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe6a4da56f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe6a4dcda49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fe6a4cdf45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fe6a4ce2548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe6a4d2f399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe6a4ce165d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe6a4da252a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fe6a4e5717a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5567be66fb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5567be660112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5567be66ac05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5567be67f70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fe6b71222fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5567be6632bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5567be616817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5567be661f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5567be65fd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5567be66ac05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5567be65efa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5567be678935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5567be679104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5567be73ffc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5567be6632bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5567be65e1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5567be678c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5567be65e1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5567be66ac05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5567be65a81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5567be66aef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5567be65a568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5567be66ac05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5567be65b3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5567be65927a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5567be658f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5567be658eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5567be7098bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5567be737adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5567be733c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5567be72b7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5567be72b6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5567be72a8a2]
=================================
2023-08-09 05:52:34,973 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:59339 -> ucx://127.0.0.1:56079
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f12e0517100, tag: 0x6458a50842f5b234, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:34,973 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51967 -> ucx://127.0.0.1:56079
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f057561f100, tag: 0xdea38d5ee09e81c1, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:34,973 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57529 -> ucx://127.0.0.1:56079
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f64719d5100, tag: 0x1b347744a71471ee, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:34,973 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41467 -> ucx://127.0.0.1:56079
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc661cf2100, tag: 0x63384e419d1cd6e6, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:34,973 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34103 -> ucx://127.0.0.1:56079
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fb711e40100, tag: 0x1adb4caa4fc74409, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-795' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-09 05:52:35,051 - distributed.nanny - WARNING - Restarting worker
[dgx13:68687:0:68687] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68687) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f12e07ecced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f12e07ecee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f12e07ed0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f1372069420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f12e086c6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f12e0894a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f12e07a645f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f12e07a9548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f12e07f6399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f12e07a865d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f12e086952a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f12e091e17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5568eeb84b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5568eeb75112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5568eeb7fc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5568eeb9470e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f12f2be22fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5568eeb782bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5568eeb2b817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5568eeb76f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5568eeb74d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5568eeb7fc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5568eeb73fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5568eeb8d935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5568eeb8e104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5568eec54fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5568eeb782bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5568eeb731bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5568eeb8dc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5568eeb731bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5568eeb7fc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5568eeb6f81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5568eeb7fef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5568eeb6f568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5568eeb7fc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5568eeb703cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5568eeb6e27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5568eeb6df07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5568eeb6deb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5568eec1e8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5568eec4cadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5568eec48c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5568eec407ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5568eec406bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5568eec3f8a2]
=================================
2023-08-09 05:52:35,401 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34103 -> ucx://127.0.0.1:59339
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb711e40100, tag: 0x414ad22756703cf2, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:35,485 - distributed.nanny - WARNING - Restarting worker
[dgx13:68672:0:68672] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68672) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc668084ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fc668084ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fc6680850aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc7076d2420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc661f796f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc661fa1a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fc66803e45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fc668041548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc66808e399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc66804065d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc661f7652a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fc6680e517a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55e649d9cb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55e649d8d112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e649d97c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55e649da5a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55e649eb59b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55e649d43817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55e649d8ef83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55e649d8cd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e649d97c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55e649d8bfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55e649da5935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55e649da6104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55e649e6cfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e649d902bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e649d8b1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55e649da5c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e649d8b1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e649d97c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e649d8781b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e649d97ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55e649d87568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e649d97c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55e649d883cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e649d8627a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55e649d85f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e649d85eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e649e368bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55e649e64adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55e649e60c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55e649e587ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55e649e586bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55e649e578a2]
=================================
[dgx13:68696:0:68696] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68696) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f05758e2ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f05758e2ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f05758e30aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f06191b8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f05759626f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f057598aa49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f057589c45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f057589f548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f05758ec399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f057589e65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f057595f52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f0575a1417a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5645b2757b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5645b2748112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5645b2752c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5645b276770e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f060c0a72fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5645b274b2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5645b26fe817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5645b2749f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5645b2747d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5645b2752c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5645b2746fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5645b2760935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5645b2761104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5645b2827fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5645b274b2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5645b27461bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5645b2760c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5645b27461bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5645b2752c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5645b274281b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5645b2752ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5645b2742568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5645b2752c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5645b27433cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5645b274127a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5645b2740f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5645b2740eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5645b27f18bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5645b281fadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5645b281bc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5645b28137ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5645b28136bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5645b28128a2]
=================================
[dgx13:68690:0:68690] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68690) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb714113ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fb714113ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fb7141140aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb7b39e2420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fb7141936f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fb7141bba49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fb7140cd45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fb7140d0548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb71411d399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fb7140cf65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fb71419052a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fb71424517a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x559b1cf38b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x559b1cf29112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b1cf33c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x559b1cf41a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x559b1d0519b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x559b1cedf817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x559b1cf2af83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x559b1cf28d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b1cf33c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x559b1cf27fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x559b1cf41935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x559b1cf42104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x559b1d008fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x559b1cf2c2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559b1cf271bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x559b1cf41c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559b1cf271bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b1cf33c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b1cf2381b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b1cf33ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x559b1cf23568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b1cf33c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x559b1cf243cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b1cf2227a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x559b1cf21f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559b1cf21eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559b1cfd28bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x559b1d000adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x559b1cffcc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x559b1cff47ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x559b1cff46bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x559b1cff38a2]
=================================
2023-08-09 05:52:36,078 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51967
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f64719d51c0, tag: 0xebc4ee621ded8367, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f64719d51c0, tag: 0xebc4ee621ded8367, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-09 05:52:36,083 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57529 -> ucx://127.0.0.1:41467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f64719d5280, tag: 0x5f8209cb53d7dec2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,084 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f64719d5140, tag: 0xf9fca84c524621a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f64719d5140, tag: 0xf9fca84c524621a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-09 05:52:36,083 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51967
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-09 05:52:36,108 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49833 -> ucx://127.0.0.1:51967
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe570508300, tag: 0x4a709749d731e6c8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,110 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51967
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fe5705081c0, tag: 0xa7be09875d13c9c0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fe5705081c0, tag: 0xa7be09875d13c9c0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
[dgx13:68684:0:68684] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  68684) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe5707ddced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fe5707ddee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fe5707de0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe602061420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe57085d6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe570885a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fe57079745f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fe57079a548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe5707e7399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe57079965d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe57085a52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fe57090f17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x559b11de6b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x559b11dd7112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b11de1c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x559b11df670e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fe582bd32fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x559b11dda2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x559b11d8d817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x559b11dd8f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x559b11dd6d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b11de1c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x559b11dd5fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x559b11def935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x559b11df0104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x559b11eb6fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x559b11dda2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559b11dd51bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x559b11defc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559b11dd51bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b11de1c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559b11dd181b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559b11de1ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x559b11dd1568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559b11de1c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x559b11dd23cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559b11dd027a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x559b11dcff07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559b11dcfeb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559b11e808bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x559b11eaeadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x559b11eaac24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x559b11ea27ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x559b11ea26bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x559b11ea18a2]
=================================
2023-08-09 05:52:36,133 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57319 -> ucx://127.0.0.1:34103
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff7982cf180, tag: 0xf2e677e015979b74, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,150 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34103
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff7982cf280, tag: 0x4377649e8447b7bd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff7982cf280, tag: 0x4377649e8447b7bd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-09 05:52:36,153 - distributed.nanny - WARNING - Restarting worker
2023-08-09 05:52:36,151 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-08-09 05:52:36,205 - distributed.nanny - WARNING - Restarting worker
2023-08-09 05:52:36,206 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57529 -> ucx://127.0.0.1:51967
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f64719d52c0, tag: 0xefab0651079f9cb, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,206 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57529 -> ucx://127.0.0.1:34103
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f64719d5240, tag: 0xb445a827cdf59e9b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,207 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34103
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f64719d5100, tag: 0x2b286c3c66b0014a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f64719d5100, tag: 0x2b286c3c66b0014a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-09 05:52:36,251 - distributed.nanny - WARNING - Restarting worker
2023-08-09 05:52:36,365 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49833
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f64719d5180, tag: 0xc3dca0b14dafba45, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f64719d5180, tag: 0xc3dca0b14dafba45, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-09 05:52:36,409 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57319 -> ucx://127.0.0.1:49833
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff7982cf1c0, tag: 0x8af29e28feaef382, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,411 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57319 -> ucx://127.0.0.1:41467
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff7982cf100, tag: 0x77083df4c557a15f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:36,412 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49833
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff7982cf300, tag: 0x7537d97ff21b67c5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff7982cf300, tag: 0x7537d97ff21b67c5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-09 05:52:36,460 - distributed.nanny - WARNING - Restarting worker
2023-08-09 05:52:36,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:36,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:37,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:37,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:37,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:37,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:37,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:37,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:37,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:37,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:38,003 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-09 05:52:38,003 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-09 05:52:38,026 - distributed.worker - WARNING - Compute Failed
Key:       ('sort_index-f363caeac9155e0cf6fe53afdb3b7d89', 0)
Function:  subgraph_callable-a9314109-b10f-4044-aaed-6a321697
args:      (                key  shuffle   payload  _partitions
0             52744        0  96332222            0
1             52745        0   2557598            0
2             52747        0  26227782            0
3             52755        0  23567156            0
4             32391        0   6074768            0
...             ...      ...       ...          ...
99999995  799954620        0  48293198            0
99999996  799954628        0  63632058            0
99999997  799954630        0  92154666            0
99999998  799999219        0  32857140            0
99999999  799999059        0  34654629            0

[100000000 rows x 4 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-09 05:52:38,027 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:57319
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 357, in read
    header_fmt = nframes * "?" + nframes * "Q"
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: MemoryError()
2023-08-09 05:52:38,027 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:57319 -> ucx://127.0.0.1:57529
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #095] ep: 0x7ff7982cf200, tag: 0x3010f77f5f4fa853, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-09 05:52:38,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-09 05:52:38,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-09 05:52:38,300 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 2)
Function:  <dask.layers.CallableLazyImport object at 0x7f5fcc
args:      ([               key  shuffle   payload  _partitions
0            52739        2  94885855            2
1            52742        2  94899210            2
2            52754        2  55881904            2
3            52757        2  83215546            2
4            32385        2  65668444            2
...            ...      ...       ...          ...
12499995  99967365        2  18359448            2
12499996  99967367        2   4647581            2
12499997  99967372        2  70137354            2
12499998  99967381        2  14692438            2
12499999  99967383        2   9472685            2

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100084546        2  30901531            2
1         100023136        2  73401992            2
2         100123561        2  94364227            2
3         100084548        2  15329016            2
4         100123565        2  67639148            2
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-09 05:52:38,451 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 3)
Function:  <dask.layers.CallableLazyImport object at 0x7f5fcc
args:      ([               key  shuffle   payload  _partitions
0            52767        3  39708266            3
1            32388        3  35866365            3
2            32412        3  72309802            3
3            32414        3  51737892            3
4            15073        3  80571841            3
...            ...      ...       ...          ...
12499995  99974920        3  63583956            3
12499996  99974930        3  15192989            3
12499997  99968477        3  20810659            3
12499998  99967371        3  63280785            3
12499999  99967384        3   4987887            3

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100084544        3  65748849            3
1         100023146        3  58713799            3
2         100123566        3  50230352            3
3         100084549        3  80994397            3
4         100123571        3  66724617            3
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-09 05:52:38,886 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7f5fcc
args:      ([               key  shuffle   payload  _partitions
0            52740        7  30053095            7
1            52741        7  65540634            7
2            52743        7  60137393            7
3            52748        7  82788815            7
4            32387        7  21827905            7
...            ...      ...       ...          ...
12499995  99974932        7  38708103            7
12499996  99967366        7  12383560            7
12499997  99967373        7  70055179            7
12499998  99967377        7  19092043            7
12499999  99967380        7  97054987            7

[12500000 rows x 4 columns],                 key  shuffle   payload  _partitions
0         100084545        7  12057364            7
1         100023137        7  72962802            7
2         100123558        7  79609979            7
3         100084547        7   2017571            7
4         100123564        7  74633331            7
...             ...      ...       ...      
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-09 05:52:39,038 - distributed.worker - WARNING - Compute Failed
Key:       ('sort_index-f363caeac9155e0cf6fe53afdb3b7d89', 6)
Function:  subgraph_callable-a9314109-b10f-4044-aaed-6a321697
args:      (                key  shuffle   payload  _partitions
0             52736        6  86125730            6
1             52737        6  53010295            6
2             52746        6  62535632            6
3             52749        6   5297625            6
4             32384        6  63531042            6
...             ...      ...       ...          ...
99999995  799999209        6  58779528            6
99999996  799999225        6   2866308            6
99999997  799999226        6  33833761            6
99999998  799999057        6  89778430            6
99999999  799999071        6  80440702            6

[100000000 rows x 4 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
