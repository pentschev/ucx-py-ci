<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>junit-dask-cuda.xml</title>
    <style type="text/css">
        body {
    background-color: white;
    padding-bottom: 20em;
    margin: 0;
    min-height: 15cm;
}

h1, h2, h3, h4, h5, h6, h7 {
    font-family: sans-serif;
}

h1 {
    background-color: #007acc;
    color: white;
    padding: 3mm;
    margin-top: 0;
    margin-bottom: 1mm;
}

.footer {
    font-style: italic;
    font-size: small;
    text-align: right;
    padding: 1em;
}

.testsuite {
    padding-bottom: 2em;
    margin-left: 1em;
}

.proplist {
    width: 100%;
    margin-bottom: 2em;
    border-collapse: collapse;
    border: 1px solid grey;
}

.proplist th {
    background-color: silver;
    width: 5em;
    padding: 2px;
    padding-right: 1em;
    text-align: left;
}

.proplist td {
    padding: 2px;
}

.index-table {
    width: 90%;
    margin-left: 1em;
}

.index-table td {
    vertical-align: top;
    width: 50%;
}

.failure-index {

}

.toc {
    margin-bottom: 2em;
    font-family: monospace;
}

.stdio, pre {
    min-height: 1em;
    background-color: #1e1e1e;
    color: silver;
    padding: 0.5em;
}
.tdpre {
    background-color: #1e1e1e;
}

.test {
    margin-left: 0.5cm;
}

.outcome {
    border-left: 1em;
    padding: 2px;
}

.outcome-failed {
    border-left: 1em solid lightcoral;
}

.outcome-passed {
    border-left: 1em solid lightgreen;
}

.outcome-skipped {
    border-left: 1em solid lightyellow;
}

.stats-table {
}

.stats-table td {
    min-width: 4em;
    text-align: right;
}

.stats-table .failed {
    background-color: lightcoral;
}

.stats-table .passed {
    background-color: lightgreen;
}

.matrix-table {
    table-layout: fixed;
    border-spacing: 0;
    width: available;
    margin-left: 1em;
}

.matrix-table td {
    vertical-align: center;
}

.matrix-table td:last-child {
    width: 0;
}

.matrix-table tr:hover {
    background-color: yellow;
}

.matrix-axis-name {
    white-space: nowrap;
    padding-right: 0.5em;
    border-left: 1px solid black;
    border-top: 1px solid black;
    text-align: right;
}

.matrix-axis-line {
    border-left: 1px solid black;
    width: 0.5em;
}

.matrix-classname {
    text-align: left;
    width: 100%;
    border-top: 2px solid grey;
    border-bottom: 1px solid silver;
}

.matrix-casename {
    text-align: left;
    font-weight: normal;
    font-style: italic;
    padding-left: 1em;
    border-bottom: 1px solid silver;
}

.matrix-result {
    display: block;
    width: 1em;
    text-align: center;
    padding: 1mm;
    margin: 0;
}

.matrix-result-combined {
    white-space: nowrap;
    padding-right: 0.2em;
    text-align: right;
}

.matrix-result-failed {
    background-color: lightcoral;
}

.matrix-result-passed {
    background-color: lightgreen;
}

.matrix-result-skipped {
    background-color: lightyellow;
}

.matrix-even {
    background-color: lightgray;
}
    </style>
</head>
<body>
    
<h1>
    Test Report : junit-dask-cuda.xml
</h1>
<a id="toc"></a>
<table class="index-table">
    <tr>
        <td>
            <ul class="toc">
            
                
                <li>dask_cuda.tests.test_cudf_builtin_spilling
                <ul>
                    
                    <li><a href="#b3a5d821-01cc-4651-89fa-ecc588e899fc">test_is_spillable_object_when_cudf_spilling_disabled</a></li>
                    
                    <li><a href="#64f35124-02ee-426a-9f46-da7f8894ee65">test_is_spillable_object_when_cudf_spilling_enabled</a></li>
                    
                    <li><a href="#da0a3cd4-bfbc-4896-bdf8-fd253b037b28">test_device_host_file_when_cudf_spilling_is_disabled</a></li>
                    
                    <li><a href="#bced51c7-5753-4552-9ff3-b5bf7a5aaf45">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#7ebbe196-8b0d-4d02-bcb5-c3a9b7d7de44">test_proxify_host_file</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dask_cuda_worker
                <ul>
                    
                    <li><a href="#93ee648b-188e-4fe6-87d5-14e8c90029fe">test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#47b626aa-15e2-4123-8f7a-06d878ebfca9">test_rmm_pool</a></li>
                    
                    <li><a href="#f4f435be-07a8-4678-a1ea-78c42c75d01f">test_rmm_managed</a></li>
                    
                    <li><a href="#850ba467-c2f6-4f6e-beca-e200b1ea7b4a">test_rmm_async</a></li>
                    
                    <li><a href="#cf2113f8-4f91-4c27-8264-63ca2001de08">test_rmm_logging</a></li>
                    
                    <li><a href="#6dc4a151-396c-4aa2-82fd-d1b2b9c4dcc0">test_dashboard_address</a></li>
                    
                    <li><a href="#d567db0b-cdbc-4699-9971-72ca220c7b8b">test_unknown_argument</a></li>
                    
                    <li><a href="#660f7388-0498-4d2d-acd2-1a77c5af67fd">test_pre_import</a></li>
                    
                    <li><a href="#4024643f-2a02-4a9f-bed4-8f237c11a18e">test_pre_import_not_found</a></li>
                    
                    <li><a href="#0093bf43-047c-489f-b083-755e7be39989">test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    <li><a href="#75d589ca-f627-480a-a7b9-2c9cbe5cbd04">test_cuda_visible_devices_uuid</a></li>
                    
                    <li><a href="#6e3103e9-4711-43ff-a2ac-e5dd02a506b6">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#8b5d170b-5989-428e-b7e3-806cf14383e3">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#937ab6df-eda5-4123-bf8b-ba44817f573b">test_worker_fraction_limits</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_device_host_file
                <ul>
                    
                    <li><a href="#5e945617-fa51-4f02-81b6-377e46fe5c98">test_device_host_file_short[array_size_range0-1-1]</a></li>
                    
                    <li><a href="#dd42e68a-9999-46d6-9c6f-61c8a1a0175d">test_device_host_file_short[array_size_range0-1-10]</a></li>
                    
                    <li><a href="#4ae93132-d1bb-465a-9cd2-254e8fc3cc3b">test_device_host_file_short[array_size_range0-1-100]</a></li>
                    
                    <li><a href="#aeb57b03-284e-447d-8c0f-5de84abb26e9">test_device_host_file_short[array_size_range0-10-1]</a></li>
                    
                    <li><a href="#b6a121b9-6c4d-458f-aa29-6a5c76290784">test_device_host_file_short[array_size_range0-10-10]</a></li>
                    
                    <li><a href="#1371d490-2a2d-4eb8-832c-39399026d7ec">test_device_host_file_short[array_size_range0-10-100]</a></li>
                    
                    <li><a href="#f0a084cb-54bf-4166-a612-3e113486d793">test_device_host_file_short[array_size_range0-100-1]</a></li>
                    
                    <li><a href="#e351399b-7a95-4466-8d53-32da67631526">test_device_host_file_short[array_size_range0-100-10]</a></li>
                    
                    <li><a href="#2f43a561-2a40-4995-add5-b607e957ea37">test_device_host_file_short[array_size_range0-100-100]</a></li>
                    
                    <li><a href="#d97054a4-05db-486b-bad4-b45ba8362911">test_device_host_file_short[array_size_range1-1-1]</a></li>
                    
                    <li><a href="#baac16f7-d412-4345-bd99-7bdd4c4667c7">test_device_host_file_short[array_size_range1-1-10]</a></li>
                    
                    <li><a href="#3e77d9ac-1efe-45e3-8db3-a375aea0a254">test_device_host_file_short[array_size_range1-1-100]</a></li>
                    
                    <li><a href="#0028dde8-226c-430b-8487-3dbfb5a5b98b">test_device_host_file_short[array_size_range1-10-1]</a></li>
                    
                    <li><a href="#85e8dd91-693e-459b-a872-ef96cf600723">test_device_host_file_short[array_size_range1-10-10]</a></li>
                    
                    <li><a href="#02daf457-bb90-4842-afac-ed3cb0d8ca49">test_device_host_file_short[array_size_range1-10-100]</a></li>
                    
                    <li><a href="#58630e36-94cb-47fe-b6fc-d8245e0cb71e">test_device_host_file_short[array_size_range1-100-1]</a></li>
                    
                    <li><a href="#0fd3800f-a629-4bac-9cce-eef826f7e987">test_device_host_file_short[array_size_range1-100-10]</a></li>
                    
                    <li><a href="#a2800a26-9cbc-45df-baa7-8222330da2bc">test_device_host_file_short[array_size_range1-100-100]</a></li>
                    
                    <li><a href="#45588d97-54ed-412d-806f-b13064beb9e0">test_device_host_file_short[array_size_range2-1-1]</a></li>
                    
                    <li><a href="#1bdb84c8-0c50-428c-8937-94e5cd4cd273">test_device_host_file_short[array_size_range2-1-10]</a></li>
                    
                    <li><a href="#7cf53b68-3fa2-4a75-b4a4-f6345c90a0e0">test_device_host_file_short[array_size_range2-1-100]</a></li>
                    
                    <li><a href="#31b8ddf0-c56b-42de-9e8f-2191c768ba57">test_device_host_file_short[array_size_range2-10-1]</a></li>
                    
                    <li><a href="#600aea74-4aaa-49e2-ab78-32153c2198bd">test_device_host_file_short[array_size_range2-10-10]</a></li>
                    
                    <li><a href="#daae5ee3-6bb8-4035-b967-53abcc8d1584">test_device_host_file_short[array_size_range2-10-100]</a></li>
                    
                    <li><a href="#bb9f4365-6e31-49e4-af60-06a18b73657c">test_device_host_file_short[array_size_range2-100-1]</a></li>
                    
                    <li><a href="#ade06dba-c572-413c-9cdf-633e24cf6673">test_device_host_file_short[array_size_range2-100-10]</a></li>
                    
                    <li><a href="#094d987d-5d69-4cab-a0b7-359e40b3a047">test_device_host_file_short[array_size_range2-100-100]</a></li>
                    
                    <li><a href="#50ef0dfb-2564-4429-9011-4d3516b79d60">test_device_host_file_step_by_step</a></li>
                    
                    <li><a href="#c2ed8983-540f-41d5-a096-eadb4e9831f3">test_serialize_cupy_collection[10-0-dict]</a></li>
                    
                    <li><a href="#9c75e091-771b-434e-83c3-13da58bbaea5">test_serialize_cupy_collection[10-0-list]</a></li>
                    
                    <li><a href="#41d13b8b-0170-4341-845d-928f94a69d5f">test_serialize_cupy_collection[10-0-tuple]</a></li>
                    
                    <li><a href="#f367c9cb-0382-445d-98f9-483c74fbea7b">test_serialize_cupy_collection[10-1-dict]</a></li>
                    
                    <li><a href="#b1016065-ff3b-4d5e-8e7b-08ad830cce48">test_serialize_cupy_collection[10-1-list]</a></li>
                    
                    <li><a href="#3a148344-0466-4c2e-8dbe-53fdc2ce0f41">test_serialize_cupy_collection[10-1-tuple]</a></li>
                    
                    <li><a href="#bbf4a080-7d22-402e-8ea0-61eaa9c66f98">test_serialize_cupy_collection[10-3-dict]</a></li>
                    
                    <li><a href="#95bed973-8db1-4f1c-95d5-27eda3d97667">test_serialize_cupy_collection[10-3-list]</a></li>
                    
                    <li><a href="#33a56030-49a5-4df1-8519-c351d3275e09">test_serialize_cupy_collection[10-3-tuple]</a></li>
                    
                    <li><a href="#18343d81-0971-4eb8-a02e-05cb8fe74dbb">test_serialize_cupy_collection[10-6-dict]</a></li>
                    
                    <li><a href="#c97b5c45-8567-40d8-a0a1-04022036289a">test_serialize_cupy_collection[10-6-list]</a></li>
                    
                    <li><a href="#59fd3141-1bc8-43f2-a278-25cce4749911">test_serialize_cupy_collection[10-6-tuple]</a></li>
                    
                    <li><a href="#74440f04-804c-4963-a8a6-b8c180179d27">test_serialize_cupy_collection[value1-0-dict]</a></li>
                    
                    <li><a href="#49b67907-63b1-4758-8551-736048e76317">test_serialize_cupy_collection[value1-0-list]</a></li>
                    
                    <li><a href="#498fff00-0b43-46e7-b211-27584db1e1f8">test_serialize_cupy_collection[value1-0-tuple]</a></li>
                    
                    <li><a href="#0663cd7a-7191-47cf-a666-a980aaf58d35">test_serialize_cupy_collection[value1-1-dict]</a></li>
                    
                    <li><a href="#fe04751d-7300-4684-8301-04ffea673d74">test_serialize_cupy_collection[value1-1-list]</a></li>
                    
                    <li><a href="#ee32acc4-4742-490e-9494-f095e19b0474">test_serialize_cupy_collection[value1-1-tuple]</a></li>
                    
                    <li><a href="#708010b0-9315-49d5-93ff-b4ff2738adb3">test_serialize_cupy_collection[value1-3-dict]</a></li>
                    
                    <li><a href="#1d3e203b-d3c6-40a1-8473-e75fe1e24a74">test_serialize_cupy_collection[value1-3-list]</a></li>
                    
                    <li><a href="#e3aaceb3-f385-40cb-ba87-f8f7755153eb">test_serialize_cupy_collection[value1-3-tuple]</a></li>
                    
                    <li><a href="#69eab2cf-56f4-4c1a-9199-77a0abc31646">test_serialize_cupy_collection[value1-6-dict]</a></li>
                    
                    <li><a href="#3f96415c-90fd-4e9d-9024-962bcb6aec72">test_serialize_cupy_collection[value1-6-list]</a></li>
                    
                    <li><a href="#23d6e1a7-739c-4202-bd34-895f837e06ed">test_serialize_cupy_collection[value1-6-tuple]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_dgx
                <ul>
                    
                    <li><a href="#4db21311-e75e-449c-986e-164ac4510a18">test_default</a></li>
                    
                    <li><a href="#bce2e316-231c-42d5-a3ce-9f19a92952e3">test_tcp_over_ucx</a></li>
                    
                    <li><a href="#9128da95-7bc1-47d9-ba5f-7165b05283c2">test_tcp_only</a></li>
                    
                    <li><a href="#ef7e969d-5da5-4a92-8faf-650d94c7fbc2">test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    <li><a href="#4cb8f194-ae48-46ff-841c-eb260715ed73">test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    <li><a href="#bd38331f-4ec2-4b59-85f9-a0a4a01e7021">test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    <li><a href="#07b90380-9843-4be7-919b-f7ce9d15d2cb">test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    <li><a href="#0f67811c-35ff-4621-97cf-1e23c826b7c3">test_ucx_infiniband_nvlink[params4]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_explicit_comms
                <ul>
                    
                    <li><a href="#c38c28d0-46bb-4187-a6c9-9d5f9a67aeca">test_local_cluster[tcp]</a></li>
                    
                    <li><a href="#9838ea92-9a28-4a6d-8504-694662cbbdfd">test_local_cluster[ucx]</a></li>
                    
                    <li><a href="#2256fb31-5857-43ea-9c10-6a04a5ef5954">test_dataframe_merge_empty_partitions</a></li>
                    
                    <li><a href="#509d524f-688c-487b-bb16-cb573f4b0145">test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    <li><a href="#a5b90c1f-69e9-4a15-9a88-e8f5c163b689">test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    <li><a href="#6ed503ce-ffc8-4c47-8a6f-59798bb7834d">test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    <li><a href="#cbfa2488-8b26-48d8-b6bd-c301e3f19de4">test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    <li><a href="#1ff4b11d-064a-4652-abaa-7bc5836e0477">test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    <li><a href="#588601cb-f39d-435c-a42e-03e7342288df">test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    <li><a href="#6d860f2e-cfdf-4097-bfae-d1ca0461eed6">test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    <li><a href="#3deba6be-fdf1-473a-afd0-50e979f2a40c">test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    <li><a href="#b0904cf7-0c6b-4487-b9a3-577db28a3274">test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    <li><a href="#8c6196a6-60cb-4c31-bf17-2a3b8ac88393">test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    <li><a href="#87ea1c35-0bef-4bae-b0ce-b2e353a8ba63">test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    <li><a href="#2ee67121-4997-4d8b-aa53-96038122339f">test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    <li><a href="#c9ca6770-bdb0-4b0e-98a0-1ba4ed90bd38">test_dask_use_explicit_comms[True]</a></li>
                    
                    <li><a href="#779874fd-681c-4bb5-84b4-49e967c7daf3">test_dask_use_explicit_comms[False]</a></li>
                    
                    <li><a href="#8fc5ef81-6c95-4418-b779-023993be739a">test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    <li><a href="#4eb3e187-5766-4c89-91d1-d956be17cc70">test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    <li><a href="#c919f1ac-29fa-4732-8647-fee800b90cc0">test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    <li><a href="#185a7934-7bf7-43f0-b67d-823f98430f92">test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    <li><a href="#21cd7e81-70d3-429c-917b-db2feeadbdaa">test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    <li><a href="#b7b4340f-6c54-4c36-a562-06c1f0f2d03d">test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    <li><a href="#dfacfea2-d36f-4541-858e-86cc95a45dd3">test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    <li><a href="#39fa94d1-b426-4d92-8fe9-90f5f7dbaa77">test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    <li><a href="#86596f70-0c90-457e-8053-79fbb191e7a6">test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    <li><a href="#cb4051c6-1a8f-4fa6-b0d7-5752dcdff7eb">test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    <li><a href="#0bc88955-d273-40ab-8c20-3a15f69d6ef4">test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    <li><a href="#456fd43b-5e1f-465e-8148-9a9b8b0a662c">test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    <li><a href="#347688ff-7ce2-4412-8b3f-888ce3aaef69">test_jit_unspill[tcp]</a></li>
                    
                    <li><a href="#0814ea3d-f1e5-440c-b815-73551a581f40">test_jit_unspill[ucx]</a></li>
                    
                    <li><a href="#beea52ed-dcd4-4803-a417-c92fd068e7fb">test_lock_workers</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_gds
                <ul>
                    
                    <li><a href="#25b2172f-d3e0-4cd5-bb77-c7e2e250398d">test_gds[True-cupy]</a></li>
                    
                    <li><a href="#dc247585-4d5d-4654-85cd-57fffeb136ae">test_gds[True-cudf]</a></li>
                    
                    <li><a href="#036211f3-b5ce-40ef-96b3-301a9f5e934f">test_gds[True-numba.cuda]</a></li>
                    
                    <li><a href="#99e978dc-fe83-4aa3-9aca-46b25f00c486">test_gds[False-cupy]</a></li>
                    
                    <li><a href="#3f0cf1ba-a666-4dc3-a2ce-a25e3dd82e89">test_gds[False-cudf]</a></li>
                    
                    <li><a href="#e82ba82f-1795-4dd5-9a74-e7fc2bbb0a05">test_gds[False-numba.cuda]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_initialize
                <ul>
                    
                    <li><a href="#29c9c3ca-4691-4255-9262-ff6ee1d58e38">test_initialize_ucx_tcp</a></li>
                    
                    <li><a href="#6fe42911-7f3f-4f26-b738-93e232d3a70c">test_initialize_ucx_nvlink</a></li>
                    
                    <li><a href="#52be3d9c-1836-4951-87a9-031a74d433c3">test_initialize_ucx_infiniband</a></li>
                    
                    <li><a href="#2f59e388-38d3-40a2-b313-4634e43f691c">test_initialize_ucx_all</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_local_cuda_cluster
                <ul>
                    
                    <li><a href="#91800987-006c-4d01-82e4-e137ad94c014">test_local_cuda_cluster</a></li>
                    
                    <li><a href="#09aac0b3-750b-44af-920c-8d520751b963">test_with_subset_of_cuda_visible_devices</a></li>
                    
                    <li><a href="#67fb8676-29c6-4211-9c08-ca46e1de3729">test_ucx_protocol[ucx]</a></li>
                    
                    <li><a href="#6a506768-53f4-4ea6-8e13-856d1f646178">test_ucx_protocol[None]</a></li>
                    
                    <li><a href="#d29baf3d-32a4-4902-99f6-890c93f01e4e">test_ucx_protocol_type_error</a></li>
                    
                    <li><a href="#809c6316-cfbe-4178-8c7f-eaea2e28e8c5">test_n_workers</a></li>
                    
                    <li><a href="#3191c401-244c-4141-8c7d-652497fdcecf">test_threads_per_worker_and_memory_limit</a></li>
                    
                    <li><a href="#fd955e94-5bf4-43f3-94a7-db78fd5b39a7">test_no_memory_limits_cluster</a></li>
                    
                    <li><a href="#f7ef042b-61d7-44d3-9cd0-072f2469ec0e">test_no_memory_limits_cudaworker</a></li>
                    
                    <li><a href="#60909971-089c-47f8-9ba4-113c80bfd5e5">test_all_to_all</a></li>
                    
                    <li><a href="#f6cb16be-fa0c-4757-a078-d3fca7db61d6">test_rmm_pool</a></li>
                    
                    <li><a href="#5c37d540-a21d-432b-8ba3-88c217229b56">test_rmm_maximum_poolsize_without_poolsize_error</a></li>
                    
                    <li><a href="#ab401c94-8f24-43c2-9044-86572ae16d59">test_rmm_managed</a></li>
                    
                    <li><a href="#78353dbb-4111-498b-980a-04023881f65f">test_rmm_async</a></li>
                    
                    <li><a href="#ceb8d151-d53c-4a43-9ddd-9c61f487ce3b">test_rmm_logging</a></li>
                    
                    <li><a href="#71542536-c337-42e3-9861-462eadbc240a">test_pre_import</a></li>
                    
                    <li><a href="#23665cc1-0ef7-4778-b815-b131a6053e57">test_pre_import_not_found</a></li>
                    
                    <li><a href="#49e7996e-8309-4689-acd1-004859beecb6">test_cluster_worker</a></li>
                    
                    <li><a href="#25e402fc-9269-4bdc-8329-45370c99ff4b">test_available_mig_workers</a></li>
                    
                    <li><a href="#dc88c39c-3ec9-4596-8808-ccbaec110230">test_gpu_uuid</a></li>
                    
                    <li><a href="#b5f8041c-73c1-4819-b400-0f5650c59078">test_rmm_track_allocations</a></li>
                    
                    <li><a href="#d2e4f369-c90e-48c6-abe0-99f8a397e7f6">test_get_cluster_configuration</a></li>
                    
                    <li><a href="#d89a5875-40a4-4c17-9b0a-c4601cfcfef8">test_worker_fraction_limits</a></li>
                    
                    <li><a href="#7b218455-ee17-403e-9ffc-296b61be1c47">test_print_cluster_config</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxify_host_file
                <ul>
                    
                    <li><a href="#91ef7c0f-c9b4-4a08-9094-4699bc88b630">test_one_dev_item_limit</a></li>
                    
                    <li><a href="#0834b3da-bdda-445e-93b5-df7557fdbcfe">test_one_item_host_limit</a></li>
                    
                    <li><a href="#f17cb4c1-f9d6-47b4-8c64-52e4fe36527f">test_spill_on_demand</a></li>
                    
                    <li><a href="#6612c77b-4bd3-451e-9d2c-ef7e26391c44">test_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#2a04be7b-c6a6-4530-addc-13ae6e48258a">test_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#4798008a-755c-4be7-8b3e-798a35696eac">test_dataframes_share_dev_mem</a></li>
                    
                    <li><a href="#aab91519-ab97-45e0-ad72-15cb8bf9de75">test_cudf_get_device_memory_objects</a></li>
                    
                    <li><a href="#9d661a9e-a358-459d-a268-77262a67f877">test_externals</a></li>
                    
                    <li><a href="#1620c788-17a9-4ed2-b730-68c7ea9a8c23">test_incompatible_types</a></li>
                    
                    <li><a href="#f66ea6de-6031-424a-84f6-a5274ea93cec">test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    <li><a href="#94419625-aa17-4591-bc79-ac32b7324a6b">test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    <li><a href="#718ead03-8dd1-4a87-8ed7-e3f645beac72">test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    <li><a href="#9e951bf1-b79b-4cbd-9026-f246b4f3cd36">test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    <li><a href="#432d9835-c146-4ee0-bd39-e8680323f2ae">test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    <li><a href="#3206cf4f-66ce-4cd1-b876-a4154f420bf8">test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    <li><a href="#8966f467-b489-4145-8e2c-453fb1b919e1">test_worker_force_spill_to_disk</a></li>
                    
                    <li><a href="#e68da2a8-cf96-401a-8afc-93b3c0a17c95">test_on_demand_debug_info</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_proxy
                <ul>
                    
                    <li><a href="#b11dd1eb-0048-4e56-b385-cc4ed3b7f786">test_proxy_object[None]</a></li>
                    
                    <li><a href="#29b95ccb-c026-454a-9791-51cc80a60a21">test_proxy_object[serializers1]</a></li>
                    
                    <li><a href="#f294c221-0125-4b24-aef5-9bac74ef44af">test_proxy_object[serializers2]</a></li>
                    
                    <li><a href="#bdba3048-ad64-4a4b-af07-f59705405264">test_proxy_object_serializer</a></li>
                    
                    <li><a href="#af0513e1-18bc-4f02-967f-09a4fba50d92">test_double_proxy_object[None-None]</a></li>
                    
                    <li><a href="#c29aa32c-1134-4b9b-b502-fba6ecd8200e">test_double_proxy_object[None-serializers_first1]</a></li>
                    
                    <li><a href="#e4b1c206-2bd5-484f-b1db-37ba29f1ba16">test_double_proxy_object[None-serializers_first2]</a></li>
                    
                    <li><a href="#b6b98723-5b5b-4c3b-8a7c-0203f8405538">test_double_proxy_object[serializers_second1-None]</a></li>
                    
                    <li><a href="#38e80504-a96c-4db6-948a-f300441093c2">test_double_proxy_object[serializers_second1-serializers_first1]</a></li>
                    
                    <li><a href="#3b273e46-dad8-4827-ba57-71071405f5f8">test_double_proxy_object[serializers_second1-serializers_first2]</a></li>
                    
                    <li><a href="#51204997-e0a4-4d88-897a-3f7b826f1f16">test_double_proxy_object[serializers_second2-None]</a></li>
                    
                    <li><a href="#151b58e4-465b-4f31-96ad-c3e109811306">test_double_proxy_object[serializers_second2-serializers_first1]</a></li>
                    
                    <li><a href="#407622ed-15f4-4371-99ef-9ab87879af95">test_double_proxy_object[serializers_second2-serializers_first2]</a></li>
                    
                    <li><a href="#7cd595e6-8a68-4856-bfb9-5dd41941df78">test_proxy_object_of_array[numpy-None]</a></li>
                    
                    <li><a href="#1565a2b6-1318-4fe6-947a-284dd05b58dc">test_proxy_object_of_array[numpy-serializers1]</a></li>
                    
                    <li><a href="#bf5ffe29-0e5c-4760-9001-4571a2e943af">test_proxy_object_of_array[numpy-serializers2]</a></li>
                    
                    <li><a href="#638c3fa2-165e-4b4f-a92e-9be5991f9930">test_proxy_object_of_array[cupy-None]</a></li>
                    
                    <li><a href="#51d7a975-ea1f-4e04-b791-7f807b421a65">test_proxy_object_of_array[cupy-serializers1]</a></li>
                    
                    <li><a href="#f01941d9-25b8-4d13-b00c-0524456dbbf3">test_proxy_object_of_array[cupy-serializers2]</a></li>
                    
                    <li><a href="#798ba2c4-3b48-4d33-9f9e-dd6261eda687">test_proxy_object_of_cudf[None]</a></li>
                    
                    <li><a href="#ba9a7a20-9764-4175-bad0-b256f7524fed">test_proxy_object_of_cudf[serializers1]</a></li>
                    
                    <li><a href="#a8984617-6682-4173-bcd6-ccde46480874">test_proxy_object_of_cudf[serializers2]</a></li>
                    
                    <li><a href="#7a26a656-072b-4a5d-9a75-734df10eda9e">test_serialize_of_proxied_cudf[dask_serializers0-None]</a></li>
                    
                    <li><a href="#5a860195-16b0-424f-ac9d-9164921c2b87">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</a></li>
                    
                    <li><a href="#19a99bd2-5be7-478a-b2e3-9cfee8008ee9">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</a></li>
                    
                    <li><a href="#392b8a40-13a0-475c-8d18-727f850af0b4">test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</a></li>
                    
                    <li><a href="#16be81ee-fb4d-4ae6-9e14-a34d79c49bb4">test_serialize_of_proxied_cudf[dask_serializers1-None]</a></li>
                    
                    <li><a href="#d386a047-4af0-481c-ace8-ec2f66fa9308">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</a></li>
                    
                    <li><a href="#3a87b78c-99ec-49e2-903f-ed08a3785acc">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</a></li>
                    
                    <li><a href="#22c202f1-1d8e-4ac9-b2e3-f4f0513033e1">test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</a></li>
                    
                    <li><a href="#120349fd-2b5c-424b-b396-ec9e85554ba2">test_fixed_attribute_length[numpy]</a></li>
                    
                    <li><a href="#36b05e12-d2fe-4e05-80c0-c9ea00aed108">test_fixed_attribute_length[cupy]</a></li>
                    
                    <li><a href="#c6308f5e-9064-4bf1-b591-4681df4c33d5">test_fixed_attribute_name</a></li>
                    
                    <li><a href="#4339f470-118c-488e-8510-c3d543962451">test_spilling_local_cuda_cluster[True]</a></li>
                    
                    <li><a href="#5cbf05ca-9f32-458d-8efe-8f9a509ff2a9">test_spilling_local_cuda_cluster[False]</a></li>
                    
                    <li><a href="#d4367e28-7b43-481f-9b97-f33a1895d19d">test_serializing_to_disk[obj0]</a></li>
                    
                    <li><a href="#8552c2d7-e0ac-4272-b342-7ac2acf3d8b0">test_serializing_to_disk[obj1]</a></li>
                    
                    <li><a href="#1258b5d5-4d53-4ae2-ae2c-b8c210c39eed">test_multiple_deserializations[dask]</a></li>
                    
                    <li><a href="#99684ad0-c6c4-4547-9d66-fca2c9e18364">test_multiple_deserializations[pickle]</a></li>
                    
                    <li><a href="#c34634ea-0d01-443e-9f03-7cddaddbb7d8">test_multiple_deserializations[disk]</a></li>
                    
                    <li><a href="#a389eaaa-4c7f-4d3e-bebb-812b8ac8fc1b">test_serializing_array_to_disk[numpy-None-10]</a></li>
                    
                    <li><a href="#40eee33b-70a0-40b8-934d-57904683927c">test_serializing_array_to_disk[numpy-None-10000]</a></li>
                    
                    <li><a href="#16984431-ad56-4c0d-8971-21d70f305f36">test_serializing_array_to_disk[numpy-serializers1-10]</a></li>
                    
                    <li><a href="#6f8ceead-0ddc-4a7e-aba4-118f2e2f555c">test_serializing_array_to_disk[numpy-serializers1-10000]</a></li>
                    
                    <li><a href="#e4226a99-510a-45d8-9933-2ba471902b68">test_serializing_array_to_disk[numpy-serializers2-10]</a></li>
                    
                    <li><a href="#cc1f323e-410d-4bd5-b260-f3f990952a3c">test_serializing_array_to_disk[numpy-serializers2-10000]</a></li>
                    
                    <li><a href="#2213d838-79ae-4149-b48f-5b61bb23452b">test_serializing_array_to_disk[numpy-serializers3-10]</a></li>
                    
                    <li><a href="#4871347b-0093-4295-a734-93492a5482b5">test_serializing_array_to_disk[numpy-serializers3-10000]</a></li>
                    
                    <li><a href="#c247d94c-3e0a-4485-bda8-7e2616cc2ade">test_serializing_array_to_disk[numpy-serializers4-10]</a></li>
                    
                    <li><a href="#532993e5-4ca2-460f-8d3f-6241dc88dee4">test_serializing_array_to_disk[numpy-serializers4-10000]</a></li>
                    
                    <li><a href="#7b8a732b-eb54-4089-9e92-272bf8e110ad">test_serializing_array_to_disk[cupy-None-10]</a></li>
                    
                    <li><a href="#2b010dcb-9697-4319-9b30-ca44e6887bd8">test_serializing_array_to_disk[cupy-None-10000]</a></li>
                    
                    <li><a href="#c5faa403-d238-4d15-af58-765261fc5824">test_serializing_array_to_disk[cupy-serializers1-10]</a></li>
                    
                    <li><a href="#5390e309-ca80-4e3e-88dc-c0afb78b6154">test_serializing_array_to_disk[cupy-serializers1-10000]</a></li>
                    
                    <li><a href="#ee36edf0-2f21-481f-95cd-b30454a2cc3a">test_serializing_array_to_disk[cupy-serializers2-10]</a></li>
                    
                    <li><a href="#ce9d8bdb-c6fb-4ca6-a79b-76f902ba4e88">test_serializing_array_to_disk[cupy-serializers2-10000]</a></li>
                    
                    <li><a href="#7822a0e3-a0a7-4232-a1d5-f3b40749c9e2">test_serializing_array_to_disk[cupy-serializers3-10]</a></li>
                    
                    <li><a href="#d5496952-8f01-4d28-97bb-cbdb2bc7421f">test_serializing_array_to_disk[cupy-serializers3-10000]</a></li>
                    
                    <li><a href="#bdd5df89-62fa-4f3e-a956-3541bd9fc87c">test_serializing_array_to_disk[cupy-serializers4-10]</a></li>
                    
                    <li><a href="#6d2adf5c-7ca3-44c2-a05c-c6f341762911">test_serializing_array_to_disk[cupy-serializers4-10000]</a></li>
                    
                    <li><a href="#1b86558d-8dae-40c9-8732-3106816d3aed">test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    <li><a href="#68c7d3b0-9cc9-41dd-ad45-7da559bfdd26">test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    <li><a href="#16f7e09c-9f96-4e0e-80b4-67d305385338">test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    <li><a href="#3d57b94e-4bd2-4e1c-88e8-8743b85188c8">test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    <li><a href="#db8296bf-252c-4cf9-958e-65e87a91f67d">test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    <li><a href="#765c561d-0bda-49fa-949e-fb64d2094065">test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    <li><a href="#9c349427-ed05-4e74-ab73-2ca7cafa0765">test_communicating_disk_objects[True-tcp]</a></li>
                    
                    <li><a href="#47276d9d-78e6-45a0-bf91-28388e47cd54">test_communicating_disk_objects[True-ucx]</a></li>
                    
                    <li><a href="#2fd26049-dff8-4ec5-a654-6537a6ced3be">test_communicating_disk_objects[False-tcp]</a></li>
                    
                    <li><a href="#eea9d194-7226-45b0-945b-4b94a03d6208">test_communicating_disk_objects[False-ucx]</a></li>
                    
                    <li><a href="#e1cf3298-ce71-46e7-99f0-de6643ac98d2">test_pickle_proxy_object[None-numpy]</a></li>
                    
                    <li><a href="#c789becb-88fd-42cd-812b-46faa2f79368">test_pickle_proxy_object[None-cupy]</a></li>
                    
                    <li><a href="#4ff0425f-3f27-4205-bf13-187bf8c8c677">test_pickle_proxy_object[serializers1-numpy]</a></li>
                    
                    <li><a href="#a35c9ee8-ea9f-4a92-8316-0d4575902022">test_pickle_proxy_object[serializers1-cupy]</a></li>
                    
                    <li><a href="#f5b5b8f8-435e-42c3-a47a-af9f5d9eebf9">test_pickle_proxy_object[serializers2-numpy]</a></li>
                    
                    <li><a href="#4aa9d932-0982-4703-9c9b-c8b5e9c23677">test_pickle_proxy_object[serializers2-cupy]</a></li>
                    
                    <li><a href="#913291fc-3b55-4c45-868c-de9c9193c6a6">test_pickle_proxy_object[serializers3-numpy]</a></li>
                    
                    <li><a href="#efbfcd98-1487-434a-9bf1-616725ffbb9d">test_pickle_proxy_object[serializers3-cupy]</a></li>
                    
                    <li><a href="#d4361439-891c-4239-89ec-2cab6290512b">test_pandas</a></li>
                    
                    <li><a href="#60a0f7d1-f9cf-4e1d-8ee9-9c794dd97fb0">test_from_cudf_of_proxy_object</a></li>
                    
                    <li><a href="#3777fed5-6bb1-4ee2-b4a4-25ab0db97ab2">test_proxy_object_parquet</a></li>
                    
                    <li><a href="#b63fd822-5bbe-43f5-86d5-5c86757d5ed8">test_assignments</a></li>
                    
                    <li><a href="#ec6a1bb9-d411-4f52-b81e-e27d97ab59ac">test_concatenate3_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#20bd3547-e523-4c5d-a1f8-223842851387">test_tensordot_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#bf670aba-c439-42d5-9f70-b487ac9bb62d">test_einsum_of_proxied_cupy_arrays</a></li>
                    
                    <li><a href="#065c95f3-a484-4c26-a2a4-75bdfabc6d1a">test_array_ufucn_proxified_object[less]</a></li>
                    
                    <li><a href="#1bafd985-0c24-4557-a393-0b443f6e8c32">test_array_ufucn_proxified_object[less_equal]</a></li>
                    
                    <li><a href="#4ae229a5-2d19-4ea1-9e5e-3e18155e5700">test_array_ufucn_proxified_object[greater]</a></li>
                    
                    <li><a href="#3eed4968-faf3-4766-90ce-a6abded84bbd">test_array_ufucn_proxified_object[greater_equal]</a></li>
                    
                    <li><a href="#6a71ec0e-e56a-4eef-9a07-10ae44825cb5">test_array_ufucn_proxified_object[equal]</a></li>
                    
                    <li><a href="#12bd547c-0fd3-4ec7-a427-3c4a834c7938">test_cudf_copy</a></li>
                    
                    <li><a href="#d823946b-46a6-40db-a47a-3ea9083d4768">test_cudf_fillna</a></li>
                    
                    <li><a href="#bcc15f75-e239-49a6-b3dd-c30bfeceb52e">test_sizeof_cupy</a></li>
                    
                    <li><a href="#90efc0b6-4a0f-4580-b2e5-fa453b259558">test_sizeof_cudf</a></li>
                    
                    <li><a href="#92ef8083-f539-4bdb-9e8e-b556dafa4fb3">test_cupy_broadcast_to</a></li>
                    
                    <li><a href="#a5588f51-cde2-4935-bed5-7dc12ce59aca">test_cupy_matmul</a></li>
                    
                    <li><a href="#8f350378-bb38-415f-9fea-3daafec10488">test_cupy_imatmul</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_spill
                <ul>
                    
                    <li><a href="#9b14de5c-f4d8-4500-aa6a-0d47d657e645">test_cupy_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#014390a7-19ea-48e5-9d5a-c9d2a48669e2">test_cupy_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#77a33e2c-215b-49ea-92ac-10439c9339cd">test_cupy_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#ad4bf03c-0cb7-48e2-9e3a-d58430c07907">test_cupy_cluster_device_spill[params3]</a></li>
                    
                    <li><a href="#2c3ebf60-d4eb-4369-8a67-3e448d354ab7">test_cudf_cluster_device_spill[params0]</a></li>
                    
                    <li><a href="#c45f4b9f-8b8e-409c-b290-f7ef7ccd066b">test_cudf_cluster_device_spill[params1]</a></li>
                    
                    <li><a href="#e4bcc657-45b3-4f2e-ac2d-52e38fd6befd">test_cudf_cluster_device_spill[params2]</a></li>
                    
                    <li><a href="#56ed431c-0143-4e22-afde-9bf06e091a48">test_cudf_cluster_device_spill[params3]</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_utils
                <ul>
                    
                    <li><a href="#dd7438af-4853-42f3-b0ca-3addf1a4de81">test_get_n_gpus</a></li>
                    
                    <li><a href="#f9731f5d-1562-4686-9c9a-6dfaefbf9b02">test_unpack_bitmask[params0]</a></li>
                    
                    <li><a href="#266a26cf-4846-40a2-96c9-9fe726a898b9">test_unpack_bitmask[params1]</a></li>
                    
                    <li><a href="#7cb2bed5-f952-4dad-8cfa-f449bd2f4a83">test_unpack_bitmask[params2]</a></li>
                    
                    <li><a href="#219626a5-6234-4d12-84be-17dcbe36e977">test_unpack_bitmask[params3]</a></li>
                    
                    <li><a href="#855ec1a1-0165-4c0a-979d-e08cfd15b2ed">test_unpack_bitmask_single_value</a></li>
                    
                    <li><a href="#0f9d2fd0-2ea9-46c6-bd27-3cc5c3fb7466">test_cpu_affinity</a></li>
                    
                    <li><a href="#ed25bf67-07d9-42fe-8d9e-35cabc344d31">test_cpu_affinity_and_cuda_visible_devices</a></li>
                    
                    <li><a href="#0fe06df5-b283-47f3-a763-2cae5272f2b1">test_get_device_total_memory</a></li>
                    
                    <li><a href="#3e0cb90d-ac17-4a1b-9fe5-78ddcedcb6aa">test_get_preload_options_default</a></li>
                    
                    <li><a href="#e889cea2-b9a0-4c37-9483-1e92af63013f">test_get_preload_options[True-True-True]</a></li>
                    
                    <li><a href="#2d645a8e-45f4-48fd-82b0-f2f65c2df0d4">test_get_preload_options[True-True-False]</a></li>
                    
                    <li><a href="#aee81289-674c-4c9c-9cb1-60b20a4d02ba">test_get_preload_options[True-False-True]</a></li>
                    
                    <li><a href="#81d4e2e8-d380-4577-9e4d-06e379e9b224">test_get_preload_options[True-False-False]</a></li>
                    
                    <li><a href="#d9bde634-678e-466e-a154-50fe15cf6600">test_get_preload_options[False-True-True]</a></li>
                    
                    <li><a href="#c099ccea-d176-4881-9924-59b4eb0065e2">test_get_preload_options[False-True-False]</a></li>
                    
                    <li><a href="#2f6038d7-b557-4ad8-8fa3-14b0ffd96a1c">test_get_preload_options[False-False-True]</a></li>
                    
                    <li><a href="#df0bbdf7-2f59-4f67-af3a-e86ae064eeb6">test_get_preload_options[False-False-False]</a></li>
                    
                    <li><a href="#b36fe8d8-ccdd-46ed-8443-1a7cf14ee775">test_get_ucx_config[True-True-True]</a></li>
                    
                    <li><a href="#2effbda8-f51d-4976-b93d-3c10a919a0cd">test_get_ucx_config[True-True-False]</a></li>
                    
                    <li><a href="#b8df7e6b-1d05-45a5-bdc3-8959f25965c5">test_get_ucx_config[True-True-None]</a></li>
                    
                    <li><a href="#c7d0695d-9301-47dc-a447-96fa2c22d089">test_get_ucx_config[True-False-True]</a></li>
                    
                    <li><a href="#0bcadcce-4950-4dea-a6cf-113e248394d8">test_get_ucx_config[True-False-False]</a></li>
                    
                    <li><a href="#abb3117f-ccb8-498e-b239-f902910c7491">test_get_ucx_config[True-False-None]</a></li>
                    
                    <li><a href="#68b8546b-f07b-46ad-9803-96c4f6737b5f">test_get_ucx_config[True-None-True]</a></li>
                    
                    <li><a href="#9c2b929d-2c43-4a44-a5e6-319878e47876">test_get_ucx_config[True-None-False]</a></li>
                    
                    <li><a href="#0cedd053-75ef-40e0-aef0-206d67da618e">test_get_ucx_config[True-None-None]</a></li>
                    
                    <li><a href="#20510dd0-5993-46e1-b3d8-d9da6ae44e68">test_get_ucx_config[False-True-True]</a></li>
                    
                    <li><a href="#eef2c8f7-254d-4789-b8b5-d888a2d276fb">test_get_ucx_config[False-True-False]</a></li>
                    
                    <li><a href="#344bc7a6-091f-4e83-90a7-94d3c46c2bcb">test_get_ucx_config[False-True-None]</a></li>
                    
                    <li><a href="#a52c07e3-e34c-40f8-8c27-0e0d26dfded9">test_get_ucx_config[False-False-True]</a></li>
                    
                    <li><a href="#17d5b7da-59ee-43a2-bbc7-3ae5f74dd6fc">test_get_ucx_config[False-False-False]</a></li>
                    
                    <li><a href="#fdb6023f-4b15-4175-8e79-c38e845b3674">test_get_ucx_config[False-False-None]</a></li>
                    
                    <li><a href="#b6fa2b6a-597b-4552-b7e2-51f1dc4b5d6b">test_get_ucx_config[False-None-True]</a></li>
                    
                    <li><a href="#a41fcd6e-c906-4e25-ae12-9fcc42291110">test_get_ucx_config[False-None-False]</a></li>
                    
                    <li><a href="#2b6ccfe9-929a-455b-9f83-701237667b87">test_get_ucx_config[False-None-None]</a></li>
                    
                    <li><a href="#09db2ae6-86bf-4a34-8f2a-f6d92972db04">test_get_ucx_config[None-True-True]</a></li>
                    
                    <li><a href="#e1bf054b-0fbb-4baf-8b3b-2b34cd1a63c6">test_get_ucx_config[None-True-False]</a></li>
                    
                    <li><a href="#f4064acc-499c-4019-8e17-b5a437934c52">test_get_ucx_config[None-True-None]</a></li>
                    
                    <li><a href="#a65e1dd1-d8bb-4dbc-8612-63578e114373">test_get_ucx_config[None-False-True]</a></li>
                    
                    <li><a href="#e84798d6-ea45-4527-9f34-9c9220ea1e5b">test_get_ucx_config[None-False-False]</a></li>
                    
                    <li><a href="#fb45f308-76a6-4cb2-8674-af66edaf904e">test_get_ucx_config[None-False-None]</a></li>
                    
                    <li><a href="#a1fe88c4-0e4d-4634-8e69-df5bb52e9539">test_get_ucx_config[None-None-True]</a></li>
                    
                    <li><a href="#39fd6806-43ec-4674-a64f-5a66be1f6987">test_get_ucx_config[None-None-False]</a></li>
                    
                    <li><a href="#fd2fa21b-354c-4d51-b562-c4c861aed87a">test_get_ucx_config[None-None-None]</a></li>
                    
                    <li><a href="#d704e01f-b0ab-43b5-ada3-3ad7e28880d2">test_parse_visible_devices</a></li>
                    
                    <li><a href="#d48a75c4-8533-462c-9131-e1d8b32c348d">test_parse_device_memory_limit</a></li>
                    
                    <li><a href="#1f763a71-ea13-4161-abc7-0a4d4bf134c1">test_parse_visible_mig_devices</a></li>
                    
                </ul>
                </li>
                
                <li>dask_cuda.tests.test_worker_spec
                <ul>
                    
                    <li><a href="#9a01525c-8812-4cff-93de-89c8089a3a02">test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c562ef62-1b7a-40fb-bbbd-aa49721051df">test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c156230e-4843-4857-a325-55847b7fe8a4">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9eba3c16-cdb0-47d4-b266-43c46174dd95">test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#78f23335-d7a5-4741-bec4-fcc7f7ee0d92">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fad955f2-3d45-4dfe-bbb8-3b80b68a48d5">test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#28f7f65d-0e0f-4025-9694-d7f6b69c4f9a">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b299957f-528d-4d03-b9ac-86942de25a9a">test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#238d4808-5af8-41c8-bef6-7f29990de508">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4e3f7c99-2111-44f1-a1b6-51eccc141016">test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#09d15009-d800-40b6-a019-306b0e7cbd9c">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0de25b6b-6d83-4f15-aa20-2018d28fedc6">test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2dcf79a2-4ad1-404e-b127-be6a86bd9881">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#45b82d8a-fc98-4d42-95d6-3293df821421">test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#7ddcde1d-9ca0-45d6-9a6f-c3de23f5d9c2">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#40eeda27-6437-4d30-8f64-628d9e298069">test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3a74b225-328b-48a7-86ab-dd9040acb04b">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#50df70e0-169d-4df7-8b59-eea6d2f94d91">test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2044a7a9-65d6-423c-94da-6c35d8c0faac">test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2a4f2f54-cd5c-4e10-81d5-a53649b481b2">test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#18f2d73d-70d2-49a0-a48c-f68bcdb6aaa6">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0f757ede-ed9b-44f3-bbb8-daae8bd5c7ac">test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1d43602f-34bc-436a-90ee-3a755ac71853">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3808921c-7642-40b2-babe-2880736a3bdb">test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e08406a2-8987-42de-812b-bd5255e34922">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a47b51b6-51ea-45da-a673-be041013e179">test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#f275bb70-ea5f-4eb0-ad4b-83cc65b6d8a2">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4d3874a9-0a6c-44e7-b90b-9d7290b24bb8">test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#92227f2d-6ab5-44e5-ac1a-a21939c3e0b1">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2c473c59-c5d0-49ec-b2c8-52cc7319749e">test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#67417730-6bf3-42db-9897-17fc83ba2662">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#fddabe82-51d9-4494-93ce-0b94209e6c12">test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e9ce6b55-5184-4327-add0-bbc6b80bd459">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#80d534ac-3a1a-428e-89ad-2132c3314e16">test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4e512b61-17aa-493b-a846-1f7bbf108fdd">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bc41259c-0548-4dfa-a3f2-0f1073d56a73">test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#64565ad3-15d9-481f-8455-e7b898e50fa5">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c1092a62-70b6-4f75-bd8c-a14108ff23b1">test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#6e4a19c7-a7cc-4e84-adc3-71e6df47e095">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fd9837ed-4424-4260-b3bf-81159ce5b801">test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c7f06fc9-41b9-4c17-9d7e-ce898aa32e76">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2f43339c-6af8-4b86-aa8d-450e0a6f0d4e">test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5b24a18e-b822-4652-b656-88e855b93400">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#cba1e463-1a4b-4276-ac82-1b0a105305a5">test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#bd768480-9e6d-4507-834a-a77c84d22dd8">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a5e33c36-64b7-43ec-93f0-e05132129c46">test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4b7acb08-7fc5-49a6-806a-d8ba078cb086">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2d538fc4-76c8-494f-b4c9-bbf70df33214">test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3ff6dcc8-7543-4f4a-8a35-33da3e12cd89">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e2db2629-c4a5-4962-8b30-79003c756705">test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#a02b9848-ad50-4f87-9377-f8a932e1e0b1">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#07bbb0b6-497f-4216-8136-e47dd6112086">test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8b632dbd-4e70-479a-a4fe-f13c17cc7422">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8157714a-c6e2-402c-85e7-c66894bad8b0">test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c052de64-843f-4200-859f-35fab79e3eb5">test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#db18360e-db90-45c1-85de-c80ce167451b">test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e4e8a8e3-7e5d-4615-bf52-8fa81f551f61">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2dfeb5ce-ab3e-42ff-9259-0dd75a36ecf7">test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1d1a1bb1-6e86-44a8-a8fa-a9e416242c65">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7e1ddb77-0943-4f62-bfd9-db0b34e8ef72">test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f6f123a3-5a31-44c8-bb7a-93e00b647edf">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#c3f41fb2-16f3-4b5e-8c44-2b18a52e0807">test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9a7cf361-1964-4122-9f70-001e7f39cf09">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#382de5fc-6467-4af0-9e83-9daffa6338eb">test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#96580c4f-966a-4eb9-a360-983752c5e6d8">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#71ddec87-a0a2-4335-aa45-1ba310a78aa3">test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a91e312b-6595-4c23-80a5-e47cee3217ff">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#54ea26c0-56c5-46ce-90e8-a1f89ca37c39">test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#42a55e87-fa2f-4d91-b61d-615c88733abc">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c02efe9f-7308-4498-887b-cad7ec463710">test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#157b6dcd-42bd-4d9b-a06b-8b64d31b5d5c">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#98592a04-555b-4b03-8e7d-347ea6809ffa">test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2b8db48b-4ccb-46aa-a60c-dc98b7be0fa4">test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5c3c3e4b-1a98-4392-a649-29243aaaadf1">test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#8c207789-bef2-4595-81b4-db7916ba667a">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9f3f97a0-19a8-4746-806e-5b1857b5d317">test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9aa34ca8-fb04-488e-9e0e-d3a7a3440b00">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2d81e172-bbfb-452c-83f0-2619fdfbadcf">test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#76d2dc26-39f6-4ee8-a5a9-29ae2dd59ddb">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#049eb793-5758-4564-aebb-0416ad082f56">test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#d8aefeaa-6965-481c-b0c8-b2140720ee94">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3c11f911-ef98-4430-b7b8-6b69cd3718e8">test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#cd59e6ab-108a-46b8-b0cf-87a29a2222e7">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#39c73d38-7476-47b2-86da-edb361376492">test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8f7201fb-b16b-49c9-a976-4d9d6c641ca0">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#14c9dcc5-97d9-4036-a3dc-17d7608f973a">test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ceb28426-ff7c-422a-aaf1-126d9593fc21">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#02eadedc-08a4-4d47-af91-d6ebb0b443fe">test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e888b6c6-38a4-4556-8517-1cb4dcafab3f">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#74765321-3ba2-4fad-8e14-ed77b5c7f5b1">test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f4c6b96a-8682-484f-8482-de8c2cc3d43e">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f33ce747-9bbb-47a9-944b-a80cf67c3e5d">test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#7ade6ef4-c171-4495-9f67-cc32e7bfd9c8">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4d99abbd-0221-49b6-aaf7-390846f4546c">test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a409f850-8a35-4212-987b-5af231bbea6c">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#aa146370-f326-4dbe-941c-bed83fbdea73">test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f82bfa18-203c-4ce3-b6a2-7bb5f4916038">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#bb15fc44-c3ba-49ee-9c19-476527d58b32">test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#50d742b5-224d-476f-a07f-882c277c3396">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5138e649-0f66-459c-b78c-b5fa5e4578e8">test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4bcb03c8-67b4-44ae-920f-91720e946cda">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5d673479-a8c5-4f9e-989b-ca9d27790b70">test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#791883a7-5116-403d-8894-01595589d7d4">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b35951a0-28c3-46d1-993c-554048b8d1ea">test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#9359a645-dde0-47b9-8653-b94c47db00bf">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#970b142f-2e0c-4e29-9b2e-79349e99b925">test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ce0469f5-7a28-4113-a537-41c20d35d771">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a8b5c241-7af4-40d5-bcd5-146d611b3afb">test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#60bba05d-6bc1-4b2d-bc26-af78d7659f8a">test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b0965a66-1cc6-4d8e-a668-531779f81970">test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#55eb10b8-327d-40b2-a72e-066c152ed5df">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6cd89e1c-fb30-48c7-a9ac-aaf897042d1b">test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#96b03a87-28fc-492f-aebf-ac82115b849d">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#defb6c59-7c83-4c1c-86d0-a73afe70e6dc">test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4460ef64-df32-4323-a75f-cb258c82ff50">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#47ffb87a-5057-4784-8fa2-b77905219cf3">test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#20799646-6a80-4de2-863f-09aa9050351f">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8694a3f2-198c-436f-8c76-563957cb81a2">test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f4f457de-3dda-447f-83f1-0d2935fcb779">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0ac4e896-51f4-43ec-aa19-4b0e860477be">test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2d022df3-67ac-4322-8063-fc6e7fb30c9f">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7821dd00-92d2-439c-a2c6-4c1fad86f091">test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#9220c299-a98d-4743-bcae-83001dd626c7">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d0d2bfbb-ac43-4da2-a42d-3cf6c257d2fd">test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b356bc72-3232-4892-ab1c-de7785ad64b9">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a2e2cae9-2b5c-421b-9efe-bd6f3816c0b1">test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ad6b196f-75ba-41c8-8601-5456cbf16c3c">test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#244ad1ef-e980-4910-b214-95166a6317a2">test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#ea751333-6dfc-495c-b03a-5d7d3c360bea">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d350ce2c-5f9c-44b0-85ec-0da85d51189f">test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#33741228-a6a0-4175-b289-3b2f7438380e">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#335f72f5-e4fd-4859-906e-062d88dda3ee">test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#32393d9e-afa5-4620-bc66-6059553e1437">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#440ea7a4-d12e-4745-b244-396bd2506380">test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#eb880993-64b8-4930-a2ab-91fabce81e20">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9e44cb18-8b3b-458f-96d6-e11056fdc4f5">test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#40227b4d-5b11-43be-8ad0-212fc091591d">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a50a0471-159d-412e-a9a9-8862208a1d2a">test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ab9ccdab-68e5-47bd-a4c8-7d52c9a96193">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#2276bbcb-5ce1-4463-9d5a-e90445b08a08">test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#178ca789-41cb-4300-8b98-3a4d7e3be328">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#63afdd1c-e16a-4af8-971e-bcb22081b0e4">test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6365434f-db75-45df-9435-b5a575577283">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#040d0403-511e-4a16-9dfe-badb6995de98">test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#2fd600db-de94-4a62-9b24-b49b76c5b095">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#d28930e0-9cb6-4332-b905-569940a09a81">test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#9d35d73c-5ca8-4b7d-8d1e-839d60d42162">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ddb3a764-9bce-4835-9d20-f597de71275f">test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f0e0d733-fc03-45bf-943e-eee7f9457baf">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c3075f61-04bd-4568-b1fa-29b5b2fb8b9c">test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#70bcde9a-86bc-48ef-9f26-bed8f0283f0d">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e9973e86-97b7-411e-b104-5104b02468fe">test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#43dd2a7a-9963-4ba0-89a3-cd136739451a">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a336a314-a6bc-4c51-8776-4ae0ee9a94db">test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f881982a-05fe-441e-b19f-8ecbe20df1b5">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6f37325d-c6b2-4dce-b3dd-0563c63ee88c">test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#811b38ae-80fc-438c-b0f7-0ce2bb1d5cce">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d08c51a8-af84-4ee2-9b6c-4db3e17c60ec">test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#abebd439-d747-4b52-a134-477a1481085c">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#883b7136-a513-4f11-bf89-59e54f7f204e">test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6cfaffd3-2ea9-463f-9ebc-ad3bd23b9bdc">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b36616a8-2853-49ce-9200-cb9944a4fdc1">test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7248a596-a49d-4c5f-b2f2-7c04416dc111">test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b1d7053e-969b-46c0-aca8-9771363fec43">test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f02cf20a-164a-4e25-99e3-0c7f92cbe769">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8391823d-2e21-41b8-b79e-f89b22f4dd75">test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1a840fa1-c920-4b97-a8aa-61a270f59edf">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6a711333-a1c2-40cf-b230-227562e6a387">test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c1bf7a91-6be5-4dea-b149-a6a357de7d55">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#15f97cdf-fa83-4582-9e94-f688cae01ae2">test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#f5f7efd4-2c79-465c-a698-e68dc40f9b26">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#16f37f21-e95a-4a1e-811f-5477b620cdb1">test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3649d095-738b-4663-9aef-0ab62c012f6d">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#80222686-0586-4718-80d2-7ae7503b7808">test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b6cfab0e-8428-40ab-a62e-3ff286a2f75b">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#b62e0595-8106-4fc6-9a04-e6cbafdef48c">test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8f3829a0-2af3-454c-953b-b87fb3b4ef5c">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e353691f-3dd7-4555-873e-cbe649f1180b">test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#eda30052-d8d5-4cb1-ac56-532bc59956b9">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#641b831a-53d9-48c4-b066-d22df668e32b">test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c95f7003-3f73-4810-9e49-f5bb5454ac7e">test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#9a569d2c-bfe7-482f-9c42-ad757ad8afd4">test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d321513c-d9cd-4103-99b9-eb4bf3150d99">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#96562e4e-ac2f-4301-9516-ff1048c38dd6">test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5044687f-30d9-440f-b012-7b2b03fce1f7">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fb8eb0ff-008a-4ffc-9cda-09130cac7cf0">test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#81a7be3d-bca1-4abf-a4c7-fcd360efa91b">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d8aef126-229a-4a73-bf7a-a2a1ee42d2bf">test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#c32c7215-36f7-4ee2-aa98-44c18b74ad9b">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ae3540d8-8f80-4738-a554-fd398e187ee8">test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9a26df42-710d-46af-babe-d3e3a46267a1">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#1395d6cc-ad4c-418e-b4b2-9907a05b46bc">test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e26489af-2462-4f26-948a-b77c5a646495">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#4b5359c1-8a0e-4ef9-9910-15b1f5578952">test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1d74bf1b-5191-4e77-9abb-13ba7e6873c1">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c28ce0a7-5033-422a-8550-aed3128eb5c7">test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#809ea22f-f4aa-45bf-a9cf-02272a0e84a7">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#79d57aef-cf85-47dc-aa6a-f60aced31993">test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5e68a4cf-49f1-4655-ae3a-fb656781eed7">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c4378c94-ffbd-4b27-b36f-dea3e6254d13">test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#38c7758e-c263-4365-ae26-86ac0a392192">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#12f8903d-c4a3-4434-8f32-bcb737ad829e">test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e1b8eee6-22e9-409e-b73b-c1a186620a9b">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#328e7503-0863-4a3a-9060-515b2f810452">test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#00f61e3b-c61f-4537-8926-c4a697921a55">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#cda8aba7-2767-4c5b-bd85-a926a0a5ec0b">test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fda556c0-b8b0-41bd-b38d-c639d8c124e4">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#72b4c425-232a-48e0-bc96-27bca12c8b7f">test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0df0b569-1cb4-4d04-ac18-770b6b7e6732">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#16fe2b1e-cb08-476c-9468-efbdde615ead">test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#808281b4-5668-4a5f-b12b-a962ae8d0010">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#f9a60309-d103-4523-b1dc-9cf1247aa06a">test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#75bdf2fe-32f7-462b-8ad1-42811b73a627">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a2e1ceea-ccac-4941-9481-149054ef0ace">test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f198fe22-423c-42a2-8537-8ed7dd90a584">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9ad4f989-0ae3-4df7-8b43-4c45ff7d24fa">test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#bbe3ecd7-a377-4a0a-a650-9a232f29ec74">test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#efa43c5c-b93a-4c77-baa6-6067cacc1071">test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#55d58897-a3fa-4e59-8549-e6dc1a71080a">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7cb32b20-684a-4f67-912a-d113324dd8af">test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bdf5f114-afca-41e0-bc71-a3db52fbf135">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f90944f1-db74-4483-9f9e-92fd52020a38">test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9f8a43fc-50d6-4ecd-bded-8d94d1427d15">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#7169e4e3-4b34-4cb2-b27a-4eae41124754">test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#d6d7d952-c1bd-4427-9d74-763ce3e0c056">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#169d845d-9d5b-49e0-8213-9e173adc589b">test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8d8b38fd-de98-457e-9d3e-8c18684a1615">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9f42202b-e565-4711-8469-13144b151b02">test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#15227586-be3c-4d07-a71e-2bef228bf275">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d3b65109-fea2-44e1-a70b-6d2ab0e17daf">test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#70b9eea3-5913-457d-8ad7-27312fc06188">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#be5da2f5-2d5c-438a-a76e-6e83254caac7">test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#170e22a3-a840-4976-bbf8-9aad967e0eaa">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f6a5e7fb-764c-46fd-83e6-f3aa9e38187d">test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cdba3395-4ece-4fee-8574-35ed5d5fd02c">test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#49d5319d-2f71-4a47-a2d0-711410908e1d">test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e1b6ce4a-1d51-4c77-a7b8-43972202495d">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#afd28dfc-412e-48bf-8ada-95dac81614fc">test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#31a980f3-a68f-40d1-9a32-05a98be06629">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#886034bb-17d1-44b9-afaf-7dbba74c3976">test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#25d7f145-f825-43bd-9c42-4ad8aea9d49b">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#41547b1f-0760-4251-8740-8eebd600bec2">test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#6d31a14b-92b0-45f3-bc44-1ab002366a36">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#06712664-9a1a-4264-8ae5-e05352fdf58d">test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#259a5ec1-40c5-4dc6-80dc-e0d05e35dba0">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b86831de-31b9-49ad-91f8-f1b554a11dbf">test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4c3f01f6-512a-4eb5-8809-5a7a76b91bc9">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#89b5d238-ad78-4f82-9bfe-6f96cd97d65a">test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#fbe9fef3-08df-4d67-aff2-a91c8343a371">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4e456136-e0b5-4fc3-a32d-6a111002dad0">test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9fad2b43-1370-406c-afe8-aa4ec7e93c24">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#69094fd8-1d47-40c9-b01c-50ff505fb59e">test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#826eabd7-6291-4e7c-916e-0591d4bd243e">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2d14e95a-5108-4472-8a03-1908779843b8">test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cdf2ab36-c0eb-489b-952f-ae347e735bb2">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#460ec5f8-e79f-4711-bd1b-bb40bab33b2e">test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0cb64740-3349-4c01-b757-ef5b912e6ea6">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#dba2c334-d0b0-41ac-b851-45f8759b8727">test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6392abe8-e4e1-4678-98ef-fa90b0feb75f">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#167aae4e-f780-4b44-81a4-15e2faf81b68">test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#2e16fd7a-abca-4a5b-9d94-ef0603dbb9d5">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#385259a3-10ea-4f99-bf80-3a0c9522742a">test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#86044e12-2873-49b3-8b8a-681c669532e1">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b2e89873-0ad9-4ab5-a0f2-6e836b08e902">test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#41844be4-c691-4da5-a739-fa26f4680204">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e6203c6d-854a-402e-951d-981f5f1773d8">test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#a65ff08f-55bb-4409-a245-4481ba644b1b">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cf8cf69e-2333-427f-8100-2cabf4d15e71">test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9a5b30fb-4d56-42ce-894a-499927615320">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fafba014-fa07-4c04-a3f2-0ae32fbcb0fa">test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a3918141-63a6-414a-864e-a9ea25d1ae12">test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b34a73e6-3570-4929-b4bf-4be9a3f63796">test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#19206d5d-c342-4a6d-81fe-955a4d1050e7">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b8443c04-55b1-431a-9eb5-0649def40ced">test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a0b07ff2-66d7-4a6a-bea6-4d1201ac8c2a">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d2f7eeba-7dca-4c22-b124-1d4415663149">test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d27ac0c4-d80d-464f-aebf-d9e025fbf556">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#2499f36e-7428-411a-b02b-3ef2f8e184d6">test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a18a281f-6650-454e-bab3-d5d7c8b07049">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#76a9c759-03c3-4be0-b161-2d545f140fbd">test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1e14d894-e1db-4e20-aff2-0f1d3cfd0a27">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a1e6bc0d-af5b-4100-ab4a-b997ce84bdf1">test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#251b42ec-4412-4d5e-94f1-cb192341cb26">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#9be04781-78cd-4ce2-b0ee-e22d4c9cb691">test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ce95d628-cbb7-4cf9-a17a-bb1f9601fde0">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#7d7a13ee-1cdb-403e-a5d0-3ff671c6471b">test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#dbbe4bbf-0dbc-45aa-b199-ee3a2bfa62d6">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5845fde1-844a-4a08-8d93-aad783feaf38">test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#189e6d4c-2ce1-4028-835e-f68177f54bf2">test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2ba9e4e6-28ce-4500-873c-88701d176d20">test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#43d557fd-65fd-4c69-b121-197a6dc9acac">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#35216a9c-14c1-4302-b098-f7b7180c8507">test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#edf0b82d-9389-497d-b3d1-ec878878742f">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#19f9a641-a6eb-49c3-9f58-2024fde7df3f">test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#460f0568-8ed7-4b68-87a2-e3a564cb3cea">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a9f4faed-1335-47c0-99f8-835c78c4dd56">test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1eade382-9937-4d12-8554-566ec5274d77">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#02eee9ad-73af-48d5-bd9d-e05c5f173795">test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ae38e9e2-22dd-4162-bb78-fe3375aaf453">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#7a0b1d69-ee4b-4424-aa22-7237cdb3c81a">test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3ee4ce84-9d2c-478f-b6ef-d23c3261a5b7">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#8fb452da-2b5e-45b5-be17-582d45727e36">test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e8befc34-ee1d-48dd-9e61-50af76d68631">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f9d1c04f-7a81-4abe-b29f-4b5a8feb9da9">test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e60b1aad-1974-49a5-b182-91e92b0c0a72">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#292a9535-5fd5-4298-8c1b-3248ff5fcef4">test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cda4fbbf-c0d2-4cdc-aaf5-01551da81f18">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#186958e3-f9c5-45bf-a643-6dc87b251f93">test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#ae5f8545-d4cd-487a-bb15-9138b99be07b">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e7ac9dde-8dda-4196-a570-625dead122cd">test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#37dbe6fe-a968-4778-97ac-16b219cccfb1">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#afc14dc0-3e22-47d7-9a9f-602be7b19353">test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3d61fba8-ef69-41c8-89b0-bce711c060f4">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#9be69925-c41d-4237-8610-557d4d5f0c29">test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#5c7517fd-14e2-4072-b35e-eeea86f4f1e4">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#050a2e2e-8e8e-41e7-8d67-dd6835fae7cc">test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1caff8a9-f296-43b4-a502-3b7dda05e8d4">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#972113e2-50ab-4545-9797-a86710a09f36">test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#39f8f596-ca63-4672-b406-627f722c3a94">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#94ba7de6-6567-41ff-8c6d-cf06a9ee4662">test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ba1bceb0-5315-474e-a471-0bbbe8c2cbd8">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5f40d059-7ad8-48ba-af0f-ee5cbff31ab6">test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bd2381f8-83ed-4c04-a456-98125f595273">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#546adca6-e4a4-4ec9-b715-d22e7daede2b">test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#afa510c3-c808-4e83-8075-faba70b1e03d">test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#cf47905f-cc7f-48f5-a849-35ab4c5e7808">test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e145c851-8b87-4e0d-af2a-c4133399b4d3">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#bd427ed5-ec22-4e9a-af04-4fb3435b4464">test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b9dd55ff-8b89-4751-a5d9-b30079a7de3c">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#15d3ee0a-4f59-47a1-8841-3061799b3bde">test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d2cd9b0e-8c13-470c-8f1b-d27abe67232a">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#3cb58b72-c527-4742-ba17-23b8d27647e2">test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#a5159f49-fabd-460f-ada5-8327355b8bcf">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#02bfbe03-ef2a-468f-9224-15d8ec8a052e">test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#919623f7-c9e0-4a75-b76c-464e1b794544">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#699dddeb-a606-4fc2-835a-ef1e568341d9">test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9152f808-4b77-4109-841d-3e6ae4df6c2f">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0c3733be-59a3-4dfb-a47d-33cf785e3e52">test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#94690508-441a-4a15-83d8-2592f66b6362">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c314ab94-ecf1-4fd6-87e1-7757fe4f38b4">test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#84d6d43e-6ef4-4234-9b66-2f95807b6a52">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#262593f3-f549-4a51-ad73-3f01e2fa01de">test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#680a0978-b67f-46dd-9ccd-a14a6e43fde7">test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#cbec5129-1579-42fb-94a0-2eda7381b513">test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#310ce1c0-4697-4869-994c-ec46e1c8c401">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6a5959f6-00bc-4abf-85af-171eca18be31">test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#17d97a06-8d03-462d-a16b-58c79abfeeec">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#74fb4995-4b15-4c42-b929-10d7bea70add">test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4398abeb-5d48-4daa-b156-d56bb5852ee8">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#ca7062d6-5e2a-421e-99ab-2a3319df52b4">test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#4e4e1aca-cc3c-4ed8-86b0-37093fc9aad7">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9c1dbde7-22d5-48a8-a31c-bae64a28e3f4">test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9a6cdc3a-da95-4845-8d06-9fc1d2ce0e01">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3a1a5633-d3de-43d0-8fcf-1147c49cfa08">test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#31ed9658-878f-4bd6-88fd-447d1704d4b3">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#1c8a988c-573d-471a-b3ec-2749d8a96fa9">test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ed55e62e-8d3c-4b60-8638-0952b9c887b0">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#68f7df42-9e92-4366-88a8-ecf3c99093a1">test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e75290c0-7d29-4114-a598-250068ee7487">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#59736629-1110-4a69-a54b-5c47274aa01c">test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0f93dc61-40a6-40e7-add5-2b3f9f49126d">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#88181e53-708f-44d2-bb1d-0d1410a5417e">test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#5447e448-fd79-46e3-b969-dea4f4e9cee6">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9077bc95-7caf-4177-8b45-046914674bf7">test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#372d7fdd-cae6-4cd5-a012-5a5a9024d6d6">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3c040096-14ac-4d37-80ec-8e6bbb56cdd9">test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7262c3cd-d5dc-4a47-8ddf-1fc789551cf8">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#1d9fadbb-0ea7-4249-88d0-8ca170f233bd">test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#94841c11-e8d8-4915-983d-1df4fe3cff3c">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#37bfdeb9-1f20-41ef-93f2-3ec2603bf9e1">test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#98f18960-2d68-46a0-a1c0-32e3784c0ca3">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#84aca958-c03b-41a7-9a3d-0290ee6c5485">test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e929918c-4bcb-427b-b906-1d440c80fffc">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#7d141378-beb2-40aa-a73a-67262351fca4">test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#806504af-a5df-412a-ae87-20bbcd773119">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#db957513-cb66-4fba-8153-66643ffd62a0">test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0d14d370-b08c-4773-938a-06972b9a5d58">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#712b17d0-e4d1-4184-a2c1-076f86a13161">test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#773a49b6-73b1-43ec-be79-5b17c6282989">test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#6e55ace4-8c6a-48b7-915f-1b92e06cc16b">test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#f01c0de8-4a17-45cf-b554-369dd66544a3">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f23ebb0a-9484-46d2-8595-a7762e884b31">test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2ae77ae0-118f-4549-be76-b9fdaa1d7daa">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c268ea54-839b-4a75-9a9a-f8f11b325448">test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a6430fa6-4af9-45b2-a092-905933775196">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#13e7b5d7-1d51-4b86-befb-3c036805f1f7">test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#674b3ab9-576c-4f3e-97f7-203dbce51366">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1f3d012f-62b6-4994-935a-369603923565">test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4d0c49d6-7425-474e-b0e8-d1d73a1b4b87">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#71d6fcd4-b9d0-40aa-90ae-687c7f04e0c0">test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#611264df-36a6-408d-8b35-f8eb994556c5">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#760c95b5-ddc5-46a8-aec1-b2078a986a8f">test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e6cf7da4-cfa8-4e96-92bb-80c0f2a809b0">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8c235013-f59f-4f97-b272-bc5649aabcee">test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0da80ca4-b94d-4418-a089-fe63c482187a">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#0c3d5bae-ba08-4a2f-b35e-228cea94203d">test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#755dac8a-5897-46af-9d54-80f8847ff881">test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#8c742ec9-e6e0-4b8f-b0f3-3b5f55563d76">test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c3ed8033-89d0-45df-a690-fdf9a29aec9a">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3ce04e9a-c45b-40ac-9d84-8d76e25d64eb">test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2e1e61fe-3019-4b89-b944-6f0ade1b7178">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#86d42fb1-dfb6-455d-98fd-a53d3d6c905e">test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8649f380-5951-4b61-a39e-6a9dd6aec7bd">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d71712e5-1a90-457b-a70f-7892d609c767">test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e2e17e5c-e050-46e8-b2b8-b20aca4c135f">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4a7c8f6f-74c4-42b0-b6bd-1004736071a3">test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#20c135ad-1546-456b-8f7b-dc47d29d7cc0">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#23cbd7bb-b409-4344-aa97-0b9f6871b42c">test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0c5e5bf9-f0af-4fca-b353-51ccea671bd4">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#52627a28-a32a-46c7-b726-4ceba0a76cc5">test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f1cedc9c-c1d0-41ea-95c8-dc56341b5d37">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6efe5843-22ed-4705-b1b7-d223ff78d513">test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5b0ed660-86f1-4088-9ac7-2e69512d7d94">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ac7579a9-340f-4fd6-8cee-c61b04e60a6e">test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7d0c3b74-0ea2-48a6-ae25-f4e6f6d1455c">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#28226ef7-dda3-4f3c-af8d-2b797fb10a7b">test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#0505adac-15ef-4fd0-a4bd-f04bad43ead5">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#334b833a-bdd0-4682-a9a3-b6c093cadbae">test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d9045578-96d0-4824-97f7-369e023610b9">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b941e492-da4c-4d86-9856-f1bbe9dd4755">test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4c8135e1-c112-4ee5-99ed-db3c9f72f0ed">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#8590f7ff-07f3-4633-9c12-62656b191bbd">test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9382df92-c770-4609-ab28-736d05df9692">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#33cc202c-d2c8-4f9b-b914-5b82739ca9f8">test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6c5f48c1-ae85-48d2-9a68-a161a805d21b">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6a0b6957-d0bb-45b3-a0c4-08ed6d12cab7">test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4f9e4edc-bddd-4828-9725-b340f68cb565">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#c9080fe7-34fd-4cb4-9d14-91c7ab12d019">test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#21a44efb-9626-44c2-86bf-42bea3d04863">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#28385d44-6048-40aa-a5c8-8ae751f628ed">test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6864a576-0be0-4f0c-ac79-537e8eee4ae5">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#28d145e1-876e-4930-9176-4db028be7d0a">test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ea03001f-928a-4ed8-bf19-8ebd18e25c8d">test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f2826e24-5541-45bc-b9be-a86705edbf21">test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e5b46194-69d7-4718-81fa-9262c0246e8b">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2c7e739d-ca7c-42a4-a6b8-d6de0607081d">test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b8c728bf-55bf-494f-ace1-cbfa66606145">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#17c60a27-6565-4d17-97dd-5962e53cecc9">test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3e6e4e1a-9cee-4a8f-bd8b-c215ca341060">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#fefec45b-fe9e-49b0-9f4a-23171b4c9285">test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1c4a1fde-118a-4bf8-9a7f-8f48a004cf4a">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#de8f7f6b-89c0-4f94-98ef-96a31a7352a5">test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#182f816f-b047-4883-a99b-36550b5ce69b">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5206aeac-b4a8-4a23-ada5-643345d47a3b">test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a2650c67-b184-4837-87eb-8b20fdac3e07">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#450848fc-ad2c-4c5a-bb37-4048b849362a">test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#b92e21d7-ccde-466f-a459-a081d793d34d">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5e48b229-7573-4dbb-a66d-8af57aae230b">test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8168df9b-4aa5-44b7-a167-3f68f0d86f8d">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#08c5c430-81d5-487e-b135-9219400a9e20">test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#cc3ce105-4c76-4787-93d0-ac557c60c6aa">test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7b6d9709-5a71-4040-a71d-b8664041816b">test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#43ffc6a3-bd44-4e14-a00f-30fdfbf05d09">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ee68e789-7b36-4659-954e-55e56e7dd425">test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#944dc4b4-6ede-4842-857c-0b9db2dbf7e4">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d2700f52-3bb7-4f99-a8ff-ad2cb62fb950">test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6ed6371a-8d42-4b43-9f2e-7fcab0785627">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#47f66b32-944a-4ee7-b5f3-3288bbbbd615">test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fc84d35a-06d5-4bfb-932e-79247035e754">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f34b80d6-b354-4766-9431-587acd756fe0">test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#aee3fbc6-fc96-4bd8-8a63-41ebb1cda6ee">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#69eeab91-2a66-4258-b718-d67cf1de9968">test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#474475af-8096-4655-b44f-4a46f83b4896">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e1e34263-2f85-457c-8ab3-dd42bf823a48">test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#3fc89ac7-5900-4606-8dc4-e9987e1df750">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8d04a8e3-7195-48f7-a62e-888c01b0c5d8">test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#4718fad6-5158-4141-8dc3-20175a3f3f4a">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2e466e2f-5b22-427e-82ea-bd202bfc4408">test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0564f87b-aa6d-44e8-ab47-ccb1a30126e0">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#9ab175d0-42d7-451b-b185-a097139f886d">test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#68dd5ce1-91b4-48bd-bd93-0c0257bece5b">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#769a0916-f694-49a5-8e24-e9ff138e0e5e">test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#74d4ee2b-885f-493f-bfb6-51e0d3f876b0">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#69b5483d-9c3f-46ff-a025-211e537bb3cc">test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8e706032-6b9c-4d0b-ac73-664b38493709">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#9c24404a-e358-479b-a46f-287a00f352f8">test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#b3949748-5a69-4f14-84d4-9182a2624e4f">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5f218888-bdb5-46a4-93b2-8e28384ba434">test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7ff506d4-3985-4351-aaa2-91fd075548ce">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6d5235b9-1f9c-41de-8e41-6f42fbb5e656">test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9e6f5c59-b43a-4774-9359-8ece541ba9a7">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a4635be2-0cb5-4ef7-9853-9361b7f0702f">test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#decca2ff-bd2d-449e-b361-cddd3f59640c">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#634d61bf-0b08-4ba3-8622-01d9bc0b96e3">test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#aad1520f-63a3-4772-95a5-a550c95b6eb2">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bc26b3d6-cd3e-4031-a22f-9c83acdacc79">test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8001d986-9eea-4729-9ffe-2b8211c32746">test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#124833b5-69d8-477e-867c-00c047e2c99f">test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#6f146966-8c80-430a-8885-caaa8d313c0c">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d803edd3-48c7-4807-aac3-40aae834401f">test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ecaa2d7f-9b98-44b0-af08-d7e781e8f77f">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#82a2f1e8-e4d7-4cd9-946f-4a8e5fd1990c">test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7229adcf-edc2-4aea-bdf8-1f2948b6cdc3">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#65280e7d-633c-4866-9627-f017e1b7a74c">test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#75e97873-5b37-485b-b08f-2d7a0c6584d0">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#00d24c77-d635-4720-9d4f-ace606ca4e3e">test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#69d3a3e4-b792-43da-84c4-dd9a371f4a32">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#853179aa-dce2-4e14-8759-f9fcf124ff21">test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b9e4a7ab-3a5a-4321-a4f2-68d7e88148f7">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#f16fed71-b55c-4831-943b-805a2201b35b">test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#b045b522-4ef9-4d2e-bddc-f22e3762dd47">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#1d70818f-5b27-4290-a575-e40047bcc71d">test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3395671b-c837-4af3-bc6b-cccb4f797ccc">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a6bca593-4c3c-46eb-8746-7979893d423d">test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#dfa302cf-4218-4340-bb5a-5f1ebcd43ce6">test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#d11ec683-4fdb-4043-8968-06c1a5a663a6">test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#c1589ad0-e79e-4a7b-aca9-a612d8586567">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#da6e9853-67b9-426e-923b-d8d6b1ff95ab">test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#0b550811-3537-4e3b-9f47-c77271883dc4">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#fae9c4b0-d599-4403-835a-4ddc589ac0c9">test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a3073e85-fa53-4c8e-a41d-c6fc1523b4f0">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#950549e8-a40a-49b7-861d-da8d50bea6c8">test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#f8200fca-4ac9-48d9-9c75-bf7ef4ff5406">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b45e10a0-8a1c-4866-82d3-79e6a7fbde64">test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#99c39af6-a103-4f56-af61-d4abaf70c480">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c0444912-4f88-493a-968d-fb1fd72479ba">test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4ee28694-d7cf-4b73-baca-253b2881bc71">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#8a3fdfa3-17bc-4e3e-bcad-a12433af73bc">test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#4a34d58d-35a6-4443-b035-ba1004d0a93e">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#769a103e-67c7-43fa-8aeb-9874802de13d">test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#473eaef6-69c1-4fdb-9ab0-6645494af7e0">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2e4929ea-38d6-4bf1-8af1-76215d0dc2f2">test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5a461fd9-f68e-4164-822f-c6589a82fa4d">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#c21417f3-e995-48f6-b360-3204d9866f37">test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#cde6cecf-54f8-401b-bbb8-8e7f1d1fd840">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#e6a31a8a-908f-445a-9c1c-dd863efa0ca9">test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#15e14c81-782b-4c65-8836-c404048b30e1">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#15a9c596-408f-413a-b1f7-040a5c2326a3">test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5aa33eca-fb1e-4e41-a3d3-ff193e295d6e">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#96e3ae21-bde0-4f31-a605-af7fb9a41860">test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#ec88cd94-1286-4a73-9076-f1d0465e07b8">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ab4b6878-00a6-4c00-9c14-2d8051ea1f92">test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#09dcd610-1952-4fa4-a83e-10efd200913d">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a580448f-d3bb-4a7f-8e2f-925be42811b7">test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a2783e2c-37b1-478e-8d12-96cd2923c600">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#bff34a99-3c67-4bf9-99aa-1aab06aaa2f7">test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#cee1c6cc-d5e3-4eb1-9829-f14f7c8137b1">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ec8073db-c7a0-47d5-bb8b-3a8511424622">test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#76513ce5-5c49-48fc-bf5a-2e6f915f11f8">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#692ee0eb-d8b8-4129-b790-e67fd889176a">test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8dfd45ef-1d83-4c21-a54f-055d6a745f31">test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#4d586503-0791-4c66-b45f-46d6a245030b">test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#476da748-8ad2-44b0-be9b-5b6583cf20ab">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b8a7b9ac-760b-4d89-aafa-3c50f5d0d551">test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5bd0c49f-eebe-43cf-b711-ced665cb9d0a">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#31f1986d-4b70-4927-8029-d415962ab10f">test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#f21673e4-0833-46fc-8e2c-4bd787997f0f">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#cf8d2984-3efd-4f6b-886c-9addc8d67e4f">test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#f729e9ab-29ec-4a0c-a9b5-4f7e66cd3e03">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#32532eb9-f499-4c5b-be29-30764e1d6b82">test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9c7c8a5b-437f-4a44-ac8c-1d82dfa4bd36">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#5038368d-2196-4641-8960-3c91a60800eb">test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fee41d16-c5db-490c-ae48-b81cb8de80cf">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#37d32fd2-d3ab-461e-bba0-13a29116fad3">test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#89106a3e-2bb6-4854-865a-3ec2bacb8f8d">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0fa0c4ef-1898-4434-9adb-3b390650f880">test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d209d077-774c-44dc-bc8d-58e58cdd468c">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f5b7e1de-dd51-4f68-8446-7c40d2cf7997">test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3dfe02a0-0030-4b12-bd0c-21997fc4ea7c">test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b3e44ae5-7fa1-477f-87e8-dfd37dde4428">test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#2050baa5-77e3-402b-80fe-f22fbc55c6ab">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6c8e050b-ed67-4d8f-8e79-a476c1e9d0af">test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#524f917c-f01c-470f-921a-a9a0fdf5cc33">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#69c2fdef-13dc-4868-8667-ccda52682be8">test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#d4dc78b4-3a44-4a16-80f6-47a967b5e3b9">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#94e76e3e-da1a-47ba-b76f-ecc87d43cddf">test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#54cd6ed5-f7a0-48d7-9a16-3eb124c44b5d">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ed0e245e-a5f8-4a02-82b1-74d627ce2f81">test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ef78e754-5ae7-46ce-b643-b0cfce6b8695">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#86c75972-9616-4c16-9900-789e850c5296">test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#5c214800-c81b-4af3-aafe-6570a3b61adc">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#8ce6df05-9237-4eaf-ad7a-aa171c80906c">test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#ba9ea284-e474-4dc6-b2be-7cf470e617d0">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#dbd52ce6-9347-4678-a3b9-ec268a3f13cb">test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f36d419b-1c9c-4928-865f-d77290090241">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#720b60d2-7d6a-4476-85c6-d82eaae19e52">test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#529d9c24-1973-4e0d-b34c-d1a5d36a55ff">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b673d2c9-0060-4f20-8c40-6ef6d22b5008">test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#2961195c-e5e6-44ab-8e48-bef58de88331">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#8221c51d-173e-42c2-9e17-6fee2edd2e24">test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f10b1f14-3c6b-4508-9449-0dd1d793b2f9">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c9ce6215-7877-4542-b501-536fd05afb09">test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8f2d04d1-c33d-473c-8300-d48353f8400d">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#72f81d36-37e2-4feb-9ad8-574d1231a7c5">test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#bf7e76b8-0cb4-4a5f-9c13-21ca7eb1ec4e">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d581db06-fd89-40ea-9fd2-7f09b3ac6e26">test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2924d4d8-a150-468f-9894-0762112fe638">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6c66445c-7995-46de-8efb-e95602837bb1">test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ff83c952-6840-47dc-bb6b-cc1e11a4c538">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0db13166-6dfd-4acb-8540-4868da621718">test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e7827bf3-564c-43cd-9873-34114ccab625">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#65bf3b6e-dbbf-4500-8256-59618343c138">test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#14f29738-43bf-4c0e-9835-2e58722e2dac">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6ceeacf9-8f13-459a-87d4-2f34413acfd8">test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#54eb439d-510c-4e67-9914-6de92ac3ec70">test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f8eeda82-f582-49ec-89fc-8b1dbfdaea62">test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#04d9bb8f-59ff-42a1-93c6-e0f7606a2903">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#80c83b5f-4af8-41f7-af98-0b1c0c68219a">test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#23bc43cf-31e4-4d3e-9a25-5768bc021348">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#82f4658c-867d-427a-ade2-a4058daa9b71">test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ebd4ca5b-3949-4142-82b4-1060517a7d83">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d15eaee9-769f-40b7-9a8a-d058ead99a1a">test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#e364ee33-4641-440c-bcc0-7f251824ebe0">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#9b25ef29-ba10-4045-9fd6-491d6ca619fd">test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f2b8270b-efa3-4e2c-a609-6cc52fec8ea2">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f79f1a0d-227f-4f06-8cd4-cbaba3101a26">test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8765b346-0851-4443-acbc-c84452b0d91a">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#3c2ab1a6-5de4-48dd-a2a5-41786af5db81">test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#28610563-1f24-4724-accf-cb376876e8ca">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a6c50859-51b4-45cf-bff2-3df6b7fb8b75">test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8885c7db-a67f-45df-aef7-4bb298310708">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9c3887f3-e17c-4e1f-bf21-d833b7be4ab1">test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e577643b-cf2e-4d48-99b3-e3141c22728d">test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#6cbb7099-fa98-4172-8640-24df89516890">test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#4fe24f0a-664c-4f80-bdd3-426c3d4f2ca9">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a8b0b116-578d-4cd6-b61b-6bf16667fd89">test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#c7c94f97-1f53-418c-95f2-0119bc7501b1">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#b1fae2b0-1a57-4172-9e93-32efc59b6804">test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#722d0b44-f063-4b83-a562-b126dc698e69">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#c75175c9-45ad-4740-9310-4d10319b1b5b">test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#158b256b-e577-4c9b-a892-1f040b4630b5">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#15569857-3fb7-4f44-a7ca-5172b1d80cf0">test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#44e82ee1-f8b6-49dc-9101-3aee7ec08017">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#58755acd-69d8-4ca2-b677-bb63354064d6">test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c409effe-07ec-4a94-b487-e3d69b442330">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#8e54198e-d4cd-4fe8-97e8-9c0a221fd7aa">test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#4abbea36-35d9-4cfc-8bf3-81cce50d97f9">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6676a245-a469-4084-ba93-9918bbccc2b7">test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d6e653eb-1304-4108-840d-b77a704da3e4">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9c525d3c-1dbe-4e8d-9316-0954633eebef">test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7c2cc806-1b07-4876-972a-cf05dd82e389">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#f7d03e6d-1c68-4b0e-9f78-50e83d349632">test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#89af616b-af7e-4ebd-889a-977a61f7eb6c">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#95476562-41b9-4219-96e0-21f4808d8194">test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#a82fc91f-0fc2-4a2e-b3a9-4c89182cd110">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#31e3d2e6-4cf6-4caf-af6c-667e8cfc4af0">test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#9636eb6b-cfd8-410b-a899-8c2d26e3cdad">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#03956827-a6b5-484a-8307-f1a9fa86b5a8">test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#fb16730a-4b30-4cce-8402-020910f3fec2">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#4df1e56e-f7ca-4e78-a36b-ef918a392a81">test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#41ea96e7-75e7-404a-ac97-8f611a9863d6">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#952a63b8-65cb-4fde-a687-83c4f654c0d3">test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#1835b179-11e8-4d5c-902e-18473c6cbd64">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#88803aab-764a-4977-809f-26a389730cee">test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#3f911d60-92b9-4238-8745-b1d0540ccd5d">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#32be981f-9010-4771-909a-13b8ae86a442">test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#7b19c0ea-4331-4832-a644-e4e5271ecfd6">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#91f9493a-a430-4c39-b862-0f117dca3771">test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a8c51669-b5d3-4b82-a67a-0d157143a939">test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#b39284f8-fbac-433b-a13c-07996029f340">test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#60dcca0a-dcd9-4f11-966c-3a4c64bb4d11">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#cc37eab3-ac8a-413d-94a3-d380fe78b573">test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#d88cd34b-a8ac-43c1-8e6e-44279a414ba0">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#d8b2e0c2-7722-4787-94f0-ff8b73a173fd">test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#34aed33c-57e7-49b4-9f36-945af3c00c8f">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#2c36b753-558b-4e8f-9814-72bc500cf209">test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#bfe86903-2c2b-4733-9d16-fcadce6f8079">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6cf3bc3a-ca82-46e1-a154-4a360df6b115">test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#9c6c1ffb-729e-493f-b247-4da2400eba42">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e5da4f6c-b1e2-49aa-976d-b7cd7c35dba9">test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#92e88396-4c7f-45a9-98d5-e2ec67626fcf">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#ed050fd6-f7af-439a-903b-5884d3eb520c">test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#6cff0466-71a9-4987-ab51-6a0e422b58ff">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0e68cbfd-38a5-493f-9f5f-1434fff481ed">test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#6c0ac44d-e559-41cb-9a24-e1bed915f38e">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#dc6402fa-55a6-4b77-8eb4-3fe7940ceb7d">test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#e8d28e03-47d4-4cd6-8f94-d3c580afba0f">test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#7fecc0bd-cf89-4125-a4f4-229d9b18fdd3">test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#d4446bf0-1e75-4738-8bbc-3fcb27d1e0ab">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#190b46f5-040b-476c-9dc5-dceac5b4593e">test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#28fba998-3118-4654-a781-7a3735cc35e1">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#947dd7b4-15e9-4ed0-8787-ba5a6d0425f7">test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ada9fe9c-f09e-43ca-8124-f3146358d532">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#f0de05ae-1b84-4f59-b920-cd6a1dcf362b">test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#7db1614f-bfc0-4d06-9019-aec47a7d709f">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#26f4d3a4-a4ef-42f1-afae-0e7dc3a609c3">test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e099cdcc-2809-4d4f-b7f2-06c316e0e635">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#30875d21-f00e-4adc-9530-6a31ffee7c34">test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#275d9edf-84e3-4f3c-9579-af71ba0ab2b1">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#932230cd-a0a4-48f7-817a-83c1011fef41">test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#393b0210-68c9-4a05-ac73-5c7953169058">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#27318908-85fa-4ce3-85fb-425fae704786">test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#32231dc9-e7ec-4849-9654-3f2428fe61c4">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#f925e55e-5889-4b8b-a8aa-cd3438049489">test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#b122eb0e-8cb5-4f2f-b8f8-a8abdede10fa">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#1bb6a5ca-a422-418b-8963-849c5df344cd">test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#e77add3c-575c-4840-94ca-a037fe48bf90">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#875609f2-fcc4-409c-9e0e-081e4a21694b">test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#19d099ec-84d5-4375-9d20-c1911ad6f086">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#144210fd-adeb-4c10-89c4-07d35c8100e3">test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7959a57e-2037-48c5-93a2-e46fb42c2a15">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#e0cce35e-eb2f-48b2-8a6a-d620c44547bf">test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0744cdb7-3b66-4cbc-9685-4eb72daa5f2d">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2ef456e0-7c0f-4948-b24d-4c1b7030950b">test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#16a31cee-0484-4018-8b19-aad4ccab0878">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#92f06bf7-d853-4ea8-a1a8-c30382e28149">test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0e76ee29-198c-4dca-a1d0-aa4b349b45cd">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#918ba569-0571-4a30-8ac0-bfb25b742d83">test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e6851539-8156-4e1b-93d6-eedf52aba117">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5f5f5b38-8ebb-49f0-9e4c-305d6775bb08">test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#ef2b4c2c-0015-4b95-888c-daf611bb672f">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#a60cd981-6fd0-4728-bceb-e107e3611254">test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#8cadc824-89fa-40d2-9815-6c345214682a">test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#41fa903e-9b61-4ee7-baf6-fbbda9d15898">test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#167b0e97-8ad1-43d1-8cf7-1a576ad776b8">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b0022f9f-9c51-4c4d-927e-d43383ef3a3c">test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#17789bd7-5bca-4f7c-9319-45ba1f0f87d0">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#2a4904ec-a813-4875-826d-bfceb31bd8d5">test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#93446c8a-82fa-4c91-afa6-4f12bdb74a29">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#4fc35a89-2c7d-4b3b-894a-9404ecb51b7a">test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#85ef15f4-6fc7-4180-b2d0-15dfbf219106">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d8ed13de-7ede-477b-a91f-21f644f34f67">test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#39e861fe-713e-49bc-8264-0e5a4e7b18fc">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#467a4a35-ebfb-4e06-a81d-eef181eb19ad">test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#363a72fe-afd2-447a-aa25-2d6ebb4f435e">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#d15a18eb-6384-4e46-b281-3892a8ffd65b">test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#be22cd39-121c-4810-8a88-5050a88ec826">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b8a6b717-920a-4083-a12a-7fed760c3c6a">test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#061b0587-09fc-4729-8e75-2b78b3738642">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#dc9e338c-a382-4f70-8df8-a541e9859045">test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#56000577-c5f0-4c65-8222-b9fdefffb74e">test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#2077fe4e-ea71-420c-8718-60b315fa5bc0">test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#3a52146b-f999-4974-9d81-0aab9afff641">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#78e5100d-ba6d-45e6-8185-5f31cebc480c">test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#922d0160-bef4-4124-9d4e-0ef9b61a49d6">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#678c19d2-1fa2-44ed-adf3-1a886ea6495f">test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#c0d22d66-6c85-49a3-8d29-0577d6740358">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#d03ca75a-e39a-4d57-82de-41c7861f1512">test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#1b1b469b-df20-4afe-94fe-0cf316ba3190">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ba521cc7-eb3b-46cd-9186-1824145b5297">test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b3631e22-63d8-4c81-8313-cfd4da15f3ad">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e6350f37-7ab4-4d10-a043-53ae21e39854">test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a5523a8e-12e6-4d23-872f-2593c2def7df">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#3e7adf96-6fab-4eb3-91ab-489f0c8fb696">test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#f6b82c3d-fccf-44e6-9a84-6eff8f162eff">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2ce0eaa8-6232-4de9-b97d-d49dcb612628">test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#8f642dfa-ab98-4fc2-8e0a-d9bcc56e7669">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#54ac7d64-3c7f-4823-b53b-87a3d610de5d">test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#94dc4bcb-957a-4bc8-9f21-b8b693cd8ec0">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5439d411-2b5c-47b4-8baf-4850db91ea3d">test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#ca891873-d60b-4808-ae98-a6ba14c6e58a">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#698990b6-c9bc-4c69-b72f-5777627bf7be">test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1687def5-669d-428b-a72a-4269f4cad8af">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4b44f7c2-39c3-4875-9843-46488e30cdc8">test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ead93d81-6e10-4c2e-91dd-982cc6728c7a">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#a99e532e-126c-442e-8dca-7c5ff8fe6456">test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#975a57fd-fe4e-44e3-8598-0d9b140348ef">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5d53a65b-b973-4a75-b128-3b792944a83d">test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#da7115ba-5fa9-462e-8ac6-f53b3f4c9797">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9410d692-0b35-4a44-8e7b-c08c5a25936f">test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ea921efe-3713-472e-82d1-0274cea2d125">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#e5458f81-e2b3-4a70-8697-59a6ce4a792d">test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#e99df161-c977-48da-8e02-4862464f66a1">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#f62e38c7-e3bf-4447-98e4-81ae1e8f2f03">test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#5c740010-27d6-44a4-a0b0-5ad763566cd4">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#631ff4ed-d3c1-4419-9304-1a1c703a88b6">test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#87c38b36-6f24-44f4-97f9-6ee8ea6cdbe2">test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#8e541a4e-59e3-4fc0-9d1e-030e06b9ee25">test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#391b8ebb-bbae-4adf-8981-e57daef1b459">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#b77e9700-3cbe-4e75-a94c-ef3d62a00169">test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#2223a650-2463-4a3b-be76-005027997d00">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#cc992dc6-a951-43e0-bb7b-f139c1559004">test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#febc135a-4ce0-4736-95c8-e975a08fbded">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#ef833360-8472-442b-bad9-fd290b9471b5">test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#9e7f2e44-b97a-46c6-b85f-8d9b84261308">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#5af5aa7e-30aa-421d-a5f1-9915696e2dde">test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#223ed98d-be58-478c-bd74-633382d9512d">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#6d0abcd7-add4-4c4b-8f16-e3dd049f70c7">test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#0b036481-03b2-448e-9359-aa09d6bb4a4d">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#a033419a-d090-49a7-863b-1659b04497a2">test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#1f54882d-c08a-461f-afd9-42a2df481f4c">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2ff3ce5a-604d-40c0-8288-703cbd9e2958">test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#691b9306-2529-4b00-89c8-2d828716151e">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#4c83e3bd-ae95-421f-bff7-877789eb94f1">test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#6b384098-5c84-48ce-bd19-30ad0128bc39">test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#421102e3-2c12-46ea-b489-7034fae55afd">test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#52d99e39-e2bc-4d7f-afc1-e232286cfd42">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#ce5fc7ac-b7df-43bf-80f8-54a07d4e6fc5">test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#03dab0f6-ed0e-4a62-943f-17077c9e2cbf">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#614106fa-6525-4f1c-9101-4f6ea04572f8">test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#1237fd04-3617-4dfd-ae5b-6760eaa4eac2">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#64f57550-6d9e-43b8-8547-1d9752fd2d26">test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#09aa7c7f-fe7c-4f77-9655-2c0423fb0529">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#3315fce6-a72f-4a2b-9523-e06fa9d02d7d">test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#bb6af3fa-9f4d-4f3c-a7a6-6b59538491b6">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#ff443941-d2fd-4e08-a429-442d5182190d">test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#a5c77d36-7e81-4173-84e9-2c9051d9d10a">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#61d21cdb-10d4-493b-8a85-123639944d28">test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#09a12cc1-3670-4e5a-9412-b3ec0ef1cb49">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2f6cf19a-7272-46b5-baf9-423f9827ec75">test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#e4dc0de7-42b7-4bcc-b45e-a1018195f54b">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#924d441e-4503-4636-94f1-dd07f3fbd45b">test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#4a73fbcf-8ece-4e0a-92a1-a5ce7650ba2f">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#e03b02e9-f4d8-4958-897c-dee8b678771d">test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#1c510b9c-cf1d-4ed3-a215-5de71205e0c6">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#d085e81d-ab65-4ca9-af4a-7fb0642cace1">test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b91f7f41-be45-4f36-9b0c-306ffe382d3b">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#c35c95f7-d43f-41e0-bcd3-74ee9a325cb1">test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#11d2529f-ba1d-4b68-8930-c4410c50b228">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#14d0b499-3547-4cfc-9dd1-f8790794b67c">test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#0473fefc-1592-4025-a7f5-9a4780999bd0">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#a64d63c7-a5be-423d-b473-abe357f9233c">test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#51ba5e01-f8b0-4f6b-bca5-51c9aec8cd44">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#20b50cc2-b259-4c63-92ce-0207934faa1d">test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#61279404-f63c-4793-8cf2-aa66e0e39c3d">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#0d63ca19-73d8-49e7-bf46-cb8ab4a7e999">test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#108de313-b4bc-4adc-9132-0a05e152ac2d">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#2c96a461-04bc-4180-9b5f-7a24fa519dc1">test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#3254f279-aa43-4e84-a4e5-7fa22fb09423">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#bc3b4f35-ee79-4f35-9b58-afcffa61d7f5">test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#bedd1dcb-e8ea-4066-a4c7-d45dd91057eb">test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#5e0926f8-1ae3-4f98-84a9-28403cdc0955">test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#429310a1-48bc-407d-a6b3-c35cd6b3a924">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c8ad60fd-91bb-47e3-b252-54c3bb68b40a">test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f1c40544-faf6-492d-82c2-cc23360f4a0d">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#3bb2e9da-e7b2-4a26-a2da-dabc103bf24a">test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#ca308400-957a-4a97-9b52-484f65a2acca">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#01f97f5d-5dea-4ded-8a36-4326580aecdc">test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#47cff11f-9403-4f4d-accf-b2bf73de8cfb">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#c3916815-b97e-4be0-9939-88e905e17aa1">test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#f51fa995-b165-4f93-b87f-4e10a92250f0">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8ad30143-c83a-487f-81bb-2d56fcd8a443">test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#856a3c57-ea51-4479-8908-696bb5480fa9">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#47b372d3-95ff-4549-b55c-5b09aebe81a8">test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#083a3861-5edf-4c14-a969-5938addd9871">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#87de06d8-65f9-4388-835e-f741b8fb4778">test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#1f4db862-6d9a-455c-99c8-5db2360f5eca">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#9801a027-c801-445a-9669-528c6f3b5069">test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#206677a4-7f73-439d-8e86-011ae50dd849">test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#af955c8b-b89b-4249-9240-75f1f2b0508f">test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#389d14d5-847d-4629-9e29-a22ffcded00e">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#79b2d359-4588-45a9-b8ba-e1c964101ee1">test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#51627e09-f55d-4304-8739-88aa3b00ee30">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#8948b7d4-63e7-44fb-a44f-bb44cf01d59c">test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#fd6d359c-2513-4422-8975-70fbf5aa195a">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#b0aa3444-3cb0-40d3-b091-396e79c5463b">test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#dca16fd9-f55b-4f59-8bd1-b2d0e9165303">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#0aa4eede-a925-4987-88be-8bfb525f5150">test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#41b23980-6547-4e3b-a989-3c7723de37fd">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#dfe07c1f-54df-41b7-9ca4-7d9be5029781">test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#3db9377c-41c5-4e05-9e30-c4b9daaba63d">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#932c8738-b978-4890-b976-c97e32de6863">test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#edac4626-d1cb-4a20-83a2-c4381b6e4db8">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#6b415d13-56ae-4608-a17f-5029f55e0be5">test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#b1d37bb4-1e83-4e52-b0eb-e1ac9c4555e0">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#e148f20f-2604-4ec0-b31b-c51af8f98b47">test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#7390fc82-44a6-4a25-9480-d9438086c55d">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</a></li>
                    
                    <li><a href="#3d9887d4-d6ea-41d8-a1f7-76cc450b0321">test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</a></li>
                    
                    <li><a href="#b519b425-9da0-424f-8871-ce5a9ee9a404">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#49583b6e-129c-4e8e-b377-4f7daf255e7c">test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#64c800b1-d86d-4aa6-a117-387a85e8527e">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#116c205d-191d-4037-a1a8-0b008097ccb8">test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#dae81305-6204-4328-8d56-ecb65279e8d2">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</a></li>
                    
                    <li><a href="#95f94971-4672-4af0-a259-97c96b82ac3b">test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</a></li>
                    
                    <li><a href="#6ffa98fc-2b60-4cec-9a78-075536af306f">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#13d44e19-5960-45a1-9fda-4123fad48e6b">test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#982dff40-0690-4475-b22e-a037b1696646">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#be2f92dc-a26c-48c5-b502-2a2372884974">test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</a></li>
                    
                    <li><a href="#88e8b8f8-72ac-4e70-9622-d0b24853516b">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</a></li>
                    
                    <li><a href="#5d901c5c-e96f-4e2d-a27a-0518f9bbf9cb">test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</a></li>
                    
                    <li><a href="#8c8742ad-b96e-42e2-bc48-cb691b2105b4">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</a></li>
                    
                    <li><a href="#fdb7d8db-32ce-4a49-aa3d-571fc417c947">test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</a></li>
                    
                    <li><a href="#49e9b24d-3b88-4367-af75-19d936562a78">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</a></li>
                    
                    <li><a href="#70caa6f0-cf30-4486-a0d2-262db4451fc8">test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</a></li>
                    
                </ul>
                </li>
                
            
            </ul>
        </td>
        <td class="failure-index">
            <ul class="toc">
            
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#93ee648b-188e-4fe6-87d5-14e8c90029fe">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_and_memory_limit_and_nthreads</a></li>
                    
                    
                    
                    <li><a href="#47b626aa-15e2-4123-8f7a-06d878ebfca9">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_pool</a></li>
                    
                    
                    
                    <li><a href="#f4f435be-07a8-4678-a1ea-78c42c75d01f">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#850ba467-c2f6-4f6e-beca-e200b1ea7b4a">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#cf2113f8-4f91-4c27-8264-63ca2001de08">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#6dc4a151-396c-4aa2-82fd-d1b2b9c4dcc0">[F] dask_cuda.tests.test_dask_cuda_worker : test_dashboard_address</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#660f7388-0498-4d2d-acd2-1a77c5af67fd">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#4024643f-2a02-4a9f-bed4-8f237c11a18e">[F] dask_cuda.tests.test_dask_cuda_worker : test_pre_import_not_found</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#75d589ca-f627-480a-a7b9-2c9cbe5cbd04">[F] dask_cuda.tests.test_dask_cuda_worker : test_cuda_visible_devices_uuid</a></li>
                    
                    
                    
                    <li><a href="#6e3103e9-4711-43ff-a2ac-e5dd02a506b6">[F] dask_cuda.tests.test_dask_cuda_worker : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#8b5d170b-5989-428e-b7e3-806cf14383e3">[F] dask_cuda.tests.test_dask_cuda_worker : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#937ab6df-eda5-4123-bf8b-ba44817f573b">[F] dask_cuda.tests.test_dask_cuda_worker : test_worker_fraction_limits</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#4db21311-e75e-449c-986e-164ac4510a18">[F] dask_cuda.tests.test_dgx : test_default</a></li>
                    
                    
                    
                    <li><a href="#bce2e316-231c-42d5-a3ce-9f19a92952e3">[F] dask_cuda.tests.test_dgx : test_tcp_over_ucx</a></li>
                    
                    
                    
                    <li><a href="#9128da95-7bc1-47d9-ba5f-7165b05283c2">[F] dask_cuda.tests.test_dgx : test_tcp_only</a></li>
                    
                    
                    
                    <li><a href="#ef7e969d-5da5-4a92-8faf-650d94c7fbc2">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params0]</a></li>
                    
                    
                    
                    <li><a href="#4cb8f194-ae48-46ff-841c-eb260715ed73">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params1]</a></li>
                    
                    
                    
                    <li><a href="#bd38331f-4ec2-4b59-85f9-a0a4a01e7021">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params2]</a></li>
                    
                    
                    
                    <li><a href="#07b90380-9843-4be7-919b-f7ce9d15d2cb">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params3]</a></li>
                    
                    
                    
                    <li><a href="#0f67811c-35ff-4621-97cf-1e23c826b7c3">[F] dask_cuda.tests.test_dgx : test_ucx_infiniband_nvlink[params4]</a></li>
                    
                    
                
                    
                    
                    <li><a href="#c38c28d0-46bb-4187-a6c9-9d5f9a67aeca">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[tcp]</a></li>
                    
                    
                    
                    <li><a href="#9838ea92-9a28-4a6d-8504-694662cbbdfd">[F] dask_cuda.tests.test_explicit_comms : test_local_cluster[ucx]</a></li>
                    
                    
                    
                    <li><a href="#2256fb31-5857-43ea-9c10-6a04a5ef5954">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_merge_empty_partitions</a></li>
                    
                    
                    
                    <li><a href="#509d524f-688c-487b-bb16-cb573f4b0145">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#a5b90c1f-69e9-4a15-9a88-e8f5c163b689">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#6ed503ce-ffc8-4c47-8a6f-59798bb7834d">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#cbfa2488-8b26-48d8-b6bd-c301e3f19de4">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#1ff4b11d-064a-4652-abaa-7bc5836e0477">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#588601cb-f39d-435c-a42e-03e7342288df">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[tcp-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#6d860f2e-cfdf-4097-bfae-d1ca0461eed6">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#3deba6be-fdf1-473a-afd0-50e979f2a40c">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#b0904cf7-0c6b-4487-b9a3-577db28a3274">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-pandas-3]</a></li>
                    
                    
                    
                    <li><a href="#8c6196a6-60cb-4c31-bf17-2a3b8ac88393">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#87ea1c35-0bef-4bae-b0ce-b2e353a8ba63">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#2ee67121-4997-4d8b-aa53-96038122339f">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle[ucx-cudf-3]</a></li>
                    
                    
                    
                    <li><a href="#c9ca6770-bdb0-4b0e-98a0-1ba4ed90bd38">[F] dask_cuda.tests.test_explicit_comms : test_dask_use_explicit_comms[True]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#8fc5ef81-6c95-4418-b779-023993be739a">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#4eb3e187-5766-4c89-91d1-d956be17cc70">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#c919f1ac-29fa-4732-8647-fee800b90cc0">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#185a7934-7bf7-43f0-b67d-823f98430f92">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#21cd7e81-70d3-429c-917b-db2feeadbdaa">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#b7b4340f-6c54-4c36-a562-06c1f0f2d03d">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[tcp-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#dfacfea2-d36f-4541-858e-86cc95a45dd3">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-1]</a></li>
                    
                    
                    
                    <li><a href="#39fa94d1-b426-4d92-8fe9-90f5f7dbaa77">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-2]</a></li>
                    
                    
                    
                    <li><a href="#86596f70-0c90-457e-8053-79fbb191e7a6">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-pandas-4]</a></li>
                    
                    
                    
                    <li><a href="#cb4051c6-1a8f-4fa6-b0d7-5752dcdff7eb">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-1]</a></li>
                    
                    
                    
                    <li><a href="#0bc88955-d273-40ab-8c20-3a15f69d6ef4">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-2]</a></li>
                    
                    
                    
                    <li><a href="#456fd43b-5e1f-465e-8148-9a9b8b0a662c">[F] dask_cuda.tests.test_explicit_comms : test_dataframe_shuffle_merge[ucx-cudf-4]</a></li>
                    
                    
                    
                    <li><a href="#347688ff-7ce2-4412-8b3f-888ce3aaef69">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[tcp]</a></li>
                    
                    
                    
                    <li><a href="#0814ea3d-f1e5-440c-b815-73551a581f40">[F] dask_cuda.tests.test_explicit_comms : test_jit_unspill[ucx]</a></li>
                    
                    
                    
                    <li><a href="#beea52ed-dcd4-4803-a417-c92fd068e7fb">[F] dask_cuda.tests.test_explicit_comms : test_lock_workers</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#29c9c3ca-4691-4255-9262-ff6ee1d58e38">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_tcp</a></li>
                    
                    
                    
                    <li><a href="#6fe42911-7f3f-4f26-b738-93e232d3a70c">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_nvlink</a></li>
                    
                    
                    
                    <li><a href="#52be3d9c-1836-4951-87a9-031a74d433c3">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_infiniband</a></li>
                    
                    
                    
                    <li><a href="#2f59e388-38d3-40a2-b313-4634e43f691c">[F] dask_cuda.tests.test_initialize : test_initialize_ucx_all</a></li>
                    
                    
                
                    
                    
                    <li><a href="#91800987-006c-4d01-82e4-e137ad94c014">[F] dask_cuda.tests.test_local_cuda_cluster : test_local_cuda_cluster</a></li>
                    
                    
                    
                    <li><a href="#09aac0b3-750b-44af-920c-8d520751b963">[F] dask_cuda.tests.test_local_cuda_cluster : test_with_subset_of_cuda_visible_devices</a></li>
                    
                    
                    
                    <li><a href="#67fb8676-29c6-4211-9c08-ca46e1de3729">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[ucx]</a></li>
                    
                    
                    
                    <li><a href="#6a506768-53f4-4ea6-8e13-856d1f646178">[F] dask_cuda.tests.test_local_cuda_cluster : test_ucx_protocol[None]</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#809c6316-cfbe-4178-8c7f-eaea2e28e8c5">[F] dask_cuda.tests.test_local_cuda_cluster : test_n_workers</a></li>
                    
                    
                    
                    <li><a href="#3191c401-244c-4141-8c7d-652497fdcecf">[F] dask_cuda.tests.test_local_cuda_cluster : test_threads_per_worker_and_memory_limit</a></li>
                    
                    
                    
                    <li><a href="#fd955e94-5bf4-43f3-94a7-db78fd5b39a7">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cluster</a></li>
                    
                    
                    
                    <li><a href="#f7ef042b-61d7-44d3-9cd0-072f2469ec0e">[F] dask_cuda.tests.test_local_cuda_cluster : test_no_memory_limits_cudaworker</a></li>
                    
                    
                    
                    <li><a href="#60909971-089c-47f8-9ba4-113c80bfd5e5">[F] dask_cuda.tests.test_local_cuda_cluster : test_all_to_all</a></li>
                    
                    
                    
                    <li><a href="#f6cb16be-fa0c-4757-a078-d3fca7db61d6">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_pool</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#ab401c94-8f24-43c2-9044-86572ae16d59">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_managed</a></li>
                    
                    
                    
                    <li><a href="#78353dbb-4111-498b-980a-04023881f65f">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_async</a></li>
                    
                    
                    
                    <li><a href="#ceb8d151-d53c-4a43-9ddd-9c61f487ce3b">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_logging</a></li>
                    
                    
                    
                    <li><a href="#71542536-c337-42e3-9861-462eadbc240a">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import</a></li>
                    
                    
                    
                    <li><a href="#23665cc1-0ef7-4778-b815-b131a6053e57">[F] dask_cuda.tests.test_local_cuda_cluster : test_pre_import_not_found</a></li>
                    
                    
                    
                    <li><a href="#49e7996e-8309-4689-acd1-004859beecb6">[F] dask_cuda.tests.test_local_cuda_cluster : test_cluster_worker</a></li>
                    
                    
                    
                    
                    
                    <li><a href="#dc88c39c-3ec9-4596-8808-ccbaec110230">[F] dask_cuda.tests.test_local_cuda_cluster : test_gpu_uuid</a></li>
                    
                    
                    
                    <li><a href="#b5f8041c-73c1-4819-b400-0f5650c59078">[F] dask_cuda.tests.test_local_cuda_cluster : test_rmm_track_allocations</a></li>
                    
                    
                    
                    <li><a href="#d2e4f369-c90e-48c6-abe0-99f8a397e7f6">[F] dask_cuda.tests.test_local_cuda_cluster : test_get_cluster_configuration</a></li>
                    
                    
                    
                    <li><a href="#d89a5875-40a4-4c17-9b0a-c4601cfcfef8">[F] dask_cuda.tests.test_local_cuda_cluster : test_worker_fraction_limits</a></li>
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#6612c77b-4bd3-451e-9d2c-ef7e26391c44">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#2a04be7b-c6a6-4530-addc-13ae6e48258a">[F] dask_cuda.tests.test_proxify_host_file : test_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#f66ea6de-6031-424a-84f6-a5274ea93cec">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-1]</a></li>
                    
                    
                    
                    <li><a href="#94419625-aa17-4591-bc79-ac32b7324a6b">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-2]</a></li>
                    
                    
                    
                    <li><a href="#718ead03-8dd1-4a87-8ed7-e3f645beac72">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[True-3]</a></li>
                    
                    
                    
                    <li><a href="#9e951bf1-b79b-4cbd-9026-f246b4f3cd36">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-1]</a></li>
                    
                    
                    
                    <li><a href="#432d9835-c146-4ee0-bd39-e8680323f2ae">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-2]</a></li>
                    
                    
                    
                    <li><a href="#3206cf4f-66ce-4cd1-b876-a4154f420bf8">[F] dask_cuda.tests.test_proxify_host_file : test_compatibility_mode_dataframe_shuffle[False-3]</a></li>
                    
                    
                    
                    <li><a href="#8966f467-b489-4145-8e2c-453fb1b919e1">[F] dask_cuda.tests.test_proxify_host_file : test_worker_force_spill_to_disk</a></li>
                    
                    
                    
                    <li><a href="#e68da2a8-cf96-401a-8afc-93b3c0a17c95">[F] dask_cuda.tests.test_proxify_host_file : test_on_demand_debug_info</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#4339f470-118c-488e-8510-c3d543962451">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[True]</a></li>
                    
                    
                    
                    <li><a href="#5cbf05ca-9f32-458d-8efe-8f9a509ff2a9">[F] dask_cuda.tests.test_proxy : test_spilling_local_cuda_cluster[False]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#1b86558d-8dae-40c9-8732-3106816d3aed">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-None]</a></li>
                    
                    
                    
                    <li><a href="#68c7d3b0-9cc9-41dd-ad45-7da559bfdd26">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#16f7e09c-9f96-4e0e-80b4-67d305385338">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[tcp-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#3d57b94e-4bd2-4e1c-88e8-8743b85188c8">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-None]</a></li>
                    
                    
                    
                    <li><a href="#db8296bf-252c-4cf9-958e-65e87a91f67d">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers1]</a></li>
                    
                    
                    
                    <li><a href="#765c561d-0bda-49fa-949e-fb64d2094065">[F] dask_cuda.tests.test_proxy : test_communicating_proxy_objects[ucx-send_serializers2]</a></li>
                    
                    
                    
                    <li><a href="#9c349427-ed05-4e74-ab73-2ca7cafa0765">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-tcp]</a></li>
                    
                    
                    
                    <li><a href="#47276d9d-78e6-45a0-bf91-28388e47cd54">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[True-ucx]</a></li>
                    
                    
                    
                    <li><a href="#2fd26049-dff8-4ec5-a654-6537a6ced3be">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-tcp]</a></li>
                    
                    
                    
                    <li><a href="#eea9d194-7226-45b0-945b-4b94a03d6208">[F] dask_cuda.tests.test_proxy : test_communicating_disk_objects[False-ucx]</a></li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
                    
                    
                    <li><a href="#9b14de5c-f4d8-4500-aa6a-0d47d657e645">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#014390a7-19ea-48e5-9d5a-c9d2a48669e2">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#77a33e2c-215b-49ea-92ac-10439c9339cd">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#ad4bf03c-0cb7-48e2-9e3a-d58430c07907">[F] dask_cuda.tests.test_spill : test_cupy_cluster_device_spill[params3]</a></li>
                    
                    
                    
                    <li><a href="#2c3ebf60-d4eb-4369-8a67-3e448d354ab7">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params0]</a></li>
                    
                    
                    
                    <li><a href="#c45f4b9f-8b8e-409c-b290-f7ef7ccd066b">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params1]</a></li>
                    
                    
                    
                    <li><a href="#e4bcc657-45b3-4f2e-ac2d-52e38fd6befd">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params2]</a></li>
                    
                    
                    
                    <li><a href="#56ed431c-0143-4e22-afde-9bf06e091a48">[F] dask_cuda.tests.test_spill : test_cudf_cluster_device_spill[params3]</a></li>
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li><a href="#d704e01f-b0ab-43b5-ada3-3ad7e28880d2">[F] dask_cuda.tests.test_utils : test_parse_visible_devices</a></li>
                    
                    
                    
                    
                    
                    
                
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                
            
            </ul>
        </td>
    </tr>
</table>


    <div class="testsuite">
        <h2>Test Suite: pytest</h2>
        <a id="60656e4a-530b-45fb-9ea9-cc77ad41cf54"></a>
        
        
        <h3>Results</h3>
        <table class="proplist">
            <tr>
                <th>Duration</th><td>462.588 sec</td>
            </tr>
            <tr>
                <th>Tests</th><td>1179</td>
            </tr>
            <tr>
                <th>Failures</th><td>106</td>
            </tr>
        </table>

        <div class="testclasses">
            <h3>Tests</h3>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_cudf_builtin_spilling</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="b3a5d821-01cc-4651-89fa-ecc588e899fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64f35124-02ee-426a-9f46-da7f8894ee65"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_is_spillable_object_when_cudf_spilling_enabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.089 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da0a3cd4-bfbc-4896-bdf8-fd253b037b28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_when_cudf_spilling_is_disabled</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bced51c7-5753-4552-9ff3-b5bf7a5aaf45"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.044 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ebbe196-8b0d-4d02-bcb5-c3a9b7d7de44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxify_host_file</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.136 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dask_cuda_worker</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="93ee648b-188e-4fe6-87d5-14e8c90029fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.123 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e12e0a0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-25&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0006361007690429688

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;
address = &#39;127.0.0.1:9359&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9359, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e12e5c1c0&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,7,8&#34;})
    def test_cuda_visible_devices_and_memory_limit_and_nthreads(loop):  # noqa: F811
        nthreads = 4
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9359&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9359&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;1 MB&#34;,
                    &#34;--nthreads&#34;,
                    str(nthreads),
                    &#34;--no-dashboard&#34;,
                    &#34;--worker-class&#34;,
                    &#34;dask_cuda.utils.MockWorker&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9359&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9359&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9359&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e12e07310&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e12e0a0d0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9359 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="47b626aa-15e2-4123-8f7a-06d878ebfca9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.114 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e026f3c10&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02ca8a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-53&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 1.5735626220703125e-05

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e0283ff10&gt;

    def test_rmm_pool(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e026f3c10&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02ca8a60&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f4f435be-07a8-4678-a1ea-78c42c75d01f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.097 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e025aae50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-81&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gd...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0008561611175537109

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02af61f0&gt;

    def test_rmm_managed(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-managed-memory&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a3c0a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e025aae50&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="850ba467-c2f6-4f6e-beca-e200b1ea7b4a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.098 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e028a9ee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-112&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0007915496826171875

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02a88100&gt;

    def test_rmm_async(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-async&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02c56c40&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e028a9ee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cf2113f8-4f91-4c27-8264-63ca2001de08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.101 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e0275f7c0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0281f1f0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-136&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.000492095947265625

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e0274d2b0&gt;

    def test_rmm_logging(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-log-directory&#34;,
                    &#34;.&#34;,
                    &#34;--no-dashboard&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e0275f7c0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0281f1f0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6dc4a151-396c-4aa2-82fd-d1b2b9c4dcc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dashboard_address</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.104 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0281f040&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-158&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0013365745544433594

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e028cf430&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_dashboard_address(loop):  # noqa: F811
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--dashboard-address&#34;,
                    &#34;127.0.0.1:9370&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02a155e0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0281f040&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d567db0b-cdbc-4699-9971-72ca220c7b8b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unknown_argument</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>2.207 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="660f7388-0498-4d2d-acd2-1a77c5af67fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.211 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02862dc0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-179&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0009965896606445312

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02699a90&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import(loop):  # noqa: F811
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--pre-import&#34;,
                    module,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e028e39a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02862dc0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4024643f-2a02-4a9f-bed4-8f237c11a18e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.314 sec</td></tr>
                        
                            <tr><th>Failed</th><td>assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
 +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.timeout(20)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_pre_import_not_found():
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            ret = subprocess.run(
                [&#34;dask&#34;, &#34;cuda&#34;, &#34;worker&#34;, &#34;127.0.0.1:9369&#34;, &#34;--pre-import&#34;, &#34;my_module&#34;],
                capture_output=True,
            )
            assert ret.returncode != 0
&gt;           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in ret.stderr
E           assert b&#34;ModuleNotFoundError: No module named &#39;my_module&#39;&#34; in b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;
E            +  where b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)...ets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39; = CompletedProcess(args=[&#39;dask&#39;, &#39;cuda&#39;, &#39;worker&#39;, &#39;127.0.0.1:9369&#39;, &#39;--pre-import&#39;, &#39;my_module&#39;], returncode=1, stdout=b&#39;&#39;, stderr=b&#39;Traceback (most recent call last):\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/bin/dask&#34;, line 10, in &lt;module&gt;\n    sys.exit(main())\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/__main__.py&#34;, line 5, in main\n    run_cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask/cli.py&#34;, line 81, in run_cli\n    cli()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1055, in main\n    rv = self.invoke(ctx)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/click/core.py&#34;, line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &#34;/datasets/pentschev/minico...ts/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 197, in __init__\n    self.nannies = [\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/cuda_worker.py&#34;, line 198, in &lt;listcomp&gt;\n    Nanny(\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/nanny.py&#34;, line 271, in __init__\n    super().__init__(handlers=handlers, connection_args=self.connection_args)\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py&#34;, line 348, in __init__\n    self.monitor = SystemMonitor()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py&#34;, line 96, in __init__\n    gpu_extra = nvml.one_time()\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 336, in one_time\n    &#34;name&#34;: _get_name(h),\n  File &#34;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py&#34;, line 319, in _get_name\n    return pynvml.nvmlDeviceGetName(h).decode()\nAttributeError: \&#39;str\&#39; object has no attribute \&#39;decode\&#39;\n&#39;).stderr

dask_cuda/tests/test_dask_cuda_worker.py:246: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="0093bf43-047c-489f-b083-755e7be39989"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_mig_visible_devices_and_memory_limit_and_nthreads</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_dask_cuda_worker.py:256: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="75d589ca-f627-480a-a7b9-2c9cbe5cbd04"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cuda_visible_devices_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02bf7b80&gt;

    def test_cuda_visible_devices_uuid(loop):  # noqa: F811
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_dask_cuda_worker.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6e3103e9-4711-43ff-a2ac-e5dd02a506b6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.115 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e029fee80&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e028b3940&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-209&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 0.00016760826110839844

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02b35280&gt;

    def test_rmm_track_allocations(loop):  # noqa: F811
        rmm = pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e029fee80&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e028b3940&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8b5d170b-5989-428e-b7e3-806cf14383e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.106 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b35e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0280eee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task cancelled name=&#39;Task-232&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:485&gt;&gt;
timeout = 1.5735626220703125e-05

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
                return fut.result()
            else:
                fut.remove_done_callback(cb)
                # We must ensure that the task is not running
                # after wait_for() returns.
                # See https://bugs.python.org/issue32751
                await _cancel_and_wait(fut, loop=loop)
&gt;               raise exceptions.TimeoutError()
E               asyncio.exceptions.TimeoutError

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:501: TimeoutError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02823430&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_get_cluster_configuration(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;30 B&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;2 GB&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;3 GB&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:373: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b35e50&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e0280eee0&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="937ab6df-eda5-4123-bf8b-ba44817f573b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>30.097 sec</td></tr>
                        
                            <tr><th>Failed</th><td>OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s</td></tr>
                        
                        
                        </table>

                        
                        <pre>ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02811790&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
&gt;               comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fut = &lt;Task finished name=&#39;Task-254&#39; coro=&lt;BaseTCPConnector.connect() done, defined at /datasets/pentschev/miniconda3/envs/g...&lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused&#39;)&gt;
timeout = 0.0016560554504394531

    async def wait_for(fut, timeout, *, loop=None):
        &#34;&#34;&#34;Wait for the single Future or coroutine to complete, with timeout.
    
        Coroutine will be wrapped in Task.
    
        Returns result of the Future or coroutine.  When a timeout occurs,
        it cancels the task and raises TimeoutError.  To avoid the task
        cancellation, wrap it in shield().
    
        If the wait is cancelled, the task is also cancelled.
    
        This function is a coroutine.
        &#34;&#34;&#34;
        if loop is None:
            loop = events.get_running_loop()
        else:
            warnings.warn(&#34;The loop argument is deprecated since Python 3.8, &#34;
                          &#34;and scheduled for removal in Python 3.10.&#34;,
                          DeprecationWarning, stacklevel=2)
    
        if timeout is None:
            return await fut
    
        if timeout &lt;= 0:
            fut = ensure_future(fut, loop=loop)
    
            if fut.done():
                return fut.result()
    
            await _cancel_and_wait(fut, loop=loop)
            try:
                fut.result()
            except exceptions.CancelledError as exc:
                raise exceptions.TimeoutError() from exc
            else:
                raise exceptions.TimeoutError()
    
        waiter = loop.create_future()
        timeout_handle = loop.call_later(timeout, _release_waiter, waiter)
        cb = functools.partial(_release_waiter, waiter)
    
        fut = ensure_future(fut, loop=loop)
        fut.add_done_callback(cb)
    
        try:
            # wait until the future completes or the timeout
            try:
                await waiter
            except exceptions.CancelledError:
                if fut.done():
                    return fut.result()
                else:
                    fut.remove_done_callback(cb)
                    # We must ensure that the task is not running
                    # after wait_for() returns.
                    # See https://bugs.python.org/issue32751
                    await _cancel_and_wait(fut, loop=loop)
                    raise
    
            if fut.done():
&gt;               return fut.result()

../../../miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;
address = &#39;127.0.0.1:9369&#39;, deserialize = True
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
ip = &#39;127.0.0.1&#39;, port = 9369, kwargs = {}

    async def connect(self, address, deserialize=True, **connection_args):
        self._check_encryption(address, connection_args)
        ip, port = parse_host_port(address)
        kwargs = self._get_connect_args(**connection_args)
    
        try:
            # server_hostname option (for SNI) only works with tornado.iostream.IOStream
            if &#34;server_hostname&#34; in kwargs:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE
                )
                stream = await stream.start_tls(False, **kwargs)
            else:
                stream = await self.client.connect(
                    ip, port, max_buffer_size=MAX_BUFFER_SIZE, **kwargs
                )
    
            # Under certain circumstances tornado will have a closed connection with an
            # error and not raise a StreamClosedError.
            #
            # This occurs with tornado 5.x and openssl 1.1+
            if stream.closed() and stream.error:
                raise StreamClosedError(stream.error)
    
        except StreamClosedError as e:
            # The socket connect() call failed
&gt;           convert_stream_closed_error(self, e)

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;
exc = ConnectionRefusedError(111, &#39;Connection refused&#39;)

    def convert_stream_closed_error(obj, exc):
        &#34;&#34;&#34;
        Re-raise StreamClosedError as CommClosedError.
        &#34;&#34;&#34;
        if exc.real_error is not None:
            # The stream was closed because of an underlying OS error
            exc = exc.real_error
            if isinstance(exc, ssl.SSLError):
                if exc.reason and &#34;UNKNOWN_CA&#34; in exc.reason:
                    raise FatalCommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;)
&gt;           raise CommClosedError(f&#34;in {obj}: {exc.__class__.__name__}: {exc}&#34;) from exc
E           distributed.comm.core.CommClosedError: in &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;: ConnectionRefusedError: [Errno 111] Connection refused

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/tcp.py:142: CommClosedError

The above exception was the direct cause of the following exception:

loop = &lt;tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f8e02901dc0&gt;

    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0&#34;})
    def test_worker_fraction_limits(loop):  # noqa: F811
        pytest.importorskip(&#34;rmm&#34;)
        with popen([&#34;dask&#34;, &#34;scheduler&#34;, &#34;--port&#34;, &#34;9369&#34;, &#34;--no-dashboard&#34;]):
            with popen(
                [
                    &#34;dask&#34;,
                    &#34;cuda&#34;,
                    &#34;worker&#34;,
                    &#34;127.0.0.1:9369&#34;,
                    &#34;--host&#34;,
                    &#34;127.0.0.1&#34;,
                    &#34;--device-memory-limit&#34;,
                    &#34;0.1&#34;,
                    &#34;--rmm-pool-size&#34;,
                    &#34;0.2&#34;,
                    &#34;--rmm-maximum-pool-size&#34;,
                    &#34;0.3&#34;,
                    &#34;--no-dashboard&#34;,
                    &#34;--rmm-track-allocations&#34;,
                ]
            ):
&gt;               with Client(&#34;127.0.0.1:9369&#34;, loop=loop) as client:

dask_cuda/tests/test_dask_cuda_worker.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:988: in __init__
    self.start(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1185: in start
    sync(self.loop, self._start, **kwargs)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1265: in _start
    await self._ensure_connected(timeout=timeout)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/client.py:1328: in _ensure_connected
    comm = await connect(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

addr = &#39;tcp://127.0.0.1:9369&#39;, timeout = 30, deserialize = True
handshake_overrides = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
scheme = &#39;tcp&#39;, loc = &#39;127.0.0.1:9369&#39;
backend = &lt;distributed.comm.tcp.TCPBackend object at 0x7f8b744337f0&gt;
connector = &lt;distributed.comm.tcp.TCPConnector object at 0x7f8e02b5c6a0&gt;
comm = None, time_left = &lt;function connect.&lt;locals&gt;.time_left at 0x7f8e02811790&gt;
backoff_base = 0.01

    async def connect(
        addr, timeout=None, deserialize=True, handshake_overrides=None, **connection_args
    ):
        &#34;&#34;&#34;
        Connect to the given address (a URI such as ``tcp://127.0.0.1:1234``)
        and yield a ``Comm`` object.  If the connection attempt fails, it is
        retried until the *timeout* is expired.
        &#34;&#34;&#34;
        if timeout is None:
            timeout = dask.config.get(&#34;distributed.comm.timeouts.connect&#34;)
        timeout = parse_timedelta(timeout, default=&#34;seconds&#34;)
    
        scheme, loc = parse_address(addr)
        backend = registry.get_backend(scheme)
        connector = backend.get_connector()
        comm = None
    
        start = time()
    
        def time_left():
            deadline = start + timeout
            return max(0, deadline - time())
    
        backoff_base = 0.01
        attempt = 0
        logger.debug(&#34;Establishing connection to %s&#34;, loc)
        # Prefer multiple small attempts than one long attempt. This should protect
        # primarily from DNS race conditions
        # gh3104, gh4176, gh4167
        intermediate_cap = timeout / 5
        active_exception = None
        while time_left() &gt; 0:
            try:
                comm = await asyncio.wait_for(
                    connector.connect(loc, deserialize=deserialize, **connection_args),
                    timeout=min(intermediate_cap, time_left()),
                )
                break
            except FatalCommClosedError:
                raise
            # Note: CommClosed inherits from OSError
            except (asyncio.TimeoutError, OSError) as exc:
                active_exception = exc
    
                # As described above, the intermediate timeout is used to distributed
                # initial, bulk connect attempts homogeneously. In particular with
                # the jitter upon retries we should not be worred about overloading
                # any more DNS servers
                intermediate_cap = timeout
                # FullJitter see https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
    
                upper_cap = min(time_left(), backoff_base * (2**attempt))
                backoff = random.uniform(0, upper_cap)
                attempt += 1
                logger.debug(
                    &#34;Could not connect to %s, waiting for %s before retrying&#34;, loc, backoff
                )
                await asyncio.sleep(backoff)
        else:
&gt;           raise OSError(
                f&#34;Timed out trying to connect to {addr} after {timeout} s&#34;
            ) from active_exception
E           OSError: Timed out trying to connect to tcp://127.0.0.1:9369 after 30 s

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py:317: OSError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_device_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="5e945617-fa51-4f02-81b6-377e46fe5c98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.132 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dd42e68a-9999-46d6-9c6f-61c8a1a0175d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.008 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ae93132-d1bb-465a-9cd2-254e8fc3cc3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.034 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aeb57b03-284e-447d-8c0f-5de84abb26e9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6a121b9-6c4d-458f-aa29-6a5c76290784"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1371d490-2a2d-4eb8-832c-39399026d7ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.039 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0a084cb-54bf-4166-a612-3e113486d793"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.065 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e351399b-7a95-4466-8d53-32da67631526"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.07 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f43a561-2a40-4995-add5-b607e957ea37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range0-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.099 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d97054a4-05db-486b-bad4-b45ba8362911"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="baac16f7-d412-4345-bd99-7bdd4c4667c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e77d9ac-1efe-45e3-8db3-a375aea0a254"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.032 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0028dde8-226c-430b-8487-3dbfb5a5b98b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85e8dd91-693e-459b-a872-ef96cf600723"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02daf457-bb90-4842-afac-ed3cb0d8ca49"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.03 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58630e36-94cb-47fe-b6fc-d8245e0cb71e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.053 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0fd3800f-a629-4bac-9cce-eef826f7e987"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.057 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2800a26-9cbc-45df-baa7-8222330da2bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range1-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.086 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45588d97-54ed-412d-806f-b13064beb9e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1bdb84c8-0c50-428c-8937-94e5cd4cd273"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cf53b68-3fa2-4a75-b4a4-f6345c90a0e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-1-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.034 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31b8ddf0-c56b-42de-9e8f-2191c768ba57"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.008 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="600aea74-4aaa-49e2-ab78-32153c2198bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.011 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="daae5ee3-6bb8-4035-b967-53abcc8d1584"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-10-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.04 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bb9f4365-6e31-49e4-af60-06a18b73657c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.067 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ade06dba-c572-413c-9cdf-633e24cf6673"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.07 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="094d987d-5d69-4cab-a0b7-359e40b3a047"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_short[array_size_range2-100-100]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.106 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50ef0dfb-2564-4429-9011-4d3516b79d60"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_device_host_file_step_by_step</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c2ed8983-540f-41d5-a096-eadb4e9831f3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c75e091-771b-434e-83c3-13da58bbaea5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41d13b8b-0170-4341-845d-928f94a69d5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f367c9cb-0382-445d-98f9-483c74fbea7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1016065-ff3b-4d5e-8e7b-08ad830cce48"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a148344-0466-4c2e-8dbe-53fdc2ce0f41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bbf4a080-7d22-402e-8ea0-61eaa9c66f98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95bed973-8db1-4f1c-95d5-27eda3d97667"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33a56030-49a5-4df1-8519-c351d3275e09"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="18343d81-0971-4eb8-a02e-05cb8fe74dbb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c97b5c45-8567-40d8-a0a1-04022036289a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59fd3141-1bc8-43f2-a278-25cce4749911"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[10-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74440f04-804c-4963-a8a6-b8c180179d27"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49b67907-63b1-4758-8551-736048e76317"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="498fff00-0b43-46e7-b211-27584db1e1f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-0-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0663cd7a-7191-47cf-a666-a980aaf58d35"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fe04751d-7300-4684-8301-04ffea673d74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee32acc4-4742-490e-9494-f095e19b0474"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-1-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.009 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="708010b0-9315-49d5-93ff-b4ff2738adb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d3e203b-d3c6-40a1-8473-e75fe1e24a74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e3aaceb3-f385-40cb-ba87-f8f7755153eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-3-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.026 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69eab2cf-56f4-4c1a-9199-77a0abc31646"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-dict]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.05 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f96415c-90fd-4e9d-9024-962bcb6aec72"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-list]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.052 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23d6e1a7-739c-4202-bd34-895f837e06ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_cupy_collection[value1-6-tuple]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.05 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_dgx</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="4db21311-e75e-449c-986e-164ac4510a18"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.086 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=55229 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_default():
        p = mp.Process(target=_test_default)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-1&#39; pid=55229 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:73: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="bce2e316-231c-42d5-a3ce-9f19a92952e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_over_ucx</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.805 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=55318 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_over_ucx():
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        p = mp.Process(target=_test_tcp_over_ucx)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-2&#39; pid=55318 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:102: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9128da95-7bc1-47d9-ba5f-7165b05283c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tcp_only</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.568 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=55404 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_tcp_only():
        p = mp.Process(target=_test_tcp_only)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-3&#39; pid=55404 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:117: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ef7e969d-5da5-4a92-8faf-650d94c7fbc2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.257 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=55535 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: False, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-4&#39; pid=55535 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4cb8f194-ae48-46ff-841c-eb260715ed73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.612 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=55631 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: False}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-5&#39; pid=55631 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="bd38331f-4ec2-4b59-85f9-a0a4a01e7021"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.809 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=55725 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: False, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-6&#39; pid=55725 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="07b90380-9843-4be7-919b-f7ce9d15d2cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>4.238 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=55860 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: True, &#39;enable_nvlink&#39;: True, &#39;enable_rdmacm&#39;: True}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-7&#39; pid=55860 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0f67811c-35ff-4621-97cf-1e23c826b7c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_infiniband_nvlink[params4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.669 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=55953 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>params = {&#39;enable_infiniband&#39;: None, &#39;enable_nvlink&#39;: None, &#39;enable_rdmacm&#39;: None}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {&#34;enable_infiniband&#34;: False, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: False},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: False, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: True, &#34;enable_nvlink&#34;: True, &#34;enable_rdmacm&#34;: True},
            {&#34;enable_infiniband&#34;: None, &#34;enable_nvlink&#34;: None, &#34;enable_rdmacm&#34;: None},
        ],
    )
    @pytest.mark.skipif(
        _get_dgx_version() == DGXVersion.DGX_A100,
        reason=&#34;Automatic InfiniBand device detection Unsupported for %s&#34; % _get_dgx_name(),
    )
    def test_ucx_infiniband_nvlink(params):
        ucp = pytest.importorskip(&#34;ucp&#34;)  # NOQA: F841
    
        if params[&#34;enable_infiniband&#34;]:
            if not any([at.startswith(&#34;rc&#34;) for at in ucp.get_active_transports()]):
                pytest.skip(&#34;No support available for &#39;rc&#39; transport in UCX&#34;)
    
        p = mp.Process(
            target=_test_ucx_infiniband_nvlink,
            args=(
                params[&#34;enable_infiniband&#34;],
                params[&#34;enable_nvlink&#34;],
                params[&#34;enable_rdmacm&#34;],
            ),
        )
        p.start()
        p.join()
    
        # Starting a new cluster on the same pytest process after an rdmacm cluster
        # has been used may cause UCX-Py to complain about being already initialized.
        if params[&#34;enable_rdmacm&#34;] is True:
            ucp.reset()
    
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-8&#39; pid=55953 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_dgx.py:211: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_explicit_comms</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="c38c28d0-46bb-4187-a6c9-9d5f9a67aeca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.106 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=56043 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-9&#39; pid=56043 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9838ea92-9a28-4a6d-8504-694662cbbdfd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cluster[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.297 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=56175 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_local_cluster(protocol):
        p = mp.Process(target=_test_local_cluster, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-10&#39; pid=56175 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:60: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2256fb31-5857-43ea-9c10-6a04a5ef5954"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_merge_empty_partitions</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.086 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=56262 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_dataframe_merge_empty_partitions():
        # Notice, we use more partitions than rows
        p = mp.Process(target=_test_dataframe_merge_empty_partitions, args=(2, 4))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-11&#39; pid=56262 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:94: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="509d524f-688c-487b-bb16-cb573f4b0145"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.094 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=56349 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-12&#39; pid=56349 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="a5b90c1f-69e9-4a15-9a88-e8f5c163b689"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.086 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=56435 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-13&#39; pid=56435 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6ed503ce-ffc8-4c47-8a6f-59798bb7834d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.306 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=56522 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-14&#39; pid=56522 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cbfa2488-8b26-48d8-b6bd-c301e3f19de4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>4.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=56651 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-15&#39; pid=56651 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1ff4b11d-064a-4652-abaa-7bc5836e0477"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.682 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=56871 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-16&#39; pid=56871 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="588601cb-f39d-435c-a42e-03e7342288df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[tcp-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.615 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=57095 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-17&#39; pid=57095 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6d860f2e-cfdf-4097-bfae-d1ca0461eed6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.083 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=57356 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-18&#39; pid=57356 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3deba6be-fdf1-473a-afd0-50e979f2a40c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.099 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=57521 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-19&#39; pid=57521 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b0904cf7-0c6b-4487-b9a3-577db28a3274"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-pandas-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>1.995 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=57609 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-20&#39; pid=57609 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8c6196a6-60cb-4c31-bf17-2a3b8ac88393"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.6 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=57697 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-21&#39; pid=57697 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="87ea1c35-0bef-4bae-b0ce-b2e353a8ba63"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.748 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=57997 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-22&#39; pid=57997 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2ee67121-4997-4d8b-aa53-96038122339f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle[ucx-cudf-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.605 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=58218 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 3

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_dataframe_shuffle, args=(backend, protocol, nworkers))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-23&#39; pid=58218 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:174: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c9ca6770-bdb0-4b0e-98a0-1ba4ed90bd38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(41b8ab2c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e1453bca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e1453bca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e1453bca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8e02747c00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8e02747340&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8e0262ac70&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8e025de3c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

in_cluster = True

    @pytest.mark.parametrize(&#34;in_cluster&#34;, [True, False])
    def test_dask_use_explicit_comms(in_cluster):
        def check_shuffle():
            &#34;&#34;&#34;Check if shuffle use explicit-comms by search for keys named
            &#39;explicit-comms-shuffle&#39;
            &#34;&#34;&#34;
            name = &#34;explicit-comms-shuffle&#34;
            ddf = dd.from_pandas(pd.DataFrame({&#34;key&#34;: np.arange(10)}), npartitions=2)
            with dask.config.set(explicit_comms=False):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                assert all(name not in str(key) for key in res.dask)
            with dask.config.set(explicit_comms=True):
                res = ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
                if in_cluster:
                    assert any(name in str(key) for key in res.dask)
                else:  # If not in cluster, we cannot use explicit comms
                    assert all(name not in str(key) for key in res.dask)
    
            if in_cluster:
                # We check environment variables by setting an illegal batchsize
                with patch.dict(
                    os.environ,
                    {&#34;DASK_EXPLICIT_COMMS&#34;: &#34;1&#34;, &#34;DASK_EXPLICIT_COMMS_BATCHSIZE&#34;: &#34;-2&#34;},
                ):
                    dask.config.refresh()  # Trigger re-read of the environment variables
                    with pytest.raises(ValueError, match=&#34;explicit-comms-batchsize&#34;):
                        ddf.shuffle(on=&#34;key&#34;, npartitions=4, shuffle=&#34;tasks&#34;)
    
        if in_cluster:
&gt;           with LocalCluster(
                protocol=&#34;tcp&#34;,
                dashboard_address=None,
                n_workers=2,
                threads_per_worker=1,
                processes=True,
            ) as cluster:

dask_cuda/tests/test_explicit_comms.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(41b8ab2c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="779874fd-681c-4bb5-84b4-49e967c7daf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dask_use_explicit_comms[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8fc5ef81-6c95-4418-b779-023993be739a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.057 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=58442 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-24&#39; pid=58442 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4eb3e187-5766-4c89-91d1-d956be17cc70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.135 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=58570 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-25&#39; pid=58570 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c919f1ac-29fa-4732-8647-fee800b90cc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.092 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=58657 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-26&#39; pid=58657 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="185a7934-7bf7-43f0-b67d-823f98430f92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.782 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=58744 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-27&#39; pid=58744 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="21cd7e81-70d3-429c-917b-db2feeadbdaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.648 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=58966 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-28&#39; pid=58966 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b7b4340f-6c54-4c36-a562-06c1f0f2d03d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[tcp-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.735 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=59225 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;tcp&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-29&#39; pid=59225 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="dfacfea2-d36f-4541-858e-86cc95a45dd3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.279 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=59445 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-30&#39; pid=59445 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="39fa94d1-b426-4d92-8fe9-90f5f7dbaa77"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.054 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=59531 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-31&#39; pid=59531 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="86596f70-0c90-457e-8053-79fbb191e7a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-pandas-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.289 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=59665 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;pandas&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-32&#39; pid=59665 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="cb4051c6-1a8f-4fa6-b0d7-5752dcdff7eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.605 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=59752 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 1

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-33&#39; pid=59752 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0bc88955-d273-40ab-8c20-3a15f69d6ef4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.567 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=59971 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 2

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-34&#39; pid=59971 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="456fd43b-5e1f-465e-8148-9a9b8b0a662c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframe_shuffle_merge[ucx-cudf-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.602 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=60231 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>backend = &#39;cudf&#39;, protocol = &#39;ucx&#39;, nworkers = 4

    @pytest.mark.parametrize(&#34;nworkers&#34;, [1, 2, 4])
    @pytest.mark.parametrize(&#34;backend&#34;, [&#34;pandas&#34;, &#34;cudf&#34;])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_dataframe_shuffle_merge(backend, protocol, nworkers):
        if backend == &#34;cudf&#34;:
            pytest.importorskip(&#34;cudf&#34;)
        p = mp.Process(
            target=_test_dataframe_shuffle_merge, args=(backend, protocol, nworkers)
        )
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-35&#39; pid=60231 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:277: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="347688ff-7ce2-4412-8b3f-888ce3aaef69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.484 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=60453 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;tcp&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-36&#39; pid=60453 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="0814ea3d-f1e5-440c-b815-73551a581f40"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_jit_unspill[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.642 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=60664 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    def test_jit_unspill(protocol):
        pytest.importorskip(&#34;cudf&#34;)
    
        p = mp.Process(target=_test_jit_unspill, args=(protocol,))
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-37&#39; pid=60664 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_explicit_comms.py:313: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="beea52ed-dcd4-4803-a417-c92fd068e7fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_lock_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCluster(8f46dad6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d040&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d040&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d040&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8e02ae9480&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8e02ae9700&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8e02b5cfa0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8e02d33740&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_lock_workers():
        &#34;&#34;&#34;
        Testing `run(...,lock_workers=True)` by spawning 30 runs with overlapping
        and non-overlapping worker sets.
        &#34;&#34;&#34;
        try:
            from distributed import MultiLock  # noqa F401
        except ImportError as e:
            pytest.skip(str(e))
    
&gt;       with LocalCluster(
            protocol=&#34;tcp&#34;,
            dashboard_address=None,
            n_workers=4,
            threads_per_worker=5,
            processes=True,
        ) as cluster:

dask_cuda/tests/test_explicit_comms.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCluster(8f46dad6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_gds</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-skipped">
                        <a id="25b2172f-d3e0-4cd5-bb77-c7e2e250398d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="dc247585-4d5d-4654-85cd-57fffeb136ae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="036211f3-b5ce-40ef-96b3-301a9f5e934f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[True-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>GDS not available</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_gds.py:36: GDS not available</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99e978dc-fe83-4aa3-9aca-46b25f00c486"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f0cf1ba-a666-4dc3-a2ce-a25e3dd82e89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-cudf]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e82ba82f-1795-4dd5-9a74-e7fc2bbb0a05"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gds[False-numba.cuda]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_initialize</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="29c9c3ca-4691-4255-9262-ff6ee1d58e38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_tcp</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.79 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=60926 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_tcp():
        p = mp.Process(target=_test_initialize_ucx_tcp)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-38&#39; pid=60926 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:55: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6fe42911-7f3f-4f26-b738-93e232d3a70c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_nvlink</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.629 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=61019 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_nvlink():
        p = mp.Process(target=_test_initialize_ucx_nvlink)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-39&#39; pid=61019 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:91: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="52be3d9c-1836-4951-87a9-031a74d433c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_infiniband</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>2.679 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=61112 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>@pytest.mark.skipif(
        &#34;ib0&#34; not in psutil.net_if_addrs(), reason=&#34;Infiniband interface ib0 not found&#34;
    )
    def test_initialize_ucx_infiniband():
        p = mp.Process(target=_test_initialize_ucx_infiniband)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-40&#39; pid=61112 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:130: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2f59e388-38d3-40a2-b313-4634e43f691c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_initialize_ucx_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>3.371 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AssertionError: assert not 1
 +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=61201 parent=51087 stopped exitcode=1&gt;.exitcode</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_initialize_ucx_all():
        p = mp.Process(target=_test_initialize_ucx_all)
        p.start()
        p.join()
&gt;       assert not p.exitcode
E       AssertionError: assert not 1
E        +  where 1 = &lt;SpawnProcess name=&#39;SpawnProcess-41&#39; pid=61201 parent=51087 stopped exitcode=1&gt;.exitcode

dask_cuda/tests/test_initialize.py:168: AssertionError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_local_cuda_cluster</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="91800987-006c-4d01-82e4-e137ad94c014"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.576 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b502a32b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0856b00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0856780&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de0855250&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de085b040&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_local_cuda_cluster():
&gt;       async with LocalCUDACluster(
            scheduler_port=0, asynchronous=True, device_memory_limit=1
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b502a32b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="09aac0b3-750b-44af-920c-8d520751b963"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_with_subset_of_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(26030496, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07e78c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07e7540&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de07e2790&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07cd5c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @pytest.mark.filterwarnings(&#34;ignore:Cannot get CPU affinity&#34;)
    @patch.dict(os.environ, {&#34;CUDA_VISIBLE_DEVICES&#34;: &#34;0,3,6,8&#34;})
    @gen_test(timeout=20)
    async def test_with_subset_of_cuda_visible_devices():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            worker_class=MockWorker,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(26030496, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="67fb8676-29c6-4211-9c08-ca46e1de3729"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.136 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d907c637, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8e02c5d9e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07e6dc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07e60c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de07f3c70&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07add40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d907c637, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6a506768-53f4-4ea6-8e13-856d1f646178"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.023 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b421eb3b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0854b00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0854500&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de088ba90&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07b8a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = None

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;ucx&#34;, None])
    @gen_test(timeout=20)
    async def test_ucx_protocol(protocol):
        pytest.importorskip(&#34;ucp&#34;)
    
        initialize(enable_tcp_over_ucx=True)
&gt;       async with LocalCUDACluster(
            protocol=protocol, enable_tcp_over_ucx=True, asynchronous=True, data=dict
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b421eb3b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d29baf3d-32a4-4902-99f6-890c93f01e4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_ucx_protocol_type_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="809c6316-cfbe-4178-8c7f-eaea2e28e8c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_n_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(7ee86067, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0899c00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0899cc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc7072640&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07749c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_n_workers():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(7ee86067, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3191c401-244c-4141-8c7d-652497fdcecf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_threads_per_worker_and_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.024 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(97804836, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07c3540&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07c3100&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc71b7eb0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07813c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_threads_per_worker_and_memory_limit():
&gt;       async with LocalCUDACluster(threads_per_worker=4, asynchronous=True) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(97804836, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="fd955e94-5bf4-43f3-94a7-db78fd5b39a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cluster</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(34d678a7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07cf040&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0894d80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6f8fa30&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07c23c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cluster():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True, memory_limit=None, device_memory_limit=None
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(34d678a7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f7ef042b-61d7-44d3-9cd0-072f2469ec0e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_no_memory_limits_cudaworker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.081 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(0b9ac630, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07cf300&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07cf500&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc7032bb0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de077cec0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_no_memory_limits_cudaworker():
    
&gt;       async with LocalCUDACluster(
            asynchronous=True,
            memory_limit=None,
            device_memory_limit=None,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(0b9ac630, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="60909971-089c-47f8-9ba4-113c80bfd5e5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_all_to_all</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(0a603126, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7035880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc70355c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6ede1f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07750c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_all_to_all():
&gt;       async with LocalCUDACluster(
            CUDA_VISIBLE_DEVICES=&#34;0,1&#34;, worker_class=MockWorker, asynchronous=True
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(0a603126, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f6cb16be-fa0c-4757-a078-d3fca7db61d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_pool</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c4a3aeea, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fa4f80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fa4340&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de083d7f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de0796940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_pool():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c4a3aeea, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c37d540-a21d-432b-8ba3-88c217229b56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_maximum_poolsize_without_poolsize_error</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ab401c94-8f24-43c2-9044-86572ae16d59"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_managed</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(67022c40, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc74558c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7455380&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6fd2880&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de0781dc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_managed():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_managed_memory=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(67022c40, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="78353dbb-4111-498b-980a-04023881f65f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_async</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(828522c6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7002bc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc715b580&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6fa6e80&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc6ffdcc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_async():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
        driver_version = rmm._cuda.gpu.driverGetVersion()
        runtime_version = rmm._cuda.gpu.runtimeGetVersion()
        if driver_version &lt; 11020 or runtime_version &lt; 11020:
            pytest.skip(&#34;cudaMallocAsync not supported&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_async=True,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(828522c6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ceb8d151-d53c-4a43-9ddd-9c61f487ce3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_logging</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(049d36a1, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc70250c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7025f40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dbe8f0d30&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de0898a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_logging():
        rmm = pytest.importorskip(&#34;rmm&#34;)
    
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_log_directory=&#34;.&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(049d36a1, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="71542536-c337-42e3-9861-462eadbc240a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.1 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(042bbf1b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc71c7a40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de08afc80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de076a6a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8de07787c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_pre_import():
        module = None
    
        # Pick a module that isn&#39;t currently loaded
        for m in pkgutil.iter_modules():
            if m.ispkg and m.name not in sys.modules.keys():
                module = m.name
                break
    
        if module is None:
            pytest.skip(&#34;No module found that isn&#39;t already loaded&#34;)
    
&gt;       async with LocalCUDACluster(
            n_workers=1,
            pre_import=module,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:274: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(042bbf1b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="23665cc1-0ef7-4778-b815-b131a6053e57"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pre_import_not_found</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ba17e5c5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0894c00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0894ac0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc72febb0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc701a440&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_pre_import_not_found():
        async def _test_pre_import_not_found():
            with raises_with_cause(RuntimeError, None, ImportError, None):
                await LocalCUDACluster(
                    n_workers=1,
                    pre_import=&#34;my_module&#34;,
                    asynchronous=True,
                    silence_logs=True,
                )
    
&gt;       asyncio.run(_test_pre_import_not_found())

dask_cuda/tests/test_local_cuda_cluster.py:296: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/runners.py:44: in run
    return loop.run_until_complete(main)
../../../miniconda3/envs/gdf/lib/python3.8/asyncio/base_events.py:616: in run_until_complete
    return future.result()
dask_cuda/tests/test_local_cuda_cluster.py:289: in _test_pre_import_not_found
    await LocalCUDACluster(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ba17e5c5, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="49e7996e-8309-4689-acd1-004859beecb6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cluster_worker</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(e21c47d6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72b0940&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72b0fc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de088fe20&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe912c40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_cluster_worker():
&gt;       async with LocalCUDACluster(
            scheduler_port=0,
            asynchronous=True,
            device_memory_limit=1,
            n_workers=1,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(e21c47d6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="25e402fc-9269-4bdc-8329-45370c99ff4b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_available_mig_workers</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>No MIG devices found</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:321: No MIG devices found</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="dc88c39c-3ec9-4596-8808-ccbaec110230"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_gpu_uuid</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>@gen_test(timeout=20)
    async def test_gpu_uuid():
&gt;       gpu_uuid = get_gpu_uuid_from_index(0)

dask_cuda/tests/test_local_cuda_cluster.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device_index = 0

    def get_gpu_uuid_from_index(device_index=0):
        &#34;&#34;&#34;Get GPU UUID from CUDA device index.
    
        Parameters
        ----------
        device_index: int or str
            The index of the device from which to obtain the UUID. Default: 0.
    
        Examples
        --------
        &gt;&gt;&gt; get_gpu_uuid_from_index()
        &#39;GPU-9baca7f5-0f2f-01ac-6b05-8da14d6e9005&#39;
    
        &gt;&gt;&gt; get_gpu_uuid_from_index(3)
        &#39;GPU-9fb42d6f-7d6b-368f-f79c-3c3e784c93f6&#39;
        &#34;&#34;&#34;
        import pynvml
    
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
&gt;       return pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E       AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/utils.py:679: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="b5f8041c-73c1-4819-b400-0f5650c59078"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_rmm_track_allocations</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(7f7a265b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0843340&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0843680&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de083d580&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc701cbc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_rmm_track_allocations():
        rmm = pytest.importorskip(&#34;rmm&#34;)
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            asynchronous=True,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(7f7a265b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d2e4f369-c90e-48c6-abe0-99f8a397e7f6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_cluster_configuration</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(584ff60c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0859440&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0859e40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8e027e1280&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe92bc40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_get_cluster_configuration():
&gt;       async with LocalCUDACluster(
            rmm_pool_size=&#34;2GB&#34;,
            rmm_maximum_pool_size=&#34;3GB&#34;,
            device_memory_limit=&#34;30B&#34;,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(584ff60c, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d89a5875-40a4-4c17-9b0a-c4601cfcfef8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_fraction_limits</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.095 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c9ac595f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de077e4c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de077e180&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc700e310&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe918940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=20)
    async def test_worker_fraction_limits():
&gt;       async with LocalCUDACluster(
            device_memory_limit=0.1,
            rmm_pool_size=0.2,
            rmm_maximum_pool_size=0.3,
            CUDA_VISIBLE_DEVICES=&#34;0&#34;,
            scheduler_port=0,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_local_cuda_cluster.py:402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c9ac595f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="7b218455-ee17-403e-9ffc-296b61be1c47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_print_cluster_config</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>could not import &#39;rich&#39;: No module named &#39;rich&#39;</td></tr>
                        
                        </table>

                        
                        
                        <pre>/datasets/pentschev/simple-ci/src/dask-cuda/dask_cuda/tests/test_local_cuda_cluster.py:426: could not import &#39;rich&#39;: No module named &#39;rich&#39;</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxify_host_file</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="91ef7c0f-c9b4-4a08-9094-4699bc88b630"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_dev_item_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0834b3da-bdda-445e-93b5-df7557fdbcfe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_one_item_host_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f17cb4c1-f9d6-47b4-8c64-52e4fe36527f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spill_on_demand</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>6.327 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="6612c77b-4bd3-451e-9d2c-ef7e26391c44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.022 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c1dcb625, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4300&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07e6840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f867c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de061f430&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc7068340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c1dcb625, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2a04be7b-c6a6-4530-addc-13ae6e48258a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d66f66ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7056a00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07c9380&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6fa6370&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc704dcc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d66f66ad, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4798008a-755c-4be7-8b3e-798a35696eac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_dataframes_share_dev_mem</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aab91519-ab97-45e0-ad72-15cb8bf9de75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_get_device_memory_objects</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d661a9e-a358-459d-a268-77262a67f877"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_externals</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1620c788-17a9-4ed2-b730-68c7ea9a8c23"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_incompatible_types</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="f66ea6de-6031-424a-84f6-a5274ea93cec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(0e97a1e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f89d80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72a1300&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc72b55b0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc6e503c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(0e97a1e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="94419625-aa17-4591-bc79-ac32b7324a6b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.099 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d3eb7897, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7183f80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc74e3b00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc71b71f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc72c7cc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d3eb7897, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="718ead03-8dd1-4a87-8ed7-e3f645beac72"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[True-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(71eff1f6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f1d9c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f1da00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de07a7ee0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc72c7bc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = True, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(71eff1f6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9e951bf1-b79b-4cbd-9026-f246b4f3cd36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(f259c7c9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc71e5bc0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc71e5e00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de05fe130&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc72e7440&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 1

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(f259c7c9, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="432d9835-c146-4ee0-bd39-e8680323f2ae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(8d6728f6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7372880&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7372a80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc71e9280&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc6e156c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 2

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(8d6728f6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3206cf4f-66ce-4cd1-b876-a4154f420bf8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_compatibility_mode_dataframe_shuffle[False-3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(62e91487, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6e59200&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6e59640&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6e833a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc72c5f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

compatibility_mode = False, npartitions = 3

    @pytest.mark.parametrize(&#34;npartitions&#34;, [1, 2, 3])
    @pytest.mark.parametrize(&#34;compatibility_mode&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_compatibility_mode_dataframe_shuffle(compatibility_mode, npartitions):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def is_proxy_object(x):
            return &#34;ProxyObject&#34; in str(type(x))
    
        with dask.config.set(jit_unspill_compatibility_mode=compatibility_mode):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:396: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(62e91487, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="8966f467-b489-4145-8e2c-453fb1b919e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_force_spill_to_disk</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(60a0eba7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbe917f80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07de740&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6e3a700&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc6e277c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    @gen_test(timeout=60)
    async def test_worker_force_spill_to_disk():
        &#34;&#34;&#34;Test Dask triggering CPU-to-Disk spilling&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with dask_cuda.LocalCUDACluster(
                n_workers=1, device_memory_limit=&#34;1MB&#34;, jit_unspill=True, asynchronous=True
            ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(60a0eba7, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e68da2a8-cf96-401a-8afc-93b3c0a17c95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_on_demand_debug_info</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.019 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ad3a8a59, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4b40&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc75286c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbe9f9380&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc7454f40&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dc72eff40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

    def test_on_demand_debug_info():
        &#34;&#34;&#34;Test worker logging when on-demand-spilling fails&#34;&#34;&#34;
        rmm = pytest.importorskip(&#34;rmm&#34;)
        if not hasattr(rmm.mr, &#34;FailureCallbackResourceAdaptor&#34;):
            pytest.skip(&#34;RMM doesn&#39;t implement FailureCallbackResourceAdaptor&#34;)
    
        rmm_pool_size = 2**20
    
        def task():
            (
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size // 2),
                rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
            )
    
&gt;       with dask_cuda.LocalCUDACluster(
            n_workers=1,
            jit_unspill=True,
            rmm_pool_size=rmm_pool_size,
            rmm_maximum_pool_size=rmm_pool_size,
            rmm_track_allocations=True,
        ) as cluster:

dask_cuda/tests/test_proxify_host_file.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/dask_cuda/local_cuda_cluster.py:336: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/local.py:253: in __init__
    super().__init__(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:286: in __init__
    self.sync(self._start)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:338: in sync
    return sync(
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:405: in sync
    raise exc.with_traceback(tb)
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py:378: in f
    result = yield future
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/tornado/gen.py:769: in run
    value = future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ad3a8a59, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_proxy</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="b11dd1eb-0048-4e56-b385-cc4ed3b7f786"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="29b95ccb-c026-454a-9791-51cc80a60a21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f294c221-0125-4b24-aef5-9bac74ef44af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdba3048-ad64-4a4b-af07-f59705405264"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_serializer</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af0513e1-18bc-4f02-967f-09a4fba50d92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c29aa32c-1134-4b9b-b502-fba6ecd8200e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4b1c206-2bd5-484f-b1db-37ba29f1ba16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[None-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6b98723-5b5b-4c3b-8a7c-0203f8405538"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="38e80504-a96c-4db6-948a-f300441093c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3b273e46-dad8-4827-ba57-71071405f5f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second1-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51204997-e0a4-4d88-897a-3f7b826f1f16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="151b58e4-465b-4f31-96ad-c3e109811306"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="407622ed-15f4-4371-99ef-9ab87879af95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_double_proxy_object[serializers_second2-serializers_first2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cd595e6-8a68-4856-bfb9-5dd41941df78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1565a2b6-1318-4fe6-947a-284dd05b58dc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf5ffe29-0e5c-4760-9001-4571a2e943af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[numpy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.017 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="638c3fa2-165e-4b4f-a92e-9be5991f9930"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.087 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51d7a975-ea1f-4e04-b791-7f807b421a65"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.063 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f01941d9-25b8-4d13-b00c-0524456dbbf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_array[cupy-serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.073 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="798ba2c4-3b48-4d33-9f9e-dd6261eda687"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba9a7a20-9764-4175-bad0-b256f7524fed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8984617-6682-4173-bcd6-ccde46480874"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_of_cudf[serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7a26a656-072b-4a5d-9a75-734df10eda9e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a860195-16b0-424f-ac9d-9164921c2b87"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19a99bd2-5be7-478a-b2e3-9cfee8008ee9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="392b8a40-13a0-475c-8d18-727f850af0b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16be81ee-fb4d-4ae6-9e14-a34d79c49bb4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d386a047-4af0-481c-ace8-ec2f66fa9308"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a87b78c-99ec-49e2-903f-ed08a3785acc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="22c202f1-1d8e-4ac9-b2e3-f4f0513033e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="120349fd-2b5c-424b-b396-ec9e85554ba2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="36b05e12-d2fe-4e05-80c0-c9ea00aed108"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_length[cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c6308f5e-9064-4bf1-b591-4681df4c33d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_fixed_attribute_name</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="4339f470-118c-488e-8510-c3d543962451"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(c205cba0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc70b5300&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc70b5040&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc72d4610&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe8c3e40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = True

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(c205cba0, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="5cbf05ca-9f32-458d-8efe-8f9a509ff2a9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_spilling_local_cuda_cluster[False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(fbb541e1, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0753380&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0753280&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6ddefa0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe8d34c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

jit_unspill = False

    @pytest.mark.parametrize(&#34;jit_unspill&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_spilling_local_cuda_cluster(jit_unspill):
        &#34;&#34;&#34;Testing spilling of a proxied cudf dataframe in a local cuda cluster&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        dask_cudf = pytest.importorskip(&#34;dask_cudf&#34;)
    
        def task(x):
            assert isinstance(x, cudf.DataFrame)
            if jit_unspill:
                # Check that `x` is a proxy object and the proxied DataFrame is serialized
                assert &#34;ProxyObject&#34; in str(type(x))
                assert x._pxy_get().serializer == &#34;dask&#34;
            else:
                assert type(x) == cudf.DataFrame
            assert len(x) == 10  # Trigger deserialization
            return x
    
        # Notice, setting `device_memory_limit=1B` to trigger spilling
&gt;       async with LocalCUDACluster(
            n_workers=1,
            device_memory_limit=&#34;1B&#34;,
            jit_unspill=jit_unspill,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(fbb541e1, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d4367e28-7b43-481f-9b97-f33a1895d19d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8552c2d7-e0ac-4272-b342-7ac2acf3d8b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_to_disk[obj1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.005 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1258b5d5-4d53-4ae2-ae2c-b8c210c39eed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[dask]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99684ad0-c6c4-4547-9d66-fca2c9e18364"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[pickle]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c34634ea-0d01-443e-9f03-7cddaddbb7d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_multiple_deserializations[disk]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a389eaaa-4c7f-4d3e-bebb-812b8ac8fc1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40eee33b-70a0-40b8-934d-57904683927c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16984431-ad56-4c0d-8971-21d70f305f36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f8ceead-0ddc-4a7e-aba4-118f2e2f555c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4226a99-510a-45d8-9933-2ba471902b68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc1f323e-410d-4bd5-b260-f3f990952a3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2213d838-79ae-4149-b48f-5b61bb23452b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4871347b-0093-4295-a734-93492a5482b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c247d94c-3e0a-4485-bda8-7e2616cc2ade"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="532993e5-4ca2-460f-8d3f-6241dc88dee4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[numpy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b8a732b-eb54-4089-9e92-272bf8e110ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b010dcb-9697-4319-9b30-ca44e6887bd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-None-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.581 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c5faa403-d238-4d15-af58-765261fc5824"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5390e309-ca80-4e3e-88dc-c0afb78b6154"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers1-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.636 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee36edf0-2f21-481f-95cd-b30454a2cc3a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce9d8bdb-c6fb-4ca6-a79b-76f902ba4e88"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers2-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.573 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7822a0e3-a0a7-4232-a1d5-f3b40749c9e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d5496952-8f01-4d28-97bb-cbdb2bc7421f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers3-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.625 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdd5df89-62fa-4f3e-a956-3541bd9fc87c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d2adf5c-7ca3-44c2-a05c-c6f341762911"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_serializing_array_to_disk[cupy-serializers4-10000]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.576 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="1b86558d-8dae-40c9-8732-3106816d3aed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(7ee58b73, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07a4280&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07a4500&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6df44f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe8d9a40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(7ee58b73, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="68c7d3b0-9cc9-41dd-ad45-7da559bfdd26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(d205bf56, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc70f3380&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8e1309cc00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6f543a0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe8ec840&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(d205bf56, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="16f7e09c-9f96-4e0e-80b4-67d305385338"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[tcp-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(41e35da2, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de06d0f40&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de06d0bc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc72abca0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbebfe340&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(41e35da2, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="3d57b94e-4bd2-4e1c-88e8-8743b85188c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(ea80cc59, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72f6180&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72f6400&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6e2c100&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbebf9f40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = None

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(ea80cc59, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="db8296bf-252c-4cf9-958e-65e87a91f67d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(9620cf3d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbeb809c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fb3e80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dbeaa6bb0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbec05940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;dask&#39;, &#39;pickle&#39;)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(9620cf3d, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="765c561d-0bda-49fa-949e-fb64d2094065"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_proxy_objects[ucx-send_serializers2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(82c92a2e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6e2bd00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbec64f00&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6df4370&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbec2e7c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, send_serializers = (&#39;cuda&#39;,)

    @pytest.mark.parametrize(&#34;send_serializers&#34;, [None, (&#34;dask&#34;, &#34;pickle&#34;), (&#34;cuda&#34;,)])
    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @gen_test(timeout=20)
    async def test_communicating_proxy_objects(protocol, send_serializers):
        &#34;&#34;&#34;Testing serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializers_used = x._pxy_get().serializer
    
            # Check that `x` is serialized with the expected serializers
            if protocol == &#34;ucx&#34;:
                if send_serializers is None:
                    assert serializers_used == &#34;cuda&#34;
                else:
                    assert serializers_used == send_serializers[0]
            else:
                assert serializers_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:422: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(82c92a2e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="9c349427-ed05-4e74-ab73-2ca7cafa0765"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(fae200e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0783840&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbec1bc80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc720cd00&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbebfd4c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(fae200e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="47276d9d-78e6-45a0-bf91-28388e47cd54"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[True-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(823aa615, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f92580&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6f92640&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc71c8be0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbed009c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = True

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(823aa615, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2fd26049-dff8-4ec5-a654-6537a6ced3be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-tcp]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(b9521d13, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07a0080&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07a0d40&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc7009070&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbed2c0c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;tcp&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(b9521d13, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="eea9d194-7226-45b0-945b-4b94a03d6208"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_communicating_disk_objects[False-ucx]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.072 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(6737e7df, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;ucx://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4ca0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de0899100&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de087bc80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc73be7f0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbed0bac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

protocol = &#39;ucx&#39;, shared_fs = False

    @pytest.mark.parametrize(&#34;protocol&#34;, [&#34;tcp&#34;, &#34;ucx&#34;])
    @pytest.mark.parametrize(&#34;shared_fs&#34;, [True, False])
    @gen_test(timeout=20)
    async def test_communicating_disk_objects(protocol, shared_fs):
        &#34;&#34;&#34;Testing disk serialization of cuDF dataframe when communicating&#34;&#34;&#34;
        cudf = pytest.importorskip(&#34;cudf&#34;)
        ProxifyHostFile._spill_to_disk.shared_filesystem = shared_fs
    
        def task(x):
            # Check that the subclass survives the trip from client to worker
            assert isinstance(x, _PxyObjTest)
            serializer_used = x._pxy_get().serializer
            if shared_fs:
                assert serializer_used == &#34;disk&#34;
            else:
                assert serializer_used == &#34;dask&#34;
    
&gt;       async with dask_cuda.LocalCUDACluster(
            n_workers=1,
            protocol=protocol,
            enable_tcp_over_ucx=protocol == &#34;ucx&#34;,
            asynchronous=True,
        ) as cluster:

dask_cuda/tests/test_proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(6737e7df, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1cf3298-ce71-46e7-99f0-de6643ac98d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c789becb-88fd-42cd-812b-46faa2f79368"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[None-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ff0425f-3f27-4205-bf13-187bf8c8c677"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a35c9ee8-ea9f-4a92-8316-0d4575902022"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers1-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5b5b8f8-435e-42c3-a47a-af9f5d9eebf9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4aa9d932-0982-4703-9c9b-c8b5e9c23677"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers2-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="913291fc-3b55-4c45-868c-de9c9193c6a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-numpy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efbfcd98-1487-434a-9bf1-616725ffbb9d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pickle_proxy_object[serializers3-cupy]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d4361439-891c-4239-89ec-2cab6290512b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_pandas</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.01 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="60a0f7d1-f9cf-4e1d-8ee9-9c794dd97fb0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_from_cudf_of_proxy_object</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.004 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3777fed5-6bb1-4ee2-b4a4-25ab0db97ab2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_proxy_object_parquet</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.013 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b63fd822-5bbe-43f5-86d5-5c86757d5ed8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_assignments</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec6a1bb9-d411-4f52-b81e-e27d97ab59ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_concatenate3_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20bd3547-e523-4c5d-a1f8-223842851387"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_tensordot_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.016 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf670aba-c439-42d5-9f70-b487ac9bb62d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_einsum_of_proxied_cupy_arrays</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.012 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="065c95f3-a484-4c26-a2a4-75bdfabc6d1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1bafd985-0c24-4557-a393-0b443f6e8c32"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[less_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ae229a5-2d19-4ea1-9e5e-3e18155e5700"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3eed4968-faf3-4766-90ce-a6abded84bbd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[greater_equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a71ec0e-e56a-4eef-9a07-10ae44825cb5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_array_ufucn_proxified_object[equal]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12bd547c-0fd3-4ec7-a427-3c4a834c7938"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_copy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d823946b-46a6-40db-a47a-3ea9083d4768"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_fillna</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bcc15f75-e239-49a6-b3dd-c30bfeceb52e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cupy</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.03 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="90efc0b6-4a0f-4580-b2e5-fa453b259558"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_sizeof_cudf</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.529 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92ef8083-f539-4bdb-9e8e-b556dafa4fb3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_broadcast_to</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="a5588f51-cde2-4935-bed5-7dc12ce59aca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_matmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-skipped">
                        <a id="8f350378-bb38-415f-9fea-3daafec10488"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_imatmul</b></td></tr>
                            <tr><th>Outcome:</th><td>Skipped</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                            <tr><th>Skipped</th><td>See: https://github.com/rapidsai/dask-cuda/issues/995</td></tr>
                        
                        </table>

                        
                        
                        <pre>skipped</pre>
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_spill</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-failed">
                        <a id="9b14de5c-f4d8-4500-aa6a-0d47d657e645"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(81dfa5e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72f5e80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc72f5600&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dbea84490&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbed0b940&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(81dfa5e3, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="014390a7-19ea-48e5-9d5a-c9d2a48669e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(8abae93b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fe33c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fe3300&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6f75640&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbea12140&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(8abae93b, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="77a33e2c-215b-49ea-92ac-10439c9339cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.007 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(a0675387, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbeb6cd00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbeb6c8c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de05bd670&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbea071c0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(a0675387, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="ad4bf03c-0cb7-48e2-9e3a-d58430c07907"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cupy_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.006 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(1b696399, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = None
dashboard = False, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = False
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7254500&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc7254b80&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8de058fac0&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbea08cc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 200000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(2000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: int(200e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(200e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cupy_cluster_device_spill(params):
        cupy = pytest.importorskip(&#34;cupy&#34;)
        with dask.config.set({&#34;distributed.worker.memory.terminate&#34;: False}):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                scheduler_port=0,
                silence_logs=False,
                dashboard_address=None,
                asynchronous=True,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
            ) as cluster:

dask_cuda/tests/test_spill.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(1b696399, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="2c3ebf60-d4eb-4369-8a67-3e448d354ab7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.021 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(26328968, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4880&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc71bf1c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc71bf2c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8db5b95940&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbea11bc0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(26328968, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="c45f4b9f-8b8e-409c-b290-f7ef7ccd066b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(23b601d6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c49e0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6eac9c0&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8de07051c0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc6fbb820&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbea34ac0&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(23b601d6, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="e4bcc657-45b3-4f2e-ac2d-52e38fd6befd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(00573e0f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c4460&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fa4e00&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dc6fa4600&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8db5c78790&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe644540&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: None, &#39;host_target&#39;: None, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(00573e0f, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="56ed431c-0143-4e22-afde-9bf06e091a48"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cudf_cluster_device_spill[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.02 sec</td></tr>
                        
                            <tr><th>Failed</th><td>RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>self = LocalCUDACluster(7977a16e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
&gt;               self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
loop = None, delete_interval = &#39;500ms&#39;, synchronize_worker_interval = &#39;60s&#39;
services = {}, service_kwargs = None, allowed_failures = 3, extensions = None
validate = False, scheduler_file = None
security = Security(require_encryption=False, tls_min_version=771)
worker_ttl = &#39;5 minutes&#39;, idle_timeout = None, interface = None
host = &#39;127.0.0.1&#39;, port = 0, protocol = &#39;tcp://&#39;, dashboard_address = &#39;:8787&#39;
dashboard = True, http_prefix = &#39;/&#39;, preload = [], preload_argv = []
plugins = (), contact_address = None, transition_counter_max = False
jupyter = False, kwargs = {&#39;blocked_handlers&#39;: None}
http_server_modules = [&#39;distributed.http.scheduler.prometheus&#39;, &#39;distributed.http.scheduler.info&#39;, &#39;distributed.http.scheduler.json&#39;, &#39;distributed.http.health&#39;, &#39;distributed.http.proxy&#39;, &#39;distributed.http.statics&#39;]
show_dashboard = True
distributed = &lt;module &#39;distributed&#39; from &#39;/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/__init__.py&#39;&gt;
routes = [(&#39;/metrics&#39;, &lt;class &#39;distributed.http.prometheus.PrometheusNotAvailableHandler&#39;&gt;, {&#39;dask_server&#39;: &lt;[AttributeError(&#34;&#39;...eError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;}), ...]

    def __init__(
        self,
        loop=None,
        delete_interval=&#34;500ms&#34;,
        synchronize_worker_interval=&#34;60s&#34;,
        services=None,
        service_kwargs=None,
        allowed_failures=None,
        extensions=None,
        validate=None,
        scheduler_file=None,
        security=None,
        worker_ttl=None,
        idle_timeout=None,
        interface=None,
        host=None,
        port=0,
        protocol=None,
        dashboard_address=None,
        dashboard=None,
        http_prefix=&#34;/&#34;,
        preload=None,
        preload_argv=(),
        plugins=(),
        contact_address=None,
        transition_counter_max=False,
        jupyter=False,
        **kwargs,
    ):
        if loop is not None:
            warnings.warn(
                &#34;the loop kwarg to Scheduler is deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self.loop = self.io_loop = IOLoop.current()
        self._setup_logging(logger)
    
        # Attributes
        if contact_address is None:
            contact_address = dask.config.get(&#34;distributed.scheduler.contact-address&#34;)
        self.contact_address = contact_address
        if allowed_failures is None:
            allowed_failures = dask.config.get(&#34;distributed.scheduler.allowed-failures&#34;)
        self.allowed_failures = allowed_failures
        if validate is None:
            validate = dask.config.get(&#34;distributed.scheduler.validate&#34;)
        self.proc = psutil.Process()
        self.delete_interval = parse_timedelta(delete_interval, default=&#34;ms&#34;)
        self.synchronize_worker_interval = parse_timedelta(
            synchronize_worker_interval, default=&#34;ms&#34;
        )
        self.service_specs = services or {}
        self.service_kwargs = service_kwargs or {}
        self.services = {}
        self.scheduler_file = scheduler_file
        worker_ttl = worker_ttl or dask.config.get(&#34;distributed.scheduler.worker-ttl&#34;)
        self.worker_ttl = parse_timedelta(worker_ttl) if worker_ttl else None
        idle_timeout = idle_timeout or dask.config.get(
            &#34;distributed.scheduler.idle-timeout&#34;
        )
        if idle_timeout:
            self.idle_timeout = parse_timedelta(idle_timeout)
        else:
            self.idle_timeout = None
        self.idle_since = time()
        self.time_started = self.idle_since  # compatibility for dask-gateway
        self._lock = asyncio.Lock()
        self.bandwidth_workers = defaultdict(float)
        self.bandwidth_types = defaultdict(float)
    
        if not preload:
            preload = dask.config.get(&#34;distributed.scheduler.preload&#34;)
        if not preload_argv:
            preload_argv = dask.config.get(&#34;distributed.scheduler.preload-argv&#34;)
        self.preloads = preloading.process_preloads(self, preload, preload_argv)
    
        if isinstance(security, dict):
            security = Security(**security)
        self.security = security or Security()
        assert isinstance(self.security, Security)
        self.connection_args = self.security.get_connection_args(&#34;scheduler&#34;)
        self.connection_args[&#34;handshake_overrides&#34;] = {  # common denominator
            &#34;pickle-protocol&#34;: 4
        }
    
        self._start_address = addresses_from_user_args(
            host=host,
            port=port,
            interface=interface,
            protocol=protocol,
            security=security,
            default_port=self.default_port,
        )
    
        http_server_modules = dask.config.get(&#34;distributed.scheduler.http.routes&#34;)
        show_dashboard = dashboard or (dashboard is None and dashboard_address)
        # install vanilla route if show_dashboard but bokeh is not installed
        if show_dashboard:
            try:
                import distributed.dashboard.scheduler
            except ImportError:
                show_dashboard = False
                http_server_modules.append(&#34;distributed.http.scheduler.missing_bokeh&#34;)
        routes = get_handlers(
            server=self, modules=http_server_modules, prefix=http_prefix
        )
        self.start_http_server(routes, dashboard_address, default_port=8787)
        if show_dashboard:
            distributed.dashboard.scheduler.connect(
                self.http_application, self.http_server, self, prefix=http_prefix
            )
        self.jupyter = jupyter
        if self.jupyter:
            try:
                from jupyter_server.serverapp import ServerApp
            except ImportError:
                raise ImportError(
                    &#34;In order to use the Dask jupyter option you &#34;
                    &#34;need to have jupyterlab installed&#34;
                )
            from traitlets.config import Config
    
            j = ServerApp.instance(
                config=Config(
                    {
                        &#34;ServerApp&#34;: {
                            &#34;base_url&#34;: &#34;jupyter&#34;,
                            # SECURITY: We usually expect the dashboard to be a read-only view into
                            # the scheduler activity. However, by adding an open Jupyter application
                            # we are allowing arbitrary remote code execution on the scheduler via the
                            # dashboard server. This option should only be used when the dashboard is
                            # protected via other means, or when you don&#39;t care about cluster security.
                            &#34;token&#34;: &#34;&#34;,
                            &#34;allow_remote_access&#34;: True,
                        }
                    }
                )
            )
            j.initialize(
                new_httpserver=False,
            )
            self._jupyter_server_application = j
            self.http_application.add_application(j.web_app)
    
        # Communication state
        self.client_comms = {}
        self.stream_comms = {}
    
        # Task state
        tasks = {}
    
        self.generation = 0
        self._last_client = None
        self._last_time = 0
        unrunnable = set()
        queued: HeapSet[TaskState] = HeapSet(key=operator.attrgetter(&#34;priority&#34;))
    
        self.datasets = {}
    
        # Prefix-keyed containers
    
        # Client state
        clients = {}
    
        # Worker state
        workers = SortedDict()
    
        host_info = {}
        resources = {}
        aliases = {}
    
        self._worker_collections = [
            workers,
            host_info,
            resources,
            aliases,
        ]
    
        self.events = defaultdict(
            partial(
                deque, maxlen=dask.config.get(&#34;distributed.scheduler.events-log-length&#34;)
            )
        )
        self.event_counts = defaultdict(int)
        self.event_subscriber = defaultdict(set)
        self.worker_plugins = {}
        self.nanny_plugins = {}
    
        worker_handlers = {
            &#34;task-finished&#34;: self.handle_task_finished,
            &#34;task-erred&#34;: self.handle_task_erred,
            &#34;release-worker-data&#34;: self.release_worker_data,
            &#34;add-keys&#34;: self.add_keys,
            &#34;long-running&#34;: self.handle_long_running,
            &#34;reschedule&#34;: self._reschedule,
            &#34;keep-alive&#34;: lambda *args, **kwargs: None,
            &#34;log-event&#34;: self.log_worker_event,
            &#34;worker-status-change&#34;: self.handle_worker_status_change,
            &#34;request-refresh-who-has&#34;: self.handle_request_refresh_who_has,
        }
    
        client_handlers = {
            &#34;update-graph&#34;: self.update_graph,
            &#34;update-graph-hlg&#34;: self.update_graph_hlg,
            &#34;client-desires-keys&#34;: self.client_desires_keys,
            &#34;update-data&#34;: self.update_data,
            &#34;report-key&#34;: self.report_on_key,
            &#34;client-releases-keys&#34;: self.client_releases_keys,
            &#34;heartbeat-client&#34;: self.client_heartbeat,
            &#34;close-client&#34;: self.remove_client,
            &#34;subscribe-topic&#34;: self.subscribe_topic,
            &#34;unsubscribe-topic&#34;: self.unsubscribe_topic,
        }
    
        self.handlers = {
            &#34;register-client&#34;: self.add_client,
            &#34;scatter&#34;: self.scatter,
            &#34;register-worker&#34;: self.add_worker,
            &#34;register_nanny&#34;: self.add_nanny,
            &#34;unregister&#34;: self.remove_worker,
            &#34;gather&#34;: self.gather,
            &#34;cancel&#34;: self.stimulus_cancel,
            &#34;retry&#34;: self.stimulus_retry,
            &#34;feed&#34;: self.feed,
            &#34;terminate&#34;: self.close,
            &#34;broadcast&#34;: self.broadcast,
            &#34;proxy&#34;: self.proxy,
            &#34;ncores&#34;: self.get_ncores,
            &#34;ncores_running&#34;: self.get_ncores_running,
            &#34;has_what&#34;: self.get_has_what,
            &#34;who_has&#34;: self.get_who_has,
            &#34;processing&#34;: self.get_processing,
            &#34;call_stack&#34;: self.get_call_stack,
            &#34;profile&#34;: self.get_profile,
            &#34;performance_report&#34;: self.performance_report,
            &#34;get_logs&#34;: self.get_logs,
            &#34;logs&#34;: self.get_logs,
            &#34;worker_logs&#34;: self.get_worker_logs,
            &#34;log_event&#34;: self.log_event,
            &#34;events&#34;: self.get_events,
            &#34;nbytes&#34;: self.get_nbytes,
            &#34;versions&#34;: self.versions,
            &#34;add_keys&#34;: self.add_keys,
            &#34;rebalance&#34;: self.rebalance,
            &#34;replicate&#34;: self.replicate,
            &#34;run_function&#34;: self.run_function,
            &#34;restart&#34;: self.restart,
            &#34;update_data&#34;: self.update_data,
            &#34;set_resources&#34;: self.add_resources,
            &#34;retire_workers&#34;: self.retire_workers,
            &#34;get_metadata&#34;: self.get_metadata,
            &#34;set_metadata&#34;: self.set_metadata,
            &#34;set_restrictions&#34;: self.set_restrictions,
            &#34;heartbeat_worker&#34;: self.heartbeat_worker,
            &#34;get_task_status&#34;: self.get_task_status,
            &#34;get_task_stream&#34;: self.get_task_stream,
            &#34;get_task_prefix_states&#34;: self.get_task_prefix_states,
            &#34;register_scheduler_plugin&#34;: self.register_scheduler_plugin,
            &#34;register_worker_plugin&#34;: self.register_worker_plugin,
            &#34;unregister_worker_plugin&#34;: self.unregister_worker_plugin,
            &#34;register_nanny_plugin&#34;: self.register_nanny_plugin,
            &#34;unregister_nanny_plugin&#34;: self.unregister_nanny_plugin,
            &#34;adaptive_target&#34;: self.adaptive_target,
            &#34;workers_to_close&#34;: self.workers_to_close,
            &#34;subscribe_worker_status&#34;: self.subscribe_worker_status,
            &#34;start_task_metadata&#34;: self.start_task_metadata,
            &#34;stop_task_metadata&#34;: self.stop_task_metadata,
            &#34;get_cluster_state&#34;: self.get_cluster_state,
            &#34;dump_cluster_state_to_url&#34;: self.dump_cluster_state_to_url,
            &#34;benchmark_hardware&#34;: self.benchmark_hardware,
            &#34;get_story&#34;: self.get_story,
        }
    
        connection_limit = get_fileno_limit() / 2
    
        SchedulerState.__init__(
            self,
            aliases=aliases,
            clients=clients,
            workers=workers,
            host_info=host_info,
            resources=resources,
            tasks=tasks,
            unrunnable=unrunnable,
            queued=queued,
            validate=validate,
            plugins=plugins,
            transition_counter_max=transition_counter_max,
        )
&gt;       ServerNode.__init__(
            self,
            handlers=self.handlers,
            stream_handlers=merge(worker_handlers, client_handlers),
            connection_limit=connection_limit,
            deserialize=False,
            connection_args=self.connection_args,
            **kwargs,
        )

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/scheduler.py:3662: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] Scheduler object at 0x7f8de08c41a0&gt;
handlers = {&#39;adaptive_target&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method objec...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbec96e80&gt;, ...}
blocked_handlers = []
stream_handlers = {&#39;add-keys&#39;: &lt;[AttributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x...ributeError(&#34;&#39;Scheduler&#39; object has no attribute &#39;listeners&#39;&#34;) raised in repr()] method object at 0x7f8dbec96dc0&gt;, ...}
connection_limit = 250000.0, deserialize = False, serializers = None
deserializers = None
connection_args = {&#39;extra_conn_args&#39;: {}, &#39;handshake_overrides&#39;: {&#39;pickle-protocol&#39;: 4}, &#39;require_encryption&#39;: False, &#39;ssl_context&#39;: None}
timeout = None, io_loop = None

    def __init__(
        self,
        handlers,
        blocked_handlers=None,
        stream_handlers=None,
        connection_limit=512,
        deserialize=True,
        serializers=None,
        deserializers=None,
        connection_args=None,
        timeout=None,
        io_loop=None,
    ):
        if io_loop is not None:
            warnings.warn(
                &#34;The io_loop kwarg to Server is ignored and will be deprecated&#34;,
                DeprecationWarning,
                stacklevel=2,
            )
    
        self._status = Status.init
        self.handlers = {
            &#34;identity&#34;: self.identity,
            &#34;echo&#34;: self.echo,
            &#34;connection_stream&#34;: self.handle_stream,
            &#34;dump_state&#34;: self._to_dict,
        }
        self.handlers.update(handlers)
        if blocked_handlers is None:
            blocked_handlers = dask.config.get(
                &#34;distributed.%s.blocked-handlers&#34; % type(self).__name__.lower(), []
            )
        self.blocked_handlers = blocked_handlers
        self.stream_handlers = {}
        self.stream_handlers.update(stream_handlers or {})
    
        self.id = type(self).__name__ + &#34;-&#34; + str(uuid.uuid4())
        self._address = None
        self._listen_address = None
        self._port = None
        self._host = None
        self._comms = {}
        self.deserialize = deserialize
&gt;       self.monitor = SystemMonitor()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;[IndexError(&#39;deque index out of range&#39;) raised in repr()] SystemMonitor object at 0x7f8dc72d4190&gt;
maxlen = 7200, monitor_disk_io = True, monitor_host_cpu = False

    def __init__(
        self,
        maxlen: int | None = 7200,
        monitor_disk_io: bool | None = None,
        monitor_host_cpu: bool | None = None,
    ):
        self.proc = psutil.Process()
        self.count = 0
        self.maxlen = maxlen
        self.last_time = monotonic()
    
        self.quantities = {
            &#34;cpu&#34;: deque(maxlen=maxlen),
            &#34;memory&#34;: deque(maxlen=maxlen),
            &#34;time&#34;: deque(maxlen=maxlen),
        }
    
        try:
            self._last_net_io_counters = psutil.net_io_counters()
        except Exception:
            # FIXME is this possible?
            self.monitor_net_io = False  # pragma: nocover
        else:
            self.monitor_net_io = True
            self.quantities[&#34;host_net_io.read_bps&#34;] = deque(maxlen=maxlen)
            self.quantities[&#34;host_net_io.write_bps&#34;] = deque(maxlen=maxlen)
    
        if monitor_disk_io is None:
            monitor_disk_io = dask.config.get(&#34;distributed.admin.system-monitor.disk&#34;)
        if monitor_disk_io:
            try:
                disk_ioc = psutil.disk_io_counters()
            except Exception:
                # FIXME occurs when psutil version doesn&#39;t have handling for given platform / kernel;
                # should we explicitly error in this case?
                monitor_disk_io = False  # pragma: nocover
            else:
                if disk_ioc is None:  # pragma: nocover
                    # diskless machine
                    monitor_disk_io = False
                else:
                    self._last_disk_io_counters = disk_ioc
                    self.quantities[&#34;host_disk_io.read_bps&#34;] = deque(maxlen=maxlen)
                    self.quantities[&#34;host_disk_io.write_bps&#34;] = deque(maxlen=maxlen)
        self.monitor_disk_io = monitor_disk_io
    
        if monitor_host_cpu is None:
            monitor_host_cpu = dask.config.get(
                &#34;distributed.admin.system-monitor.host-cpu&#34;
            )
        self.monitor_host_cpu = monitor_host_cpu
        if monitor_host_cpu:
            self._last_host_cpu_counters = hostcpu_c = psutil.cpu_times()
            # This is a namedtuple whose fields change based on OS and kernel version
            for k in hostcpu_c._fields:
                self.quantities[&#34;host_cpu.&#34; + k] = deque(maxlen=maxlen)
    
        if not WINDOWS:
            self.quantities[&#34;num_fds&#34;] = deque(maxlen=maxlen)
    
        if nvml.device_get_count() &gt; 0:
&gt;           gpu_extra = nvml.one_time()

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/system_monitor.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def one_time():
        h = _pynvml_handles()
        return {
            &#34;memory-total&#34;: _get_memory_total(h),
&gt;           &#34;name&#34;: _get_name(h),
        }

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

h = &lt;pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7f8dbe63ed40&gt;

    def _get_name(h):
        try:
&gt;           return pynvml.nvmlDeviceGetName(h).decode()
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diagnostics/nvml.py:319: AttributeError

The above exception was the direct cause of the following exception:

params = {&#39;device_memory_limit&#39;: 50000000, &#39;host_pause&#39;: False, &#39;host_spill&#39;: False, &#39;host_target&#39;: False, ...}

    @pytest.mark.parametrize(
        &#34;params&#34;,
        [
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(1000e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                # This test setup differs from the one above as Distributed worker
                # pausing is enabled and thus triggers `DeviceHostFile.evict()`
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: int(50e6),
                &#34;host_target&#34;: None,
                &#34;host_spill&#34;: None,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: True,
            },
            {
                &#34;device_memory_limit&#34;: int(50e6),
                &#34;memory_limit&#34;: None,
                &#34;host_target&#34;: False,
                &#34;host_spill&#34;: False,
                &#34;host_pause&#34;: False,
                &#34;spills_to_disk&#34;: False,
            },
        ],
    )
    @gen_test(timeout=30)
    async def test_cudf_cluster_device_spill(params):
        cudf = pytest.importorskip(&#34;cudf&#34;)
    
        with dask.config.set(
            {
                &#34;distributed.comm.compression&#34;: False,
                &#34;distributed.worker.memory.terminate&#34;: False,
            }
        ):
&gt;           async with LocalCUDACluster(
                n_workers=1,
                device_memory_limit=params[&#34;device_memory_limit&#34;],
                memory_limit=params[&#34;memory_limit&#34;],
                memory_target_fraction=params[&#34;host_target&#34;],
                memory_spill_fraction=params[&#34;host_spill&#34;],
                memory_pause_fraction=params[&#34;host_pause&#34;],
                asynchronous=True,
            ) as cluster:

dask_cuda/tests/test_spill.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:469: in __aenter__
    await self
../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:411: in _
    await self._start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalCUDACluster(7977a16e, &#39;&lt;Not Connected&gt;&#39;, workers=0, threads=0, memory=0 B)

    async def _start(self):
        while self.status == Status.starting:
            await asyncio.sleep(0.01)
        if self.status == Status.running:
            return
        if self.status == Status.closed:
            raise ValueError(&#34;Cluster is closed&#34;)
    
        self._lock = asyncio.Lock()
        self.status = Status.starting
    
        if self.scheduler_spec is None:
            try:
                import distributed.dashboard  # noqa: F401
            except ImportError:
                pass
            else:
                options = {&#34;dashboard&#34;: True}
            self.scheduler_spec = {&#34;cls&#34;: Scheduler, &#34;options&#34;: options}
    
        try:
            # Check if scheduler has already been created by a subclass
            if self.scheduler is None:
                cls = self.scheduler_spec[&#34;cls&#34;]
                if isinstance(cls, str):
                    cls = import_term(cls)
                self.scheduler = cls(**self.scheduler_spec.get(&#34;options&#34;, {}))
                self.scheduler = await self.scheduler
            self.scheduler_comm = rpc(
                getattr(self.scheduler, &#34;external_address&#34;, None)
                or self.scheduler.address,
                connection_args=self.security.get_connection_args(&#34;client&#34;),
            )
            await super()._start()
        except Exception as e:  # pragma: no cover
            self.status = Status.failed
            await self._close()
&gt;           raise RuntimeError(f&#34;Cluster failed to start: {e}&#34;) from e
E           RuntimeError: Cluster failed to start: &#39;str&#39; object has no attribute &#39;decode&#39;

../../../miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/deploy/spec.py:330: RuntimeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_utils</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="dd7438af-4853-42f3-b0ca-3addf1a4de81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_n_gpus</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9731f5d-1562-4686-9c9a-6dfaefbf9b02"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params0]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="266a26cf-4846-40a2-96c9-9fe726a898b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cb2bed5-f952-4dad-8cfa-f449bd2f4a83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params2]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="219626a5-6234-4d12-84be-17dcbe36e977"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask[params3]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="855ec1a1-0165-4c0a-979d-e08cfd15b2ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_unpack_bitmask_single_value</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f9d2fd0-2ea9-46c6-bd27-3cc5c3fb7466"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.133 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed25bf67-07d9-42fe-8d9e-35cabc344d31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_cpu_affinity_and_cuda_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0fe06df5-b283-47f3-a763-2cae5272f2b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_device_total_memory</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.883 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e0cb90d-ac17-4a1b-9fe5-78ddcedcb6aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options_default</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e889cea2-b9a0-4c37-9483-1e92af63013f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d645a8e-45f4-48fd-82b0-f2f65c2df0d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aee81289-674c-4c9c-9cb1-60b20a4d02ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81d4e2e8-d380-4577-9e4d-06e379e9b224"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9bde634-678e-466e-a154-50fe15cf6600"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c099ccea-d176-4881-9924-59b4eb0065e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f6038d7-b557-4ad8-8fa3-14b0ffd96a1c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="df0bbdf7-2f59-4f67-af3a-e86ae064eeb6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_preload_options[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b36fe8d8-ccdd-46ed-8443-1a7cf14ee775"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2effbda8-f51d-4976-b93d-3c10a919a0cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8df7e6b-1d05-45a5-bdc3-8959f25965c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7d0695d-9301-47dc-a447-96fa2c22d089"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0bcadcce-4950-4dea-a6cf-113e248394d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abb3117f-ccb8-498e-b239-f902910c7491"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68b8546b-f07b-46ad-9803-96c4f6737b5f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c2b929d-2c43-4a44-a5e6-319878e47876"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0cedd053-75ef-40e0-aef0-206d67da618e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[True-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20510dd0-5993-46e1-b3d8-d9da6ae44e68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eef2c8f7-254d-4789-b8b5-d888a2d276fb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="344bc7a6-091f-4e83-90a7-94d3c46c2bcb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a52c07e3-e34c-40f8-8c27-0e0d26dfded9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17d5b7da-59ee-43a2-bbc7-3ae5f74dd6fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fdb6023f-4b15-4175-8e79-c38e845b3674"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6fa2b6a-597b-4552-b7e2-51f1dc4b5d6b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a41fcd6e-c906-4e25-ae12-9fcc42291110"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b6ccfe9-929a-455b-9f83-701237667b87"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[False-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09db2ae6-86bf-4a34-8f2a-f6d92972db04"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1bf054b-0fbb-4baf-8b3b-2b34cd1a63c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4064acc-499c-4019-8e17-b5a437934c52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-True-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a65e1dd1-d8bb-4dbc-8612-63578e114373"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e84798d6-ea45-4527-9f34-9c9220ea1e5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb45f308-76a6-4cb2-8674-af66edaf904e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-False-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1fe88c4-0e4d-4634-8e69-df5bb52e9539"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-True]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39fd6806-43ec-4674-a64f-5a66be1f6987"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-False]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd2fa21b-354c-4d51-b562-c4c861aed87a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_get_ucx_config[None-None-None]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-failed">
                        <a id="d704e01f-b0ab-43b5-ada3-3ad7e28880d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Failed</td></tr>
                            <tr><th>Duration:</th><td>0.0 sec</td></tr>
                        
                            <tr><th>Failed</th><td>AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;</td></tr>
                        
                        
                        </table>

                        
                        <pre>def test_parse_visible_devices():
        pynvml = pytest.importorskip(&#34;pynvml&#34;)
        pynvml.nvmlInit()
        indices = []
        uuids = []
        for index in range(get_gpu_count()):
            handle = pynvml.nvmlDeviceGetHandleByIndex(index)
&gt;           uuid = pynvml.nvmlDeviceGetUUID(handle).decode(&#34;utf-8&#34;)
E           AttributeError: &#39;str&#39; object has no attribute &#39;decode&#39;

dask_cuda/tests/test_utils.py:192: AttributeError</pre>
                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d48a75c4-8533-462c-9131-e1d8b32c348d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_device_memory_limit</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f763a71-ea13-4161-abc7-0a4d4bf134c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_parse_visible_mig_devices</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
            <div class="testclass">
                <h4>dask_cuda.tests.test_worker_spec</h4>
                <div class="testcases">
                
                    <div class="test outcome outcome-passed">
                        <a id="9a01525c-8812-4cff-93de-89c8089a3a02"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c562ef62-1b7a-40fb-bbbd-aa49721051df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c156230e-4843-4857-a325-55847b7fe8a4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9eba3c16-cdb0-47d4-b266-43c46174dd95"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="78f23335-d7a5-4741-bec4-fcc7f7ee0d92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fad955f2-3d45-4dfe-bbb8-3b80b68a48d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28f7f65d-0e0f-4025-9694-d7f6b69c4f9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b299957f-528d-4d03-b9ac-86942de25a9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="238d4808-5af8-41c8-bef6-7f29990de508"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e3f7c99-2111-44f1-a1b6-51eccc141016"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09d15009-d800-40b6-a019-306b0e7cbd9c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0de25b6b-6d83-4f15-aa20-2018d28fedc6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2dcf79a2-4ad1-404e-b127-be6a86bd9881"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="45b82d8a-fc98-4d42-95d6-3293df821421"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ddcde1d-9ca0-45d6-9a6f-c3de23f5d9c2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40eeda27-6437-4d30-8f64-628d9e298069"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a74b225-328b-48a7-86ab-dd9040acb04b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50df70e0-169d-4df7-8b59-eea6d2f94d91"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2044a7a9-65d6-423c-94da-6c35d8c0faac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a4f2f54-cd5c-4e10-81d5-a53649b481b2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="18f2d73d-70d2-49a0-a48c-f68bcdb6aaa6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f757ede-ed9b-44f3-bbb8-daae8bd5c7ac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d43602f-34bc-436a-90ee-3a755ac71853"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3808921c-7642-40b2-babe-2880736a3bdb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e08406a2-8987-42de-812b-bd5255e34922"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a47b51b6-51ea-45da-a673-be041013e179"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f275bb70-ea5f-4eb0-ad4b-83cc65b6d8a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d3874a9-0a6c-44e7-b90b-9d7290b24bb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92227f2d-6ab5-44e5-ac1a-a21939c3e0b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2c473c59-c5d0-49ec-b2c8-52cc7319749e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="67417730-6bf3-42db-9897-17fc83ba2662"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fddabe82-51d9-4494-93ce-0b94209e6c12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9ce6b55-5184-4327-add0-bbc6b80bd459"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80d534ac-3a1a-428e-89ad-2132c3314e16"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e512b61-17aa-493b-a846-1f7bbf108fdd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc41259c-0548-4dfa-a3f2-0f1073d56a73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64565ad3-15d9-481f-8455-e7b898e50fa5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1092a62-70b6-4f75-bd8c-a14108ff23b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e4a19c7-a7cc-4e84-adc3-71e6df47e095"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd9837ed-4424-4260-b3bf-81159ce5b801"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7f06fc9-41b9-4c17-9d7e-ce898aa32e76"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f43339c-6af8-4b86-aa8d-450e0a6f0d4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b24a18e-b822-4652-b656-88e855b93400"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cba1e463-1a4b-4276-ac82-1b0a105305a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd768480-9e6d-4507-834a-a77c84d22dd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5e33c36-64b7-43ec-93f0-e05132129c46"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4b7acb08-7fc5-49a6-806a-d8ba078cb086"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d538fc4-76c8-494f-b4c9-bbf70df33214"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ff6dcc8-7543-4f4a-8a35-33da3e12cd89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e2db2629-c4a5-4962-8b30-79003c756705"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a02b9848-ad50-4f87-9377-f8a932e1e0b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="07bbb0b6-497f-4216-8136-e47dd6112086"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8b632dbd-4e70-479a-a4fe-f13c17cc7422"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8157714a-c6e2-402c-85e7-c66894bad8b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c052de64-843f-4200-859f-35fab79e3eb5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="db18360e-db90-45c1-85de-c80ce167451b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4e8a8e3-7e5d-4615-bf52-8fa81f551f61"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2dfeb5ce-ab3e-42ff-9259-0dd75a36ecf7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d1a1bb1-6e86-44a8-a8fa-a9e416242c65"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7e1ddb77-0943-4f62-bfd9-db0b34e8ef72"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f6f123a3-5a31-44c8-bb7a-93e00b647edf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3f41fb2-16f3-4b5e-8c44-2b18a52e0807"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a7cf361-1964-4122-9f70-001e7f39cf09"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="382de5fc-6467-4af0-9e83-9daffa6338eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96580c4f-966a-4eb9-a360-983752c5e6d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71ddec87-a0a2-4335-aa45-1ba310a78aa3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a91e312b-6595-4c23-80a5-e47cee3217ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54ea26c0-56c5-46ce-90e8-a1f89ca37c39"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="42a55e87-fa2f-4d91-b61d-615c88733abc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c02efe9f-7308-4498-887b-cad7ec463710"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="157b6dcd-42bd-4d9b-a06b-8b64d31b5d5c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="98592a04-555b-4b03-8e7d-347ea6809ffa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2b8db48b-4ccb-46aa-a60c-dc98b7be0fa4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c3c3e4b-1a98-4392-a649-29243aaaadf1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c207789-bef2-4595-81b4-db7916ba667a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f3f97a0-19a8-4746-806e-5b1857b5d317"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9aa34ca8-fb04-488e-9e0e-d3a7a3440b00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d81e172-bbfb-452c-83f0-2619fdfbadcf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76d2dc26-39f6-4ee8-a5a9-29ae2dd59ddb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="049eb793-5758-4564-aebb-0416ad082f56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8aefeaa-6965-481c-b0c8-b2140720ee94"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c11f911-ef98-4430-b7b8-6b69cd3718e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cd59e6ab-108a-46b8-b0cf-87a29a2222e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39c73d38-7476-47b2-86da-edb361376492"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f7201fb-b16b-49c9-a976-4d9d6c641ca0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14c9dcc5-97d9-4036-a3dc-17d7608f973a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ceb28426-ff7c-422a-aaf1-126d9593fc21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02eadedc-08a4-4d47-af91-d6ebb0b443fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e888b6c6-38a4-4556-8517-1cb4dcafab3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74765321-3ba2-4fad-8e14-ed77b5c7f5b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4c6b96a-8682-484f-8482-de8c2cc3d43e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f33ce747-9bbb-47a9-944b-a80cf67c3e5d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ade6ef4-c171-4495-9f67-cc32e7bfd9c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d99abbd-0221-49b6-aaf7-390846f4546c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a409f850-8a35-4212-987b-5af231bbea6c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aa146370-f326-4dbe-941c-bed83fbdea73"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f82bfa18-203c-4ce3-b6a2-7bb5f4916038"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bb15fc44-c3ba-49ee-9c19-476527d58b32"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="50d742b5-224d-476f-a07f-882c277c3396"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5138e649-0f66-459c-b78c-b5fa5e4578e8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4bcb03c8-67b4-44ae-920f-91720e946cda"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d673479-a8c5-4f9e-989b-ca9d27790b70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="791883a7-5116-403d-8894-01595589d7d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b35951a0-28c3-46d1-993c-554048b8d1ea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9359a645-dde0-47b9-8653-b94c47db00bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="970b142f-2e0c-4e29-9b2e-79349e99b925"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce0469f5-7a28-4113-a537-41c20d35d771"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8b5c241-7af4-40d5-bcd5-146d611b3afb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="60bba05d-6bc1-4b2d-bc26-af78d7659f8a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0965a66-1cc6-4d8e-a668-531779f81970"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55eb10b8-327d-40b2-a72e-066c152ed5df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cd89e1c-fb30-48c7-a9ac-aaf897042d1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96b03a87-28fc-492f-aebf-ac82115b849d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="defb6c59-7c83-4c1c-86d0-a73afe70e6dc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4460ef64-df32-4323-a75f-cb258c82ff50"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47ffb87a-5057-4784-8fa2-b77905219cf3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20799646-6a80-4de2-863f-09aa9050351f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8694a3f2-198c-436f-8c76-563957cb81a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f4f457de-3dda-447f-83f1-0d2935fcb779"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0ac4e896-51f4-43ec-aa19-4b0e860477be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d022df3-67ac-4322-8063-fc6e7fb30c9f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7821dd00-92d2-439c-a2c6-4c1fad86f091"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9220c299-a98d-4743-bcae-83001dd626c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d0d2bfbb-ac43-4da2-a42d-3cf6c257d2fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b356bc72-3232-4892-ab1c-de7785ad64b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2e2cae9-2b5c-421b-9efe-bd6f3816c0b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ad6b196f-75ba-41c8-8601-5456cbf16c3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="244ad1ef-e980-4910-b214-95166a6317a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea751333-6dfc-495c-b03a-5d7d3c360bea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d350ce2c-5f9c-44b0-85ec-0da85d51189f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33741228-a6a0-4175-b289-3b2f7438380e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="335f72f5-e4fd-4859-906e-062d88dda3ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32393d9e-afa5-4620-bc66-6059553e1437"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="440ea7a4-d12e-4745-b244-396bd2506380"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eb880993-64b8-4930-a2ab-91fabce81e20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e44cb18-8b3b-458f-96d6-e11056fdc4f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="40227b4d-5b11-43be-8ad0-212fc091591d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a50a0471-159d-412e-a9a9-8862208a1d2a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab9ccdab-68e5-47bd-a4c8-7d52c9a96193"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2276bbcb-5ce1-4463-9d5a-e90445b08a08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="178ca789-41cb-4300-8b98-3a4d7e3be328"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="63afdd1c-e16a-4af8-971e-bcb22081b0e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6365434f-db75-45df-9435-b5a575577283"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="040d0403-511e-4a16-9dfe-badb6995de98"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2fd600db-de94-4a62-9b24-b49b76c5b095"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d28930e0-9cb6-4332-b905-569940a09a81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9d35d73c-5ca8-4b7d-8d1e-839d60d42162"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ddb3a764-9bce-4835-9d20-f597de71275f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0e0d733-fc03-45bf-943e-eee7f9457baf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3075f61-04bd-4568-b1fa-29b5b2fb8b9c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70bcde9a-86bc-48ef-9f26-bed8f0283f0d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e9973e86-97b7-411e-b104-5104b02468fe"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43dd2a7a-9963-4ba0-89a3-cd136739451a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a336a314-a6bc-4c51-8776-4ae0ee9a94db"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f881982a-05fe-441e-b19f-8ecbe20df1b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f37325d-c6b2-4dce-b3dd-0563c63ee88c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="811b38ae-80fc-438c-b0f7-0ce2bb1d5cce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d08c51a8-af84-4ee2-9b6c-4db3e17c60ec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="abebd439-d747-4b52-a134-477a1481085c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="883b7136-a513-4f11-bf89-59e54f7f204e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cfaffd3-2ea9-463f-9ebc-ad3bd23b9bdc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b36616a8-2853-49ce-9200-cb9944a4fdc1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7248a596-a49d-4c5f-b2f2-7c04416dc111"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1d7053e-969b-46c0-aca8-9771363fec43"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f02cf20a-164a-4e25-99e3-0c7f92cbe769"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8391823d-2e21-41b8-b79e-f89b22f4dd75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1a840fa1-c920-4b97-a8aa-61a270f59edf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a711333-a1c2-40cf-b230-227562e6a387"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1bf7a91-6be5-4dea-b149-a6a357de7d55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15f97cdf-fa83-4582-9e94-f688cae01ae2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5f7efd4-2c79-465c-a698-e68dc40f9b26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16f37f21-e95a-4a1e-811f-5477b620cdb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3649d095-738b-4663-9aef-0ab62c012f6d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80222686-0586-4718-80d2-7ae7503b7808"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b6cfab0e-8428-40ab-a62e-3ff286a2f75b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b62e0595-8106-4fc6-9a04-e6cbafdef48c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f3829a0-2af3-454c-953b-b87fb3b4ef5c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e353691f-3dd7-4555-873e-cbe649f1180b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="eda30052-d8d5-4cb1-ac56-532bc59956b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="641b831a-53d9-48c4-b066-d22df668e32b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c95f7003-3f73-4810-9e49-f5bb5454ac7e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a569d2c-bfe7-482f-9c42-ad757ad8afd4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d321513c-d9cd-4103-99b9-eb4bf3150d99"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96562e4e-ac2f-4301-9516-ff1048c38dd6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5044687f-30d9-440f-b012-7b2b03fce1f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb8eb0ff-008a-4ffc-9cda-09130cac7cf0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="81a7be3d-bca1-4abf-a4c7-fcd360efa91b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8aef126-229a-4a73-bf7a-a2a1ee42d2bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c32c7215-36f7-4ee2-aa98-44c18b74ad9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae3540d8-8f80-4738-a554-fd398e187ee8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a26df42-710d-46af-babe-d3e3a46267a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1395d6cc-ad4c-418e-b4b2-9907a05b46bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e26489af-2462-4f26-948a-b77c5a646495"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4b5359c1-8a0e-4ef9-9910-15b1f5578952"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d74bf1b-5191-4e77-9abb-13ba7e6873c1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c28ce0a7-5033-422a-8550-aed3128eb5c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="809ea22f-f4aa-45bf-a9cf-02272a0e84a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79d57aef-cf85-47dc-aa6a-f60aced31993"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e68a4cf-49f1-4655-ae3a-fb656781eed7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c4378c94-ffbd-4b27-b36f-dea3e6254d13"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="38c7758e-c263-4365-ae26-86ac0a392192"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="12f8903d-c4a3-4434-8f32-bcb737ad829e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1b8eee6-22e9-409e-b73b-c1a186620a9b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="328e7503-0863-4a3a-9060-515b2f810452"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00f61e3b-c61f-4537-8926-c4a697921a55"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cda8aba7-2767-4c5b-bd85-a926a0a5ec0b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fda556c0-b8b0-41bd-b38d-c639d8c124e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72b4c425-232a-48e0-bc96-27bca12c8b7f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0df0b569-1cb4-4d04-ac18-770b6b7e6732"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16fe2b1e-cb08-476c-9468-efbdde615ead"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="808281b4-5668-4a5f-b12b-a962ae8d0010"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9a60309-d103-4523-b1dc-9cf1247aa06a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="75bdf2fe-32f7-462b-8ad1-42811b73a627"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2e1ceea-ccac-4941-9481-149054ef0ace"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f198fe22-423c-42a2-8537-8ed7dd90a584"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ad4f989-0ae3-4df7-8b43-4c45ff7d24fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bbe3ecd7-a377-4a0a-a650-9a232f29ec74"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="efa43c5c-b93a-4c77-baa6-6067cacc1071"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="55d58897-a3fa-4e59-8549-e6dc1a71080a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7cb32b20-684a-4f67-912a-d113324dd8af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bdf5f114-afca-41e0-bc71-a3db52fbf135"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f90944f1-db74-4483-9f9e-92fd52020a38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f8a43fc-50d6-4ecd-bded-8d94d1427d15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7169e4e3-4b34-4cb2-b27a-4eae41124754"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6d7d952-c1bd-4427-9d74-763ce3e0c056"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="169d845d-9d5b-49e0-8213-9e173adc589b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8d8b38fd-de98-457e-9d3e-8c18684a1615"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9f42202b-e565-4711-8469-13144b151b02"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15227586-be3c-4d07-a71e-2bef228bf275"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d3b65109-fea2-44e1-a70b-6d2ab0e17daf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70b9eea3-5913-457d-8ad7-27312fc06188"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be5da2f5-2d5c-438a-a76e-6e83254caac7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="170e22a3-a840-4976-bbf8-9aad967e0eaa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f6a5e7fb-764c-46fd-83e6-f3aa9e38187d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cdba3395-4ece-4fee-8574-35ed5d5fd02c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49d5319d-2f71-4a47-a2d0-711410908e1d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1b6ce4a-1d51-4c77-a7b8-43972202495d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afd28dfc-412e-48bf-8ada-95dac81614fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31a980f3-a68f-40d1-9a32-05a98be06629"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="886034bb-17d1-44b9-afaf-7dbba74c3976"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="25d7f145-f825-43bd-9c42-4ad8aea9d49b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41547b1f-0760-4251-8740-8eebd600bec2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d31a14b-92b0-45f3-bc44-1ab002366a36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="06712664-9a1a-4264-8ae5-e05352fdf58d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="259a5ec1-40c5-4dc6-80dc-e0d05e35dba0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b86831de-31b9-49ad-91f8-f1b554a11dbf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4c3f01f6-512a-4eb5-8809-5a7a76b91bc9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="89b5d238-ad78-4f82-9bfe-6f96cd97d65a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fbe9fef3-08df-4d67-aff2-a91c8343a371"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e456136-e0b5-4fc3-a32d-6a111002dad0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9fad2b43-1370-406c-afe8-aa4ec7e93c24"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69094fd8-1d47-40c9-b01c-50ff505fb59e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="826eabd7-6291-4e7c-916e-0591d4bd243e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2d14e95a-5108-4472-8a03-1908779843b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cdf2ab36-c0eb-489b-952f-ae347e735bb2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="460ec5f8-e79f-4711-bd1b-bb40bab33b2e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0cb64740-3349-4c01-b757-ef5b912e6ea6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dba2c334-d0b0-41ac-b851-45f8759b8727"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6392abe8-e4e1-4678-98ef-fa90b0feb75f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="167aae4e-f780-4b44-81a4-15e2faf81b68"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e16fd7a-abca-4a5b-9d94-ef0603dbb9d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="385259a3-10ea-4f99-bf80-3a0c9522742a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86044e12-2873-49b3-8b8a-681c669532e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b2e89873-0ad9-4ab5-a0f2-6e836b08e902"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41844be4-c691-4da5-a739-fa26f4680204"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6203c6d-854a-402e-951d-981f5f1773d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a65ff08f-55bb-4409-a245-4481ba644b1b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf8cf69e-2333-427f-8100-2cabf4d15e71"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a5b30fb-4d56-42ce-894a-499927615320"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fafba014-fa07-4c04-a3f2-0ae32fbcb0fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3918141-63a6-414a-864e-a9ea25d1ae12"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b34a73e6-3570-4929-b4bf-4be9a3f63796"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19206d5d-c342-4a6d-81fe-955a4d1050e7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8443c04-55b1-431a-9eb5-0649def40ced"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a0b07ff2-66d7-4a6a-bea6-4d1201ac8c2a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2f7eeba-7dca-4c22-b124-1d4415663149"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d27ac0c4-d80d-464f-aebf-d9e025fbf556"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2499f36e-7428-411a-b02b-3ef2f8e184d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a18a281f-6650-454e-bab3-d5d7c8b07049"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76a9c759-03c3-4be0-b161-2d545f140fbd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1e14d894-e1db-4e20-aff2-0f1d3cfd0a27"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a1e6bc0d-af5b-4100-ab4a-b997ce84bdf1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="251b42ec-4412-4d5e-94f1-cb192341cb26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9be04781-78cd-4ce2-b0ee-e22d4c9cb691"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce95d628-cbb7-4cf9-a17a-bb1f9601fde0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d7a13ee-1cdb-403e-a5d0-3ff671c6471b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbbe4bbf-0dbc-45aa-b199-ee3a2bfa62d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5845fde1-844a-4a08-8d93-aad783feaf38"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="189e6d4c-2ce1-4028-835e-f68177f54bf2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ba9e4e6-28ce-4500-873c-88701d176d20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43d557fd-65fd-4c69-b121-197a6dc9acac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="35216a9c-14c1-4302-b098-f7b7180c8507"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="edf0b82d-9389-497d-b3d1-ec878878742f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19f9a641-a6eb-49c3-9f58-2024fde7df3f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="460f0568-8ed7-4b68-87a2-e3a564cb3cea"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a9f4faed-1335-47c0-99f8-835c78c4dd56"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1eade382-9937-4d12-8554-566ec5274d77"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02eee9ad-73af-48d5-bd9d-e05c5f173795"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae38e9e2-22dd-4162-bb78-fe3375aaf453"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7a0b1d69-ee4b-4424-aa22-7237cdb3c81a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ee4ce84-9d2c-478f-b6ef-d23c3261a5b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8fb452da-2b5e-45b5-be17-582d45727e36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e8befc34-ee1d-48dd-9e61-50af76d68631"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f9d1c04f-7a81-4abe-b29f-4b5a8feb9da9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e60b1aad-1974-49a5-b182-91e92b0c0a72"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="292a9535-5fd5-4298-8c1b-3248ff5fcef4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cda4fbbf-c0d2-4cdc-aaf5-01551da81f18"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="186958e3-f9c5-45bf-a643-6dc87b251f93"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ae5f8545-d4cd-487a-bb15-9138b99be07b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e7ac9dde-8dda-4196-a570-625dead122cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="37dbe6fe-a968-4778-97ac-16b219cccfb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afc14dc0-3e22-47d7-9a9f-602be7b19353"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d61fba8-ef69-41c8-89b0-bce711c060f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9be69925-c41d-4237-8610-557d4d5f0c29"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c7517fd-14e2-4072-b35e-eeea86f4f1e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="050a2e2e-8e8e-41e7-8d67-dd6835fae7cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1caff8a9-f296-43b4-a502-3b7dda05e8d4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="972113e2-50ab-4545-9797-a86710a09f36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39f8f596-ca63-4672-b406-627f722c3a94"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94ba7de6-6567-41ff-8c6d-cf06a9ee4662"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba1bceb0-5315-474e-a471-0bbbe8c2cbd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f40d059-7ad8-48ba-af0f-ee5cbff31ab6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd2381f8-83ed-4c04-a456-98125f595273"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="546adca6-e4a4-4ec9-b715-d22e7daede2b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="afa510c3-c808-4e83-8075-faba70b1e03d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf47905f-cc7f-48f5-a849-35ab4c5e7808"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e145c851-8b87-4e0d-af2a-c4133399b4d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bd427ed5-ec22-4e9a-af04-4fb3435b4464"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b9dd55ff-8b89-4751-a5d9-b30079a7de3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15d3ee0a-4f59-47a1-8841-3061799b3bde"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2cd9b0e-8c13-470c-8f1b-d27abe67232a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3cb58b72-c527-4742-ba17-23b8d27647e2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5159f49-fabd-460f-ada5-8327355b8bcf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="02bfbe03-ef2a-468f-9224-15d8ec8a052e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="919623f7-c9e0-4a75-b76c-464e1b794544"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="699dddeb-a606-4fc2-835a-ef1e568341d9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9152f808-4b77-4109-841d-3e6ae4df6c2f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c3733be-59a3-4dfb-a47d-33cf785e3e52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94690508-441a-4a15-83d8-2592f66b6362"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c314ab94-ecf1-4fd6-87e1-7757fe4f38b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="84d6d43e-6ef4-4234-9b66-2f95807b6a52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="262593f3-f549-4a51-ad73-3f01e2fa01de"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="680a0978-b67f-46dd-9ccd-a14a6e43fde7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cbec5129-1579-42fb-94a0-2eda7381b513"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="310ce1c0-4697-4869-994c-ec46e1c8c401"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a5959f6-00bc-4abf-85af-171eca18be31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17d97a06-8d03-462d-a16b-58c79abfeeec"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74fb4995-4b15-4c42-b929-10d7bea70add"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4398abeb-5d48-4daa-b156-d56bb5852ee8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca7062d6-5e2a-421e-99ab-2a3319df52b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4e4e1aca-cc3c-4ed8-86b0-37093fc9aad7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c1dbde7-22d5-48a8-a31c-bae64a28e3f4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9a6cdc3a-da95-4845-8d06-9fc1d2ce0e01"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a1a5633-d3de-43d0-8fcf-1147c49cfa08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31ed9658-878f-4bd6-88fd-447d1704d4b3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c8a988c-573d-471a-b3ec-2749d8a96fa9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed55e62e-8d3c-4b60-8638-0952b9c887b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68f7df42-9e92-4366-88a8-ecf3c99093a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e75290c0-7d29-4114-a598-250068ee7487"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="59736629-1110-4a69-a54b-5c47274aa01c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0f93dc61-40a6-40e7-add5-2b3f9f49126d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88181e53-708f-44d2-bb1d-0d1410a5417e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5447e448-fd79-46e3-b969-dea4f4e9cee6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9077bc95-7caf-4177-8b45-046914674bf7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="372d7fdd-cae6-4cd5-a012-5a5a9024d6d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c040096-14ac-4d37-80ec-8e6bbb56cdd9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7262c3cd-d5dc-4a47-8ddf-1fc789551cf8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d9fadbb-0ea7-4249-88d0-8ca170f233bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94841c11-e8d8-4915-983d-1df4fe3cff3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="37bfdeb9-1f20-41ef-93f2-3ec2603bf9e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="98f18960-2d68-46a0-a1c0-32e3784c0ca3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="84aca958-c03b-41a7-9a3d-0290ee6c5485"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e929918c-4bcb-427b-b906-1d440c80fffc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d141378-beb2-40aa-a73a-67262351fca4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="806504af-a5df-412a-ae87-20bbcd773119"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="db957513-cb66-4fba-8153-66643ffd62a0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d14d370-b08c-4773-938a-06972b9a5d58"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="712b17d0-e4d1-4184-a2c1-076f86a13161"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="773a49b6-73b1-43ec-be79-5b17c6282989"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6e55ace4-8c6a-48b7-915f-1b92e06cc16b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f01c0de8-4a17-45cf-b554-369dd66544a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f23ebb0a-9484-46d2-8595-a7762e884b31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ae77ae0-118f-4549-be76-b9fdaa1d7daa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c268ea54-839b-4a75-9a9a-f8f11b325448"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6430fa6-4af9-45b2-a092-905933775196"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13e7b5d7-1d51-4b86-befb-3c036805f1f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="674b3ab9-576c-4f3e-97f7-203dbce51366"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f3d012f-62b6-4994-935a-369603923565"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d0c49d6-7425-474e-b0e8-d1d73a1b4b87"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="71d6fcd4-b9d0-40aa-90ae-687c7f04e0c0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="611264df-36a6-408d-8b35-f8eb994556c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="760c95b5-ddc5-46a8-aec1-b2078a986a8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6cf7da4-cfa8-4e96-92bb-80c0f2a809b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c235013-f59f-4f97-b272-bc5649aabcee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0da80ca4-b94d-4418-a089-fe63c482187a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c3d5bae-ba08-4a2f-b35e-228cea94203d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="755dac8a-5897-46af-9d54-80f8847ff881"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c742ec9-e6e0-4b8f-b0f3-3b5f55563d76"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3ed8033-89d0-45df-a690-fdf9a29aec9a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3ce04e9a-c45b-40ac-9d84-8d76e25d64eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e1e61fe-3019-4b89-b944-6f0ade1b7178"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86d42fb1-dfb6-455d-98fd-a53d3d6c905e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8649f380-5951-4b61-a39e-6a9dd6aec7bd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d71712e5-1a90-457b-a70f-7892d609c767"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e2e17e5c-e050-46e8-b2b8-b20aca4c135f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a7c8f6f-74c4-42b0-b6bd-1004736071a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20c135ad-1546-456b-8f7b-dc47d29d7cc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23cbd7bb-b409-4344-aa97-0b9f6871b42c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0c5e5bf9-f0af-4fca-b353-51ccea671bd4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52627a28-a32a-46c7-b726-4ceba0a76cc5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f1cedc9c-c1d0-41ea-95c8-dc56341b5d37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6efe5843-22ed-4705-b1b7-d223ff78d513"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5b0ed660-86f1-4088-9ac7-2e69512d7d94"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ac7579a9-340f-4fd6-8cee-c61b04e60a6e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7d0c3b74-0ea2-48a6-ae25-f4e6f6d1455c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28226ef7-dda3-4f3c-af8d-2b797fb10a7b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0505adac-15ef-4fd0-a4bd-f04bad43ead5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="334b833a-bdd0-4682-a9a3-b6c093cadbae"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d9045578-96d0-4824-97f7-369e023610b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b941e492-da4c-4d86-9856-f1bbe9dd4755"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4c8135e1-c112-4ee5-99ed-db3c9f72f0ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8590f7ff-07f3-4633-9c12-62656b191bbd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9382df92-c770-4609-ab28-736d05df9692"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="33cc202c-d2c8-4f9b-b914-5b82739ca9f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c5f48c1-ae85-48d2-9a68-a161a805d21b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6a0b6957-d0bb-45b3-a0c4-08ed6d12cab7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4f9e4edc-bddd-4828-9725-b340f68cb565"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9080fe7-34fd-4cb4-9d14-91c7ab12d019"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="21a44efb-9626-44c2-86bf-42bea3d04863"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28385d44-6048-40aa-a5c8-8ae751f628ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6864a576-0be0-4f0c-ac79-537e8eee4ae5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28d145e1-876e-4930-9176-4db028be7d0a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[False-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea03001f-928a-4ed8-bf19-8ebd18e25c8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f2826e24-5541-45bc-b9be-a86705edbf21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5b46194-69d7-4718-81fa-9262c0246e8b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2c7e739d-ca7c-42a4-a6b8-d6de0607081d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8c728bf-55bf-494f-ace1-cbfa66606145"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17c60a27-6565-4d17-97dd-5962e53cecc9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e6e4e1a-9cee-4a8f-bd8b-c215ca341060"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fefec45b-fe9e-49b0-9f4a-23171b4c9285"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c4a1fde-118a-4bf8-9a7f-8f48a004cf4a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="de8f7f6b-89c0-4f94-98ef-96a31a7352a5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="182f816f-b047-4883-a99b-36550b5ce69b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5206aeac-b4a8-4a23-ada5-643345d47a3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2650c67-b184-4837-87eb-8b20fdac3e07"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="450848fc-ad2c-4c5a-bb37-4048b849362a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b92e21d7-ccde-466f-a459-a081d793d34d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e48b229-7573-4dbb-a66d-8af57aae230b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8168df9b-4aa5-44b7-a167-3f68f0d86f8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="08c5c430-81d5-487e-b135-9219400a9e20"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc3ce105-4c76-4787-93d0-ac557c60c6aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b6d9709-5a71-4040-a71d-b8664041816b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="43ffc6a3-bd44-4e14-a00f-30fdfbf05d09"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ee68e789-7b36-4659-954e-55e56e7dd425"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="944dc4b4-6ede-4842-857c-0b9db2dbf7e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d2700f52-3bb7-4f99-a8ff-ad2cb62fb950"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ed6371a-8d42-4b43-9f2e-7fcab0785627"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47f66b32-944a-4ee7-b5f3-3288bbbbd615"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fc84d35a-06d5-4bfb-932e-79247035e754"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f34b80d6-b354-4766-9431-587acd756fe0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aee3fbc6-fc96-4bd8-8a63-41ebb1cda6ee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69eeab91-2a66-4258-b718-d67cf1de9968"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="474475af-8096-4655-b44f-4a46f83b4896"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e1e34263-2f85-457c-8ab3-dd42bf823a48"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3fc89ac7-5900-4606-8dc4-e9987e1df750"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8d04a8e3-7195-48f7-a62e-888c01b0c5d8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4718fad6-5158-4141-8dc3-20175a3f3f4a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e466e2f-5b22-427e-82ea-bd202bfc4408"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0564f87b-aa6d-44e8-ab47-ccb1a30126e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9ab175d0-42d7-451b-b185-a097139f886d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="68dd5ce1-91b4-48bd-bd93-0c0257bece5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="769a0916-f694-49a5-8e24-e9ff138e0e5e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="74d4ee2b-885f-493f-bfb6-51e0d3f876b0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69b5483d-9c3f-46ff-a025-211e537bb3cc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e706032-6b9c-4d0b-ac73-664b38493709"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c24404a-e358-479b-a46f-287a00f352f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3949748-5a69-4f14-84d4-9182a2624e4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f218888-bdb5-46a4-93b2-8e28384ba434"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7ff506d4-3985-4351-aaa2-91fd075548ce"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d5235b9-1f9c-41de-8e41-6f42fbb5e656"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e6f5c59-b43a-4774-9359-8ece541ba9a7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a4635be2-0cb5-4ef7-9853-9361b7f0702f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="decca2ff-bd2d-449e-b361-cddd3f59640c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="634d61bf-0b08-4ba3-8622-01d9bc0b96e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="aad1520f-63a3-4772-95a5-a550c95b6eb2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc26b3d6-cd3e-4031-a22f-9c83acdacc79"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8001d986-9eea-4729-9ffe-2b8211c32746"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="124833b5-69d8-477e-867c-00c047e2c99f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6f146966-8c80-430a-8885-caaa8d313c0c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d803edd3-48c7-4807-aac3-40aae834401f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ecaa2d7f-9b98-44b0-af08-d7e781e8f77f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="82a2f1e8-e4d7-4cd9-946f-4a8e5fd1990c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7229adcf-edc2-4aea-bdf8-1f2948b6cdc3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65280e7d-633c-4866-9627-f017e1b7a74c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="75e97873-5b37-485b-b08f-2d7a0c6584d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="00d24c77-d635-4720-9d4f-ace606ca4e3e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69d3a3e4-b792-43da-84c4-dd9a371f4a32"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="853179aa-dce2-4e14-8759-f9fcf124ff21"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b9e4a7ab-3a5a-4321-a4f2-68d7e88148f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f16fed71-b55c-4831-943b-805a2201b35b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b045b522-4ef9-4d2e-bddc-f22e3762dd47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1d70818f-5b27-4290-a575-e40047bcc71d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3395671b-c837-4af3-bc6b-cccb4f797ccc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6bca593-4c3c-46eb-8746-7979893d423d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dfa302cf-4218-4340-bb5a-5f1ebcd43ce6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d11ec683-4fdb-4043-8968-06c1a5a663a6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c1589ad0-e79e-4a7b-aca9-a612d8586567"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da6e9853-67b9-426e-923b-d8d6b1ff95ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b550811-3537-4e3b-9f47-c77271883dc4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fae9c4b0-d599-4403-835a-4ddc589ac0c9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a3073e85-fa53-4c8e-a41d-c6fc1523b4f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="950549e8-a40a-49b7-861d-da8d50bea6c8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f8200fca-4ac9-48d9-9c75-bf7ef4ff5406"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b45e10a0-8a1c-4866-82d3-79e6a7fbde64"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="99c39af6-a103-4f56-af61-d4abaf70c480"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c0444912-4f88-493a-968d-fb1fd72479ba"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4ee28694-d7cf-4b73-baca-253b2881bc71"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8a3fdfa3-17bc-4e3e-bcad-a12433af73bc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a34d58d-35a6-4443-b035-ba1004d0a93e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="769a103e-67c7-43fa-8aeb-9874802de13d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="473eaef6-69c1-4fdb-9ab0-6645494af7e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2e4929ea-38d6-4bf1-8af1-76215d0dc2f2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5a461fd9-f68e-4164-822f-c6589a82fa4d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c21417f3-e995-48f6-b360-3204d9866f37"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cde6cecf-54f8-401b-bbb8-8e7f1d1fd840"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6a31a8a-908f-445a-9c1c-dd863efa0ca9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15e14c81-782b-4c65-8836-c404048b30e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15a9c596-408f-413a-b1f7-040a5c2326a3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5aa33eca-fb1e-4e41-a3d3-ff193e295d6e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="96e3ae21-bde0-4f31-a605-af7fb9a41860"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec88cd94-1286-4a73-9076-f1d0465e07b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ab4b6878-00a6-4c00-9c14-2d8051ea1f92"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09dcd610-1952-4fa4-a83e-10efd200913d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a580448f-d3bb-4a7f-8e2f-925be42811b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a2783e2c-37b1-478e-8d12-96cd2923c600"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bff34a99-3c67-4bf9-99aa-1aab06aaa2f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cee1c6cc-d5e3-4eb1-9829-f14f7c8137b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ec8073db-c7a0-47d5-bb8b-3a8511424622"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="76513ce5-5c49-48fc-bf5a-2e6f915f11f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="692ee0eb-d8b8-4129-b790-e67fd889176a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8dfd45ef-1d83-4c21-a54f-055d6a745f31"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4d586503-0791-4c66-b45f-46d6a245030b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="476da748-8ad2-44b0-be9b-5b6583cf20ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8a7b9ac-760b-4d89-aafa-3c50f5d0d551"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5bd0c49f-eebe-43cf-b711-ced665cb9d0a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31f1986d-4b70-4927-8029-d415962ab10f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f21673e4-0833-46fc-8e2c-4bd787997f0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cf8d2984-3efd-4f6b-886c-9addc8d67e4f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f729e9ab-29ec-4a0c-a9b5-4f7e66cd3e03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32532eb9-f499-4c5b-be29-30764e1d6b82"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c7c8a5b-437f-4a44-ac8c-1d82dfa4bd36"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5038368d-2196-4641-8960-3c91a60800eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fee41d16-c5db-490c-ae48-b81cb8de80cf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="37d32fd2-d3ab-461e-bba0-13a29116fad3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="89106a3e-2bb6-4854-865a-3ec2bacb8f8d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0fa0c4ef-1898-4434-9adb-3b390650f880"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d209d077-774c-44dc-bc8d-58e58cdd468c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f5b7e1de-dd51-4f68-8446-7c40d2cf7997"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3dfe02a0-0030-4b12-bd0c-21997fc4ea7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3e44ae5-7fa1-477f-87e8-dfd37dde4428"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2050baa5-77e3-402b-80fe-f22fbc55c6ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c8e050b-ed67-4d8f-8e79-a476c1e9d0af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="524f917c-f01c-470f-921a-a9a0fdf5cc33"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="69c2fdef-13dc-4868-8667-ccda52682be8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d4dc78b4-3a44-4a16-80f6-47a967b5e3b9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94e76e3e-da1a-47ba-b76f-ecc87d43cddf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54cd6ed5-f7a0-48d7-9a16-3eb124c44b5d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed0e245e-a5f8-4a02-82b1-74d627ce2f81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef78e754-5ae7-46ce-b643-b0cfce6b8695"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="86c75972-9616-4c16-9900-789e850c5296"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c214800-c81b-4af3-aafe-6570a3b61adc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ce6df05-9237-4eaf-ad7a-aa171c80906c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba9ea284-e474-4dc6-b2be-7cf470e617d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dbd52ce6-9347-4678-a3b9-ec268a3f13cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f36d419b-1c9c-4928-865f-d77290090241"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="720b60d2-7d6a-4476-85c6-d82eaae19e52"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="529d9c24-1973-4e0d-b34c-d1a5d36a55ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b673d2c9-0060-4f20-8c40-6ef6d22b5008"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2961195c-e5e6-44ab-8e48-bef58de88331"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8221c51d-173e-42c2-9e17-6fee2edd2e24"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f10b1f14-3c6b-4508-9449-0dd1d793b2f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c9ce6215-7877-4542-b501-536fd05afb09"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f2d04d1-c33d-473c-8300-d48353f8400d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="72f81d36-37e2-4feb-9ad8-574d1231a7c5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bf7e76b8-0cb4-4a5f-9c13-21ca7eb1ec4e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d581db06-fd89-40ea-9fd2-7f09b3ac6e26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2924d4d8-a150-468f-9894-0762112fe638"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c66445c-7995-46de-8efb-e95602837bb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ff83c952-6840-47dc-bb6b-cc1e11a4c538"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0db13166-6dfd-4acb-8540-4868da621718"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.197 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e7827bf3-564c-43cd-9873-34114ccab625"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.064 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="65bf3b6e-dbbf-4500-8256-59618343c138"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14f29738-43bf-4c0e-9835-2e58722e2dac"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ceeacf9-8f13-459a-87d4-2f34413acfd8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54eb439d-510c-4e67-9914-6de92ac3ec70"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f8eeda82-f582-49ec-89fc-8b1dbfdaea62"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="04d9bb8f-59ff-42a1-93c6-e0f7606a2903"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="80c83b5f-4af8-41f7-af98-0b1c0c68219a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="23bc43cf-31e4-4d3e-9a25-5768bc021348"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="82f4658c-867d-427a-ade2-a4058daa9b71"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ebd4ca5b-3949-4142-82b4-1060517a7d83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d15eaee9-769f-40b7-9a8a-d058ead99a1a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e364ee33-4641-440c-bcc0-7f251824ebe0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9b25ef29-ba10-4045-9fd6-491d6ca619fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f2b8270b-efa3-4e2c-a609-6cc52fec8ea2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f79f1a0d-227f-4f06-8cd4-cbaba3101a26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8765b346-0851-4443-acbc-c84452b0d91a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3c2ab1a6-5de4-48dd-a2a5-41786af5db81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28610563-1f24-4724-accf-cb376876e8ca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a6c50859-51b4-45cf-bff2-3df6b7fb8b75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8885c7db-a67f-45df-aef7-4bb298310708"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c3887f3-e17c-4e1f-bf21-d833b7be4ab1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e577643b-cf2e-4d48-99b3-e3141c22728d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cbb7099-fa98-4172-8640-24df89516890"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4fe24f0a-664c-4f80-bdd3-426c3d4f2ca9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8b0b116-578d-4cd6-b61b-6bf16667fd89"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c7c94f97-1f53-418c-95f2-0119bc7501b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1fae2b0-1a57-4172-9e93-32efc59b6804"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="722d0b44-f063-4b83-a562-b126dc698e69"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c75175c9-45ad-4740-9310-4d10319b1b5b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="158b256b-e577-4c9b-a892-1f040b4630b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="15569857-3fb7-4f44-a7ca-5172b1d80cf0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="44e82ee1-f8b6-49dc-9101-3aee7ec08017"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="58755acd-69d8-4ca2-b677-bb63354064d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c409effe-07ec-4a94-b487-e3d69b442330"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e54198e-d4cd-4fe8-97e8-9c0a221fd7aa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4abbea36-35d9-4cfc-8bf3-81cce50d97f9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6676a245-a469-4084-ba93-9918bbccc2b7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d6e653eb-1304-4108-840d-b77a704da3e4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c525d3c-1dbe-4e8d-9316-0954633eebef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7c2cc806-1b07-4876-972a-cf05dd82e389"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f7d03e6d-1c68-4b0e-9f78-50e83d349632"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="89af616b-af7e-4ebd-889a-977a61f7eb6c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95476562-41b9-4219-96e0-21f4808d8194"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a82fc91f-0fc2-4a2e-b3a9-4c89182cd110"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="31e3d2e6-4cf6-4caf-af6c-667e8cfc4af0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9636eb6b-cfd8-410b-a899-8c2d26e3cdad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="03956827-a6b5-484a-8307-f1a9fa86b5a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fb16730a-4b30-4cce-8402-020910f3fec2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4df1e56e-f7ca-4e78-a36b-ef918a392a81"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41ea96e7-75e7-404a-ac97-8f611a9863d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="952a63b8-65cb-4fde-a687-83c4f654c0d3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1835b179-11e8-4d5c-902e-18473c6cbd64"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88803aab-764a-4977-809f-26a389730cee"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3f911d60-92b9-4238-8745-b1d0540ccd5d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32be981f-9010-4771-909a-13b8ae86a442"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7b19c0ea-4331-4832-a644-e4e5271ecfd6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="91f9493a-a430-4c39-b862-0f117dca3771"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-False-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a8c51669-b5d3-4b82-a67a-0d157143a939"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b39284f8-fbac-433b-a13c-07996029f340"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="60dcca0a-dcd9-4f11-966c-3a4c64bb4d11"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc37eab3-ac8a-413d-94a3-d380fe78b573"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d88cd34b-a8ac-43c1-8e6e-44279a414ba0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8b2e0c2-7722-4787-94f0-ff8b73a173fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="34aed33c-57e7-49b4-9f36-945af3c00c8f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2c36b753-558b-4e8f-9814-72bc500cf209"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bfe86903-2c2b-4733-9d16-fcadce6f8079"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cf3bc3a-ca82-46e1-a154-4a360df6b115"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9c6c1ffb-729e-493f-b247-4da2400eba42"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5da4f6c-b1e2-49aa-976d-b7cd7c35dba9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92e88396-4c7f-45a9-98d5-e2ec67626fcf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ed050fd6-f7af-439a-903b-5884d3eb520c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6cff0466-71a9-4987-ab51-6a0e422b58ff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e68cbfd-38a5-493f-9f5f-1434fff481ed"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6c0ac44d-e559-41cb-9a24-e1bed915f38e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dc6402fa-55a6-4b77-8eb4-3fe7940ceb7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e8d28e03-47d4-4cd6-8f94-d3c580afba0f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7fecc0bd-cf89-4125-a4f4-229d9b18fdd3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d4446bf0-1e75-4738-8bbc-3fcb27d1e0ab"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="190b46f5-040b-476c-9dc5-dceac5b4593e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="28fba998-3118-4654-a781-7a3735cc35e1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="947dd7b4-15e9-4ed0-8787-ba5a6d0425f7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ada9fe9c-f09e-43ca-8124-f3146358d532"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f0de05ae-1b84-4f59-b920-cd6a1dcf362b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7db1614f-bfc0-4d06-9019-aec47a7d709f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="26f4d3a4-a4ef-42f1-afae-0e7dc3a609c3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e099cdcc-2809-4d4f-b7f2-06c316e0e635"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="30875d21-f00e-4adc-9530-6a31ffee7c34"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="275d9edf-84e3-4f3c-9579-af71ba0ab2b1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="932230cd-a0a4-48f7-817a-83c1011fef41"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="393b0210-68c9-4a05-ac73-5c7953169058"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="27318908-85fa-4ce3-85fb-425fae704786"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="32231dc9-e7ec-4849-9654-3f2428fe61c4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f925e55e-5889-4b8b-a8aa-cd3438049489"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b122eb0e-8cb5-4f2f-b8f8-a8abdede10fa"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1bb6a5ca-a422-418b-8963-849c5df344cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e77add3c-575c-4840-94ca-a037fe48bf90"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="875609f2-fcc4-409c-9e0e-081e4a21694b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="19d099ec-84d5-4375-9d20-c1911ad6f086"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="144210fd-adeb-4c10-89c4-07d35c8100e3"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7959a57e-2037-48c5-93a2-e46fb42c2a15"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e0cce35e-eb2f-48b2-8a6a-d620c44547bf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0744cdb7-3b66-4cbc-9685-4eb72daa5f2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ef456e0-7c0f-4948-b24d-4c1b7030950b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="16a31cee-0484-4018-8b19-aad4ccab0878"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="92f06bf7-d853-4ea8-a1a8-c30382e28149"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0e76ee29-198c-4dca-a1d0-aa4b349b45cd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="918ba569-0571-4a30-8ac0-bfb25b742d83"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6851539-8156-4e1b-93d6-eedf52aba117"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5f5f5b38-8ebb-49f0-9e4c-305d6775bb08"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef2b4c2c-0015-4b95-888c-daf611bb672f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a60cd981-6fd0-4728-bceb-e107e3611254"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8cadc824-89fa-40d2-9815-6c345214682a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41fa903e-9b61-4ee7-baf6-fbbda9d15898"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="167b0e97-8ad1-43d1-8cf7-1a576ad776b8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0022f9f-9c51-4c4d-927e-d43383ef3a3c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="17789bd7-5bca-4f7c-9319-45ba1f0f87d0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2a4904ec-a813-4875-826d-bfceb31bd8d5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="93446c8a-82fa-4c91-afa6-4f12bdb74a29"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4fc35a89-2c7d-4b3b-894a-9404ecb51b7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="85ef15f4-6fc7-4180-b2d0-15dfbf219106"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d8ed13de-7ede-477b-a91f-21f644f34f67"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="39e861fe-713e-49bc-8264-0e5a4e7b18fc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="467a4a35-ebfb-4e06-a81d-eef181eb19ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="363a72fe-afd2-447a-aa25-2d6ebb4f435e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d15a18eb-6384-4e46-b281-3892a8ffd65b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be22cd39-121c-4810-8a88-5050a88ec826"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b8a6b717-920a-4083-a12a-7fed760c3c6a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="061b0587-09fc-4729-8e75-2b78b3738642"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dc9e338c-a382-4f70-8df8-a541e9859045"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="56000577-c5f0-4c65-8222-b9fdefffb74e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2077fe4e-ea71-420c-8718-60b315fa5bc0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3a52146b-f999-4974-9d81-0aab9afff641"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="78e5100d-ba6d-45e6-8185-5f31cebc480c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="922d0160-bef4-4124-9d4e-0ef9b61a49d6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="678c19d2-1fa2-44ed-adf3-1a886ea6495f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c0d22d66-6c85-49a3-8d29-0577d6740358"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d03ca75a-e39a-4d57-82de-41c7861f1512"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1b1b469b-df20-4afe-94fe-0cf316ba3190"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ba521cc7-eb3b-46cd-9186-1824145b5297"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b3631e22-63d8-4c81-8313-cfd4da15f3ad"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e6350f37-7ab4-4d10-a043-53ae21e39854"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5523a8e-12e6-4d23-872f-2593c2def7df"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3e7adf96-6fab-4eb3-91ab-489f0c8fb696"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f6b82c3d-fccf-44e6-9a84-6eff8f162eff"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ce0eaa8-6232-4de9-b97d-d49dcb612628"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8f642dfa-ab98-4fc2-8e0a-d9bcc56e7669"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="54ac7d64-3c7f-4823-b53b-87a3d610de5d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="94dc4bcb-957a-4bc8-9f21-b8b693cd8ec0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5439d411-2b5c-47b4-8baf-4850db91ea3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca891873-d60b-4808-ae98-a6ba14c6e58a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="698990b6-c9bc-4c69-b72f-5777627bf7be"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1687def5-669d-428b-a72a-4269f4cad8af"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4b44f7c2-39c3-4875-9843-46488e30cdc8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ead93d81-6e10-4c2e-91dd-982cc6728c7a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a99e532e-126c-442e-8dca-7c5ff8fe6456"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="975a57fd-fe4e-44e3-8598-0d9b140348ef"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d53a65b-b973-4a75-b128-3b792944a83d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="da7115ba-5fa9-462e-8ac6-f53b3f4c9797"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9410d692-0b35-4a44-8e7b-c08c5a25936f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ea921efe-3713-472e-82d1-0274cea2d125"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e5458f81-e2b3-4a70-8697-59a6ce4a792d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e99df161-c977-48da-8e02-4862464f66a1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f62e38c7-e3bf-4447-98e4-81ae1e8f2f03"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5c740010-27d6-44a4-a0b0-5ad763566cd4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="631ff4ed-d3c1-4419-9304-1a1c703a88b6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-False-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87c38b36-6f24-44f4-97f9-6ee8ea6cdbe2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8e541a4e-59e3-4fc0-9d1e-030e06b9ee25"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="391b8ebb-bbae-4adf-8981-e57daef1b459"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b77e9700-3cbe-4e75-a94c-ef3d62a00169"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2223a650-2463-4a3b-be76-005027997d00"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="cc992dc6-a951-43e0-bb7b-f139c1559004"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="febc135a-4ce0-4736-95c8-e975a08fbded"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ef833360-8472-442b-bad9-fd290b9471b5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9e7f2e44-b97a-46c6-b85f-8d9b84261308"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5af5aa7e-30aa-421d-a5f1-9915696e2dde"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="223ed98d-be58-478c-bd74-633382d9512d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6d0abcd7-add4-4c4b-8f16-e3dd049f70c7"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0b036481-03b2-448e-9359-aa09d6bb4a4d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a033419a-d090-49a7-863b-1659b04497a2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f54882d-c08a-461f-afd9-42a2df481f4c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2ff3ce5a-604d-40c0-8288-703cbd9e2958"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="691b9306-2529-4b00-89c8-2d828716151e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4c83e3bd-ae95-421f-bff7-877789eb94f1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b384098-5c84-48ce-bd19-30ad0128bc39"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="421102e3-2c12-46ea-b489-7034fae55afd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="52d99e39-e2bc-4d7f-afc1-e232286cfd42"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ce5fc7ac-b7df-43bf-80f8-54a07d4e6fc5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="03dab0f6-ed0e-4a62-943f-17077c9e2cbf"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="614106fa-6525-4f1c-9101-4f6ea04572f8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1237fd04-3617-4dfd-ae5b-6760eaa4eac2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64f57550-6d9e-43b8-8547-1d9752fd2d26"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09aa7c7f-fe7c-4f77-9655-2c0423fb0529"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3315fce6-a72f-4a2b-9523-e06fa9d02d7d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bb6af3fa-9f4d-4f3c-a7a6-6b59538491b6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ff443941-d2fd-4e08-a429-442d5182190d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a5c77d36-7e81-4173-84e9-2c9051d9d10a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61d21cdb-10d4-493b-8a85-123639944d28"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="09a12cc1-3670-4e5a-9412-b3ec0ef1cb49"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2f6cf19a-7272-46b5-baf9-423f9827ec75"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e4dc0de7-42b7-4bcc-b45e-a1018195f54b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="924d441e-4503-4636-94f1-dd07f3fbd45b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="4a73fbcf-8ece-4e0a-92a1-a5ce7650ba2f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e03b02e9-f4d8-4958-897c-dee8b678771d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1c510b9c-cf1d-4ed3-a215-5de71205e0c6"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="d085e81d-ab65-4ca9-af4a-7fb0642cace1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b91f7f41-be45-4f36-9b0c-306ffe382d3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c35c95f7-d43f-41e0-bcd3-74ee9a325cb1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="11d2529f-ba1d-4b68-8930-c4410c50b228"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="14d0b499-3547-4cfc-9dd1-f8790794b67c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0473fefc-1592-4025-a7f5-9a4780999bd0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="a64d63c7-a5be-423d-b473-abe357f9233c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51ba5e01-f8b0-4f6b-bca5-51c9aec8cd44"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="20b50cc2-b259-4c63-92ce-0207934faa1d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="61279404-f63c-4793-8cf2-aa66e0e39c3d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0d63ca19-73d8-49e7-bf46-cb8ab4a7e999"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="108de313-b4bc-4adc-9132-0a05e152ac2d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="2c96a461-04bc-4180-9b5f-7a24fa519dc1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3254f279-aa43-4e84-a4e5-7fa22fb09423"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bc3b4f35-ee79-4f35-9b58-afcffa61d7f5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-1-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="bedd1dcb-e8ea-4066-a4c7-d45dd91057eb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5e0926f8-1ae3-4f98-84a9-28403cdc0955"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="429310a1-48bc-407d-a6b3-c35cd6b3a924"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c8ad60fd-91bb-47e3-b252-54c3bb68b40a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f1c40544-faf6-492d-82c2-cc23360f4a0d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3bb2e9da-e7b2-4a26-a2da-dabc103bf24a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="ca308400-957a-4a97-9b52-484f65a2acca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="01f97f5d-5dea-4ded-8a36-4326580aecdc"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47cff11f-9403-4f4d-accf-b2bf73de8cfb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="c3916815-b97e-4be0-9939-88e905e17aa1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="f51fa995-b165-4f93-b87f-4e10a92250f0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8ad30143-c83a-487f-81bb-2d56fcd8a443"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="856a3c57-ea51-4479-8908-696bb5480fa9"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="47b372d3-95ff-4549-b55c-5b09aebe81a8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="083a3861-5edf-4c14-a969-5938addd9871"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="87de06d8-65f9-4388-835e-f741b8fb4778"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="1f4db862-6d9a-455c-99c8-5db2360f5eca"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="9801a027-c801-445a-9669-528c6f3b5069"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-None-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="206677a4-7f73-439d-8e86-011ae50dd849"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="af955c8b-b89b-4249-9240-75f1f2b0508f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="389d14d5-847d-4629-9e29-a22ffcded00e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="79b2d359-4588-45a9-b8ba-e1c964101ee1"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="51627e09-f55d-4304-8739-88aa3b00ee30"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8948b7d4-63e7-44fb-a44f-bb44cf01d59c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fd6d359c-2513-4422-8975-70fbf5aa195a"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b0aa3444-3cb0-40d3-b091-396e79c5463b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dca16fd9-f55b-4f59-8bd1-b2d0e9165303"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="0aa4eede-a925-4987-88be-8bfb525f5150"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="41b23980-6547-4e3b-a989-3c7723de37fd"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dfe07c1f-54df-41b7-9ca4-7d9be5029781"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3db9377c-41c5-4e05-9e30-c4b9daaba63d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="932c8738-b978-4890-b976-c97e32de6863"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="edac4626-d1cb-4a20-83a2-c4381b6e4db8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6b415d13-56ae-4608-a17f-5029f55e0be5"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b1d37bb4-1e83-4e52-b0eb-e1ac9c4555e0"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="e148f20f-2604-4ec0-b31b-c51af8f98b47"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:0-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="7390fc82-44a6-4a25-9480-d9438086c55d"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="3d9887d4-d6ea-41d8-a1f7-76cc450b0321"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="b519b425-9da0-424f-8871-ce5a9ee9a404"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49583b6e-129c-4e8e-b377-4f7daf255e7c"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="64c800b1-d86d-4aa6-a117-387a85e8527e"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="116c205d-191d-4037-a1a8-0b008097ccb8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-None-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="dae81305-6204-4328-8d56-ecb65279e8d2"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="95f94971-4672-4af0-a259-97c96b82ac3b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="6ffa98fc-2b60-4cec-9a78-075536af306f"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="13d44e19-5960-45a1-9fda-4123fad48e6b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="982dff40-0690-4475-b22e-a037b1696646"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="be2f92dc-a26c-48c5-b502-2a2372884974"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-tcp-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.001 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="88e8b8f8-72ac-4e70-9622-d0b24853516b"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="5d901c5c-e96f-4e2d-a27a-0518f9bbf9cb"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-None-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="8c8742ad-b96e-42e2-bc48-cb691b2105b4"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="fdb7d8db-32ce-4a49-aa3d-571fc417c947"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-eth0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="49e9b24d-3b88-4367-af75-19d936562a78"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-1]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.002 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                    <div class="test outcome outcome-passed">
                        <a id="70caa6f0-cf30-4486-a0d2-262db4451fc8"></a>
                        <table class="proplist">
                            <tr><th>Test case:</th><td><b>test_worker_spec[True-True-True-8-:8787-ucx-enp1s0f0-Nanny-4]</b></td></tr>
                            <tr><th>Outcome:</th><td>Passed</td></tr>
                            <tr><th>Duration:</th><td>0.003 sec</td></tr>
                        
                        
                        </table>

                        
                        

                        
                        
                        
                    </div>
                
                </div>
            </div>
            
        </div>
    </div>
    



<p class="footer">
    Generated by junit2html
</p>
</body>
</html>