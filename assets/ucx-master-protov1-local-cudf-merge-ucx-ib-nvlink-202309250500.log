[1695628261.905581] [dgx13:80683:0]    ib_mlx5dv_md.c:367  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:80683:0:80683]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80683) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fee50ee6eed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fee50ee4aa1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29c3c) [0x7fee50ee4c3c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x74684) [0x7fee50f91684]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fee50f68c6f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7fee50fa5c3d]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6dd) [0x7fee50fab12d]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7fee50fabdbf]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x67d37) [0x7fee51059d37]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x556cc99b444c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x556cc99996fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc99a6519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x556cc9997128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc99a6519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x556cc9997128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x556cc999be64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x556cc999be64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x556cc999be64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x556cc999be64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x556cc999be64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x556cc9a49162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7feee44931e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7feee4493aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x556cc999e77c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x556cc9950d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x556cc999d7f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x556cc999b929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc99a6519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x556cc9997128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x556cc99b3ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x556cc99b444c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x556cc9a7710e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x556cc999e77c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x556cc99996fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x556cc99b3dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x556cc99996fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x556cc99a6519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x556cc99965c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x556cc99a67c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x556cc9996312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x556cc9995094]
=================================
Task exception was never retrieved
future: <Task finished name='Task-1079' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-890' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-09-25 07:51:02,189 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8185b10140, tag: 0x5444aa70574c9621, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8185b10140, tag: 0x5444aa70574c9621, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-916' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-09-25 07:51:02,320 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1104, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 294, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-09-25 07:51:02,356 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:44044 -> ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 294, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-09-25 07:51:02,362 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1104, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 294, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-09-25 07:51:02,481 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34668 -> ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f228caac380, tag: 0xffdc8574be735f3c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-25 07:51:02,482 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f228caac180, tag: 0x8a64535be715c4fe, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f228caac180, tag: 0x8a64535be715c4fe, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-25 07:51:02,485 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1f64ab0100, tag: 0x88fb94a1c273fe01, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1f64ab0100, tag: 0x88fb94a1c273fe01, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-09-25 07:51:02,507 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60798 -> ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1f64ab0400, tag: 0xb73b672694e88b2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-25 07:51:02,559 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54794 -> ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8185b10340, tag: 0x3ddd86b22ede600f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-25 07:51:02,690 - distributed.nanny - WARNING - Restarting worker
2023-09-25 07:51:31,161 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1910, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:52823 after 30 s
2023-09-25 07:51:31,168 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52823
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 471, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1910, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 473, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:52823 after 30 s
[1695628292.213033] [dgx13:80688:0]    ib_mlx5dv_md.c:367  UCX  ERROR mlx5_2: LRU push returned Unsupported operation
[dgx13:80688:0:80688]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80688) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f4031ca7eed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f4031ca5aa1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x29c3c) [0x7f4031ca5c3c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x74684) [0x7f4031d52684]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f4031d29c6f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f4031d66c3d]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6dd) [0x7f4031d6c12d]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f4031d6cdbf]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x67d37) [0x7f4031e1ad37]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55705cbfd44c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55705cbe26fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55705cbef519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55705cbe0128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55705cbef519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55705cbe0128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55705cbe4e64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55705cbe4e64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55705cbe4e64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55705cbe4e64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55705cbe4e64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55705cc92162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f4056ed61e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f4056ed6aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55705cbe777c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55705cb99d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55705cbe67f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55705cbe4929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55705cbef519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55705cbe0128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55705cbfcccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55705cbfd44c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55705ccc010e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55705cbe777c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55705cbe26fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55705cbfcdac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55705cbe26fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55705cbef519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55705cbdf5c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55705cbef7c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55705cbdf312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55705cbde094]
=================================
2023-09-25 07:51:32,502 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #029] ep: 0x7f8185b10280, tag: 0x1025ff4733561f57, nbytes: 800041496, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #029] ep: 0x7f8185b10280, tag: 0x1025ff4733561f57, nbytes: 800041496, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-25 07:51:32,537 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:44044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1910, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-09-25 07:51:32,956 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3)
Function:  shuffle_group
args:      (               key   payload
shuffle                     
3            31828  73636940
3            31836  80143307
3            31971  28275316
3            31979  27052103
3            31981  72398802
...            ...       ...
3        799993891  13201944
3        799993897  60498597
3        799993898  27335491
3        799993904  33762432
3        799993909  85369504

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-25 07:51:33,002 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 6)
Function:  subgraph_callable-3b3023a6-dfd6-4da5-a4de-f9fa733c
args:      (               key   payload
shuffle                     
0           137475  74590861
0            31180  93390287
0            55270  36156466
0            17753     36373
0           493724  76277316
...            ...       ...
7        799824930  33371792
7        799810645  99657131
7        799984473  60693335
7        799967067  32399158
7        799937976  25234566

[99977935 rows x 2 columns],                  key   payload
63495      814479993  88054400
63496      505829955  41038733
63500      304493238  31733762
63502      820064719  69409427
2149       700510538  84062198
...              ...       ...
99970349   690076304  97201906
99970353   395560937  44035997
99970357   289903111  43536994
99970359  1500642987  40711097
99970365  1521740850  16439286

[100006787 rows x 2 columns], 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-25 07:51:33,018 - distributed.nanny - WARNING - Restarting worker
2023-09-25 07:51:33,527 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-09-25 07:51:33,528 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 801, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-09-25 07:51:33,551 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-2f7c39ce5e6399e29bac23110d347e6e', 4)
Function:  shuffle_group
args:      (                key  shuffle   payload  _partitions
0         400000000        1  48863339            1
1         400000001        6  82208751            6
2         400000002        5  23172095            5
3         400000003        3  83618300            3
4         400000004        7  32090160            7
...             ...      ...       ...          ...
99999995  499999995        4   2417575            4
99999996  499999996        3  79206659            3
99999997  499999997        4  89655348            4
99999998  499999998        0  82540937            0
99999999  499999999        1  42812172            1

[100000000 rows x 4 columns], '_partitions', 0, 8, 8, True, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-25 07:51:33,690 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 4)
Function:  _concat
args:      ([                key   payload
63488     610321960  79966525
63489     833697582  51960092
63493     810095290  23524986
63501     839604975  12466059
63510     815862002  31298976
...             ...       ...
99980058  822268828  68813384
99980067  819288735  45631900
99980079  828042106  58858843
99980083  837224880  92370785
99980093  867531865   3131568

[12500589 rows x 2 columns],                 key   payload
22762     944805583  12794969
22768     915754544  51874709
22769     924817007  77836694
22774     946367485  64742453
63538     900813296  44738953
...             ...       ...
99996001   13200036  78327323
99996007  935381755   7581229
99996015  901120421  18563961
99996022  910701113  32274182
99996029  930954140  42722566

[12501715 rows x 2 columns],                  key   payload
93216     1003009703  16248951
93219      636453144  92511233
103084     335396657  52915773
93222      333778356  72073353
103086     431202276  32283714
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
