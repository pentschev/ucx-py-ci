/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35385 instead
  warnings.warn(
2023-05-26 06:38:04,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6j71ufmo', purging
2023-05-26 06:38:04,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4n1a0exg', purging
2023-05-26 06:38:04,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:04,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:04,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:06,823 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:07,198 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:07,228 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:07,255 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:07,507 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:07,881 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:07,920 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:08,127 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:08,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_sllvn2', purging
2023-05-26 06:38:08,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3k36jnov', purging
2023-05-26 06:38:08,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ysvk7h5b', purging
2023-05-26 06:38:08,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-80vy103q', purging
2023-05-26 06:38:08,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4w8vluvq', purging
2023-05-26 06:38:08,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1xa979s', purging
2023-05-26 06:38:08,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvlrkxvj', purging
2023-05-26 06:38:08,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tw36kj3e', purging
2023-05-26 06:38:08,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:08,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:08,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:08,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:08,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zaf6txvd', purging
2023-05-26 06:38:08,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:08,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:08,890 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:08,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:08,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:09,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:09,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:09,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:09,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:09,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:09,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:09,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:09,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:10,031 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:10,121 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:10,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xycctuld', purging
2023-05-26 06:38:10,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xk86v8m2', purging
2023-05-26 06:38:10,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9evdyao9', purging
2023-05-26 06:38:10,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:10,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:10,527 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:11,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g_fxdvmu', purging
2023-05-26 06:38:11,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:11,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:11,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:11,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:11,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:11,957 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:11,983 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:12,115 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1o1mwazt', purging
2023-05-26 06:38:12,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3c6xdx2f', purging
2023-05-26 06:38:12,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:12,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:12,726 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:13,354 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:13,586 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:13,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zeadt325', purging
2023-05-26 06:38:13,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hyqwxqno', purging
2023-05-26 06:38:13,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ky05nlkx', purging
2023-05-26 06:38:13,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9pgz4eo4', purging
2023-05-26 06:38:13,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:13,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:13,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:13,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:13,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:13,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:13,615 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:13,648 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:14,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zp47o892', purging
2023-05-26 06:38:14,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:14,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:14,667 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:14,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-52zwee1r', purging
2023-05-26 06:38:14,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:14,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:15,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:15,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:15,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:15,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:15,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:15,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:15,628 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:15,665 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:16,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vsci_onc', purging
2023-05-26 06:38:16,223 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f40omg61', purging
2023-05-26 06:38:16,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:16,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:17,088 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:17,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83pw3n62', purging
2023-05-26 06:38:17,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:17,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:17,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:17,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:17,481 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:17,509 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:17,731 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:17,758 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:18,377 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:18,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1mzwxvg6', purging
2023-05-26 06:38:18,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fh6smxse', purging
2023-05-26 06:38:18,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_clqawgg', purging
2023-05-26 06:38:18,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ql3bw23c', purging
2023-05-26 06:38:18,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kk92afar', purging
2023-05-26 06:38:18,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:18,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:18,805 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:18,834 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:19,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6kt770r', purging
2023-05-26 06:38:19,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-np6bltwo', purging
2023-05-26 06:38:19,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:19,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:19,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:19,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:19,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:19,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:19,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:19,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:19,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:19,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:20,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9r302jjo', purging
2023-05-26 06:38:20,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:20,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:20,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:20,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:20,637 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:21,135 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:21,179 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:21,409 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:21,629 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:22,208 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:22,236 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:22,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g40207ng', purging
2023-05-26 06:38:22,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o2i9ypdq', purging
2023-05-26 06:38:22,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-al5u_ewl', purging
2023-05-26 06:38:22,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eedpavza', purging
2023-05-26 06:38:22,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03udrhwd', purging
2023-05-26 06:38:22,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zej1rxjf', purging
2023-05-26 06:38:22,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-203te1rc', purging
2023-05-26 06:38:22,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:22,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:22,293 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:22,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:22,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:22,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:22,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:23,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:23,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:23,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:23,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:23,533 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:23,821 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-albdzah5', purging
2023-05-26 06:38:23,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:23,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:23,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:23,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:23,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:23,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:24,354 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:24,392 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:24,482 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:25,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wc7n0m_9', purging
2023-05-26 06:38:25,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8s42ezdv', purging
2023-05-26 06:38:25,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9k2o96k', purging
2023-05-26 06:38:25,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:25,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:25,319 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:25,764 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:25,841 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:25,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ewg15yr2', purging
2023-05-26 06:38:25,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ndcfnk7', purging
2023-05-26 06:38:25,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9eivduhh', purging
2023-05-26 06:38:25,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:25,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:25,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:25,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:26,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8sjwsrp', purging
2023-05-26 06:38:26,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:26,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:26,216 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:26,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:26,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:27,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mf01aqpx', purging
2023-05-26 06:38:27,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:27,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:27,354 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:27,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:27,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:27,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:27,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:28,216 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:28,246 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:28,276 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:28,711 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:28,768 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:28,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cdb6ed_m', purging
2023-05-26 06:38:28,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s68bq4rp', purging
2023-05-26 06:38:28,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d4uwk0mo', purging
2023-05-26 06:38:28,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-onkgkc07', purging
2023-05-26 06:38:28,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6u556rh', purging
2023-05-26 06:38:28,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1u5_ch2j', purging
2023-05-26 06:38:28,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:28,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:28,988 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:29,574 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:29,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it29howh', purging
2023-05-26 06:38:29,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:29,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:29,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:29,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:29,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:29,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:30,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:30,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:30,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:30,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:30,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqbqkjun', purging
2023-05-26 06:38:30,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:30,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:30,840 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:31,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:31,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:31,664 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:31,694 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:31,719 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:32,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ysej4yo', purging
2023-05-26 06:38:32,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dr2n2sma', purging
2023-05-26 06:38:32,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lya7qss_', purging
2023-05-26 06:38:32,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlezg2_o', purging
2023-05-26 06:38:32,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f0080evk', purging
2023-05-26 06:38:32,340 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xud3poux', purging
2023-05-26 06:38:32,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:32,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:32,564 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:32,591 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:32,617 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:33,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4k9l920', purging
2023-05-26 06:38:33,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:33,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:33,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:33,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:33,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:33,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:33,408 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:34,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i5v255vj', purging
2023-05-26 06:38:34,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:34,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:34,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:34,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:34,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:34,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:34,253 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:34,941 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:35,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccyu0bq3', purging
2023-05-26 06:38:35,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ab42c2r', purging
2023-05-26 06:38:35,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itdnq22y', purging
2023-05-26 06:38:35,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:35,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:35,143 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:35,169 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:35,680 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:35,708 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:35,736 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:35,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kf7iiixj', purging
2023-05-26 06:38:35,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pml3yy0b', purging
2023-05-26 06:38:35,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ww87bxg8', purging
2023-05-26 06:38:35,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:35,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:36,125 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:36,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05294o29', purging
2023-05-26 06:38:36,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:36,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:36,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:36,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:36,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:36,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:36,875 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:37,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ha6z_fln', purging
2023-05-26 06:38:37,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:37,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:37,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:37,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:37,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:37,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:37,341 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:37,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cc4uq94t', purging
2023-05-26 06:38:37,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:37,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:38,086 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:38,114 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:38,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hczsy1pi', purging
2023-05-26 06:38:38,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s47btivw', purging
2023-05-26 06:38:38,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:38,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:38,499 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:38,523 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:38,571 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:38,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5prqp_a9', purging
2023-05-26 06:38:38,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_i0yyas', purging
2023-05-26 06:38:38,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tnuhldow', purging
2023-05-26 06:38:38,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:38,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:38,891 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:39,013 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:39,473 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:39,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x48fmpao', purging
2023-05-26 06:38:39,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_0qcq89x', purging
2023-05-26 06:38:39,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zncazm8f', purging
2023-05-26 06:38:39,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:39,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:39,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:39,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:39,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:39,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:40,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:40,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:40,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:40,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:40,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:40,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:40,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:40,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:40,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2818lzvd', purging
2023-05-26 06:38:40,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oceriz3g', purging
2023-05-26 06:38:40,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:40,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:40,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:41,092 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:41,890 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:41,914 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:41,946 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:42,068 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:42,105 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:42,324 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:42,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-67svxwxp', purging
2023-05-26 06:38:42,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-huz7dr4g', purging
2023-05-26 06:38:42,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6rqtcr7', purging
2023-05-26 06:38:42,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hb8xay9o', purging
2023-05-26 06:38:42,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5nyv6psh', purging
2023-05-26 06:38:42,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhk24rg7', purging
2023-05-26 06:38:42,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:42,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:42,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:42,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:43,298 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:43,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ewikctss', purging
2023-05-26 06:38:43,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:43,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:43,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:43,471 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:43,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-00dki_ak', purging
2023-05-26 06:38:43,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:43,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:43,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:43,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:44,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:44,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:44,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:44,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:45,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:45,259 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:45,288 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:45,317 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:45,339 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:45,772 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:45,898 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:46,066 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:46,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an2q516l', purging
2023-05-26 06:38:46,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88p_covw', purging
2023-05-26 06:38:46,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0wiryg7', purging
2023-05-26 06:38:46,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9t96rzm6', purging
2023-05-26 06:38:46,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_8f4z9e', purging
2023-05-26 06:38:46,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-timo5c6g', purging
2023-05-26 06:38:46,691 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ui8dwnao', purging
2023-05-26 06:38:46,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oipr8t0h', purging
2023-05-26 06:38:46,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:46,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:46,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:46,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:46,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:46,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:46,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:46,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:46,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:46,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:47,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:47,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:47,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:47,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:47,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:47,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:48,726 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:48,747 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:48,777 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:48,798 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:48,846 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:49,080 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:49,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:49,281 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:50,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tgts7hy', purging
2023-05-26 06:38:50,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oey1we4k', purging
2023-05-26 06:38:50,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24ae1mfk', purging
2023-05-26 06:38:50,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgsyxkch', purging
2023-05-26 06:38:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a36e_p5b', purging
2023-05-26 06:38:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqi32xq6', purging
2023-05-26 06:38:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vj4jd932', purging
2023-05-26 06:38:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rb_pr2md', purging
2023-05-26 06:38:50,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:50,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:50,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:51,757 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:52,251 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:52,278 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:52,317 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:52,371 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:52,598 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:52,627 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:52,789 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:53,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e12f5tes', purging
2023-05-26 06:38:53,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z7dxjvo8', purging
2023-05-26 06:38:53,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmjbo1zk', purging
2023-05-26 06:38:53,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z37cey9n', purging
2023-05-26 06:38:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kslk3hkh', purging
2023-05-26 06:38:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nlz9s2d3', purging
2023-05-26 06:38:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6vmkuyi', purging
2023-05-26 06:38:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9j8okbh_', purging
2023-05-26 06:38:53,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:53,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:53,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:53,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:53,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:53,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:53,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:53,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:53,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:53,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:54,031 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:54,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmu1ad1q', purging
2023-05-26 06:38:54,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:54,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:54,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:54,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:54,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:54,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:55,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:55,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:55,978 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:56,016 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:56,042 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:56,065 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:56,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:56,124 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:56,313 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:56,599 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:57,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ioyzgf1', purging
2023-05-26 06:38:57,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gg4qxcvl', purging
2023-05-26 06:38:57,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwcsmg9l', purging
2023-05-26 06:38:57,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6pa4cks', purging
2023-05-26 06:38:57,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mr3gwnpw', purging
2023-05-26 06:38:57,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3o6ifd4', purging
2023-05-26 06:38:57,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y22oje87', purging
2023-05-26 06:38:57,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u6xqlh63', purging
2023-05-26 06:38:57,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:57,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:57,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:38:58,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:38:58,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:38:59,524 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,791 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,792 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,803 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,825 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,839 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:38:59,862 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:00,166 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:01,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un6mh9_y', purging
2023-05-26 06:39:01,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtu2s1c_', purging
2023-05-26 06:39:01,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_056bdn', purging
2023-05-26 06:39:01,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uguuay9a', purging
2023-05-26 06:39:01,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6277ly4', purging
2023-05-26 06:39:01,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7hncti1', purging
2023-05-26 06:39:01,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ckyr15i', purging
2023-05-26 06:39:01,054 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zz6bdu0s', purging
2023-05-26 06:39:01,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:01,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:01,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:02,931 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:03,265 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:03,372 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:03,425 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:03,452 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:03,477 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:03,503 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:03,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:04,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vtz2ukh_', purging
2023-05-26 06:39:04,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fp1yor4l', purging
2023-05-26 06:39:04,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ge9p7vsq', purging
2023-05-26 06:39:04,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-icccu678', purging
2023-05-26 06:39:04,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78gjoruo', purging
2023-05-26 06:39:04,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8mqenby', purging
2023-05-26 06:39:04,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6uxu82k', purging
2023-05-26 06:39:04,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_qeucz91', purging
2023-05-26 06:39:04,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:04,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:04,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:05,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:05,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:05,251 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,186 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjg_r4fw', purging
2023-05-26 06:39:06,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yf7bvj9b', purging
2023-05-26 06:39:06,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:06,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,774 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,840 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,890 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:06,936 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:06,963 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:07,133 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:07,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x16d39cn', purging
2023-05-26 06:39:07,734 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb9dcu5d', purging
2023-05-26 06:39:07,734 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-174llzm_', purging
2023-05-26 06:39:07,735 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bje_uh9h', purging
2023-05-26 06:39:07,735 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1vhb90tj', purging
2023-05-26 06:39:07,735 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojq0m9j6', purging
2023-05-26 06:39:07,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:07,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:07,830 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:08,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hn7eivi', purging
2023-05-26 06:39:08,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:08,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:08,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:08,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:08,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:08,614 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:08,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wctsqfyk', purging
2023-05-26 06:39:08,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:08,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:09,297 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fg8zxbj', purging
2023-05-26 06:39:09,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:09,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:09,354 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:09,889 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:10,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6hrmdjo', purging
2023-05-26 06:39:10,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:10,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:10,193 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:10,218 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:10,245 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:10,286 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:10,546 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:10,816 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:10,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dduqs0c7', purging
2023-05-26 06:39:10,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6gq8wm5w', purging
2023-05-26 06:39:10,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0fi599z', purging
2023-05-26 06:39:10,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3qlvw9z4', purging
2023-05-26 06:39:10,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqkq79ie', purging
2023-05-26 06:39:10,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtu3q3_8', purging
2023-05-26 06:39:10,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:10,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:11,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:11,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:11,667 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:11,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_f4rkmi3', purging
2023-05-26 06:39:11,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:11,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:11,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:11,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:11,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:11,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:11,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:11,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:12,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:12,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:12,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:12,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:13,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:13,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:13,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:13,535 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:13,569 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:13,594 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:13,658 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:13,995 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:14,019 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:14,257 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:14,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-useduqfm', purging
2023-05-26 06:39:14,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1kvw2x1', purging
2023-05-26 06:39:14,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hrlfz5fo', purging
2023-05-26 06:39:14,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_p9k20dk', purging
2023-05-26 06:39:14,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q62jqu6r', purging
2023-05-26 06:39:14,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrk1fdh7', purging
2023-05-26 06:39:14,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5n57odp', purging
2023-05-26 06:39:14,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k35rt7ds', purging
2023-05-26 06:39:14,949 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:14,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,182 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:15,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:15,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:16,860 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,053 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,081 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,107 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,132 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:17,354 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,395 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:17,570 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:18,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-16ay6ldi', purging
2023-05-26 06:39:18,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhg_8m_3', purging
2023-05-26 06:39:18,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgp8j6_7', purging
2023-05-26 06:39:18,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hip_8tn9', purging
2023-05-26 06:39:18,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxgie3ko', purging
2023-05-26 06:39:18,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pxzim5oe', purging
2023-05-26 06:39:18,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2kjqy27', purging
2023-05-26 06:39:18,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nya0zd5c', purging
2023-05-26 06:39:18,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:18,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:18,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:19,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:19,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:20,554 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:20,578 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:20,600 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:20,626 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:20,681 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:20,865 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:20,907 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:21,077 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:22,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ew316zzc', purging
2023-05-26 06:39:22,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4htrhqqf', purging
2023-05-26 06:39:22,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mesls6st', purging
2023-05-26 06:39:22,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vz_g06iy', purging
2023-05-26 06:39:22,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5kxzd2mp', purging
2023-05-26 06:39:22,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yjqch3b', purging
2023-05-26 06:39:22,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csewkf6u', purging
2023-05-26 06:39:22,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p8_a14fu', purging
2023-05-26 06:39:22,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:22,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:22,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:24,145 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,323 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,364 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,392 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,428 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,446 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:24,481 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:24,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:25,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h0htd3lv', purging
2023-05-26 06:39:25,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbgvcmal', purging
2023-05-26 06:39:25,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-or49udtq', purging
2023-05-26 06:39:25,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6evahm0b', purging
2023-05-26 06:39:25,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8j6t78rc', purging
2023-05-26 06:39:25,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zg45smao', purging
2023-05-26 06:39:25,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fnmitz5v', purging
2023-05-26 06:39:25,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-144omma_', purging
2023-05-26 06:39:25,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:25,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:25,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:25,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:25,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:25,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:25,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:25,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:26,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:26,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:26,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:26,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:26,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:26,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:26,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:26,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:27,907 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:27,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:27,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:28,024 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:28,047 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:28,087 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:28,107 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:28,406 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:29,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-njgmj1pm', purging
2023-05-26 06:39:29,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-11zc3dhz', purging
2023-05-26 06:39:29,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brldswrs', purging
2023-05-26 06:39:29,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ky4fkwa4', purging
2023-05-26 06:39:29,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-drlgm8v8', purging
2023-05-26 06:39:29,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubs61tsb', purging
2023-05-26 06:39:29,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhoaxiew', purging
2023-05-26 06:39:29,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jvskrh8s', purging
2023-05-26 06:39:29,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:29,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:29,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:31,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:31,757 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:31,783 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:31,811 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:31,833 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:31,859 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:31,884 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:32,069 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:33,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gw5e37r7', purging
2023-05-26 06:39:33,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgj_hp9r', purging
2023-05-26 06:39:33,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4krak90e', purging
2023-05-26 06:39:33,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cdpxmu0', purging
2023-05-26 06:39:33,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9t0cxi6', purging
2023-05-26 06:39:33,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vp1fuyns', purging
2023-05-26 06:39:33,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f1bpjdji', purging
2023-05-26 06:39:33,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0e0248x0', purging
2023-05-26 06:39:33,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:33,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:33,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:35,426 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,460 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,496 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,523 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,549 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,575 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:35,614 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:35,840 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:37,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_7uuq90', purging
2023-05-26 06:39:37,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gebty6ik', purging
2023-05-26 06:39:37,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n80awq16', purging
2023-05-26 06:39:37,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-na5vj30v', purging
2023-05-26 06:39:37,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3epmpqf3', purging
2023-05-26 06:39:37,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_awci13s', purging
2023-05-26 06:39:37,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-on6vohmd', purging
2023-05-26 06:39:37,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-borqgh5s', purging
2023-05-26 06:39:37,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:37,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:37,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:39,242 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,265 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,295 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,320 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,348 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,372 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,397 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:39,552 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:40,796 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-amr1g8dz', purging
2023-05-26 06:39:40,796 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vodbpif', purging
2023-05-26 06:39:40,796 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xfbiu0nq', purging
2023-05-26 06:39:40,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4nhtscp6', purging
2023-05-26 06:39:40,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_tc0473', purging
2023-05-26 06:39:40,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8u6uxye', purging
2023-05-26 06:39:40,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wi7sr724', purging
2023-05-26 06:39:40,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2gmk42a7', purging
2023-05-26 06:39:40,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:40,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:40,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:41,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:41,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:42,982 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,080 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,107 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,131 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,156 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,180 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:43,333 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:44,529 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-clt978pl', purging
2023-05-26 06:39:44,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i73ufaxy', purging
2023-05-26 06:39:44,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yajrke3g', purging
2023-05-26 06:39:44,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ixoewhon', purging
2023-05-26 06:39:44,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wd0zgyn9', purging
2023-05-26 06:39:44,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8_8sidw', purging
2023-05-26 06:39:44,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dfr8vm7n', purging
2023-05-26 06:39:44,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h61n20ma', purging
2023-05-26 06:39:44,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:44,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:44,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:46,748 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,774 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,831 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,858 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,886 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,911 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:46,936 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:47,086 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:48,158 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2j4zta23', purging
2023-05-26 06:39:48,158 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9ra439p', purging
2023-05-26 06:39:48,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8v0zi6b', purging
2023-05-26 06:39:48,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7aj09hk2', purging
2023-05-26 06:39:48,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8s113w9y', purging
2023-05-26 06:39:48,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92rpwjup', purging
2023-05-26 06:39:48,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c5q8tnmm', purging
2023-05-26 06:39:48,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zh8ju9vy', purging
2023-05-26 06:39:48,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:48,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:48,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:50,305 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:50,401 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:50,425 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:50,451 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:50,502 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:50,546 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:50,588 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:50,750 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:51,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r60cfigg', purging
2023-05-26 06:39:51,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ibndjhv', purging
2023-05-26 06:39:51,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jvnhhn17', purging
2023-05-26 06:39:51,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_ctvli2', purging
2023-05-26 06:39:51,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6lncknh', purging
2023-05-26 06:39:51,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m25bfyf2', purging
2023-05-26 06:39:51,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ji5xx4xd', purging
2023-05-26 06:39:51,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bx7k6edf', purging
2023-05-26 06:39:51,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:51,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:51,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:51,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:52,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:52,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:53,914 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:53,951 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:54,020 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:54,055 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:54,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:54,211 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:54,267 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:54,421 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:55,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0jfissb_', purging
2023-05-26 06:39:55,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6whaeoit', purging
2023-05-26 06:39:55,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dgh10i1', purging
2023-05-26 06:39:55,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1tae_w6', purging
2023-05-26 06:39:55,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-561rgxfg', purging
2023-05-26 06:39:55,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4otmoh0s', purging
2023-05-26 06:39:55,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mk38idlt', purging
2023-05-26 06:39:55,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68d596p1', purging
2023-05-26 06:39:55,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:55,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:55,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:57,616 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,701 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,810 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,812 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,824 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:57,837 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:39:58,081 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:39:59,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a41q7qub', purging
2023-05-26 06:39:59,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_n25d1w3', purging
2023-05-26 06:39:59,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vszsb9dw', purging
2023-05-26 06:39:59,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-19xplc77', purging
2023-05-26 06:39:59,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-337l2j5a', purging
2023-05-26 06:39:59,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4ic7plz', purging
2023-05-26 06:39:59,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pgs49b1q', purging
2023-05-26 06:39:59,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ata8iizs', purging
2023-05-26 06:39:59,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:39:59,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:39:59,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:01,266 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:01,284 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:01,336 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:01,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:01,389 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:01,426 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:01,479 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:01,744 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:02,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8oa8vgfg', purging
2023-05-26 06:40:02,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_oojk5i', purging
2023-05-26 06:40:02,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9oq639ni', purging
2023-05-26 06:40:02,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3p190xgm', purging
2023-05-26 06:40:02,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovu199wq', purging
2023-05-26 06:40:02,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3n2748v', purging
2023-05-26 06:40:02,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db4tql71', purging
2023-05-26 06:40:02,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7p97kt63', purging
2023-05-26 06:40:02,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:02,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:02,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:02,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:02,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:02,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:02,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:03,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:03,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:03,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:03,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:04,878 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:04,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:04,953 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:04,981 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:05,009 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:05,034 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:05,061 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:05,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:06,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yty15kb0', purging
2023-05-26 06:40:06,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eugkzjon', purging
2023-05-26 06:40:06,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lwwkbfpq', purging
2023-05-26 06:40:06,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-10pu15bg', purging
2023-05-26 06:40:06,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fl1grqvv', purging
2023-05-26 06:40:06,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zez5k2a4', purging
2023-05-26 06:40:06,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wsphwpa9', purging
2023-05-26 06:40:06,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_tfu23g2', purging
2023-05-26 06:40:06,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:06,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:06,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:08,608 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:08,671 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:08,710 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:08,795 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:08,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:08,808 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:08,975 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:10,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vp6ucx6n', purging
2023-05-26 06:40:10,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4lbzudye', purging
2023-05-26 06:40:10,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b47moots', purging
2023-05-26 06:40:10,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vkn98qyd', purging
2023-05-26 06:40:10,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y05tkxt0', purging
2023-05-26 06:40:10,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sv9r2jrk', purging
2023-05-26 06:40:10,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9buwyyyf', purging
2023-05-26 06:40:10,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_2v16da', purging
2023-05-26 06:40:10,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:10,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:10,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:12,025 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:12,049 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:12,076 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:12,104 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:12,133 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:12,179 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:12,439 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:13,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0kflhsae', purging
2023-05-26 06:40:13,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fegve_rr', purging
2023-05-26 06:40:13,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db0mdrmp', purging
2023-05-26 06:40:13,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yetfmqsp', purging
2023-05-26 06:40:13,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2aznq6sj', purging
2023-05-26 06:40:13,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1awoofbq', purging
2023-05-26 06:40:13,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c_5p81zy', purging
2023-05-26 06:40:13,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:13,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:13,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:15,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:15,516 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:15,544 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:15,566 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:15,611 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:15,633 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:15,842 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:16,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xycvmxay', purging
2023-05-26 06:40:16,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7gszu6u', purging
2023-05-26 06:40:16,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-swx4t1og', purging
2023-05-26 06:40:16,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pb63hhdu', purging
2023-05-26 06:40:16,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-350hrlcj', purging
2023-05-26 06:40:16,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xbu_k3x9', purging
2023-05-26 06:40:16,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gr2ub04h', purging
2023-05-26 06:40:16,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:16,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:17,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:17,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:18,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:18,942 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:18,967 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:18,993 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:19,026 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:19,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:19,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:20,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acypfohx', purging
2023-05-26 06:40:20,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2psj772e', purging
2023-05-26 06:40:20,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tv2icl5q', purging
2023-05-26 06:40:20,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4m_f1_9', purging
2023-05-26 06:40:20,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wyhmdd6a', purging
2023-05-26 06:40:20,367 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wlxf6a7d', purging
2023-05-26 06:40:20,367 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xja6yont', purging
2023-05-26 06:40:20,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:20,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:20,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:22,320 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:22,398 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:22,412 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:22,438 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:22,459 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:22,480 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:22,660 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:23,821 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2p5ur1_', purging
2023-05-26 06:40:23,821 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qx7ts3e9', purging
2023-05-26 06:40:23,821 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jjmjstd_', purging
2023-05-26 06:40:23,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17563dlx', purging
2023-05-26 06:40:23,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-806ji_c8', purging
2023-05-26 06:40:23,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jjz7enei', purging
2023-05-26 06:40:23,823 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6vy96cuu', purging
2023-05-26 06:40:23,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:23,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:23,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:23,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:23,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:23,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:23,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:24,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:24,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:25,814 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:25,867 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:25,900 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:25,925 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:25,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:25,975 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:26,134 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:27,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sgqrj6ye', purging
2023-05-26 06:40:27,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s414c9dy', purging
2023-05-26 06:40:27,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hfiug8q1', purging
2023-05-26 06:40:27,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fupxu5_o', purging
2023-05-26 06:40:27,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kw2ikrmp', purging
2023-05-26 06:40:27,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itchvmj2', purging
2023-05-26 06:40:27,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1dpr61q1', purging
2023-05-26 06:40:27,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:27,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:27,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:29,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,223 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,275 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,297 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,323 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,348 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:29,500 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:30,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-klhhil5c', purging
2023-05-26 06:40:30,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d61mnpw_', purging
2023-05-26 06:40:30,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzyfio3p', purging
2023-05-26 06:40:30,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kkzfp342', purging
2023-05-26 06:40:30,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fpnk2ey', purging
2023-05-26 06:40:30,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4poujokr', purging
2023-05-26 06:40:30,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rwcwea65', purging
2023-05-26 06:40:30,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:30,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:30,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:32,619 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:32,666 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:32,699 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:32,782 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:32,783 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 06:40:32,996 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:34,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tz8qodq4', purging
2023-05-26 06:40:34,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e636jenu', purging
2023-05-26 06:40:34,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxbksxpd', purging
2023-05-26 06:40:34,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u6ybtn2h', purging
2023-05-26 06:40:34,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5souyr5', purging
2023-05-26 06:40:34,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wicckx1', purging
2023-05-26 06:40:34,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nkxzujc9', purging
2023-05-26 06:40:34,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:34,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:34,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:34,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:34,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:34,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:34,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:35,667 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:35,806 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:35,807 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:35,818 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:36,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:37,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mg8jbbby', purging
2023-05-26 06:40:37,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7wll4im', purging
2023-05-26 06:40:37,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_h1voldg', purging
2023-05-26 06:40:37,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_tw7oi0a', purging
2023-05-26 06:40:37,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sago777p', purging
2023-05-26 06:40:37,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fqz7zb3', purging
2023-05-26 06:40:37,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:37,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:37,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:37,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:37,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:37,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:37,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:37,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:37,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:37,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:38,488 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:38,522 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:38,562 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:38,587 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:38,864 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:39,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sphph_6u', purging
2023-05-26 06:40:39,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-swxg_cja', purging
2023-05-26 06:40:39,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ayqbifg_', purging
2023-05-26 06:40:39,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2meg2xv8', purging
2023-05-26 06:40:39,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tgb6afje', purging
2023-05-26 06:40:39,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:39,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:39,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:39,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:39,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:39,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:40,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:40,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:40,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:40,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:41,424 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:41,474 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:41,499 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:41,524 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:41,700 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:42,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rm52fv4', purging
2023-05-26 06:40:42,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mg_tncb0', purging
2023-05-26 06:40:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9wfmw49', purging
2023-05-26 06:40:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ck1ecoan', purging
2023-05-26 06:40:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3pvdynax', purging
2023-05-26 06:40:42,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:42,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:42,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:42,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:42,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:42,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:42,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:42,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:43,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:43,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:44,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:44,415 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:44,439 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:44,460 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:44,638 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:45,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py4za6sj', purging
2023-05-26 06:40:45,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74tyfwc6', purging
2023-05-26 06:40:45,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dcfu2pun', purging
2023-05-26 06:40:45,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-syy4njm4', purging
2023-05-26 06:40:45,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qtqsk29y', purging
2023-05-26 06:40:45,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:45,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:45,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:45,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:45,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:45,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:45,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:45,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:46,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:46,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:47,352 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:47,407 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:47,435 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:47,457 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:47,623 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:48,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j855hjm5', purging
2023-05-26 06:40:48,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zaorrnvg', purging
2023-05-26 06:40:48,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_0x7ems', purging
2023-05-26 06:40:48,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4wzwhgp', purging
2023-05-26 06:40:48,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94z7y38b', purging
2023-05-26 06:40:48,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:48,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:48,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:48,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:48,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:48,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:48,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:48,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:49,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:49,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:50,248 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:50,298 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:50,323 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:50,345 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:50,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:51,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-if6gwamn', purging
2023-05-26 06:40:51,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlr1jnby', purging
2023-05-26 06:40:51,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-leule_2_', purging
2023-05-26 06:40:51,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-280q_cka', purging
2023-05-26 06:40:51,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufc6hedf', purging
2023-05-26 06:40:51,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:51,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:51,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:51,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:51,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:51,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:51,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:51,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:51,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:51,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:53,194 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:53,217 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:53,244 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:53,266 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:53,427 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:54,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ns1q8vja', purging
2023-05-26 06:40:54,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9zed08i', purging
2023-05-26 06:40:54,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yds1i8in', purging
2023-05-26 06:40:54,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e1shhe_k', purging
2023-05-26 06:40:54,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5a_jsl6', purging
2023-05-26 06:40:54,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:54,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:54,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:54,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:54,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:54,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:54,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:54,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:54,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:54,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:56,075 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:56,136 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:56,152 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:56,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:56,339 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:57,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9dysv_62', purging
2023-05-26 06:40:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ql4t6dp', purging
2023-05-26 06:40:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oodrjv4k', purging
2023-05-26 06:40:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64nrm9k9', purging
2023-05-26 06:40:57,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsaji845', purging
2023-05-26 06:40:57,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:57,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:57,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:57,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:57,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:57,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:57,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:57,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:40:57,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:40:57,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:40:59,002 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:59,056 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:59,080 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:59,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:40:59,271 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:00,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8keihr4', purging
2023-05-26 06:41:00,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8can927', purging
2023-05-26 06:41:00,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7b_yaber', purging
2023-05-26 06:41:00,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqchq5xz', purging
2023-05-26 06:41:00,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ww5m6hi', purging
2023-05-26 06:41:00,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:00,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:00,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:00,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:00,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:00,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:00,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:00,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:00,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:00,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:01,970 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:02,025 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:02,049 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:02,074 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:02,258 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:03,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8ueby_w', purging
2023-05-26 06:41:03,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cip40h35', purging
2023-05-26 06:41:03,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ai8ik6w', purging
2023-05-26 06:41:03,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvzkdvtt', purging
2023-05-26 06:41:03,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iydbmf1v', purging
2023-05-26 06:41:03,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:03,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:03,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:03,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:03,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:03,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:03,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:03,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:03,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:03,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:04,926 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:04,955 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:04,979 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:05,007 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:05,169 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:06,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c0yxctda', purging
2023-05-26 06:41:06,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zzgy9bhd', purging
2023-05-26 06:41:06,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u3svh6ht', purging
2023-05-26 06:41:06,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovk42vls', purging
2023-05-26 06:41:06,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9f9lh9b', purging
2023-05-26 06:41:06,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:06,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:06,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:06,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:06,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:06,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:06,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:06,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:06,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:06,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:07,829 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:07,881 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:07,907 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:07,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:08,110 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:09,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4m3qjcfh', purging
2023-05-26 06:41:09,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qqsk3skk', purging
2023-05-26 06:41:09,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w65g68wd', purging
2023-05-26 06:41:09,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-quf2398g', purging
2023-05-26 06:41:09,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2bj6t2u', purging
2023-05-26 06:41:09,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:09,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:09,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:09,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:09,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:09,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:09,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:09,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:09,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:09,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:10,755 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:10,800 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:10,830 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:10,852 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:11,018 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:12,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4sb1v2n1', purging
2023-05-26 06:41:12,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtqxhqe5', purging
2023-05-26 06:41:12,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwrymrue', purging
2023-05-26 06:41:12,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxlk4he3', purging
2023-05-26 06:41:12,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfzvs9yk', purging
2023-05-26 06:41:12,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:12,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:12,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:12,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:12,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:12,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:12,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:12,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:12,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:12,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:13,663 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:13,716 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:13,765 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:13,767 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:13,920 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:15,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fer47wu8', purging
2023-05-26 06:41:15,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-13j0c5wm', purging
2023-05-26 06:41:15,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_vagmu3', purging
2023-05-26 06:41:15,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gytsmnno', purging
2023-05-26 06:41:15,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r4lds32q', purging
2023-05-26 06:41:15,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:15,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:15,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:15,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:15,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:15,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:15,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:15,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:15,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:15,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:16,601 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:16,631 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:16,658 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:16,683 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:16,846 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:18,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fss61f4q', purging
2023-05-26 06:41:18,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jboxvkbi', purging
2023-05-26 06:41:18,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_uz4881', purging
2023-05-26 06:41:18,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8dmdn0o', purging
2023-05-26 06:41:18,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_cyuqcof', purging
2023-05-26 06:41:18,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:18,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:18,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:18,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:18,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:18,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:18,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:18,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:18,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:18,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:19,541 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:19,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:19,611 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:19,635 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:19,802 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:20,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y53qg0iw', purging
2023-05-26 06:41:20,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-upilzmki', purging
2023-05-26 06:41:20,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ha92k3p4', purging
2023-05-26 06:41:20,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apof3xjo', purging
2023-05-26 06:41:20,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbfruv0e', purging
2023-05-26 06:41:20,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:20,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:21,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:21,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:21,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:21,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:21,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:21,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:21,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:21,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:22,459 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:22,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:22,523 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:22,550 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:22,735 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:23,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5g2i9mfc', purging
2023-05-26 06:41:23,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ythc72e', purging
2023-05-26 06:41:23,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tc6py0jq', purging
2023-05-26 06:41:23,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmkg1qxl', purging
2023-05-26 06:41:23,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tg00qtnh', purging
2023-05-26 06:41:23,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:23,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:23,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:23,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:23,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:23,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:24,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:24,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:24,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:24,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:25,431 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:25,453 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:25,501 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:25,529 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:25,700 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:26,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kuv5v016', purging
2023-05-26 06:41:26,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yth79rx9', purging
2023-05-26 06:41:26,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yibthpn1', purging
2023-05-26 06:41:26,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jajctkre', purging
2023-05-26 06:41:26,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_hrsma9u', purging
2023-05-26 06:41:26,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:26,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:26,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:26,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:26,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:26,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:26,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:26,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:27,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:27,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:28,322 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:28,345 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:28,389 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:28,417 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:28,588 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:29,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:29,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vr4olsl1', purging
2023-05-26 06:41:29,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:29,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jdw3n4jc', purging
2023-05-26 06:41:29,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cl8o888h', purging
2023-05-26 06:41:29,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5pq95yl', purging
2023-05-26 06:41:29,773 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kgcqk6_j', purging
2023-05-26 06:41:29,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:29,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:29,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:29,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:29,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:29,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:30,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:30,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:31,287 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:31,324 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:31,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:31,382 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:31,537 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:32,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yx79s2f4', purging
2023-05-26 06:41:32,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ophbkjh1', purging
2023-05-26 06:41:32,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ra4s3lyv', purging
2023-05-26 06:41:32,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jcgo1tq3', purging
2023-05-26 06:41:32,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-27_0imbp', purging
2023-05-26 06:41:32,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:32,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:32,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:32,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:32,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:32,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:32,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:32,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:32,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:32,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:34,168 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:34,218 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:34,272 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:34,432 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:35,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-71oisyft', purging
2023-05-26 06:41:35,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un2g2dnn', purging
2023-05-26 06:41:35,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtj50wmq', purging
2023-05-26 06:41:35,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jjxabd5u', purging
2023-05-26 06:41:35,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k6byusu', purging
2023-05-26 06:41:35,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:35,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:35,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:35,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:35,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:35,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:35,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:35,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:36,789 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:36,834 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:36,864 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:37,035 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:38,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cr37eblv', purging
2023-05-26 06:41:38,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtwl6_si', purging
2023-05-26 06:41:38,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hhz_2hk', purging
2023-05-26 06:41:38,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrq2uhh3', purging
2023-05-26 06:41:38,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:38,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:38,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:38,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:38,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:38,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:38,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:38,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:39,405 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:39,433 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:39,455 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:39,615 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:40,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aj86k7iq', purging
2023-05-26 06:41:40,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tsq9258', purging
2023-05-26 06:41:40,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9njitpfi', purging
2023-05-26 06:41:40,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1gqj5b5e', purging
2023-05-26 06:41:40,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:40,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:40,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:40,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:40,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:40,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:41,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:41,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:42,090 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:42,117 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:42,141 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:42,291 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:43,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bx14obzw', purging
2023-05-26 06:41:43,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxi1_sb_', purging
2023-05-26 06:41:43,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3wu3d876', purging
2023-05-26 06:41:43,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75s7_9xn', purging
2023-05-26 06:41:43,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:43,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:43,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:43,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:43,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:43,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:43,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:43,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:44,716 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:44,756 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:44,777 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:44,951 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:46,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0g46sci4', purging
2023-05-26 06:41:46,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3dkx3ah4', purging
2023-05-26 06:41:46,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-esf487nd', purging
2023-05-26 06:41:46,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7budboci', purging
2023-05-26 06:41:46,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:46,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:46,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:46,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:46,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:46,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:46,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:46,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:47,397 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:47,437 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:47,460 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:47,629 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:48,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xigxw9vd', purging
2023-05-26 06:41:48,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wex94qse', purging
2023-05-26 06:41:48,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r8z71ttl', purging
2023-05-26 06:41:48,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frmxp1z5', purging
2023-05-26 06:41:48,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:48,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:48,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:48,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:48,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:48,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:49,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:49,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:49,996 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:50,030 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:50,063 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:50,253 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:51,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:51,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-imcgm7fo', purging
2023-05-26 06:41:51,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:51,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gy83pd_p', purging
2023-05-26 06:41:51,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ivb9cyit', purging
2023-05-26 06:41:51,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4i4lsrnj', purging
2023-05-26 06:41:51,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:51,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:51,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:51,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:51,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:51,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:52,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:52,734 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:52,757 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:52,910 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:54,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5433mnre', purging
2023-05-26 06:41:54,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4gop9tv', purging
2023-05-26 06:41:54,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-555xyle1', purging
2023-05-26 06:41:54,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3jrppb1d', purging
2023-05-26 06:41:54,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:54,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:54,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:54,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:54,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:54,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:54,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:54,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:55,403 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:55,449 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:55,474 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:55,648 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:56,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s8crtaxa', purging
2023-05-26 06:41:56,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-loqzvqvh', purging
2023-05-26 06:41:56,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cu92nkp7', purging
2023-05-26 06:41:56,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hghs529g', purging
2023-05-26 06:41:56,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:56,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:56,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:56,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:56,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:56,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:57,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:57,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:41:58,147 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:58,165 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:58,204 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:58,383 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:41:59,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5egw3g9', purging
2023-05-26 06:41:59,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-341s4z5x', purging
2023-05-26 06:41:59,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-schrv205', purging
2023-05-26 06:41:59,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvwqxmh_', purging
2023-05-26 06:41:59,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:59,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:59,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:59,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:59,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:59,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:41:59,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:41:59,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:00,879 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:00,903 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:00,940 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:01,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:02,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9nr6vgyc', purging
2023-05-26 06:42:02,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k9qykv1', purging
2023-05-26 06:42:02,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l366cit7', purging
2023-05-26 06:42:02,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-45zncvlr', purging
2023-05-26 06:42:02,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:02,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:02,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:02,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:02,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:02,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:02,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:02,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:03,486 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:03,521 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:03,543 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:03,704 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:04,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ogo0vd6', purging
2023-05-26 06:42:04,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_0j79q5', purging
2023-05-26 06:42:04,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3shji42', purging
2023-05-26 06:42:04,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1w8ur7bj', purging
2023-05-26 06:42:04,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:04,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:04,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:04,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:04,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:04,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:05,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:05,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:06,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:06,231 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:06,254 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:06,408 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:07,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c39nkge3', purging
2023-05-26 06:42:07,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y69itnyx', purging
2023-05-26 06:42:07,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vstpwgtp', purging
2023-05-26 06:42:07,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1gg13zsn', purging
2023-05-26 06:42:07,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:07,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:07,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:07,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:07,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:07,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:07,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:07,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:08,913 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:08,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:08,963 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:09,135 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:10,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1r2bcgpu', purging
2023-05-26 06:42:10,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8e71pd3f', purging
2023-05-26 06:42:10,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9j61c45', purging
2023-05-26 06:42:10,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t4mh0j6w', purging
2023-05-26 06:42:10,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:10,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:10,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:10,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:10,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:10,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:10,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:10,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:11,588 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:11,633 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:11,659 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:11,838 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:13,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5uttvsfq', purging
2023-05-26 06:42:13,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mg1aqif2', purging
2023-05-26 06:42:13,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8d2vc70', purging
2023-05-26 06:42:13,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i0d9hj7v', purging
2023-05-26 06:42:13,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:13,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:13,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:13,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:13,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:13,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:13,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:13,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:14,285 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:14,332 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:14,355 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:14,514 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:15,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nusd1mub', purging
2023-05-26 06:42:15,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k1vyl4v', purging
2023-05-26 06:42:15,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cm78obhx', purging
2023-05-26 06:42:15,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gcijcm11', purging
2023-05-26 06:42:15,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:15,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:15,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:15,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:15,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:15,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:15,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:15,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:17,027 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:17,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:17,076 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:17,241 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:18,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7arf90z', purging
2023-05-26 06:42:18,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flp52uuk', purging
2023-05-26 06:42:18,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kql_pzk3', purging
2023-05-26 06:42:18,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:18,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:18,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flqun_n7', purging
2023-05-26 06:42:18,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:18,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:18,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:18,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:18,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:18,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:19,753 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:19,755 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:19,787 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:19,951 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:21,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:21,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8pg1cub', purging
2023-05-26 06:42:21,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:21,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9fvwpntm', purging
2023-05-26 06:42:21,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-00xj6smg', purging
2023-05-26 06:42:21,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0z961ym5', purging
2023-05-26 06:42:21,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:21,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:21,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:21,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:21,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:21,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:22,496 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:22,517 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:22,548 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:22,709 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:23,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feeq5fhz', purging
2023-05-26 06:42:23,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6kfs1zv', purging
2023-05-26 06:42:23,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-keycgrvj', purging
2023-05-26 06:42:23,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iid1nedc', purging
2023-05-26 06:42:23,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:23,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:23,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:23,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:23,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:23,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:24,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:24,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:25,185 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:25,211 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:25,245 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:25,401 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:26,621 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ym1ntg6', purging
2023-05-26 06:42:26,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fo596xf', purging
2023-05-26 06:42:26,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-binowfxw', purging
2023-05-26 06:42:26,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ej84ggz', purging
2023-05-26 06:42:26,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:26,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:26,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:26,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:26,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:26,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:26,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:26,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:27,876 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:27,921 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:27,956 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:28,118 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:29,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mgj32rt', purging
2023-05-26 06:42:29,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s_h3dfct', purging
2023-05-26 06:42:29,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7u8u9vge', purging
2023-05-26 06:42:29,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqsjpnm7', purging
2023-05-26 06:42:29,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:29,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:29,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:29,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:29,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:29,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:29,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:29,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:30,605 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:30,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:30,659 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:30,842 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:32,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4gjzrl6r', purging
2023-05-26 06:42:32,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hl_xbtvz', purging
2023-05-26 06:42:32,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-150luwgq', purging
2023-05-26 06:42:32,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-so6ylmdo', purging
2023-05-26 06:42:32,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:32,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:32,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:32,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:32,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:32,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:32,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:32,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:33,286 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:33,330 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:33,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:33,546 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:34,693 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-batr8t3s', purging
2023-05-26 06:42:34,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6prju23', purging
2023-05-26 06:42:34,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vha7v4jo', purging
2023-05-26 06:42:34,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka75eo7b', purging
2023-05-26 06:42:34,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:34,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:34,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:34,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:34,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:34,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:34,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:34,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:35,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:35,995 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:36,031 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:36,201 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:37,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5_7y45j', purging
2023-05-26 06:42:37,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqnacnfi', purging
2023-05-26 06:42:37,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vbsglum_', purging
2023-05-26 06:42:37,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6n290qe', purging
2023-05-26 06:42:37,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:37,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:37,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:37,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:37,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:37,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:37,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:37,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:38,597 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:38,645 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:38,664 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:38,850 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:40,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wiyfl8g', purging
2023-05-26 06:42:40,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mulv1ti1', purging
2023-05-26 06:42:40,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atwwrx_4', purging
2023-05-26 06:42:40,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vdk2a1hc', purging
2023-05-26 06:42:40,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:40,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:40,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:40,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:40,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:40,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:40,242 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:40,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:41,304 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:41,351 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:41,385 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:41,548 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:42,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k36t626n', purging
2023-05-26 06:42:42,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5gs1naa', purging
2023-05-26 06:42:42,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ap7f5nnx', purging
2023-05-26 06:42:42,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-st41sc6z', purging
2023-05-26 06:42:42,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:42,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:42,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:42,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:42,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:42,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:42,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:42,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:43,965 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:44,009 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:44,032 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:44,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:45,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vsyt327b', purging
2023-05-26 06:42:45,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0yzwoa4', purging
2023-05-26 06:42:45,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30thzcxy', purging
2023-05-26 06:42:45,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8crsifes', purging
2023-05-26 06:42:45,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:45,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:45,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:45,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:45,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:45,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:45,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:45,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:46,652 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:46,688 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:46,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:46,869 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:48,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zrz6ckc4', purging
2023-05-26 06:42:48,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-voba7cir', purging
2023-05-26 06:42:48,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffodfi1m', purging
2023-05-26 06:42:48,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ry_uofyi', purging
2023-05-26 06:42:48,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:48,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:48,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:48,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:48,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:48,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:48,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:48,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:49,293 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:49,322 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:49,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:49,530 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:50,700 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2q1fa0p', purging
2023-05-26 06:42:50,700 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x2xch9aa', purging
2023-05-26 06:42:50,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tiwodcwv', purging
2023-05-26 06:42:50,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7dxkkkh', purging
2023-05-26 06:42:50,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:50,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:50,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:50,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:50,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:50,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:50,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:50,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:51,960 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:51,982 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:52,025 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:52,207 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:53,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yvzqchtt', purging
2023-05-26 06:42:53,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8cajro84', purging
2023-05-26 06:42:53,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-482t_wty', purging
2023-05-26 06:42:53,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2uk37wj', purging
2023-05-26 06:42:53,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:53,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:53,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:53,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:53,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:53,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:53,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:53,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:54,622 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:54,674 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:54,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:54,849 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:56,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7gkwn31', purging
2023-05-26 06:42:56,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k_inty4s', purging
2023-05-26 06:42:56,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vmxbqpve', purging
2023-05-26 06:42:56,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqdowk9v', purging
2023-05-26 06:42:56,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:56,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:56,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:56,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:56,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:56,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:56,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:56,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:57,303 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:57,350 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:57,376 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:57,538 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:58,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nml6znqr', purging
2023-05-26 06:42:58,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wjl2jy9', purging
2023-05-26 06:42:58,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5xe8elc', purging
2023-05-26 06:42:58,686 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fkbjn800', purging
2023-05-26 06:42:58,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:58,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:58,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:58,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:58,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:58,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:42:58,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:42:58,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:42:59,924 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:59,968 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:42:59,995 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:00,178 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:01,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7yas8_g3', purging
2023-05-26 06:43:01,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fj1yjy88', purging
2023-05-26 06:43:01,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jqf0l75e', purging
2023-05-26 06:43:01,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ouwlaih', purging
2023-05-26 06:43:01,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:01,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:01,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:01,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:01,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:01,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:01,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:01,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:02,625 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:02,652 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:02,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:02,836 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:04,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18d8q93r', purging
2023-05-26 06:43:04,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntrkxfw4', purging
2023-05-26 06:43:04,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5opb8r8', purging
2023-05-26 06:43:04,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hgqspq2v', purging
2023-05-26 06:43:04,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:04,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:04,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:04,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:04,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:04,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:04,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:04,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:05,273 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:05,324 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:05,346 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:05,528 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:06,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrjhql8e', purging
2023-05-26 06:43:06,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wp95o_sk', purging
2023-05-26 06:43:06,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oe55tak9', purging
2023-05-26 06:43:06,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o14789h1', purging
2023-05-26 06:43:06,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:06,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:06,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:06,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:06,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:06,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:06,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:06,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:07,962 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:07,996 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:08,021 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:08,175 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:09,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7f7d44g', purging
2023-05-26 06:43:09,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-absl28bg', purging
2023-05-26 06:43:09,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrem77n9', purging
2023-05-26 06:43:09,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtp4d5rt', purging
2023-05-26 06:43:09,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:09,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:09,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:09,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:09,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:09,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:09,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:09,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:10,640 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:10,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:10,705 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:10,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:12,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fx81s2on', purging
2023-05-26 06:43:12,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s44kl_tl', purging
2023-05-26 06:43:12,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8e5xi6kj', purging
2023-05-26 06:43:12,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xccyvmn_', purging
2023-05-26 06:43:12,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:12,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:12,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:12,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:12,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:12,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:12,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:12,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:13,273 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:13,324 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:13,342 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:13,508 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:14,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-awulhs51', purging
2023-05-26 06:43:14,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrmybg8m', purging
2023-05-26 06:43:14,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yuq810p3', purging
2023-05-26 06:43:14,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gehsvghz', purging
2023-05-26 06:43:14,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:14,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:14,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:14,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:14,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:14,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:14,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:14,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:15,936 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:15,983 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:16,007 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:16,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:17,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7qstd44', purging
2023-05-26 06:43:17,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-246298v_', purging
2023-05-26 06:43:17,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcqpchz6', purging
2023-05-26 06:43:17,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jebhjijc', purging
2023-05-26 06:43:17,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:17,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:17,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:17,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:17,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:17,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:17,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:17,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:18,623 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:18,655 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:18,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:18,856 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:19,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nc6uh9kx', purging
2023-05-26 06:43:20,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z3q4ihx1', purging
2023-05-26 06:43:20,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-twb0jl9_', purging
2023-05-26 06:43:20,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vl0pk_75', purging
2023-05-26 06:43:20,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:20,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:20,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:20,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:20,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:20,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:20,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:20,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:21,247 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:21,291 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:21,330 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:21,482 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:22,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frn5eo8b', purging
2023-05-26 06:43:22,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3z1vt00', purging
2023-05-26 06:43:22,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5fcq30j', purging
2023-05-26 06:43:22,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h0jmx4d1', purging
2023-05-26 06:43:22,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:22,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:22,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:22,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:22,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:22,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:22,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:22,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:23,924 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:23,975 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:23,984 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:24,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:25,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56py5zhj', purging
2023-05-26 06:43:25,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65vk3vgj', purging
2023-05-26 06:43:25,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_vt5nf_', purging
2023-05-26 06:43:25,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sm1t6cf0', purging
2023-05-26 06:43:25,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:25,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:25,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:25,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:25,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:25,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:25,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:25,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:26,625 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:26,669 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:26,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:26,874 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:28,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m38penhd', purging
2023-05-26 06:43:28,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mnwplsgk', purging
2023-05-26 06:43:28,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e25qe2fb', purging
2023-05-26 06:43:28,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37vmuec8', purging
2023-05-26 06:43:28,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:28,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:28,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:28,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:28,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:28,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:28,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:28,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:29,218 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:29,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:29,278 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:29,514 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:30,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rchmwvfv', purging
2023-05-26 06:43:30,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-em3hskg8', purging
2023-05-26 06:43:30,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8t1q_hdu', purging
2023-05-26 06:43:30,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmef4igf', purging
2023-05-26 06:43:30,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:30,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:30,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:30,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:30,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:30,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:30,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:30,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:31,798 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:31,852 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:31,868 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:32,107 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:33,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fexe7s6g', purging
2023-05-26 06:43:33,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_8regmw', purging
2023-05-26 06:43:33,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ysqige7d', purging
2023-05-26 06:43:33,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jt9esmy0', purging
2023-05-26 06:43:33,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:33,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:33,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:33,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:33,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:33,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:33,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:33,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:34,392 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:34,414 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:34,448 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:34,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:35,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yx3di5vx', purging
2023-05-26 06:43:35,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mt7hzxak', purging
2023-05-26 06:43:35,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htf56tgl', purging
2023-05-26 06:43:35,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0rz1v5k', purging
2023-05-26 06:43:35,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:35,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:35,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:35,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:35,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:35,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:36,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:36,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:37,051 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:37,084 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:37,102 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:37,270 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:38,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-al0dirf7', purging
2023-05-26 06:43:38,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_banwcol', purging
2023-05-26 06:43:38,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r6fitvpb', purging
2023-05-26 06:43:38,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uo227amo', purging
2023-05-26 06:43:38,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:38,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:38,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:38,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:38,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:38,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:38,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:38,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:39,771 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:39,792 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:39,811 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:39,973 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:41,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9odawydl', purging
2023-05-26 06:43:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15tshxas', purging
2023-05-26 06:43:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6mu9z9n', purging
2023-05-26 06:43:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qhdxhy1m', purging
2023-05-26 06:43:41,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:41,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:41,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:41,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:41,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:41,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:41,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:41,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:42,480 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:42,523 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:42,545 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:42,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:43,944 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8g_xlanj', purging
2023-05-26 06:43:43,944 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5k59kbz', purging
2023-05-26 06:43:43,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_zig9ioi', purging
2023-05-26 06:43:43,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tk5t2ark', purging
2023-05-26 06:43:43,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:43,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:43,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:43,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:43,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:43,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:44,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:44,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:45,242 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:45,275 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:45,306 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:45,468 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:46,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y1lqsjqo', purging
2023-05-26 06:43:46,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbp43em_', purging
2023-05-26 06:43:46,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tv7p1ffq', purging
2023-05-26 06:43:46,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1chd49r9', purging
2023-05-26 06:43:46,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:46,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:46,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:46,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:46,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:46,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:46,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:46,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:47,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:47,984 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:48,008 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:48,169 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:49,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90od5s9s', purging
2023-05-26 06:43:49,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4cbt55h_', purging
2023-05-26 06:43:49,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vomx5vmy', purging
2023-05-26 06:43:49,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_bqs6ss', purging
2023-05-26 06:43:49,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:49,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:49,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:49,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:49,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:49,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:49,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:49,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:50,626 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:50,679 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:50,690 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:50,843 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:52,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-boc9chj8', purging
2023-05-26 06:43:52,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3y2xgv5w', purging
2023-05-26 06:43:52,054 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dyhe0vco', purging
2023-05-26 06:43:52,054 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8aldmnf', purging
2023-05-26 06:43:52,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:52,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:52,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:52,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:52,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:52,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:52,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:52,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:53,442 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:53,469 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:53,497 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:53,670 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:54,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_i1c9m1g', purging
2023-05-26 06:43:54,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hgstp5tm', purging
2023-05-26 06:43:54,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7v6xy_ns', purging
2023-05-26 06:43:54,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jb_q7yoo', purging
2023-05-26 06:43:54,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:54,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:54,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:54,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:54,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:54,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:55,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:55,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:56,082 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:56,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:56,135 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:56,307 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:57,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zoa_ftvg', purging
2023-05-26 06:43:57,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mh3njpc3', purging
2023-05-26 06:43:57,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qb8t16jp', purging
2023-05-26 06:43:57,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rrf2d9ve', purging
2023-05-26 06:43:57,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:57,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:57,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:57,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:57,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:57,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:43:57,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:43:57,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:43:58,773 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:58,795 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:58,826 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:43:58,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:00,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6_dvyyp', purging
2023-05-26 06:44:00,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbhsd227', purging
2023-05-26 06:44:00,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3p6m1z2t', purging
2023-05-26 06:44:00,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_03p1k9', purging
2023-05-26 06:44:00,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:00,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:00,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:00,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:00,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:00,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:00,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:00,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:01,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:01,521 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 06:44:01,716 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:02,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8e0qkpg4', purging
2023-05-26 06:44:02,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wwlt5qt5', purging
2023-05-26 06:44:02,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xbq4_kac', purging
2023-05-26 06:44:02,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lsczpqfb', purging
2023-05-26 06:44:02,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:02,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:02,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:02,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:03,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:03,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:03,909 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:03,946 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:04,113 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:05,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74hqmzng', purging
2023-05-26 06:44:05,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7qy5rgi', purging
2023-05-26 06:44:05,291 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqloba5m', purging
2023-05-26 06:44:05,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:05,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:05,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:05,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:05,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:05,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:06,344 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:06,377 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:06,549 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:07,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tse3mjtq', purging
2023-05-26 06:44:07,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6638xaz', purging
2023-05-26 06:44:07,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dmltjcta', purging
2023-05-26 06:44:07,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:07,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:07,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:07,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:07,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:07,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:08,725 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:08,772 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:08,931 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:10,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sfhdlliv', purging
2023-05-26 06:44:10,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qlvdnvl0', purging
2023-05-26 06:44:10,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v24niwjb', purging
2023-05-26 06:44:10,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:10,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:10,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:10,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:10,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:10,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:11,179 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:11,226 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:11,391 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:12,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1bouvp_s', purging
2023-05-26 06:44:12,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kaxhwq4h', purging
2023-05-26 06:44:12,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b46nlhwn', purging
2023-05-26 06:44:12,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:12,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:12,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:12,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:12,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:12,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:13,620 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:13,653 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:13,815 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:15,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31gmw2k_', purging
2023-05-26 06:44:15,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qojgjpmt', purging
2023-05-26 06:44:15,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93y8gbvo', purging
2023-05-26 06:44:15,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:15,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:15,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:15,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:15,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:15,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:16,045 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:16,071 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:16,248 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:17,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s8kkgldh', purging
2023-05-26 06:44:17,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5uka8gxw', purging
2023-05-26 06:44:17,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gfcto6jr', purging
2023-05-26 06:44:17,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:17,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:17,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:17,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:17,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:17,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:18,412 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:18,449 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:18,614 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:19,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7pbl1rfq', purging
2023-05-26 06:44:19,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3teogja', purging
2023-05-26 06:44:19,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uwp5e2su', purging
2023-05-26 06:44:19,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:19,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:19,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:19,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:19,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:19,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:20,840 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:20,880 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:21,047 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:22,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhaxs9gc', purging
2023-05-26 06:44:22,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg_k7zuh', purging
2023-05-26 06:44:22,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8gtkdpg1', purging
2023-05-26 06:44:22,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:22,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:22,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:22,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:22,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:22,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:23,249 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 06:44:23,456 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:24,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6_frncc', purging
2023-05-26 06:44:24,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qetbx44t', purging
2023-05-26 06:44:24,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wrhytll2', purging
2023-05-26 06:44:24,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:24,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:24,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:24,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:25,474 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:25,652 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:26,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdcgamhk', purging
2023-05-26 06:44:26,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-juqy3qxn', purging
2023-05-26 06:44:26,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:26,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:27,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:27,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:27,635 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:27,789 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:28,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97oq5inl', purging
2023-05-26 06:44:28,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k2_rv8y4', purging
2023-05-26 06:44:28,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:28,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:29,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:29,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:29,807 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:29,984 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:31,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pa2ndu4p', purging
2023-05-26 06:44:31,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrpdo2b9', purging
2023-05-26 06:44:31,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:31,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:31,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:31,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:32,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:32,212 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:33,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8j2kndx', purging
2023-05-26 06:44:33,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1nflvnj', purging
2023-05-26 06:44:33,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:33,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:33,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:33,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:34,218 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:34,383 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:35,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvfts4og', purging
2023-05-26 06:44:35,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nhznbz73', purging
2023-05-26 06:44:35,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:35,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:35,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:35,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:36,376 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:36,546 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:37,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0am5oaqf', purging
2023-05-26 06:44:37,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-simzusak', purging
2023-05-26 06:44:37,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:37,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:37,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:37,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:38,553 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:38,715 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:39,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gqyjmm6x', purging
2023-05-26 06:44:39,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5mh7r8y', purging
2023-05-26 06:44:39,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:39,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:40,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:40,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:40,719 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:40,896 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:42,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dz6j6u6u', purging
2023-05-26 06:44:42,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wryzma8s', purging
2023-05-26 06:44:42,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:42,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:42,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:42,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:42,926 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:43,095 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:44,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6qot70gd', purging
2023-05-26 06:44:44,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6p_mdr_', purging
2023-05-26 06:44:44,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:44,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:44,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:44,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:45,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:45,271 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:46,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zco5ak4q', purging
2023-05-26 06:44:46,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e96oibbk', purging
2023-05-26 06:44:46,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:46,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:46,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:46,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:47,298 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:47,454 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:48,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2cdxdw4', purging
2023-05-26 06:44:48,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2qzmobi', purging
2023-05-26 06:44:48,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:48,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:48,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:48,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:49,466 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:49,631 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:50,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-787drh9l', purging
2023-05-26 06:44:50,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bgqu2h8f', purging
2023-05-26 06:44:50,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:50,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:50,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:50,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:51,636 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:51,805 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:52,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-79r9jdt_', purging
2023-05-26 06:44:52,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f57g5n22', purging
2023-05-26 06:44:52,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:52,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:53,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:53,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:53,771 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:53,934 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:55,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4n07ght', purging
2023-05-26 06:44:55,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-07_1gnpl', purging
2023-05-26 06:44:55,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:55,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:55,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:55,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:55,981 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:56,147 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:57,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6jfwitez', purging
2023-05-26 06:44:57,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-euqwk4vw', purging
2023-05-26 06:44:57,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:57,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:57,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:57,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:44:58,168 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:58,329 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:44:59,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0hz9gr7o', purging
2023-05-26 06:44:59,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xhngznw6', purging
2023-05-26 06:44:59,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:59,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:44:59,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:44:59,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:00,324 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:00,489 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:01,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0f8zenl', purging
2023-05-26 06:45:01,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl218qs8', purging
2023-05-26 06:45:01,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:01,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:01,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:01,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:02,479 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:02,654 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:03,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03wsxek2', purging
2023-05-26 06:45:03,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n20cf784', purging
2023-05-26 06:45:03,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:03,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:03,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:03,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:04,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:04,816 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:05,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u65tm425', purging
2023-05-26 06:45:05,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78r0uvvf', purging
2023-05-26 06:45:05,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:05,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:06,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:06,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:06,792 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:06,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:08,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5y0fatq', purging
2023-05-26 06:45:08,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bxp_drla', purging
2023-05-26 06:45:08,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:08,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:08,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:08,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:08,926 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:09,097 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:10,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uz67vion', purging
2023-05-26 06:45:10,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8gpfvy9u', purging
2023-05-26 06:45:10,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:10,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:10,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:10,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:11,071 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:11,243 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:12,432 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qc16vjay', purging
2023-05-26 06:45:12,432 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ltiallf', purging
2023-05-26 06:45:12,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:12,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:12,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:12,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:13,267 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:13,433 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:14,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2k_g9qg', purging
2023-05-26 06:45:14,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30krxno7', purging
2023-05-26 06:45:14,610 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:14,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:14,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:14,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:15,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:15,615 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:16,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xu_inifs', purging
2023-05-26 06:45:16,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ukop7ndy', purging
2023-05-26 06:45:16,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:16,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:16,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:16,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:17,600 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:17,770 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:18,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ows2v5j', purging
2023-05-26 06:45:18,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bv6pd3hq', purging
2023-05-26 06:45:18,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:18,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:19,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:19,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:19,794 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:19,946 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:21,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xmo4m1_r', purging
2023-05-26 06:45:21,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lr0xcg66', purging
2023-05-26 06:45:21,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:21,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:21,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:21,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:21,947 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:22,107 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:23,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-61lqvabu', purging
2023-05-26 06:45:23,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ri6o_05_', purging
2023-05-26 06:45:23,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:23,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:23,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:23,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:24,115 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:24,275 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:25,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nd13l3et', purging
2023-05-26 06:45:25,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2fdmw9k4', purging
2023-05-26 06:45:25,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:25,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:25,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:25,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:26,359 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:26,535 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:27,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4d68v3_', purging
2023-05-26 06:45:27,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ca81gy2d', purging
2023-05-26 06:45:27,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:27,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:27,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:27,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:28,515 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:28,683 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:29,844 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eggv1efz', purging
2023-05-26 06:45:29,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3jzd2nw_', purging
2023-05-26 06:45:29,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:29,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:30,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:30,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:30,652 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:30,832 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:32,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sb7l2huh', purging
2023-05-26 06:45:32,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5qqxlpq4', purging
2023-05-26 06:45:32,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:32,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:32,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:32,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:32,867 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:33,022 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:34,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uiw7xq7s', purging
2023-05-26 06:45:34,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vc2q7pgu', purging
2023-05-26 06:45:34,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:34,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:34,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:34,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:35,083 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:35,249 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:36,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d452ueor', purging
2023-05-26 06:45:36,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oe_axq7h', purging
2023-05-26 06:45:36,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:36,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 06:45:36,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:36,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 06:45:37,408 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:38,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jb1qw2sf', purging
2023-05-26 06:45:38,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgvfaas9', purging
2023-05-26 06:45:38,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:38,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:39,461 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:40,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qxey23a3', purging
2023-05-26 06:45:40,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:40,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:41,521 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:42,809 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25mkdvlc', purging
2023-05-26 06:45:42,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:42,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:43,569 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:44,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w70sogd1', purging
2023-05-26 06:45:44,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:44,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:45,626 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:46,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24veezzt', purging
2023-05-26 06:45:46,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:46,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:47,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:48,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yeenvzzz', purging
2023-05-26 06:45:48,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:48,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:49,757 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:51,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c60jeryf', purging
2023-05-26 06:45:51,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:51,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:51,813 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:53,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8i9q4dts', purging
2023-05-26 06:45:53,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:53,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:53,876 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:55,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-li6mg54m', purging
2023-05-26 06:45:55,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:55,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:55,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:57,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cai71t9b', purging
2023-05-26 06:45:57,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:57,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:45:58,008 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:45:59,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu5lhe7d', purging
2023-05-26 06:45:59,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:45:59,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:00,075 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:01,376 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mnrgfhtr', purging
2023-05-26 06:46:01,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:01,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:02,135 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:03,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18syrqc7', purging
2023-05-26 06:46:03,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:03,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:04,193 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:05,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rc4n8vo5', purging
2023-05-26 06:46:05,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:05,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:06,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:07,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_neokdr', purging
2023-05-26 06:46:07,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:07,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:08,325 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:09,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojscr9tv', purging
2023-05-26 06:46:09,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:09,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:10,390 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:11,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-io9aivl_', purging
2023-05-26 06:46:11,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:11,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:12,458 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:13,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wl2ou0hc', purging
2023-05-26 06:46:13,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:13,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:14,532 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:15,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0yvndc4', purging
2023-05-26 06:46:15,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:15,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:16,601 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:17,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-laq7rlxk', purging
2023-05-26 06:46:17,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:17,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:18,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:19,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wp8xa3yc', purging
2023-05-26 06:46:19,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:19,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:20,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:22,016 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mb7d5nlp', purging
2023-05-26 06:46:22,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:22,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:22,783 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:24,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lkwb_e9y', purging
2023-05-26 06:46:24,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:24,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:24,846 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:26,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulpkvv6r', purging
2023-05-26 06:46:26,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:26,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:26,907 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:28,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-abqj_9yu', purging
2023-05-26 06:46:28,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:28,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:28,982 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:30,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-herufesg', purging
2023-05-26 06:46:30,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:30,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:31,045 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:32,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18zxef5l', purging
2023-05-26 06:46:32,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:32,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:33,113 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:34,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avfzziiv', purging
2023-05-26 06:46:34,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:34,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:35,180 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:36,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-241n5b1h', purging
2023-05-26 06:46:36,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:36,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:37,238 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:38,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjnqzbc1', purging
2023-05-26 06:46:38,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:38,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:39,304 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:40,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fosukmjw', purging
2023-05-26 06:46:40,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:40,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:41,358 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:42,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ecovoak1', purging
2023-05-26 06:46:42,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:42,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:43,411 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:44,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65f_c_nh', purging
2023-05-26 06:46:44,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:44,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:45,477 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:46,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_kxcz1bn', purging
2023-05-26 06:46:46,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:46,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:47,531 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:48,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oq_vi05f', purging
2023-05-26 06:46:48,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:48,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:49,599 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:50,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htabyv_7', purging
2023-05-26 06:46:50,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:50,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:51,653 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:52,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m44e2n7q', purging
2023-05-26 06:46:52,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:52,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:53,719 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:55,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6gx3grf', purging
2023-05-26 06:46:55,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:55,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:55,778 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:57,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxpdyfkc', purging
2023-05-26 06:46:57,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:57,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:57,860 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:46:59,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h642dz47', purging
2023-05-26 06:46:59,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:46:59,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:46:59,948 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:01,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2ib7083', purging
2023-05-26 06:47:01,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:01,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:02,018 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:03,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-al8ehumn', purging
2023-05-26 06:47:03,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:03,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:04,094 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:05,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7sui7gh', purging
2023-05-26 06:47:05,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:05,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:06,182 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:07,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr3fuf1b', purging
2023-05-26 06:47:07,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:07,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:08,236 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:09,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmg7behe', purging
2023-05-26 06:47:09,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:09,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:10,305 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:11,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fjxiaym5', purging
2023-05-26 06:47:11,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:11,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:12,402 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:13,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vdha80_t', purging
2023-05-26 06:47:13,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:13,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:14,462 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:15,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70kl0l0p', purging
2023-05-26 06:47:15,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:15,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:16,539 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:17,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0i4tg02', purging
2023-05-26 06:47:17,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:17,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:18,601 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:19,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9a18ogxf', purging
2023-05-26 06:47:19,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:19,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:20,685 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:21,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zaxlb9am', purging
2023-05-26 06:47:21,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:21,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:22,754 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:24,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zevu2z1o', purging
2023-05-26 06:47:24,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:24,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:24,816 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:26,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvd_64ye', purging
2023-05-26 06:47:26,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:26,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:26,873 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:28,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e6ra3v5p', purging
2023-05-26 06:47:28,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:28,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:28,969 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:30,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0izmc03v', purging
2023-05-26 06:47:30,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:30,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:31,033 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:32,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-71w981xd', purging
2023-05-26 06:47:32,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:32,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:33,087 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:34,376 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ya6q62x_', purging
2023-05-26 06:47:34,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:34,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:35,151 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:36,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cfd2dqpm', purging
2023-05-26 06:47:36,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:36,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:37,216 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:38,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-269jnwfv', purging
2023-05-26 06:47:38,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:38,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:39,277 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:40,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yj76_7bd', purging
2023-05-26 06:47:40,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:40,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:41,364 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:42,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2najozw7', purging
2023-05-26 06:47:42,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:42,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:43,425 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:44,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec_tlav0', purging
2023-05-26 06:47:44,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:44,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:45,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:46,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-00bt3f5p', purging
2023-05-26 06:47:46,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:46,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:47,559 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:48,857 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9qkjo6if', purging
2023-05-26 06:47:48,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:48,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:49,624 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:50,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46_8zlab', purging
2023-05-26 06:47:50,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:50,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:51,683 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:52,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5a8zwuj', purging
2023-05-26 06:47:52,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:52,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:53,750 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:55,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9zdswl1u', purging
2023-05-26 06:47:55,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:55,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:55,804 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:57,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5vjdyizn', purging
2023-05-26 06:47:57,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:57,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:57,868 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:47:59,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sq956x1r', purging
2023-05-26 06:47:59,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:47:59,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:47:59,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:01,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_lvamjs', purging
2023-05-26 06:48:01,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:01,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:01,996 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:03,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cj09uzo8', purging
2023-05-26 06:48:03,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:03,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:04,058 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:05,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w4j9bul', purging
2023-05-26 06:48:05,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:05,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:06,125 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:07,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec89s4el', purging
2023-05-26 06:48:07,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:07,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:08,215 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:09,508 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fp21vlu0', purging
2023-05-26 06:48:09,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:09,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:10,267 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:11,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tw9ajt6c', purging
2023-05-26 06:48:11,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:11,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:12,330 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:13,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vu6lhidh', purging
2023-05-26 06:48:13,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:13,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:14,383 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:15,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6m3w77wa', purging
2023-05-26 06:48:15,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:15,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:16,442 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:17,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8rqgioi', purging
2023-05-26 06:48:17,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:17,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:18,505 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:19,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zht31ymy', purging
2023-05-26 06:48:19,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:19,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:20,578 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:21,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0pvvzzrj', purging
2023-05-26 06:48:21,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:21,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:22,632 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:23,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tfnmyx_', purging
2023-05-26 06:48:23,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:23,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:24,711 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:26,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1ktr1a_', purging
2023-05-26 06:48:26,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:26,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:26,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:28,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_cngao9_', purging
2023-05-26 06:48:28,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:28,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:28,841 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:30,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q1eay7uz', purging
2023-05-26 06:48:30,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:30,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:30,903 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:32,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-juc3myhf', purging
2023-05-26 06:48:32,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:32,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:32,978 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:34,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70tixyji', purging
2023-05-26 06:48:34,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:34,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:35,057 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:36,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qwdyxzx3', purging
2023-05-26 06:48:36,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:36,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:37,114 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:38,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjyzy1n3', purging
2023-05-26 06:48:38,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:38,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:39,186 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:40,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkja3a73', purging
2023-05-26 06:48:40,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:40,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:41,262 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:42,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwep5l_f', purging
2023-05-26 06:48:42,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:42,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:43,315 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:44,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s36zn4_5', purging
2023-05-26 06:48:44,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:44,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:45,389 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:46,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8taewpi', purging
2023-05-26 06:48:46,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:46,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:47,467 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:48,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1j00eysj', purging
2023-05-26 06:48:48,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:48,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:49,526 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:50,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-61bugwj0', purging
2023-05-26 06:48:50,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:50,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:51,587 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:52,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31_juy9g', purging
2023-05-26 06:48:52,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:52,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:53,661 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:54,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhhjcgyg', purging
2023-05-26 06:48:54,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:54,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:55,728 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:57,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5d7bt55a', purging
2023-05-26 06:48:57,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:57,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:57,793 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:48:59,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sxraz3rh', purging
2023-05-26 06:48:59,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:48:59,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:48:59,867 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:01,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j2f4nht', purging
2023-05-26 06:49:01,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:01,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:01,932 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:03,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dbk0kmyi', purging
2023-05-26 06:49:03,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:03,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:04,015 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:05,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jw21keh3', purging
2023-05-26 06:49:05,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:05,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:06,082 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:07,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uditlpo', purging
2023-05-26 06:49:07,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:07,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:08,133 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:09,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rylek2gj', purging
2023-05-26 06:49:09,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:09,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:10,198 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:11,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3q84awzn', purging
2023-05-26 06:49:11,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:11,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:12,278 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:13,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flc0utgm', purging
2023-05-26 06:49:13,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:13,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:14,343 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:15,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tluwl3vb', purging
2023-05-26 06:49:15,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:15,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:16,438 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:17,749 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2s8s9nu1', purging
2023-05-26 06:49:17,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:17,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:18,517 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:19,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v38a4gqh', purging
2023-05-26 06:49:19,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:19,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:20,599 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:21,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z83af3cv', purging
2023-05-26 06:49:21,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:21,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:22,660 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:23,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04jwzo4p', purging
2023-05-26 06:49:23,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:23,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:24,727 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:26,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xymunhsr', purging
2023-05-26 06:49:26,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:26,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:26,804 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:28,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-551t2qwr', purging
2023-05-26 06:49:28,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:28,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:28,859 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:30,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-at_cicw1', purging
2023-05-26 06:49:30,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:30,166 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:30,931 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:32,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sezcslfl', purging
2023-05-26 06:49:32,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:32,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:32,998 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:34,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cmmkm_5p', purging
2023-05-26 06:49:34,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:34,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:35,069 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:36,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wvtlabhb', purging
2023-05-26 06:49:36,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:36,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:37,133 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:38,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c7iilaxp', purging
2023-05-26 06:49:38,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:38,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:39,212 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:40,506 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5kxhsif_', purging
2023-05-26 06:49:40,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:40,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:41,268 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:42,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vtj2y8_0', purging
2023-05-26 06:49:42,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:42,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:43,335 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:44,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t1_qy7hy', purging
2023-05-26 06:49:44,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:44,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:45,405 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:46,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dxosuu6q', purging
2023-05-26 06:49:46,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:46,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:47,472 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:48,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eui7a5t4', purging
2023-05-26 06:49:48,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:48,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:49,552 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:50,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofllizkl', purging
2023-05-26 06:49:50,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:50,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:51,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:52,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3f6un397', purging
2023-05-26 06:49:52,915 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:52,915 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:53,690 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:54,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-heknvgkl', purging
2023-05-26 06:49:54,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:54,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:55,763 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:57,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f_l474zt', purging
2023-05-26 06:49:57,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:57,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:57,838 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:49:59,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_n6gvmpe', purging
2023-05-26 06:49:59,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:49:59,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:49:59,897 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:01,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-orr9sk3i', purging
2023-05-26 06:50:01,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:01,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:01,966 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:03,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j4llh6q1', purging
2023-05-26 06:50:03,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:03,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:04,047 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:05,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkh6d__3', purging
2023-05-26 06:50:05,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:05,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:06,101 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:07,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urjxbtwp', purging
2023-05-26 06:50:07,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:07,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:08,179 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:09,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-worfs4s0', purging
2023-05-26 06:50:09,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:09,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:10,235 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:11,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m3key5lm', purging
2023-05-26 06:50:11,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:11,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:12,295 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:13,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s5467pxp', purging
2023-05-26 06:50:13,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:13,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:14,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:15,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7vlpxj_a', purging
2023-05-26 06:50:15,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:15,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:16,443 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:17,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x39g01y4', purging
2023-05-26 06:50:17,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:17,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:18,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:19,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lzo25ved', purging
2023-05-26 06:50:19,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:19,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:20,564 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:21,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofpr0mb_', purging
2023-05-26 06:50:21,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:21,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:22,620 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:23,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6fa0e_h', purging
2023-05-26 06:50:23,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:23,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:24,696 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:26,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1za8p8ni', purging
2023-05-26 06:50:26,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:26,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:26,767 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:28,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mg554s73', purging
2023-05-26 06:50:28,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:28,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:28,827 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:30,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emk9ii6j', purging
2023-05-26 06:50:30,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:30,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:30,882 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:32,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9u264tk3', purging
2023-05-26 06:50:32,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:32,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:32,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:34,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-et5a18pg', purging
2023-05-26 06:50:34,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:34,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:35,011 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:36,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jpau4zb', purging
2023-05-26 06:50:36,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:36,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:37,075 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:38,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pu1fpzbw', purging
2023-05-26 06:50:38,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:38,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:39,151 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:40,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wctoz4ih', purging
2023-05-26 06:50:40,450 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:40,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:41,210 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:42,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkgwzk3o', purging
2023-05-26 06:50:42,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:42,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:43,281 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:44,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_vtdca7f', purging
2023-05-26 06:50:44,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:44,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:45,343 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:46,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9ab0vnf', purging
2023-05-26 06:50:46,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:46,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:47,406 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:48,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wwx6ezd4', purging
2023-05-26 06:50:48,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:48,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:49,470 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:50,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yz_7so5i', purging
2023-05-26 06:50:50,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:50,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:51,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:52,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iey_11e0', purging
2023-05-26 06:50:52,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:52,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:53,598 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:54,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9374_f7_', purging
2023-05-26 06:50:54,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:54,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:55,680 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:56,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqd68lo_', purging
2023-05-26 06:50:56,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:56,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:57,738 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:50:59,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-50eto1hd', purging
2023-05-26 06:50:59,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:50:59,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:50:59,834 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:01,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1hhzv2sw', purging
2023-05-26 06:51:01,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:01,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:01,906 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:03,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w806cxsx', purging
2023-05-26 06:51:03,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:03,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:03,966 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:05,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yc1k4jtk', purging
2023-05-26 06:51:05,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:05,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:06,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:07,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3kbihpw', purging
2023-05-26 06:51:07,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:07,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:08,113 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:09,411 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x04p9a76', purging
2023-05-26 06:51:09,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:09,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:10,179 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:11,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92xcg15s', purging
2023-05-26 06:51:11,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:11,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:12,263 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:13,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0dduazge', purging
2023-05-26 06:51:13,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:13,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:14,332 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:15,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ww28b4j', purging
2023-05-26 06:51:15,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:15,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:16,408 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:17,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3fuvrou', purging
2023-05-26 06:51:17,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:17,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:18,510 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:19,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a37tv1pd', purging
2023-05-26 06:51:19,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:19,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:20,578 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:21,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_eh5u349', purging
2023-05-26 06:51:21,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:21,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:22,658 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:23,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0bmjio4y', purging
2023-05-26 06:51:23,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:23,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:24,722 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:26,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ivdt98md', purging
2023-05-26 06:51:26,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:26,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:26,798 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:28,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lwnzy857', purging
2023-05-26 06:51:28,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:28,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:28,873 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:30,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vor6w87s', purging
2023-05-26 06:51:30,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:30,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:30,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:32,236 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ax7bps0a', purging
2023-05-26 06:51:32,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:32,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:33,003 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:34,303 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wd557ryr', purging
2023-05-26 06:51:34,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:34,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:35,078 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:36,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhsl94s6', purging
2023-05-26 06:51:36,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:36,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:37,141 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:38,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufh586eh', purging
2023-05-26 06:51:38,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:38,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:39,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:40,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ol_qij8n', purging
2023-05-26 06:51:40,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:40,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:41,276 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:42,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ztrmujlt', purging
2023-05-26 06:51:42,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:42,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:43,353 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:44,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cifkue3', purging
2023-05-26 06:51:44,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:44,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:45,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:46,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-718s41n7', purging
2023-05-26 06:51:46,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:46,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:47,484 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:48,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qqu88a8k', purging
2023-05-26 06:51:48,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:48,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:49,547 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:50,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6wg6_5o', purging
2023-05-26 06:51:50,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:50,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:51,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:52,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cdunmwxp', purging
2023-05-26 06:51:52,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:52,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:53,685 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:55,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zsvaiv6x', purging
2023-05-26 06:51:55,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:55,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:55,784 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:57,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvnpyvvm', purging
2023-05-26 06:51:57,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:57,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:57,899 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:51:59,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ng3b3_oj', purging
2023-05-26 06:51:59,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:51:59,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:51:59,987 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:01,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8tcytq8', purging
2023-05-26 06:52:01,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:01,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:02,075 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:03,377 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqtsd4gn', purging
2023-05-26 06:52:03,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:03,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:04,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:05,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dh0ey7wx', purging
2023-05-26 06:52:05,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:05,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:06,222 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:07,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x61wfpj1', purging
2023-05-26 06:52:07,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:07,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:08,313 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:09,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5rx0eu8', purging
2023-05-26 06:52:09,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:09,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:10,375 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:11,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_q0_f99c', purging
2023-05-26 06:52:11,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:11,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:12,458 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:13,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t_sx9g69', purging
2023-05-26 06:52:13,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:13,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:14,528 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:15,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5grcgpi1', purging
2023-05-26 06:52:15,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:15,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:16,600 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:17,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkhrbaof', purging
2023-05-26 06:52:17,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:17,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:18,673 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:19,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8c6uqtuq', purging
2023-05-26 06:52:19,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:19,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:20,736 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:22,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k314rqgu', purging
2023-05-26 06:52:22,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:22,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:22,809 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:24,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9t7urbj', purging
2023-05-26 06:52:24,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:24,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:24,889 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:26,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wpfsz24', purging
2023-05-26 06:52:26,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:26,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:26,957 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:28,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ed2oi0lz', purging
2023-05-26 06:52:28,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:28,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:29,023 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:30,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ls14u0h', purging
2023-05-26 06:52:30,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:30,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:31,091 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:32,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9a23ey79', purging
2023-05-26 06:52:32,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:32,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:33,156 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:34,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zh8mwuyw', purging
2023-05-26 06:52:34,471 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:34,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:35,272 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:36,584 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wg_b76m2', purging
2023-05-26 06:52:36,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:36,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:37,346 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:38,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9582o7k1', purging
2023-05-26 06:52:38,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:38,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:39,412 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:40,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3nvaaudt', purging
2023-05-26 06:52:40,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:40,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:41,498 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:42,796 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vx674yko', purging
2023-05-26 06:52:42,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:42,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:43,566 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:44,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9voqnod8', purging
2023-05-26 06:52:44,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:44,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:45,685 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:47,019 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5r8e65f', purging
2023-05-26 06:52:47,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:47,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:47,789 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:49,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w5t1o2ve', purging
2023-05-26 06:52:49,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:49,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:49,874 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:51,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9pe6c0l', purging
2023-05-26 06:52:51,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:51,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:51,971 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:53,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr2_q6km', purging
2023-05-26 06:52:53,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:53,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:54,046 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:55,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_v0y2u1t', purging
2023-05-26 06:52:55,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:55,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:56,116 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:57,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o4i7ezd4', purging
2023-05-26 06:52:57,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:57,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:52:58,299 - distributed.nanny - WARNING - Restarting worker
2023-05-26 06:52:59,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3d2z2xiw', purging
2023-05-26 06:52:59,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 06:52:59,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 06:53:00,386 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 906 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
