/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43705 instead
  warnings.warn(
[dgx13:92044:0:92044] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  92044) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f52d4216efd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0f4) [0x7f52d42170f4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2ba) [0x7f52d42172ba]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f53758a8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f52d4298827]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f52d42c135d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2093f) [0x7f52d41cf93f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23b18) [0x7f52d41d2b18]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f52d42207f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f52d41d1c2d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f52d429571a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f52d435406a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x564b177ec3f6]
13  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564b177f8469]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
16  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
17  /opt/conda/envs/gdf/bin/python(+0x14ca83) [0x564b17805a83]
18  /opt/conda/envs/gdf/bin/python(+0x25819c) [0x564b1791119c]
19  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x564b177ab3ff]
20  /opt/conda/envs/gdf/bin/python(+0x136723) [0x564b177ef723]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x564b177ed929]
22  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
24  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
26  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
28  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
30  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564b177f8469]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x564b177e9042]
33  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
34  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x564b178058cb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x564b1780604c]
36  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x564b178c980e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x564b177f06ac]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x564b177ec3f6]
39  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
40  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x564b178059ac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x564b177ec3f6]
42  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
44  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564b177f8469]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x564b177e84e6]
47  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x564b177f8712]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x564b177e8232]
49  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x564b177f8469]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x564b177e9042]
52  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x564b177e6fb4]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x564b177e6c88]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x564b177e6c39]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x564b178942cb]
56  /opt/conda/envs/gdf/bin/python(+0x2086ca) [0x564b178c16ca]
57  /opt/conda/envs/gdf/bin/python(+0x204a63) [0x564b178bda63]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x564b178b587a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x564b178b576c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x564b178b49a7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x564b17888107]
=================================
2024-01-06 07:01:19,776 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35359 -> ucx://127.0.0.1:36733
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f09dc584140, tag: 0xdc0b2b357b7c9b78, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:19,776 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36733
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f3f10011140, tag: 0xc84f881e50b2210e, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f3f10011140, tag: 0xc84f881e50b2210e, nbytes: 800000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[dgx13:92029:0:92029] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  92029) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f3f1031befd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0f4) [0x7f3f1031c0f4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2ba) [0x7f3f1031c2ba]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f3fa3a05420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f3f1039d827]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f3f103c635d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2093f) [0x7f3f102d493f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23b18) [0x7f3f102d7b18]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f3f103257f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f3f102d6c2d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f3f1039a71a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f3f1045906a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e4711b63f6]
13  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e4711c2469]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
16  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55e4712656d2]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f3f999df1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55e4711ba6ac]
19  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55e4711753ff]
20  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55e4711b9723]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55e4711b7929]
22  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
24  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
26  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
28  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
30  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e4711c2469]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55e4711b3042]
33  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
34  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55e4711cf8cb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55e4711d004c]
36  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55e47129380e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55e4711ba6ac]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e4711b63f6]
39  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
40  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55e4711cf9ac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55e4711b63f6]
42  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
44  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e4711c2469]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55e4711b24e6]
47  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55e4711c2712]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55e4711b2232]
49  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55e4711c2469]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55e4711b3042]
52  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55e4711b0fb4]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55e4711b0c88]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e4711b0c39]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e47125e2cb]
56  /opt/conda/envs/gdf/bin/python(+0x2086ca) [0x55e47128b6ca]
57  /opt/conda/envs/gdf/bin/python(+0x204a63) [0x55e471287a63]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55e47127f87a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55e47127f76c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55e47127e9a7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55e471252107]
=================================
[dgx13:92048:0:92048] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  92048) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb7a8042efd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0f4) [0x7fb7a80430f4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2ba) [0x7fb7a80432ba]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb8496cf420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fb7a80c4827]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fb7a80ed35d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2093f) [0x7fb7a1fe493f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23b18) [0x7fb7a1fe7b18]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb7a804c7f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fb7a1fe6c2d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fb7a80c171a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7fb7a818006a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5597813923f6]
13  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55978139e469]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
16  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x5597814416d2]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fb83f69f1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5597813966ac]
19  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x5597813513ff]
20  /opt/conda/envs/gdf/bin/python(+0x136723) [0x559781395723]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x559781393929]
22  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
24  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
26  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
28  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
30  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55978139e469]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55978138f042]
33  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
34  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x5597813ab8cb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5597813ac04c]
36  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55978146f80e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5597813966ac]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5597813923f6]
39  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
40  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x5597813ab9ac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5597813923f6]
42  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
44  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55978139e469]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55978138e4e6]
47  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55978139e712]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55978138e232]
49  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55978139e469]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55978138f042]
52  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55978138cfb4]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55978138cc88]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55978138cc39]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55978143a2cb]
56  /opt/conda/envs/gdf/bin/python(+0x2086ca) [0x5597814676ca]
57  /opt/conda/envs/gdf/bin/python(+0x204a63) [0x559781463a63]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55978145b87a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55978145b76c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55978145a9a7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55978142e107]
=================================
[dgx13:92033:0:92033] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  92033) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f88a074fefd]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0f4) [0x7f88a07500f4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2ba) [0x7f88a07502ba]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f8941de6420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f88a07d1827]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f88a07fa35d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2093f) [0x7f88a070893f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23b18) [0x7f88a070bb18]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f88a07597f9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f88a070ac2d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f88a07ce71a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3206a) [0x7f88a088d06a]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x560fffad93f6]
13  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560fffae5469]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
16  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x560fffb886d2]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f8933dc41e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x560fffadd6ac]
19  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x560fffa983ff]
20  /opt/conda/envs/gdf/bin/python(+0x136723) [0x560fffadc723]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x560fffada929]
22  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
24  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
26  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
28  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
30  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560fffae5469]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x560fffad6042]
33  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
34  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x560fffaf28cb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x560fffaf304c]
36  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x560fffbb680e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x560fffadd6ac]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x560fffad93f6]
39  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
40  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x560fffaf29ac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x560fffad93f6]
42  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
44  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560fffae5469]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x560fffad54e6]
47  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x560fffae5712]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x560fffad5232]
49  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x560fffae5469]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x560fffad6042]
52  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x560fffad3fb4]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x560fffad3c88]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x560fffad3c39]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x560fffb812cb]
56  /opt/conda/envs/gdf/bin/python(+0x2086ca) [0x560fffbae6ca]
57  /opt/conda/envs/gdf/bin/python(+0x204a63) [0x560fffbaaa63]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x560fffba287a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x560fffba276c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x560fffba19a7]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x560fffb75107]
=================================
2024-01-06 07:01:22,470 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f09dc584180, tag: 0x9a3e9b4f3035fc85, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f09dc584180, tag: 0x9a3e9b4f3035fc85, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,472 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35359 -> ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #012] ep: 0x7f09dc584100, tag: 0x1708c66bd57e255c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1780, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #012] ep: 0x7f09dc584100, tag: 0x1708c66bd57e255c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,473 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50605 -> ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f736477f100, tag: 0xaab36d4581fd0ffc, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,478 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
2024-01-06 07:01:22,478 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 467, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1016, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 328, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 60, in exchange_peer_info
    await asyncio.wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 469, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2024-01-06 07:01:22,479 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2024-01-06 07:01:22,654 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fb20c5d6200, tag: 0x59bae6991d5b4cb7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fb20c5d6200, tag: 0x59bae6991d5b4cb7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,655 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:53975 -> ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f01157dc100, tag: 0xea4292751dc70957, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,655 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f01157dc200, tag: 0x9298c3bd04ee674d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f01157dc200, tag: 0x9298c3bd04ee674d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,656 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51409 -> ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb20c5d6140, tag: 0xc460f346850e7163, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,656 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:51409 -> ucx://127.0.0.1:40559
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fb20c5d6100, tag: 0x75ff42f91bc40c29, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,661 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35359 -> ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f09dc5842c0, tag: 0xfe5abac86b7a2e86, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,662 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f09dc584140, tag: 0xe947d97e2ade0b69, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f09dc584140, tag: 0xe947d97e2ade0b69, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,660 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 467, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1016, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 328, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 60, in exchange_peer_info
    await asyncio.wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 469, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2024-01-06 07:01:22,926 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35359 -> ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f09dc584300, tag: 0xe009dbcd5a3c1ad8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,926 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f01157dc2c0, tag: 0x39040c4537a9cdf1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f01157dc2c0, tag: 0x39040c4537a9cdf1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,926 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f09dc584240, tag: 0xde50e5d9d4a2e8a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f09dc584240, tag: 0xde50e5d9d4a2e8a9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2024-01-06 07:01:22,926 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50605 -> ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f736477f1c0, tag: 0xb99f30b2dc4395b6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,927 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:50605 -> ucx://127.0.0.1:47935
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 334, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 662, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7f736477f140, tag: 0x42cb707d825f1478, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1779, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2024-01-06 07:01:22,928 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f736477f300, tag: 0x24d632d45d6113e1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f736477f300, tag: 0x24d632d45d6113e1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:22,934 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54373
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fb20c5d6340, tag: 0xe36599d2b5a035a2, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2857, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fb20c5d6340, tag: 0xe36599d2b5a035a2, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-06 07:01:24,255 - distributed.comm.ucx - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-06 07:01:24,255 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-06 07:01:24,295 - distributed.comm.ucx - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-06 07:01:24,295 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-06 07:01:24,586 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 4)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           140017  15585719
0            43643  65855837
0           136833  83425029
0           113675  64603471
0            69297  48597365
...            ...       ...
0        799554536  46241758
0        799580035  79756665
0        799569296  69482363
0        799405268  84560257
0        799471771  73391236

[12503392 rows x 2 columns],                key   payload
shuffle                     
1           619870  41252478
1            16336  22109198
1           719364  12267474
1            87035  64779835
1           704255  25221513
...            ...       ...
1        799628367  24821251
1        799756077  92468731
1        799701049  32975129
1        799589576  17338483
1        799770974  34909311

[12500389 rows x 2 columns],                key   payload
shuffle                     
2           671608  49641902
2           637777  37296695
2           667493  79221455
2           450789  75598108
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:24,589 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3)
Function:  _concat
args:      ([               key   payload
shuffle                     
0            99863  80778823
0            93418  60523498
0           181399  19776403
0            83479  47629473
0            16454  14985260
...            ...       ...
0        799470693  94152771
0        799455755   3235067
0        799572866  43661863
0        799418067  91765997
0        799594929  62272562

[12497076 rows x 2 columns],                key   payload
shuffle                     
1           624913  72256133
1            83744  66218983
1           699910  64936486
1           146294  44044612
1           666994  53627620
...            ...       ...
1        799756669  84682654
1        799815045   7135948
1        799756070  17867443
1        799641606  19592502
1        799656487  58958915

[12501362 rows x 2 columns],                key   payload
shuffle                     
2           608719  15499176
2           595823  50724596
2           573705   9944085
2           530811  19891148
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:24,615 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  _concat
args:      ([                key   payload
63204     857619529  79008636
63213     824641852  19251117
63216     815987982  27688444
63227     712119793  70167323
1216      311309858  91874461
...             ...       ...
99994893  309965319  61583959
99994895  855157169  38376060
99994908  841920534  18040100
99994950  837096249  60326530
99994953  606008492  60668055

[12500893 rows x 2 columns],                 key   payload
134244    968831401  23178602
134270    966491330  25148236
84072      19184279  18411916
84081     912148598  58740594
84087     945665256   4716837
...             ...       ...
99990835  723255898  14017064
99990843  314721602  19802680
99990848  959370570  91457194
99990858  516762724  15211546
99990879  935881336  29983340

[12495890 rows x 2 columns],                  key   payload
52965     1043197130  79668959
52966      225421251  65600915
52972     1002650600  74147345
52975     1027268499  91570422
52976     1010450471  68346032
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:24,725 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 3)
Function:  _concat
args:      ([                key   payload
63201     835635959  90872416
63203     833606945  45583668
63212     858929011  65510435
63219     828635137  16442532
1220      813230210  17621555
...             ...       ...
99994954  412048158  78321915
99994959  709567876  71788121
99994961  307904994  62998183
99994966  811703053  82360489
99994968  860594734  45064370

[12498632 rows x 2 columns],                 key   payload
134241    615260234   4790190
134243    941217846  10923273
134260    959543250  33987345
134262    959861669  36368790
134266    908879554  55584269
...             ...       ...
99990819   14756690  70443957
99990823  712834253  92684838
99990853  968781087  75232544
99990856  906481534  34670472
99990860  923304291  68197943

[12502237 rows x 2 columns],                  key   payload
52963     1033370665  33562756
52970     1013860911  30536424
52986     1014675117  71981102
20166     1049422656  11054413
23271      727111777  72373600
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:24,743 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 2)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           144521  92533606
0            60976  47736694
0            93856  86017062
0            99870   5848256
0           133639  22009106
...            ...       ...
0        799364287  72739909
0        799426220  97055578
0        799428660  31688436
0        799431185  27003435
0        799550876  80898050

[12497244 rows x 2 columns],                key   payload
shuffle                     
1           386975  60912734
1            77150  76016088
1            90450  85921784
1           132002  39238100
1            90456  74746777
...            ...       ...
1        799606827  38578968
1        799739196  16710557
1        799717428  83410433
1        799555669  37158062
1        799638761  36441758

[12500558 rows x 2 columns],                key   payload
shuffle                     
2           675790  25291038
2           620920  87573571
2           639962  18986138
2           754721  99135661
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:24,758 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0)
Function:  _concat
args:      ([                key   payload
63207     865046574  63580180
63210     705736368  10375964
63214     868349619  78925944
63215     611834714  98645437
1228      813677803   7380991
...             ...       ...
99994891  704480524  24324595
99994897  847827807  78094658
99994949  835484224  67346320
99994958  109106451  77371165
99994970  805899025  24430828

[12497168 rows x 2 columns],                 key   payload
134246    906491040  80576393
134252    921476875  94135316
134253    949565172  71587800
134269    948011858  48132184
84068     901847362  31110604
...             ...       ...
99990827  515986740  60425157
99990829  524946424  41681380
99990845  915478042  35944899
99990846  621180653   8901640
99990875  713845874  52298924

[12502889 rows x 2 columns],                  key   payload
52967     1008172183  44823803
52968     1030306634  29323067
52969      425745708  13811056
52982     1021736304  63643055
20168     1045846953  44665528
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2024-01-06 07:01:31,059 - distributed.nanny - WARNING - Restarting worker
2024-01-06 07:01:36,751 - distributed.nanny - WARNING - Restarting worker
2024-01-06 07:01:37,082 - distributed.nanny - WARNING - Restarting worker
2024-01-06 07:01:37,084 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
