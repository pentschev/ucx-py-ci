2023-02-17 00:53:35,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:35,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:35,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:36122:0:36122] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  36122) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f445ddca4f4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e6cf) [0x7f445ddca6cf]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e9f4) [0x7f445ddca9f4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f44e5975980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f44702a0494]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f44702d4238]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x20b1f) [0x7f447002fb1f]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x210f4) [0x7f44700300f4]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f4470032548]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f445ddd4bc9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f44700325eb]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f447029ca7a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272b9) [0x7f447055b2b9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x562ce1bc6343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x562ce1bd11fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x562ce1bb7b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562ce1bc193c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x562ce1bcec36]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x562ce1ccd65a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x562ce1b78b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x562ce1bb8f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x562ce1bcf1ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x562ce1bb7178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562ce1bc193c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x562ce1bb5efb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562ce1bc193c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x562ce1bcee8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x562ce1bb9a92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x562ce1c86049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x562ce1bd1283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x562ce1bb33de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x562ce1bcee8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x562ce1bd11fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x562ce1bb33de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562ce1bc193c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562ce1bb1a55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562ce1bc18a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x562ce1bb1729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562ce1bc193c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x562ce1bb253f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562ce1bb02f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x562ce1c62e99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x562ce1c62e5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x562ce1c837f9]
=================================
[dgx13:36130:0:36130] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  36130) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f1bb56034f4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e6cf) [0x7f1bb56036cf]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e9f4) [0x7f1bb56039f4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f1c2b110980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f1bb588c494]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f1bb58c0238]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x20b1f) [0x7f1bb53b7b1f]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x210f4) [0x7f1bb53b80f4]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f1bb53ba548]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f1bb560dbc9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f1bb53ba5eb]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f1bb5888a7a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272b9) [0x7f1bb5b472b9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55adfd630343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55adfd63b1fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55adfd621b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55adfd62b93c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x55adfd638c36]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x55adfd73765a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55adfd5e2b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55adfd622f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55adfd6391ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55adfd621178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55adfd62b93c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55adfd61fefb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55adfd62b93c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55adfd638e8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55adfd623a92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55adfd6f0049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55adfd63b283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55adfd61d3de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55adfd638e8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55adfd63b1fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55adfd61d3de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55adfd62b93c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55adfd61ba55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55adfd62b8a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55adfd61b729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55adfd62b93c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55adfd61c53f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55adfd61a2f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55adfd6cce99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55adfd6cce5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55adfd6ed7f9]
=================================
Task exception was never retrieved
future: <Task finished name='Task-951' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-947' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-959' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-02-17 00:53:44,251 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f015c00c180, tag: 0xf33af2179353b70c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f015c00c180, tag: 0xf33af2179353b70c, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-02-17 00:53:44,255 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42705 -> ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f015c00c240, tag: 0x1f0332fc3653f386, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1766, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-02-17 00:53:44,285 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f015c00c100, tag: 0xde4bd4c5e8fdde5e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f015c00c100, tag: 0xde4bd4c5e8fdde5e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-02-17 00:53:44,284 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ffa8c1c1100, tag: 0x5e70a001675390af, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ffa8c1c1100, tag: 0x5e70a001675390af, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-02-17 00:53:44,284 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f642573e100, tag: 0x85b628591af6ebb2, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f642573e100, tag: 0x85b628591af6ebb2, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-02-17 00:53:44,441 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40051 -> ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2e100e7240, tag: 0xb1047e1a7c7d6c34, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1766, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-02-17 00:53:44,443 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f2e100e7100, tag: 0x66da82093bd371ab, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f2e100e7100, tag: 0x66da82093bd371ab, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-02-17 00:53:44,525 - distributed.nanny - WARNING - Restarting worker
2023-02-17 00:53:44,589 - distributed.nanny - WARNING - Restarting worker
[dgx13:36126:0:36126] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  36126) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f9439cee4f4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e6cf) [0x7f9439cee6cf]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2e9f4) [0x7f9439cee9f4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f94af68a980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f9439f77494]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9439fab238]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x20b1f) [0x7f9439aa2b1f]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x210f4) [0x7f9439aa30f4]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f9439aa5548]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f9439cf8bc9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9439aa55eb]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9439f73a7a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272b9) [0x7f943a2322b9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x563e54b67343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x563e54b721fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x563e54b58b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e54b6293c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x563e54b6fc36]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x563e54c6e65a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x563e54b19b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x563e54b59f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x563e54b701ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x563e54b58178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e54b6293c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x563e54b56efb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e54b6293c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x563e54b6fe8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x563e54b5aa92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x563e54c27049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x563e54b72283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x563e54b543de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x563e54b6fe8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x563e54b721fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x563e54b543de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e54b6293c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e54b52a55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e54b628a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x563e54b52729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e54b6293c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x563e54b5353f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e54b512f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563e54c03e99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563e54c03e5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x563e54c247f9]
=================================
2023-02-17 00:53:45,086 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36825
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ffa8c1c1100, tag: 0x9b499a311f96f8f9, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2846, in _get_data
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ffa8c1c1100, tag: 0x9b499a311f96f8f9, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-02-17 00:53:45,086 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60031 -> ucx://127.0.0.1:36825
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f642573e3c0, tag: 0xf09bebe0117d78c8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1766, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 741, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-2587' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-02-17 00:53:45,172 - distributed.nanny - WARNING - Restarting worker
2023-02-17 00:53:46,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:46,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:46,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:46,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:53:46,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-02-17 00:53:46,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-02-17 00:54:14,025 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:38151 after 30 s
2023-02-17 00:54:14,027 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:38151 after 30 s
2023-02-17 00:54:14,029 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:38151 after 30 s
2023-02-17 00:54:14,112 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:50933
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:50933 after 30 s
2023-02-17 00:54:14,114 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38151
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:38151 after 30 s
2023-02-17 00:54:14,850 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36825
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:36825 after 30 s
2023-02-17 00:54:14,864 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36825
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 291, in connect
    comm = await asyncio.wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2052, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2866, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 410, in retry_operation
    return await retry(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2843, in _get_data
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1439, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1375, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 317, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:36825 after 30 s
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
