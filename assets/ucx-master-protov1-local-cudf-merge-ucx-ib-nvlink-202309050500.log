[1693898966.016437] [dgx13:80521:0]            sock.c:481  UCX  ERROR bind(fd=174 addr=0.0.0.0:40800) failed: Address already in use
[1693898981.245564] [dgx13:80622:0]    ib_mlx5dv_md.c:369  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:80622:0:80622]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80622) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f4350eb315d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f4350eb0d11]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28eac) [0x7f4350eb0eac]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x73e04) [0x7f4350f5be04]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f4350f3339f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f4350f703bd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6dd) [0x7f4350f7586d]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f4350f764ff]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x67d37) [0x7f4351023d37]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55873509844c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55873507d6fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55873508a519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55873507b128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55873508a519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55873507b128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55873507fe64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55873507fe64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55873507fe64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55873507fe64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55873507fe64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55873512d162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f43640bd1e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f43640bdaa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55873508277c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x558735034d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x5587350817f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55873507f929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55873508a519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55873507b128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x558735097ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55873509844c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55873515b10e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55873508277c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55873507d6fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x558735097dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55873507d6fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55873508a519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55873507a5c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55873508a7c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55873507a312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x558735079094]
=================================
2023-09-05 07:29:41,511 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #058] ep: 0x7f31b00672c0, tag: 0x45468741dc2cbbbb, nbytes: 100010368, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #058] ep: 0x7f31b00672c0, tag: 0x45468741dc2cbbbb, nbytes: 100010368, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:41,511 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #040] ep: 0x7f24b4b1c280, tag: 0xda6b0d68eb099b9a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #040] ep: 0x7f24b4b1c280, tag: 0xda6b0d68eb099b9a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-09-05 07:29:41,522 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:55438 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #039] ep: 0x7f29040102c0, tag: 0x5f6a805afca96c1d, nbytes: 99981040, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,522 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41481 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #037] ep: 0x7fa23403e140, tag: 0x7631fa293d90011c, nbytes: 99982368, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,524 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #044] ep: 0x7f2904010240, tag: 0x631c24ffeb326e3f, nbytes: 99998536, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #044] ep: 0x7f2904010240, tag: 0x631c24ffeb326e3f, nbytes: 99998536, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:41,527 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #038] ep: 0x7fa23403e300, tag: 0x209e6c0b771b4972, nbytes: 99980632, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #038] ep: 0x7fa23403e300, tag: 0x209e6c0b771b4972, nbytes: 99980632, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:41,531 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43854 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #044] ep: 0x7f73ece00300, tag: 0xc5cc5b52ad97a3c5, nbytes: 100009184, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,533 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #045] ep: 0x7f73ece00180, tag: 0x1b8ebc4f38d9c766, nbytes: 99992784, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #045] ep: 0x7f73ece00180, tag: 0x1b8ebc4f38d9c766, nbytes: 99992784, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:41,637 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60664 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #037] ep: 0x7f31b0067380, tag: 0x16e69ad8f241d06c, nbytes: 100028504, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,648 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49140 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #045] ep: 0x7f24b4b1c3c0, tag: 0x876ac5430026a948, nbytes: 99992320, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,696 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43008 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #046] ep: 0x7f9cdc604300, tag: 0x5cb639d149ef20f9, nbytes: 99977208, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,701 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #047] ep: 0x7f9cdc6041c0, tag: 0x93385c21f7d5a1c7, nbytes: 99961104, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #047] ep: 0x7f9cdc6041c0, tag: 0x93385c21f7d5a1c7, nbytes: 99961104, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:41,720 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52517 -> ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #031] ep: 0x7f165d150440, tag: 0x895f785b8b8ea563, nbytes: 100048904, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:41,723 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48087
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #040] ep: 0x7f165d1501c0, tag: 0xa1d3fb7f8cc6093c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #040] ep: 0x7f165d1501c0, tag: 0xa1d3fb7f8cc6093c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-09-05 07:29:41,984 - distributed.nanny - WARNING - Restarting worker
[1693898985.515166] [dgx13:80624:0]    ib_mlx5dv_md.c:369  UCX  ERROR mlx5_2: LRU push returned Unsupported operation
[dgx13:80624:0:80624]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80624) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa23ce0c15d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fa23ce09d11]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28eac) [0x7fa23ce09eac]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x73e04) [0x7fa23ceb4e04]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fa23ce8c39f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7fa23cec93bd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6dd) [0x7fa23cece86d]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7fa23cecf4ff]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x67d37) [0x7fa23cf7cd37]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55aa7664c44c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aa766316fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aa7663e519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55aa7662f128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aa7663e519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55aa7662f128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55aa76633e64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55aa76633e64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55aa76633e64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55aa76633e64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55aa76633e64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55aa766e1162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fa2d03921e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7fa2d0392aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55aa7663677c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55aa765e8d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55aa766357f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55aa76633929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aa7663e519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55aa7662f128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55aa7664bccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55aa7664c44c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55aa7670f10e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55aa7663677c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aa766316fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55aa7664bdac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aa766316fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aa7663e519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aa7662e5c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aa7663e7c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55aa7662e312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aa7662d094]
=================================
2023-09-05 07:29:45,754 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41481
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7facfd77e180, tag: 0x502636c1a2a80c1b, nbytes: 99974584, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7facfd77e180, tag: 0x502636c1a2a80c1b, nbytes: 99974584, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:45,756 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41481
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #095] ep: 0x7f73ece00240, tag: 0x3b5af42b36520c4a, nbytes: 800016096, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #095] ep: 0x7f73ece00240, tag: 0x3b5af42b36520c4a, nbytes: 800016096, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:45,757 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41481
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #104] ep: 0x7f165d150280, tag: 0x13ff00f6bbdb12f5, nbytes: 100059872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #104] ep: 0x7f165d150280, tag: 0x13ff00f6bbdb12f5, nbytes: 100059872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-09-05 07:29:45,757 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:41481
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #111] ep: 0x7f9cdc6042c0, tag: 0xc35da201002a6e63, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #111] ep: 0x7f9cdc6042c0, tag: 0xc35da201002a6e63, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-09-05 07:29:45,802 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52517 -> ucx://127.0.0.1:41481
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #102] ep: 0x7f165d1503c0, tag: 0x116ee978fe6da22d, nbytes: 100036056, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1781, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-09-05 07:29:46,007 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-05 07:29:46,028 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 4)
Function:  generate_chunk
args:      (4, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-05 07:29:46,232 - distributed.nanny - WARNING - Restarting worker
2023-09-05 07:29:46,374 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  _concat
args:      ([                key   payload
60084     501975792  66983565
60093     817898252  93904236
38918     843408950   7196814
38919     801068132  89083836
34022     103028486  43332511
...             ...       ...
99988473  310795567  92457345
99988475  867073689  34983022
99988368  817778857  46859298
99988369  111939700  75999276
99988370  834845922  79255630

[12497796 rows x 2 columns],                 key   payload
20034     901572094  42952957
20040     713873290  75516624
20049     928835625   8886069
20055     950848661  66977639
11394     323955332  66327578
...             ...       ...
99996498  909180365  74364604
99996501  936232827  62726748
99996619  931748559  55951464
99996620  906652948  60205884
99996627  962050010  80533290

[12497151 rows x 2 columns],                  key   payload
11492       32905415  22123917
63651     1043960794  59725810
31875      633355490  14630465
63653      626756338  77368479
11501       36867759  76980431
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-05 07:29:50,141 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 5)
Function:  _concat
args:      ([                key   payload
59569     804604266  74976482
59581     855605185  22859010
59582     820224806  26102099
57508     807588580  19818629
57513     858648496  91852634
...             ...       ...
99986372  815358158  41672848
99986374  827700469   9075731
99986394  835827428  62302380
99986395  806297912  45917116
99986397  803798935   3138754

[12498923 rows x 2 columns],                 key   payload
23106     903815984  41147372
2785      956621536  85693109
23125     316332356  24570506
2793      418269931  34134424
11425     967463177  26335481
...             ...       ...
99988936  221785508  91500808
99988959  953224853  18120333
99988982  933779610  95447319
99988984  935289288  31999902
99988989  964507114   1191047

[12501128 rows x 2 columns],                  key   payload
2272        27614233  50713061
2277      1004797903  89332315
39585     1040536170  12497167
2279      1010801639  10507816
39599      231568973  75699498
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-05 07:29:50,325 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  _concat
args:      ([                key   payload
59559     856711277   6621506
59571     826736721  85576457
59574     823610949  31652380
57504     708516700  14357037
18671     508674524  38798352
...             ...       ...
99986431  818129420  10929969
99986371  407072489  99882441
99986382  824695367  58450302
99986387  825862025  44935359
99986389  501338493  91090521

[12500893 rows x 2 columns],                 key   payload
23110     912688039  10193501
2790      517128635   2029181
23112     958623699  72223425
2802      948024289  92295360
23118     967232294  43121654
...             ...       ...
99988964  516051619  88502134
99988975  917655400  85346275
99988978  918457209  64192785
99988988  123062709  71130742
99988991  316305402  36913089

[12495890 rows x 2 columns],                  key   payload
2289      1032439591  89486937
2296        25783923  85228195
39614     1020906070  91881172
2303      1060970085  54631523
8390      1061386683  22115134
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-09-05 07:29:50,359 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-09-05 07:29:50,359 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2055, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2848, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
