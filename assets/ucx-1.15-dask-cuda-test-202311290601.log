============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-11-29 06:41:41,641 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:41:41,646 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37781 instead
  warnings.warn(
2023-11-29 06:41:41,650 - distributed.scheduler - INFO - State start
2023-11-29 06:41:42,591 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:41:42,592 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-29 06:41:42,593 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37781/status
2023-11-29 06:41:42,593 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:41:42,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46707'
2023-11-29 06:41:42,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40829'
2023-11-29 06:41:42,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36209'
2023-11-29 06:41:42,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41785'
2023-11-29 06:41:43,337 - distributed.scheduler - INFO - Receive client connection: Client-59d5a592-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:41:43,350 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57424
2023-11-29 06:41:44,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:44,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:44,574 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:44,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:44,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:44,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:44,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:44,682 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:44,685 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:44,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:44,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:44,704 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-11-29 06:41:44,811 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34395
2023-11-29 06:41:44,811 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34395
2023-11-29 06:41:44,811 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38613
2023-11-29 06:41:44,811 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-29 06:41:44,811 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:44,811 - distributed.worker - INFO -               Threads:                          4
2023-11-29 06:41:44,811 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-29 06:41:44,811 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ssea64dz
2023-11-29 06:41:44,811 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-60e74383-77e0-430f-a10c-b3d3ac863b94
2023-11-29 06:41:44,812 - distributed.worker - INFO - Starting Worker plugin PreImport-fbd50071-ca9d-4144-a5da-cbee757fe515
2023-11-29 06:41:44,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ca605e32-032b-4d10-b098-dfb7ee1bc8d0
2023-11-29 06:41:44,812 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:44,955 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34395', status: init, memory: 0, processing: 0>
2023-11-29 06:41:44,956 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34395
2023-11-29 06:41:44,956 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57436
2023-11-29 06:41:44,957 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:44,958 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-29 06:41:44,958 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:44,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-29 06:41:45,876 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36007
2023-11-29 06:41:45,877 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36007
2023-11-29 06:41:45,877 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33247
2023-11-29 06:41:45,877 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-29 06:41:45,877 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:45,877 - distributed.worker - INFO -               Threads:                          4
2023-11-29 06:41:45,877 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-29 06:41:45,877 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-x_s4olwd
2023-11-29 06:41:45,878 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1148e7aa-7372-49eb-ab65-9f12da4ef630
2023-11-29 06:41:45,878 - distributed.worker - INFO - Starting Worker plugin PreImport-a2394130-70f1-49ee-89d6-e3f6e5959058
2023-11-29 06:41:45,879 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aaaf07f5-c374-45c8-806d-6841e4e3ecff
2023-11-29 06:41:45,879 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:45,914 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36007', status: init, memory: 0, processing: 0>
2023-11-29 06:41:45,916 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36007
2023-11-29 06:41:45,916 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57444
2023-11-29 06:41:45,917 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:45,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-29 06:41:45,919 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:45,922 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-29 06:41:46,204 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32931
2023-11-29 06:41:46,204 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32931
2023-11-29 06:41:46,204 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39151
2023-11-29 06:41:46,204 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-29 06:41:46,204 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,204 - distributed.worker - INFO -               Threads:                          4
2023-11-29 06:41:46,205 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-29 06:41:46,205 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-dxh3a9db
2023-11-29 06:41:46,204 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32771
2023-11-29 06:41:46,205 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32771
2023-11-29 06:41:46,205 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35955
2023-11-29 06:41:46,205 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7578949b-6a53-4727-aae2-7e279a55a579
2023-11-29 06:41:46,205 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-29 06:41:46,205 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,205 - distributed.worker - INFO -               Threads:                          4
2023-11-29 06:41:46,205 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-29 06:41:46,205 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-s4313z2x
2023-11-29 06:41:46,205 - distributed.worker - INFO - Starting Worker plugin PreImport-aae434d8-cd68-464b-bcae-83074a0d915c
2023-11-29 06:41:46,206 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0d6cb675-d9a4-4021-9e41-ca2eafdf9b86
2023-11-29 06:41:46,206 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6844241f-b8d5-4686-9e3a-db249c2308a4
2023-11-29 06:41:46,206 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2be7d52d-810b-4631-bbc4-23f4fd0cdbd2
2023-11-29 06:41:46,206 - distributed.worker - INFO - Starting Worker plugin PreImport-7b2e19dd-b16b-4084-a5df-29aabbdaf5b8
2023-11-29 06:41:46,206 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,206 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,235 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32771', status: init, memory: 0, processing: 0>
2023-11-29 06:41:46,236 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32771
2023-11-29 06:41:46,236 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57456
2023-11-29 06:41:46,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:46,238 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-29 06:41:46,238 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,239 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32931', status: init, memory: 0, processing: 0>
2023-11-29 06:41:46,239 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32931
2023-11-29 06:41:46,240 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57464
2023-11-29 06:41:46,241 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:46,242 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-29 06:41:46,242 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:46,243 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-29 06:41:46,258 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-29 06:41:46,343 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-29 06:41:46,343 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-29 06:41:46,343 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-29 06:41:46,344 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-29 06:41:46,349 - distributed.scheduler - INFO - Remove client Client-59d5a592-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:41:46,349 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57424; closing.
2023-11-29 06:41:46,349 - distributed.scheduler - INFO - Remove client Client-59d5a592-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:41:46,349 - distributed.scheduler - INFO - Close client connection: Client-59d5a592-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:41:46,350 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46707'. Reason: nanny-close
2023-11-29 06:41:46,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:46,351 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40829'. Reason: nanny-close
2023-11-29 06:41:46,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:46,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36007. Reason: nanny-close
2023-11-29 06:41:46,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32771. Reason: nanny-close
2023-11-29 06:41:46,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-29 06:41:46,353 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57444; closing.
2023-11-29 06:41:46,354 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36007', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240106.354069')
2023-11-29 06:41:46,354 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:46,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-29 06:41:46,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36209'. Reason: nanny-close
2023-11-29 06:41:46,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57456; closing.
2023-11-29 06:41:46,355 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:46,355 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41785'. Reason: nanny-close
2023-11-29 06:41:46,356 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240106.3560917')
2023-11-29 06:41:46,356 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:46,356 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:46,356 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34395. Reason: nanny-close
2023-11-29 06:41:46,357 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32931. Reason: nanny-close
2023-11-29 06:41:46,356 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:57456>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:57456>: Stream is closed
2023-11-29 06:41:46,358 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-29 06:41:46,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57436; closing.
2023-11-29 06:41:46,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57464; closing.
2023-11-29 06:41:46,359 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-29 06:41:46,359 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34395', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240106.3596814')
2023-11-29 06:41:46,359 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:46,360 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32931', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240106.3600798')
2023-11-29 06:41:46,360 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:41:46,361 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:48,469 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:41:48,470 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:41:48,470 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:41:48,471 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-29 06:41:48,472 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-11-29 06:41:50,674 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:41:50,678 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45915 instead
  warnings.warn(
2023-11-29 06:41:50,683 - distributed.scheduler - INFO - State start
2023-11-29 06:41:50,789 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:41:50,790 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:41:50,790 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:41:50,791 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:41:51,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45997'
2023-11-29 06:41:51,794 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40537'
2023-11-29 06:41:51,816 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46365'
2023-11-29 06:41:51,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44807'
2023-11-29 06:41:51,831 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35775'
2023-11-29 06:41:51,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44651'
2023-11-29 06:41:51,852 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44365'
2023-11-29 06:41:51,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41027'
2023-11-29 06:41:53,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,847 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,863 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,867 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,869 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,872 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:53,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:41:53,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:41:53,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:41:54,893 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45997'. Reason: nanny-close
2023-11-29 06:41:54,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40537'. Reason: nanny-close
2023-11-29 06:41:54,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46365'. Reason: nanny-close
2023-11-29 06:41:54,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44807'. Reason: nanny-close
2023-11-29 06:41:54,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35775'. Reason: nanny-close
2023-11-29 06:41:54,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44651'. Reason: nanny-close
2023-11-29 06:41:54,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44365'. Reason: nanny-close
2023-11-29 06:41:54,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41027'. Reason: nanny-close
2023-11-29 06:41:59,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39907
2023-11-29 06:41:59,307 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39907
2023-11-29 06:41:59,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45057
2023-11-29 06:41:59,307 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,307 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,307 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,307 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h_65hxq5
2023-11-29 06:41:59,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a7901bb-8bef-4598-8386-4fee2310973f
2023-11-29 06:41:59,352 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43751
2023-11-29 06:41:59,353 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43751
2023-11-29 06:41:59,353 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36335
2023-11-29 06:41:59,353 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,353 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,353 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,354 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,354 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7xq3gqj6
2023-11-29 06:41:59,354 - distributed.worker - INFO - Starting Worker plugin RMMSetup-30afa4b9-0310-4125-8104-df7ef0c634eb
2023-11-29 06:41:59,357 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40681
2023-11-29 06:41:59,358 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40681
2023-11-29 06:41:59,357 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41935
2023-11-29 06:41:59,358 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39185
2023-11-29 06:41:59,358 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41935
2023-11-29 06:41:59,358 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,358 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,358 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37641
2023-11-29 06:41:59,358 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,358 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,358 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,358 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,358 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nf3feny5
2023-11-29 06:41:59,358 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,359 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,359 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-njp46f7a
2023-11-29 06:41:59,359 - distributed.worker - INFO - Starting Worker plugin PreImport-5ea20a77-09de-4a90-852f-b154c4b6833c
2023-11-29 06:41:59,359 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0cbd36af-aa53-45a6-b9ab-ca935c7d2b51
2023-11-29 06:41:59,359 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df205c4e-c1a3-4672-819f-5537598f61e3
2023-11-29 06:41:59,359 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d55ca9e3-da18-4072-b420-fc1fdab157d1
2023-11-29 06:41:59,366 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37277
2023-11-29 06:41:59,367 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37277
2023-11-29 06:41:59,367 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35275
2023-11-29 06:41:59,367 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,367 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,367 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,367 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,367 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r5ncmov_
2023-11-29 06:41:59,368 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dae70a87-c78a-476c-a36d-01e0a4e396de
2023-11-29 06:41:59,377 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43793
2023-11-29 06:41:59,377 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35751
2023-11-29 06:41:59,378 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35751
2023-11-29 06:41:59,378 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43793
2023-11-29 06:41:59,379 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38483
2023-11-29 06:41:59,379 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33147
2023-11-29 06:41:59,379 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,379 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,379 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,379 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,379 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,379 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,379 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,379 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,379 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-czktus3a
2023-11-29 06:41:59,379 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-er7nsdkn
2023-11-29 06:41:59,380 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5f3a350-2ba9-4024-952d-8af05e230123
2023-11-29 06:41:59,378 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40105
2023-11-29 06:41:59,380 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40105
2023-11-29 06:41:59,380 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2e37d124-dc0b-4911-9e2c-f75c05ae158e
2023-11-29 06:41:59,380 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42671
2023-11-29 06:41:59,380 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,380 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,380 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:41:59,380 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:41:59,380 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-50kdkku7
2023-11-29 06:41:59,381 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d27af2b2-c1dc-4ad1-8950-c6bbed3d0f67
2023-11-29 06:41:59,505 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73b1c13a-3d8d-4961-a370-438f0bf6126d
2023-11-29 06:41:59,505 - distributed.worker - INFO - Starting Worker plugin PreImport-6d471f4b-04cd-4895-a9ca-ef5c72934263
2023-11-29 06:41:59,506 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,511 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ea7f7749-5b89-46e2-bf03-18a028f6e355
2023-11-29 06:41:59,511 - distributed.worker - INFO - Starting Worker plugin PreImport-f3c612cd-3f6f-4fb8-a8ac-4e01f734a454
2023-11-29 06:41:59,511 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-adc6e216-2a8a-418e-8aa9-359cf473e782
2023-11-29 06:41:59,529 - distributed.worker - INFO - Starting Worker plugin PreImport-196d6df1-73a5-47a7-b7e7-59e2958deeed
2023-11-29 06:41:59,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-89d87d7c-458c-4041-9bf6-715242dc7447
2023-11-29 06:41:59,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-81b64846-4d1b-4520-bda7-d4b23045e0b9
2023-11-29 06:41:59,529 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,530 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,530 - distributed.worker - INFO - Starting Worker plugin PreImport-9f6a4b73-8906-4272-9341-71a0f9d4bbfb
2023-11-29 06:41:59,531 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,531 - distributed.worker - INFO - Starting Worker plugin PreImport-c4da8d28-e811-4f67-98c7-8dddcd8da057
2023-11-29 06:41:59,532 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,538 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef662fd5-1ee8-4382-87e8-e7d33ab94d44
2023-11-29 06:41:59,544 - distributed.worker - INFO - Starting Worker plugin PreImport-006330b6-6561-4f83-b7df-24809a5723ed
2023-11-29 06:41:59,544 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,563 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,564 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,566 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,567 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,567 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,567 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,568 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,568 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,570 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb6ade19-9b05-4187-9970-715440a064b6
2023-11-29 06:41:59,570 - distributed.worker - INFO - Starting Worker plugin PreImport-5ae882f4-ed1e-415c-814c-7f36822612f0
2023-11-29 06:41:59,570 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,570 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,572 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,588 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,589 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,592 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,592 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,598 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,600 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,600 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43751. Reason: nanny-close
2023-11-29 06:41:59,601 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35751. Reason: nanny-close
2023-11-29 06:41:59,601 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,601 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,602 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,602 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41935. Reason: nanny-close
2023-11-29 06:41:59,602 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43793. Reason: nanny-close
2023-11-29 06:41:59,602 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,602 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,604 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,604 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40105. Reason: nanny-close
2023-11-29 06:41:59,605 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,605 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,605 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,606 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,606 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,608 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,608 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,608 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,609 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,609 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,612 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:41:59,613 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:41:59,614 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:41:59,614 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:41:59,649 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,650 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,650 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37277. Reason: nanny-close
2023-11-29 06:41:59,651 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39907. Reason: nanny-close
2023-11-29 06:41:59,652 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:41:59,653 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40681. Reason: nanny-close
2023-11-29 06:41:59,653 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,654 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,656 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,656 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:41:59,657 - distributed.nanny - INFO - Worker closed
2023-11-29 06:41:59,658 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:55702 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-29 06:42:00,368 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63671 parent=63482 started daemon>
2023-11-29 06:42:00,369 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63668 parent=63482 started daemon>
2023-11-29 06:42:00,369 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63665 parent=63482 started daemon>
2023-11-29 06:42:00,369 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63662 parent=63482 started daemon>
2023-11-29 06:42:00,369 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63654 parent=63482 started daemon>
2023-11-29 06:42:00,370 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63650 parent=63482 started daemon>
2023-11-29 06:42:00,370 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63647 parent=63482 started daemon>
2023-11-29 06:42:00,589 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63671 exit status was already read will report exitcode 255
2023-11-29 06:42:00,700 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63665 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-11-29 06:42:03,007 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:03,011 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45367 instead
  warnings.warn(
2023-11-29 06:42:03,014 - distributed.scheduler - INFO - State start
2023-11-29 06:42:03,294 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:03,295 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:42:03,296 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:03,296 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:42:03,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34281'
2023-11-29 06:42:03,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43833'
2023-11-29 06:42:03,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38871'
2023-11-29 06:42:03,765 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38837'
2023-11-29 06:42:03,773 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33265'
2023-11-29 06:42:03,782 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42849'
2023-11-29 06:42:03,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46003'
2023-11-29 06:42:03,800 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36423'
2023-11-29 06:42:04,960 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34281'. Reason: nanny-close
2023-11-29 06:42:04,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43833'. Reason: nanny-close
2023-11-29 06:42:04,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38871'. Reason: nanny-close
2023-11-29 06:42:04,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38837'. Reason: nanny-close
2023-11-29 06:42:04,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33265'. Reason: nanny-close
2023-11-29 06:42:04,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42849'. Reason: nanny-close
2023-11-29 06:42:04,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46003'. Reason: nanny-close
2023-11-29 06:42:04,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36423'. Reason: nanny-close
2023-11-29 06:42:05,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,509 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,791 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,801 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,907 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,935 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:05,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:05,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,941 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:05,943 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:07,702 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43401
2023-11-29 06:42:07,703 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43401
2023-11-29 06:42:07,703 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40351
2023-11-29 06:42:07,703 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:07,703 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:07,703 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:07,703 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:07,703 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rhammn5m
2023-11-29 06:42:07,703 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b96ff660-fd91-4462-af15-71360fef6767
2023-11-29 06:42:07,757 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-45096763-c380-413d-90d9-e793c363560f
2023-11-29 06:42:07,757 - distributed.worker - INFO - Starting Worker plugin PreImport-8c2a9b80-bf7a-4e45-8c0c-c0b5a7d6a302
2023-11-29 06:42:07,757 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:08,872 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36427
2023-11-29 06:42:08,873 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36427
2023-11-29 06:42:08,874 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37751
2023-11-29 06:42:08,874 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:08,874 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:08,874 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:08,874 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:08,874 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-od2sj42z
2023-11-29 06:42:08,875 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-381ec766-34d3-4f07-9f8c-ef6a92b57e31
2023-11-29 06:42:08,875 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1d4437d6-49a3-429f-86d5-06571d2fbe23
2023-11-29 06:42:08,881 - distributed.worker - INFO - Starting Worker plugin PreImport-d6565fad-90c9-4bc9-a4a5-41856f269fcb
2023-11-29 06:42:08,881 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,032 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44243
2023-11-29 06:42:09,033 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44243
2023-11-29 06:42:09,033 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34335
2023-11-29 06:42:09,033 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,033 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,033 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,033 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,033 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lc18r6xm
2023-11-29 06:42:09,034 - distributed.worker - INFO - Starting Worker plugin PreImport-265e2aeb-3ae1-41a6-9ef9-9a7b23ce827e
2023-11-29 06:42:09,034 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20e8c9c9-ac6b-43a5-b78e-dbcc0fd6d0e7
2023-11-29 06:42:09,048 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34941
2023-11-29 06:42:09,049 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34941
2023-11-29 06:42:09,049 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36285
2023-11-29 06:42:09,049 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,049 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,049 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,049 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,049 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7c3hy16u
2023-11-29 06:42:09,048 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46335
2023-11-29 06:42:09,050 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46335
2023-11-29 06:42:09,049 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35719
2023-11-29 06:42:09,050 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38747
2023-11-29 06:42:09,050 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35719
2023-11-29 06:42:09,050 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,050 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34397
2023-11-29 06:42:09,050 - distributed.worker - INFO - Starting Worker plugin RMMSetup-39be477c-037d-4efb-8249-b22a486cb7c9
2023-11-29 06:42:09,050 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,050 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,050 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,050 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,050 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,050 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,050 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0j7zx5x9
2023-11-29 06:42:09,050 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,050 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sdvqwtad
2023-11-29 06:42:09,051 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e65e800-d8d1-43cb-a89c-be09e3da2263
2023-11-29 06:42:09,051 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b04b3d97-2fee-4d11-a929-445014a1d09c
2023-11-29 06:42:09,052 - distributed.worker - INFO - Starting Worker plugin RMMSetup-43215ab1-267c-42d6-a640-d1f0480d50cb
2023-11-29 06:42:09,054 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36261
2023-11-29 06:42:09,054 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36261
2023-11-29 06:42:09,054 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43043
2023-11-29 06:42:09,054 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,054 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,054 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,055 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,055 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wiudt9dn
2023-11-29 06:42:09,055 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1dcdd3c7-6df5-4ad9-acdb-108211c0b320
2023-11-29 06:42:09,055 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40767
2023-11-29 06:42:09,056 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40767
2023-11-29 06:42:09,056 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37671
2023-11-29 06:42:09,056 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,056 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,056 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:09,057 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:09,057 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s614mgst
2023-11-29 06:42:09,057 - distributed.worker - INFO - Starting Worker plugin PreImport-920caa7b-255b-4c46-90dd-e6e5a0c69efb
2023-11-29 06:42:09,057 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cdd2cc5d-c138-474d-8c22-220bdd6f6200
2023-11-29 06:42:09,058 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a736c4bb-62ae-49b4-b319-de3275c5fb49
2023-11-29 06:42:09,072 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0bebbe3f-1bdd-4d56-962f-87eaa4d27828
2023-11-29 06:42:09,073 - distributed.worker - INFO - Starting Worker plugin PreImport-0dd58b5b-52d5-4532-8ec9-2a5e3532f5b3
2023-11-29 06:42:09,073 - distributed.worker - INFO - Starting Worker plugin PreImport-14021958-e3ef-4f69-9b2d-7f5242bf17dd
2023-11-29 06:42:09,074 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,074 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,074 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-099459a9-a357-4e11-b0e7-eeaffbc51d6c
2023-11-29 06:42:09,075 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bda233df-2de5-4f5b-bb4d-f37480a7ccc5
2023-11-29 06:42:09,076 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,076 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83281b0e-91cd-48c9-b923-511b8f2bf2e4
2023-11-29 06:42:09,076 - distributed.worker - INFO - Starting Worker plugin PreImport-ecf2a6f9-4188-4988-bd6d-233ad5587f2e
2023-11-29 06:42:09,077 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,077 - distributed.worker - INFO - Starting Worker plugin PreImport-9d95d774-4acf-42c1-a2da-7b7560adf12d
2023-11-29 06:42:09,077 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,082 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,274 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,276 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,279 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,280 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,280 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,281 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,301 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,302 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,302 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36261. Reason: nanny-close
2023-11-29 06:42:09,303 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40767. Reason: nanny-close
2023-11-29 06:42:09,304 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,305 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,306 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,307 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,310 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,311 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,311 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,341 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,341 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,342 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,348 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,349 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,349 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,351 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44243. Reason: nanny-close
2023-11-29 06:42:09,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35719. Reason: nanny-close
2023-11-29 06:42:09,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,356 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,357 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,404 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36427. Reason: nanny-close
2023-11-29 06:42:09,407 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,409 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,529 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,531 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:09,531 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,532 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:09,532 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:09,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:09,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,555 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34941. Reason: nanny-close
2023-11-29 06:42:09,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,559 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:09,561 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46335. Reason: nanny-close
2023-11-29 06:42:09,561 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:09,563 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:09,565 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:42570 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-29 06:42:09,978 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63968 parent=63779 started daemon>
2023-11-29 06:42:09,978 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63963 parent=63779 started daemon>
2023-11-29 06:42:09,978 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63959 parent=63779 started daemon>
2023-11-29 06:42:09,978 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63955 parent=63779 started daemon>
2023-11-29 06:42:09,979 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63951 parent=63779 started daemon>
2023-11-29 06:42:09,979 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63947 parent=63779 started daemon>
2023-11-29 06:42:09,979 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=63944 parent=63779 started daemon>
2023-11-29 06:42:10,065 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63968 exit status was already read will report exitcode 255
2023-11-29 06:42:10,249 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63959 exit status was already read will report exitcode 255
2023-11-29 06:42:10,444 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 63955 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-11-29 06:42:12,669 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:12,673 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45487 instead
  warnings.warn(
2023-11-29 06:42:12,677 - distributed.scheduler - INFO - State start
2023-11-29 06:42:12,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-rhammn5m', purging
2023-11-29 06:42:12,908 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:12,909 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:42:12,910 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:12,911 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:42:13,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45575'
2023-11-29 06:42:13,380 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45359'
2023-11-29 06:42:13,393 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40209'
2023-11-29 06:42:13,407 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40999'
2023-11-29 06:42:13,409 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44217'
2023-11-29 06:42:13,417 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37247'
2023-11-29 06:42:13,425 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43183'
2023-11-29 06:42:13,435 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44297'
2023-11-29 06:42:14,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45575'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45359'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40209'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40999'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44217'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37247'. Reason: nanny-close
2023-11-29 06:42:14,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43183'. Reason: nanny-close
2023-11-29 06:42:14,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44297'. Reason: nanny-close
2023-11-29 06:42:15,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,291 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,291 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,299 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,301 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,352 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,380 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:15,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:15,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:15,487 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:18,460 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43049
2023-11-29 06:42:18,460 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43049
2023-11-29 06:42:18,461 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35735
2023-11-29 06:42:18,461 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,461 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,461 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,461 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,461 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_8l1pdma
2023-11-29 06:42:18,461 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58750420-e16c-4fcb-a1b2-1c9bb9ab9d82
2023-11-29 06:42:18,477 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41895
2023-11-29 06:42:18,477 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41895
2023-11-29 06:42:18,478 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39187
2023-11-29 06:42:18,478 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,478 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,478 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,478 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,478 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l0nljtqm
2023-11-29 06:42:18,478 - distributed.worker - INFO - Starting Worker plugin RMMSetup-06d5ec4f-c703-4c67-b7c5-4eb10f6a3627
2023-11-29 06:42:18,483 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35031
2023-11-29 06:42:18,483 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36179
2023-11-29 06:42:18,484 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35031
2023-11-29 06:42:18,484 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38419
2023-11-29 06:42:18,484 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36179
2023-11-29 06:42:18,485 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,485 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,485 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37503
2023-11-29 06:42:18,485 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,485 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,485 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,485 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,485 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lpaim80l
2023-11-29 06:42:18,485 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,485 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,485 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bt97dh3u
2023-11-29 06:42:18,485 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bffbc387-9389-4b57-8402-e42e4df232c2
2023-11-29 06:42:18,486 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-083cff19-7fc9-46e3-8fb3-db94084e1f59
2023-11-29 06:42:18,487 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae174019-ee0c-4c28-9e65-a2cf2a0c3bc7
2023-11-29 06:42:18,487 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42781
2023-11-29 06:42:18,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42781
2023-11-29 06:42:18,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38479
2023-11-29 06:42:18,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,489 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,489 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,489 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34339
2023-11-29 06:42:18,489 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ydv8558e
2023-11-29 06:42:18,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34339
2023-11-29 06:42:18,490 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38271
2023-11-29 06:42:18,490 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,490 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,490 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v99yxbia
2023-11-29 06:42:18,490 - distributed.worker - INFO - Starting Worker plugin PreImport-5f3e70c7-0393-48e5-be3f-80f208f4a6a7
2023-11-29 06:42:18,490 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7032f671-3303-45d2-b20a-7fad130a4f30
2023-11-29 06:42:18,491 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7da03ed3-9fe5-4c08-9d3d-d22563026ca6
2023-11-29 06:42:18,492 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3aa0484d-040c-4144-859a-1967d902337e
2023-11-29 06:42:18,504 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42631
2023-11-29 06:42:18,506 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42631
2023-11-29 06:42:18,506 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40499
2023-11-29 06:42:18,506 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,506 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,506 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,505 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35759
2023-11-29 06:42:18,507 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,507 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-35l5h2z_
2023-11-29 06:42:18,507 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35759
2023-11-29 06:42:18,507 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46375
2023-11-29 06:42:18,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,507 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,507 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:18,508 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:18,508 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-86cb37d3-9103-4ca4-ac57-d0664dcc3ec2
2023-11-29 06:42:18,508 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2_ifjh7y
2023-11-29 06:42:18,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-959cc9b0-6a2b-490e-ad5c-fd048386606b
2023-11-29 06:42:18,510 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b4327145-782c-4174-8b64-1135928746bd
2023-11-29 06:42:18,691 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a9921cfe-dc70-4343-be52-08e46f167cfb
2023-11-29 06:42:18,692 - distributed.worker - INFO - Starting Worker plugin PreImport-6028324e-9605-428f-a7ae-2acd0ef369c3
2023-11-29 06:42:18,692 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,706 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc90944b-c27e-425a-8ba7-8a610a49955f
2023-11-29 06:42:18,707 - distributed.worker - INFO - Starting Worker plugin PreImport-bceac35b-fff0-4fa5-8004-617f3ac7a7bd
2023-11-29 06:42:18,708 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,725 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae16f0b3-fe49-45c7-9fe2-02b3cf84fd1c
2023-11-29 06:42:18,725 - distributed.worker - INFO - Starting Worker plugin PreImport-c30a7e5c-d080-41b4-9fc1-4301fc4297db
2023-11-29 06:42:18,725 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b71fe1fd-fd51-4f54-8ea0-770dc4c10690
2023-11-29 06:42:18,725 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,725 - distributed.worker - INFO - Starting Worker plugin PreImport-d4525bba-b3ec-40f4-bf8d-67818d9b733e
2023-11-29 06:42:18,726 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,727 - distributed.worker - INFO - Starting Worker plugin PreImport-99bc0729-8522-4090-ac91-7a9a4e950232
2023-11-29 06:42:18,727 - distributed.worker - INFO - Starting Worker plugin PreImport-ec18f43e-2550-42b9-835d-bcb41233f54c
2023-11-29 06:42:18,727 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,728 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,734 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,734 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cad47168-a014-4146-a93d-ce11d37d5699
2023-11-29 06:42:18,735 - distributed.worker - INFO - Starting Worker plugin PreImport-ef296eb7-d154-43ed-b93e-8e5fdcc4c8ac
2023-11-29 06:42:18,735 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,851 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,852 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,852 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,854 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,855 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,856 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,856 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,858 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,870 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,871 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,871 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,871 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,872 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,872 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,874 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,893 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,893 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,893 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,893 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,894 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,894 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42631. Reason: nanny-close
2023-11-29 06:42:18,894 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,895 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,895 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,895 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34339. Reason: nanny-close
2023-11-29 06:42:18,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,895 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43049. Reason: nanny-close
2023-11-29 06:42:18,896 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42781. Reason: nanny-close
2023-11-29 06:42:18,896 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,896 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,897 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,897 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,898 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,898 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,898 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,899 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,899 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,900 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,900 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,904 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,905 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35759. Reason: nanny-close
2023-11-29 06:42:18,907 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,909 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,938 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,939 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,939 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,940 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:18,943 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,944 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:18,944 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41895. Reason: nanny-close
2023-11-29 06:42:18,945 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35031. Reason: nanny-close
2023-11-29 06:42:18,946 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,947 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:18,948 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,949 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:18,962 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:18,963 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:18,963 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:18,965 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:19,000 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:19,001 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36179. Reason: nanny-close
2023-11-29 06:42:19,003 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:19,005 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:43638 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-29 06:42:19,744 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64259 parent=64070 started daemon>
2023-11-29 06:42:19,744 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64256 parent=64070 started daemon>
2023-11-29 06:42:19,744 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64251 parent=64070 started daemon>
2023-11-29 06:42:19,744 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64246 parent=64070 started daemon>
2023-11-29 06:42:19,745 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64242 parent=64070 started daemon>
2023-11-29 06:42:19,745 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64238 parent=64070 started daemon>
2023-11-29 06:42:19,745 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64235 parent=64070 started daemon>
2023-11-29 06:42:20,120 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64251 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-11-29 06:42:22,358 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:22,362 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35053 instead
  warnings.warn(
2023-11-29 06:42:22,366 - distributed.scheduler - INFO - State start
2023-11-29 06:42:22,879 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:22,880 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:42:22,881 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:22,882 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:42:23,133 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36395'
2023-11-29 06:42:23,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39351'
2023-11-29 06:42:23,163 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44473'
2023-11-29 06:42:23,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38893'
2023-11-29 06:42:23,173 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36147'
2023-11-29 06:42:23,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46745'
2023-11-29 06:42:23,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35271'
2023-11-29 06:42:23,200 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45185'
2023-11-29 06:42:24,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36395'. Reason: nanny-close
2023-11-29 06:42:24,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39351'. Reason: nanny-close
2023-11-29 06:42:24,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44473'. Reason: nanny-close
2023-11-29 06:42:24,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38893'. Reason: nanny-close
2023-11-29 06:42:24,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36147'. Reason: nanny-close
2023-11-29 06:42:24,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46745'. Reason: nanny-close
2023-11-29 06:42:24,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35271'. Reason: nanny-close
2023-11-29 06:42:24,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45185'. Reason: nanny-close
2023-11-29 06:42:25,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,034 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,147 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,157 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:25,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:25,163 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,163 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:25,165 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:28,117 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46617
2023-11-29 06:42:28,118 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46617
2023-11-29 06:42:28,118 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37181
2023-11-29 06:42:28,118 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,118 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,118 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,119 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,119 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-20l_qv76
2023-11-29 06:42:28,119 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7ddd2ac2-82cc-4821-a307-66d34cce44b7
2023-11-29 06:42:28,119 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c709a7c7-0116-4180-b0aa-0724810eb1b9
2023-11-29 06:42:28,121 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32861
2023-11-29 06:42:28,123 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32861
2023-11-29 06:42:28,124 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44631
2023-11-29 06:42:28,124 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,124 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,124 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,124 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,124 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-66clqv6j
2023-11-29 06:42:28,125 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7f848544-73c4-4acb-9fcc-79c15c386595
2023-11-29 06:42:28,126 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40501
2023-11-29 06:42:28,127 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40501
2023-11-29 06:42:28,127 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37217
2023-11-29 06:42:28,127 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,127 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,127 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,127 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,127 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ywydsmde
2023-11-29 06:42:28,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26823712-d065-4266-aac9-72293b2534a5
2023-11-29 06:42:28,316 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36643
2023-11-29 06:42:28,317 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36643
2023-11-29 06:42:28,317 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40789
2023-11-29 06:42:28,317 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,317 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,317 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,318 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,318 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kbd1pvxw
2023-11-29 06:42:28,318 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46547
2023-11-29 06:42:28,318 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8129dfd4-7968-42a2-8ce0-844b933253d8
2023-11-29 06:42:28,318 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46547
2023-11-29 06:42:28,318 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42891
2023-11-29 06:42:28,319 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,319 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,319 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,319 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,319 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lfvj1epl
2023-11-29 06:42:28,319 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5ffd6d2-f808-48fb-8eb9-2465c9bc8deb
2023-11-29 06:42:28,321 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44687
2023-11-29 06:42:28,322 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44687
2023-11-29 06:42:28,322 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37783
2023-11-29 06:42:28,322 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,322 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,322 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,323 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4b98qz5a
2023-11-29 06:42:28,323 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2479b056-a1e9-4541-b48b-fb83ed106c70
2023-11-29 06:42:28,325 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36757
2023-11-29 06:42:28,325 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36757
2023-11-29 06:42:28,326 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35431
2023-11-29 06:42:28,326 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,326 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,326 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,326 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,326 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oi4dk8z_
2023-11-29 06:42:28,326 - distributed.worker - INFO - Starting Worker plugin PreImport-f71af07f-f9c9-43f5-bf0f-dea4d6f93502
2023-11-29 06:42:28,327 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-831ab023-783e-489a-bde2-b01fce6f4b68
2023-11-29 06:42:28,327 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df6517a0-43e3-49b6-80ab-51461dcc83cc
2023-11-29 06:42:28,330 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39301
2023-11-29 06:42:28,332 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39301
2023-11-29 06:42:28,332 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38115
2023-11-29 06:42:28,332 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,332 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,332 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:28,333 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:28,333 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-osw03txn
2023-11-29 06:42:28,334 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-72ad8a4c-b5f1-464e-b48e-456da76ef73f
2023-11-29 06:42:28,334 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4126ae0c-2b60-430b-9f93-558545012da0
2023-11-29 06:42:28,366 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d48307a8-6a54-4cff-b0f2-3484960794d7
2023-11-29 06:42:28,366 - distributed.worker - INFO - Starting Worker plugin PreImport-f5e2e2d7-7c3c-4c1b-befa-567636fc3fe9
2023-11-29 06:42:28,367 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,371 - distributed.worker - INFO - Starting Worker plugin PreImport-e72e8bf7-7b69-4cfc-b5f3-a3a87e5801a1
2023-11-29 06:42:28,371 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,373 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b50ee955-c3c2-4a4c-a9eb-c33e9193aaff
2023-11-29 06:42:28,373 - distributed.worker - INFO - Starting Worker plugin PreImport-017afed8-ff3b-4602-896e-b95d2f57cbd5
2023-11-29 06:42:28,374 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,421 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,424 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,424 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,424 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,425 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,425 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,426 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,427 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,427 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,434 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,458 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,459 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,460 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,460 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32861. Reason: nanny-close
2023-11-29 06:42:28,460 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40501. Reason: nanny-close
2023-11-29 06:42:28,460 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46617. Reason: nanny-close
2023-11-29 06:42:28,462 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,462 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,463 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,463 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,464 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,465 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,515 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-713e3951-dbd1-4b66-abd1-04d0c42cd505
2023-11-29 06:42:28,515 - distributed.worker - INFO - Starting Worker plugin PreImport-25263db5-0ef4-4706-a87e-0b9de71258af
2023-11-29 06:42:28,516 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,518 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,519 - distributed.worker - INFO - Starting Worker plugin PreImport-84f7dc8a-033a-4e72-a809-2de87f04cc33
2023-11-29 06:42:28,520 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,522 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9cb2835c-379e-4e10-a167-3be7c7bad25a
2023-11-29 06:42:28,523 - distributed.worker - INFO - Starting Worker plugin PreImport-096c0f6d-ccca-48ce-8311-6890d0480ea9
2023-11-29 06:42:28,524 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,525 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8585496a-57b6-4ded-a2ac-c998998e30ff
2023-11-29 06:42:28,525 - distributed.worker - INFO - Starting Worker plugin PreImport-1f202edb-e09d-4296-b0b8-59f05bc244c8
2023-11-29 06:42:28,525 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,547 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,547 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,547 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,555 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,556 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,556 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,558 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,559 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,559 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,560 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,561 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,561 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36757. Reason: nanny-close
2023-11-29 06:42:28,562 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,564 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,565 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,565 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,565 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:28,569 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:28,569 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:28,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:28,609 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,610 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,610 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39301. Reason: nanny-close
2023-11-29 06:42:28,611 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36643. Reason: nanny-close
2023-11-29 06:42:28,611 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,611 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:28,612 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46547. Reason: nanny-close
2023-11-29 06:42:28,613 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44687. Reason: nanny-close
2023-11-29 06:42:28,613 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,613 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,615 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,615 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:28,619 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:28,620 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:58748 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-29 06:42:29,229 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64553 parent=64367 started daemon>
2023-11-29 06:42:29,229 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64550 parent=64367 started daemon>
2023-11-29 06:42:29,229 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64547 parent=64367 started daemon>
2023-11-29 06:42:29,229 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64543 parent=64367 started daemon>
2023-11-29 06:42:29,229 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64539 parent=64367 started daemon>
2023-11-29 06:42:29,230 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64535 parent=64367 started daemon>
2023-11-29 06:42:29,230 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64532 parent=64367 started daemon>
2023-11-29 06:42:29,410 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64550 exit status was already read will report exitcode 255
2023-11-29 06:42:29,473 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64539 exit status was already read will report exitcode 255
2023-11-29 06:42:29,509 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64547 exit status was already read will report exitcode 255
2023-11-29 06:42:29,546 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64543 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-11-29 06:42:31,637 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:31,641 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45313 instead
  warnings.warn(
2023-11-29 06:42:31,645 - distributed.scheduler - INFO - State start
2023-11-29 06:42:31,694 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:31,695 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:42:31,695 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:31,696 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:42:31,837 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43619'
2023-11-29 06:42:31,858 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35499'
2023-11-29 06:42:31,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37519'
2023-11-29 06:42:31,871 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40465'
2023-11-29 06:42:31,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43079'
2023-11-29 06:42:31,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37293'
2023-11-29 06:42:31,899 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42507'
2023-11-29 06:42:31,909 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42661'
2023-11-29 06:42:33,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,704 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,704 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,706 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,708 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,731 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,774 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,809 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,831 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:33,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:33,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:33,837 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:36,326 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36205
2023-11-29 06:42:36,327 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36205
2023-11-29 06:42:36,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39659
2023-11-29 06:42:36,327 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,327 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,327 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,327 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,327 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nkzu0wxw
2023-11-29 06:42:36,327 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41431
2023-11-29 06:42:36,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-986db342-ae7b-4410-b6a6-379d23636c18
2023-11-29 06:42:36,328 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41431
2023-11-29 06:42:36,328 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38333
2023-11-29 06:42:36,328 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,328 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,328 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,328 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,328 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-46h3_17n
2023-11-29 06:42:36,329 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aed166d2-3836-48d3-ba11-40d491d8b1a8
2023-11-29 06:42:36,390 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37827
2023-11-29 06:42:36,391 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37827
2023-11-29 06:42:36,391 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40591
2023-11-29 06:42:36,391 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,392 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,392 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,392 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,392 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t66nw240
2023-11-29 06:42:36,391 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44893
2023-11-29 06:42:36,392 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44893
2023-11-29 06:42:36,392 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36905
2023-11-29 06:42:36,392 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3a973aaf-6da4-441c-a0cc-954ab4e2b353
2023-11-29 06:42:36,392 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,392 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,392 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,393 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,393 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dmeh17om
2023-11-29 06:42:36,393 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a0e48777-d5fd-4817-889a-9a91363c25c2
2023-11-29 06:42:36,443 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43743
2023-11-29 06:42:36,443 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43743
2023-11-29 06:42:36,444 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40647
2023-11-29 06:42:36,444 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,444 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,444 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,444 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,444 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k0cfps71
2023-11-29 06:42:36,444 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cc0c9f55-8fca-42ba-ae09-6719b1fbf130
2023-11-29 06:42:36,446 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45875
2023-11-29 06:42:36,447 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45875
2023-11-29 06:42:36,447 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39109
2023-11-29 06:42:36,447 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,447 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,447 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,447 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,447 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3a5o3ndf
2023-11-29 06:42:36,448 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6e9becd8-34f0-4d4c-891d-154a13e691da
2023-11-29 06:42:36,473 - distributed.worker - INFO - Starting Worker plugin PreImport-2f14d7d7-550b-4818-a88b-6fecff9af6b6
2023-11-29 06:42:36,473 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8c27a80b-9819-44a5-9030-158d2fd81b57
2023-11-29 06:42:36,473 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,479 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce416e7f-1d12-4acb-bbdf-a9c6aa3fb500
2023-11-29 06:42:36,479 - distributed.worker - INFO - Starting Worker plugin PreImport-72845e66-e52d-4aa4-8dab-68c64dc26225
2023-11-29 06:42:36,479 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,485 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37113
2023-11-29 06:42:36,486 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37113
2023-11-29 06:42:36,486 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37799
2023-11-29 06:42:36,486 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,486 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,486 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,486 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,486 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p2igw4gj
2023-11-29 06:42:36,487 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-be4d6e97-ca15-4500-b61a-355aedef2c85
2023-11-29 06:42:36,487 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df5b5238-c928-4b72-a50e-7f89ed138c67
2023-11-29 06:42:36,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39797
2023-11-29 06:42:36,490 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39797
2023-11-29 06:42:36,490 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41791
2023-11-29 06:42:36,490 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,490 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,490 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:36,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:42:36,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yddytobv
2023-11-29 06:42:36,491 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83d93376-a786-413d-af6a-d260f874e8bf
2023-11-29 06:42:36,566 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-65889684-3a9b-4382-86ec-a767dd27ca38
2023-11-29 06:42:36,566 - distributed.worker - INFO - Starting Worker plugin PreImport-7feaed63-4197-49fb-b39a-7e69a70af9fd
2023-11-29 06:42:36,567 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,571 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7fb698d-c822-4367-8de1-8b20b8749364
2023-11-29 06:42:36,573 - distributed.worker - INFO - Starting Worker plugin PreImport-061ef8fc-fec0-45ea-aa7b-15c65cff4960
2023-11-29 06:42:36,574 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,607 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7cca9c2-1cb1-4e3f-8ae6-3fbcf447ddb7
2023-11-29 06:42:36,607 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-101509e0-8245-4acc-9d78-e1bbb8fa9029
2023-11-29 06:42:36,607 - distributed.worker - INFO - Starting Worker plugin PreImport-2bfb8d39-2970-450a-935b-5a0835cf1b55
2023-11-29 06:42:36,607 - distributed.worker - INFO - Starting Worker plugin PreImport-14bbb63f-e99f-4f4a-b54d-281a8b6b3480
2023-11-29 06:42:36,607 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,607 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,613 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f4c6fe6c-091b-4aff-823f-44621437b61f
2023-11-29 06:42:36,613 - distributed.worker - INFO - Starting Worker plugin PreImport-b2e43b2f-a78e-418e-b2dd-86ed5aacf07b
2023-11-29 06:42:36,613 - distributed.worker - INFO - Starting Worker plugin PreImport-e177fda3-e6e0-4ccd-b33e-0bbdcd225eb4
2023-11-29 06:42:36,613 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,613 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,974 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:36,974 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:36,974 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:36,976 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,007 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42507'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,007 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,009 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39797. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,010 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,012 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:37,020 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:37,021 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:37,021 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:37,023 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:37,033 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:37,033 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:37,034 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35499'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,052 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37519'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,053 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,053 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44893. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,054 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37827. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,055 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,056 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,057 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:37,058 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:37,151 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:37,152 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:37,152 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:37,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37293'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,159 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,160 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37113. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,162 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,164 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:37,220 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:37,221 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:37,221 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:37,222 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,261 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43079'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,261 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,262 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36205. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,265 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,267 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:37,308 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:37,309 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:37,309 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:37,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:37,314 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42661'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,314 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,315 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43743. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-29 06:42:37,317 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:37,318 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:48690 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-29 06:42:37,669 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64853 parent=64664 started daemon>
2023-11-29 06:42:37,669 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64847 parent=64664 started daemon>
2023-11-29 06:42:37,670 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64844 parent=64664 started daemon>
2023-11-29 06:42:37,670 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64840 parent=64664 started daemon>
2023-11-29 06:42:37,670 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64836 parent=64664 started daemon>
2023-11-29 06:42:37,671 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64832 parent=64664 started daemon>
2023-11-29 06:42:37,671 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64829 parent=64664 started daemon>
2023-11-29 06:42:37,864 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64844 exit status was already read will report exitcode 255
2023-11-29 06:42:38,167 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64829 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-11-29 06:42:47,917 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:47,922 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33701 instead
  warnings.warn(
2023-11-29 06:42:47,925 - distributed.scheduler - INFO - State start
2023-11-29 06:42:47,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3a5o3ndf', purging
2023-11-29 06:42:47,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-46h3_17n', purging
2023-11-29 06:42:47,950 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:47,950 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-29 06:42:47,951 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33701/status
2023-11-29 06:42:47,951 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:42:47,964 - distributed.scheduler - INFO - Receive client connection: Client-81669226-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:42:47,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40932
2023-11-29 06:42:48,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37125'
2023-11-29 06:42:49,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:49,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:50,169 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:42:50,993 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35539
2023-11-29 06:42:50,994 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35539
2023-11-29 06:42:50,994 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-11-29 06:42:50,994 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:42:50,994 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:50,994 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:42:50,994 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-29 06:42:50,994 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i8bis6ld
2023-11-29 06:42:50,994 - distributed.worker - INFO - Starting Worker plugin PreImport-df5586b0-aa05-41c2-af92-c5c15892f49b
2023-11-29 06:42:50,995 - distributed.worker - INFO - Starting Worker plugin RMMSetup-09455068-8020-4953-b378-e3ab77eeb094
2023-11-29 06:42:50,995 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f293abfb-f183-41d3-9da8-297bacab88b7
2023-11-29 06:42:50,995 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:51,020 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35539', status: init, memory: 0, processing: 0>
2023-11-29 06:42:51,021 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35539
2023-11-29 06:42:51,021 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46988
2023-11-29 06:42:51,022 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:42:51,023 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:42:51,023 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:42:51,025 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:42:51,064 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:42:51,067 - distributed.scheduler - INFO - Remove client Client-81669226-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:42:51,067 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40932; closing.
2023-11-29 06:42:51,067 - distributed.scheduler - INFO - Remove client Client-81669226-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:42:51,068 - distributed.scheduler - INFO - Close client connection: Client-81669226-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:42:51,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37125'. Reason: nanny-close
2023-11-29 06:42:51,074 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:42:51,075 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35539. Reason: nanny-close
2023-11-29 06:42:51,077 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:42:51,077 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46988; closing.
2023-11-29 06:42:51,077 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35539', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240171.0777316')
2023-11-29 06:42:51,078 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:42:51,078 - distributed.nanny - INFO - Worker closed
2023-11-29 06:42:52,185 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:42:52,185 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:42:52,186 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:52,187 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-29 06:42:52,187 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-11-29 06:42:56,008 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:56,012 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40541 instead
  warnings.warn(
2023-11-29 06:42:56,016 - distributed.scheduler - INFO - State start
2023-11-29 06:42:56,036 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:42:56,037 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-29 06:42:56,038 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:42:56,039 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-29 06:42:56,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43963'
2023-11-29 06:42:58,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:42:58,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:42:58,568 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:01,028 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34239
2023-11-29 06:43:01,028 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34239
2023-11-29 06:43:01,029 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35083
2023-11-29 06:43:01,029 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:01,029 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:01,029 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:01,029 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-29 06:43:01,029 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2mr30ioo
2023-11-29 06:43:01,029 - distributed.worker - INFO - Starting Worker plugin PreImport-5d3338cc-2154-4a46-890c-1b0bf0ae878e
2023-11-29 06:43:01,031 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f53e2932-727d-4079-bbbf-bcc3bbc4564c
2023-11-29 06:43:01,031 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4bba500f-de4b-40ad-9a2b-2305faec305d
2023-11-29 06:43:01,032 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:01,075 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:01,076 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:01,076 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:01,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:06,265 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43963'. Reason: nanny-close
2023-11-29 06:43:06,266 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:06,268 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34239. Reason: nanny-close
2023-11-29 06:43:06,271 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:06,274 - distributed.nanny - INFO - Worker closed
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-11-29 06:43:09,431 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:09,435 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41605 instead
  warnings.warn(
2023-11-29 06:43:09,438 - distributed.scheduler - INFO - State start
2023-11-29 06:43:09,458 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:09,459 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-29 06:43:09,460 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41605/status
2023-11-29 06:43:09,460 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:43:09,701 - distributed.scheduler - INFO - Receive client connection: Client-8e8fb763-8e82-11ee-b4a5-d8c49764f6bb
2023-11-29 06:43:09,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44742
2023-11-29 06:43:12,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46727', status: init, memory: 0, processing: 0>
2023-11-29 06:43:12,783 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46727
2023-11-29 06:43:12,783 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58760
2023-11-29 06:43:12,806 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:12,808 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:12,810 - distributed.scheduler - INFO - Remove client Client-8e8fb763-8e82-11ee-b4a5-d8c49764f6bb
2023-11-29 06:43:12,811 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44742; closing.
2023-11-29 06:43:12,811 - distributed.scheduler - INFO - Remove client Client-8e8fb763-8e82-11ee-b4a5-d8c49764f6bb
2023-11-29 06:43:12,811 - distributed.scheduler - INFO - Close client connection: Client-8e8fb763-8e82-11ee-b4a5-d8c49764f6bb
2023-11-29 06:43:12,815 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58760; closing.
2023-11-29 06:43:12,815 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46727', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240192.8158414')
2023-11-29 06:43:12,816 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:43:13,437 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:44732'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44732>: Stream is closed
2023-11-29 06:43:13,759 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:43:13,759 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:43:13,759 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:43:13,760 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-29 06:43:13,761 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-11-29 06:43:15,886 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:15,890 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35693 instead
  warnings.warn(
2023-11-29 06:43:15,894 - distributed.scheduler - INFO - State start
2023-11-29 06:43:15,916 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:15,917 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-29 06:43:15,918 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35693/status
2023-11-29 06:43:15,918 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:43:16,026 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45855'
2023-11-29 06:43:17,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:17,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:17,534 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:17,847 - distributed.scheduler - INFO - Receive client connection: Client-9205c9f0-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:17,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39794
2023-11-29 06:43:18,397 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39805
2023-11-29 06:43:18,398 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39805
2023-11-29 06:43:18,398 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32869
2023-11-29 06:43:18,398 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-29 06:43:18,398 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:18,398 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:18,398 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-29 06:43:18,398 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-6isktq1y
2023-11-29 06:43:18,399 - distributed.worker - INFO - Starting Worker plugin PreImport-097b815e-a450-4720-a44e-897fdc95668d
2023-11-29 06:43:18,399 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a23a13fa-c038-46d4-b54c-3296da47caaa
2023-11-29 06:43:18,399 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-86e6ecc4-322e-4820-a0f0-9780e1244d10
2023-11-29 06:43:18,399 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:18,424 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39805', status: init, memory: 0, processing: 0>
2023-11-29 06:43:18,425 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39805
2023-11-29 06:43:18,425 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39816
2023-11-29 06:43:18,426 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:18,426 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-29 06:43:18,427 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:18,428 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-29 06:43:18,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:18,480 - distributed.scheduler - INFO - Remove client Client-9205c9f0-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:18,481 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39794; closing.
2023-11-29 06:43:18,481 - distributed.scheduler - INFO - Remove client Client-9205c9f0-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:18,481 - distributed.scheduler - INFO - Close client connection: Client-9205c9f0-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:18,482 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45855'. Reason: nanny-close
2023-11-29 06:43:18,482 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:18,483 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39805. Reason: nanny-close
2023-11-29 06:43:18,485 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-29 06:43:18,485 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39816; closing.
2023-11-29 06:43:18,485 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39805', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240198.4857345')
2023-11-29 06:43:18,486 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:43:18,486 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:19,448 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:43:19,449 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:43:19,449 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:43:19,450 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-29 06:43:19,451 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-11-29 06:43:21,692 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:21,696 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34255 instead
  warnings.warn(
2023-11-29 06:43:21,700 - distributed.scheduler - INFO - State start
2023-11-29 06:43:21,720 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:21,721 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-29 06:43:21,721 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34255/status
2023-11-29 06:43:21,722 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:43:22,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38317'
2023-11-29 06:43:22,064 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36883'
2023-11-29 06:43:22,075 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34575'
2023-11-29 06:43:22,089 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34643'
2023-11-29 06:43:22,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36789'
2023-11-29 06:43:22,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33479'
2023-11-29 06:43:22,107 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40967'
2023-11-29 06:43:22,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44237'
2023-11-29 06:43:23,238 - distributed.scheduler - INFO - Receive client connection: Client-958c618c-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:23,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37528
2023-11-29 06:43:23,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,893 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,893 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,894 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,914 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,935 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,936 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:23,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:23,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:23,983 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:26,744 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42457
2023-11-29 06:43:26,745 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42457
2023-11-29 06:43:26,745 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43963
2023-11-29 06:43:26,745 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,745 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,745 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,745 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,745 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ybznrvhp
2023-11-29 06:43:26,745 - distributed.worker - INFO - Starting Worker plugin RMMSetup-425a11fd-18e6-4c7a-b010-e293f77cdae1
2023-11-29 06:43:26,756 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33823
2023-11-29 06:43:26,757 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33823
2023-11-29 06:43:26,757 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35907
2023-11-29 06:43:26,757 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,758 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,758 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,758 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,758 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-52zanobf
2023-11-29 06:43:26,757 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34257
2023-11-29 06:43:26,758 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34257
2023-11-29 06:43:26,758 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46361
2023-11-29 06:43:26,758 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,758 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,758 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f18fbd4-6ef1-45f1-94ff-1b995bd0e5a0
2023-11-29 06:43:26,758 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,758 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,758 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pfa0h2ly
2023-11-29 06:43:26,759 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c95d046-c82b-45d7-9b9d-b63ca9639506
2023-11-29 06:43:26,760 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33117
2023-11-29 06:43:26,760 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33117
2023-11-29 06:43:26,761 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45779
2023-11-29 06:43:26,761 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,761 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,761 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,761 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,761 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-avxckt7n
2023-11-29 06:43:26,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1459a82-ea17-4032-bb02-7c9353cbacaa
2023-11-29 06:43:26,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42941
2023-11-29 06:43:26,762 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42941
2023-11-29 06:43:26,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44841
2023-11-29 06:43:26,762 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43825
2023-11-29 06:43:26,762 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44841
2023-11-29 06:43:26,762 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,762 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41627
2023-11-29 06:43:26,762 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,762 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,762 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,762 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,762 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,762 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,762 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yoovstex
2023-11-29 06:43:26,762 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,762 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xg1jc0sv
2023-11-29 06:43:26,763 - distributed.worker - INFO - Starting Worker plugin RMMSetup-699e80fb-95da-41e5-9392-10e093910f08
2023-11-29 06:43:26,763 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9997366e-3aff-4e1c-93b7-ac358f510d69
2023-11-29 06:43:26,771 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46223
2023-11-29 06:43:26,773 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46223
2023-11-29 06:43:26,773 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35579
2023-11-29 06:43:26,773 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,773 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,773 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,774 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,774 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7hj1qgda
2023-11-29 06:43:26,775 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-474ea202-54c4-4c49-bc7a-22ab09d91942
2023-11-29 06:43:26,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f4c26dc9-cfd4-4127-8d64-3eeb189e1194
2023-11-29 06:43:26,776 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42779
2023-11-29 06:43:26,777 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42779
2023-11-29 06:43:26,777 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45147
2023-11-29 06:43:26,777 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,777 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,777 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:26,778 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-29 06:43:26,778 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rkz7zywk
2023-11-29 06:43:26,778 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ef465f2-71d5-498d-89c6-858eef1d79d5
2023-11-29 06:43:26,896 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a6dddef7-037e-4f00-b464-5c1657012998
2023-11-29 06:43:26,896 - distributed.worker - INFO - Starting Worker plugin PreImport-25e6feb3-e6bc-4968-9ece-89b43dec2fb1
2023-11-29 06:43:26,897 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,907 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a172f43-5651-4ec9-92fa-e15d65297ef6
2023-11-29 06:43:26,912 - distributed.worker - INFO - Starting Worker plugin PreImport-3c8b1b96-27ba-4330-be10-b9e2bcf8dc90
2023-11-29 06:43:26,912 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,914 - distributed.worker - INFO - Starting Worker plugin PreImport-38dd5493-a3af-4b6a-9717-bacc089f1f81
2023-11-29 06:43:26,914 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-567eb10e-7f2d-437a-96ca-23b32ff2cb4e
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin PreImport-2e67972e-21b5-48fc-b247-7210fb5a1a11
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin PreImport-aad70b82-60bb-45ca-ba3e-e385578c0fda
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d43e038d-ebcf-47b3-a925-8f3993c57733
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-95660a58-221b-4cb5-aa89-65a26d9cb48f
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71443e2b-a52c-48ec-b8a2-592c2d180dda
2023-11-29 06:43:26,915 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,915 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,915 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-907d3977-571d-4ebb-8f2d-d1c247dff73c
2023-11-29 06:43:26,915 - distributed.worker - INFO - Starting Worker plugin PreImport-70687893-8e7b-4eb4-8053-9aeb19774bc3
2023-11-29 06:43:26,916 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,917 - distributed.worker - INFO - Starting Worker plugin PreImport-76a7677f-2668-4630-afa8-bf83afd0ed84
2023-11-29 06:43:26,918 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,920 - distributed.worker - INFO - Starting Worker plugin PreImport-c637e550-6505-4c14-a713-88df9d002ef1
2023-11-29 06:43:26,920 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,937 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42457', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,938 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42457
2023-11-29 06:43:26,938 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37552
2023-11-29 06:43:26,940 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,945 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33823', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,946 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33823
2023-11-29 06:43:26,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37560
2023-11-29 06:43:26,947 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,947 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,948 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42941', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,949 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42941
2023-11-29 06:43:26,949 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37582
2023-11-29 06:43:26,950 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,950 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,951 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,951 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,953 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,953 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42779', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,953 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42779
2023-11-29 06:43:26,954 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37586
2023-11-29 06:43:26,954 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,954 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,955 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46223', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,955 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,955 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46223
2023-11-29 06:43:26,955 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,955 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37574
2023-11-29 06:43:26,956 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34257', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,957 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34257
2023-11-29 06:43:26,957 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37556
2023-11-29 06:43:26,957 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,957 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,957 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44841', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,958 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44841
2023-11-29 06:43:26,958 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37594
2023-11-29 06:43:26,958 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,958 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,958 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,961 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,965 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,965 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,966 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,966 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:26,970 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33117', status: init, memory: 0, processing: 0>
2023-11-29 06:43:26,971 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33117
2023-11-29 06:43:26,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37598
2023-11-29 06:43:26,972 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:26,978 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:26,978 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:26,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:27,029 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,030 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,031 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-29 06:43:27,043 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,043 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,044 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:27,048 - distributed.scheduler - INFO - Remove client Client-958c618c-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:27,048 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37528; closing.
2023-11-29 06:43:27,049 - distributed.scheduler - INFO - Remove client Client-958c618c-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:27,049 - distributed.scheduler - INFO - Close client connection: Client-958c618c-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:27,050 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38317'. Reason: nanny-close
2023-11-29 06:43:27,050 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,051 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36883'. Reason: nanny-close
2023-11-29 06:43:27,052 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,052 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42941. Reason: nanny-close
2023-11-29 06:43:27,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34575'. Reason: nanny-close
2023-11-29 06:43:27,052 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,052 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33823. Reason: nanny-close
2023-11-29 06:43:27,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34643'. Reason: nanny-close
2023-11-29 06:43:27,053 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,053 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33117. Reason: nanny-close
2023-11-29 06:43:27,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36789'. Reason: nanny-close
2023-11-29 06:43:27,054 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,054 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37582; closing.
2023-11-29 06:43:27,054 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34257. Reason: nanny-close
2023-11-29 06:43:27,054 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,054 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42941', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.05449')
2023-11-29 06:43:27,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33479'. Reason: nanny-close
2023-11-29 06:43:27,055 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,055 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,055 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42779. Reason: nanny-close
2023-11-29 06:43:27,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40967'. Reason: nanny-close
2023-11-29 06:43:27,055 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,056 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,056 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46223. Reason: nanny-close
2023-11-29 06:43:27,056 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44237'. Reason: nanny-close
2023-11-29 06:43:27,056 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,056 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:27,057 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,057 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37560; closing.
2023-11-29 06:43:27,057 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42457. Reason: nanny-close
2023-11-29 06:43:27,057 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,058 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33823', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0583193')
2023-11-29 06:43:27,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,058 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37598; closing.
2023-11-29 06:43:27,058 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44841. Reason: nanny-close
2023-11-29 06:43:27,059 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33117', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0592477')
2023-11-29 06:43:27,059 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,059 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,059 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37556; closing.
2023-11-29 06:43:27,060 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34257', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0603268')
2023-11-29 06:43:27,060 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,060 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37586; closing.
2023-11-29 06:43:27,060 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37574; closing.
2023-11-29 06:43:27,061 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,061 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42779', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0613606')
2023-11-29 06:43:27,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,061 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46223', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0618384')
2023-11-29 06:43:27,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:27,062 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37552; closing.
2023-11-29 06:43:27,063 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37594; closing.
2023-11-29 06:43:27,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42457', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0634365')
2023-11-29 06:43:27,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44841', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240207.0637567')
2023-11-29 06:43:27,063 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:43:27,064 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,064 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:27,064 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37552>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-29 06:43:27,065 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37594>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-29 06:43:28,618 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:43:28,618 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:43:28,619 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:43:28,620 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-29 06:43:28,620 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-11-29 06:43:30,696 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:30,700 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39631 instead
  warnings.warn(
2023-11-29 06:43:30,704 - distributed.scheduler - INFO - State start
2023-11-29 06:43:30,764 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:30,765 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-29 06:43:30,765 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39631/status
2023-11-29 06:43:30,766 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:43:30,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43977'
2023-11-29 06:43:32,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:32,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:32,462 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:33,263 - distributed.scheduler - INFO - Receive client connection: Client-9ad854bc-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:33,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34840
2023-11-29 06:43:33,735 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35441
2023-11-29 06:43:33,736 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35441
2023-11-29 06:43:33,736 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44187
2023-11-29 06:43:33,736 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:33,736 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:33,736 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:33,736 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-29 06:43:33,736 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-msd5pc6m
2023-11-29 06:43:33,737 - distributed.worker - INFO - Starting Worker plugin PreImport-104d394c-20b4-45e0-9ff9-4ab706ae6d97
2023-11-29 06:43:33,737 - distributed.worker - INFO - Starting Worker plugin RMMSetup-43b1b68f-5cb3-4a04-aefb-c17743256c4f
2023-11-29 06:43:33,848 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eed78ed2-6ae1-43fb-9155-93e47c017854
2023-11-29 06:43:33,849 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:33,881 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35441', status: init, memory: 0, processing: 0>
2023-11-29 06:43:33,882 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35441
2023-11-29 06:43:33,882 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34856
2023-11-29 06:43:33,883 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:33,884 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:33,884 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:33,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:33,892 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-29 06:43:33,896 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:33,898 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:33,900 - distributed.scheduler - INFO - Remove client Client-9ad854bc-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:33,900 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34840; closing.
2023-11-29 06:43:33,901 - distributed.scheduler - INFO - Remove client Client-9ad854bc-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:33,901 - distributed.scheduler - INFO - Close client connection: Client-9ad854bc-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:33,902 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43977'. Reason: nanny-close
2023-11-29 06:43:33,936 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:33,937 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35441. Reason: nanny-close
2023-11-29 06:43:33,939 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:33,939 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34856; closing.
2023-11-29 06:43:33,940 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35441', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240213.9400623')
2023-11-29 06:43:33,940 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:43:33,941 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:34,918 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:43:34,919 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:43:34,919 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:43:34,920 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-29 06:43:34,920 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-11-29 06:43:36,978 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:36,982 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38719 instead
  warnings.warn(
2023-11-29 06:43:36,985 - distributed.scheduler - INFO - State start
2023-11-29 06:43:37,005 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-29 06:43:37,006 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-29 06:43:37,007 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38719/status
2023-11-29 06:43:37,007 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-29 06:43:37,329 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41121'
2023-11-29 06:43:37,367 - distributed.scheduler - INFO - Receive client connection: Client-9ea8c068-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:37,377 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34948
2023-11-29 06:43:39,043 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-29 06:43:39,043 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-29 06:43:39,047 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-29 06:43:39,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36205
2023-11-29 06:43:39,907 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36205
2023-11-29 06:43:39,907 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36879
2023-11-29 06:43:39,907 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-29 06:43:39,907 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:39,907 - distributed.worker - INFO -               Threads:                          1
2023-11-29 06:43:39,907 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-29 06:43:39,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7nr6j8ft
2023-11-29 06:43:39,908 - distributed.worker - INFO - Starting Worker plugin PreImport-f892d8e3-be7d-4ada-be46-45c9c6dc0310
2023-11-29 06:43:39,908 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e01e26a0-870e-47d1-b66a-7bc0d3b0ed3c
2023-11-29 06:43:40,155 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a141e531-2324-4d70-b7b0-98cd890ab176
2023-11-29 06:43:40,156 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:40,310 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36205', status: init, memory: 0, processing: 0>
2023-11-29 06:43:40,311 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36205
2023-11-29 06:43:40,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50824
2023-11-29 06:43:40,312 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-29 06:43:40,313 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-29 06:43:40,313 - distributed.worker - INFO - -------------------------------------------------
2023-11-29 06:43:40,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-29 06:43:40,318 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-11-29 06:43:40,594 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-29 06:43:40,597 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:40,599 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-29 06:43:40,601 - distributed.scheduler - INFO - Remove client Client-9ea8c068-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:40,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34948; closing.
2023-11-29 06:43:40,602 - distributed.scheduler - INFO - Remove client Client-9ea8c068-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:40,602 - distributed.scheduler - INFO - Close client connection: Client-9ea8c068-8e82-11ee-b66a-d8c49764f6bb
2023-11-29 06:43:40,603 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41121'. Reason: nanny-close
2023-11-29 06:43:40,604 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-29 06:43:40,605 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36205. Reason: nanny-close
2023-11-29 06:43:40,607 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50824; closing.
2023-11-29 06:43:40,607 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-29 06:43:40,607 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36205', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701240220.607449')
2023-11-29 06:43:40,607 - distributed.scheduler - INFO - Lost all workers
2023-11-29 06:43:40,608 - distributed.nanny - INFO - Worker closed
2023-11-29 06:43:41,720 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-29 06:43:41,720 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-29 06:43:41,721 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-29 06:43:41,722 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-29 06:43:41,722 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38043 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40361 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38277 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46213 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33251 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39847 instead
  warnings.warn(
2023-11-29 06:44:57,142 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-29 06:44:57,146 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:36255', name: 1, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46287 instead
  warnings.warn(
2023-11-29 06:45:08,548 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-29 06:45:08,550 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:53338', name: 1, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39169 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44383 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38453 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45811 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42321 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42753 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34035 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35067 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45767 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37831 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43673 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41979 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45561 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40159 instead
  warnings.warn(
[1701240518.729625] [dgx13:72091:0]            sock.c:470  UCX  ERROR bind(fd=160 addr=0.0.0.0:36578) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] 2023-11-29 06:49:35,685 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-5cc7fa73-b47f-443a-af16-1938eb23cf92
Function:  _run_coroutine_on_worker
args:      (273666500748140271793267329380328129568, <function shuffle_task at 0x7f3db4b21d30>, ('explicit-comms-shuffle-958d4c306596076fb29ab08d1fbd55c1', {0: {('explicit-comms-shuffle-660b1370f6c47f932dbc02bf54c4ffc7', 0)}, 1: set(), 2: set()}, {0: {0}, 1: set(), 2: set()}, ['_partitions'], 1, False, 1, 1))
kwargs:    {}
Exception: "RuntimeError('CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 18 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
