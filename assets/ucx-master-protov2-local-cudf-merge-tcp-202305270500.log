2023-05-27 06:37:56,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xu7kdaz', purging
2023-05-27 06:37:56,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:56,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:56,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:58,982 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,044 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,085 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,453 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:59,672 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:00,006 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:00,661 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zbbu1dgh', purging
2023-05-27 06:38:00,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zp3v53r6', purging
2023-05-27 06:38:00,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwtmhl0h', purging
2023-05-27 06:38:00,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1fiyz1l', purging
2023-05-27 06:38:00,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kt3ptjpz', purging
2023-05-27 06:38:00,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t4dbckgj', purging
2023-05-27 06:38:00,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e6xfj22f', purging
2023-05-27 06:38:00,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5cz6dp3', purging
2023-05-27 06:38:00,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:00,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:00,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:00,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:00,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:00,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:00,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:00,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:00,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:00,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:01,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:01,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:02,067 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:02,185 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:02,580 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:02,850 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:03,661 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-srxvii8n', purging
2023-05-27 06:38:03,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1kxsn6d', purging
2023-05-27 06:38:03,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ivpv8x6l', purging
2023-05-27 06:38:03,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x6szk5q1', purging
2023-05-27 06:38:03,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:03,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:03,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:03,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:04,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7a6xrzwh', purging
2023-05-27 06:38:04,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:04,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:04,169 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:04,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:04,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:04,552 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:04,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:04,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:05,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zrx612dc', purging
2023-05-27 06:38:05,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ex_c8p9d', purging
2023-05-27 06:38:05,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fpu6ujgn', purging
2023-05-27 06:38:05,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:05,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:05,917 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:05,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:05,996 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:06,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ag783f95', purging
2023-05-27 06:38:06,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xcv87vx_', purging
2023-05-27 06:38:06,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yjotkovo', purging
2023-05-27 06:38:06,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,239 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:06,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b3y46ne4', purging
2023-05-27 06:38:06,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,581 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x4n74kna', purging
2023-05-27 06:38:06,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:06,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:06,595 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:06,908 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:07,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8ow2a3o', purging
2023-05-27 06:38:07,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:07,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:07,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:07,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:07,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:07,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:07,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:07,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:08,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:08,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:08,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:08,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:09,036 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:10,227 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:10,561 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,633 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-exmo3pc5', purging
2023-05-27 06:38:10,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5pdjz6va', purging
2023-05-27 06:38:10,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17nrqrfz', purging
2023-05-27 06:38:10,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fm0vw6hr', purging
2023-05-27 06:38:10,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9rb0wtmv', purging
2023-05-27 06:38:10,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3qkkuf5z', purging
2023-05-27 06:38:10,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aueus3fd', purging
2023-05-27 06:38:10,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2zkqo_fp', purging
2023-05-27 06:38:10,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:10,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:10,660 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,684 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,710 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:10,735 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:11,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:11,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:12,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,288 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmlo7yd6', purging
2023-05-27 06:38:12,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:12,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:12,395 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:13,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:13,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2m7lqza1', purging
2023-05-27 06:38:13,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:13,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:14,429 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:14,469 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:15,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:15,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b64plgez', purging
2023-05-27 06:38:15,345 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_vckxzg', purging
2023-05-27 06:38:15,345 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k05jebse', purging
2023-05-27 06:38:15,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4tv2i07c', purging
2023-05-27 06:38:15,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qoh0dh_8', purging
2023-05-27 06:38:15,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0580si1c', purging
2023-05-27 06:38:15,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:15,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:15,393 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:15,425 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:15,452 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:16,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xyzqq05w', purging
2023-05-27 06:38:16,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:16,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:16,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:16,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:16,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:16,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:16,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifoct620', purging
2023-05-27 06:38:16,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:16,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:17,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,191 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:17,221 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:17,676 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58l6cos8', purging
2023-05-27 06:38:17,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qgdw40o9', purging
2023-05-27 06:38:17,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rdhbdc9u', purging
2023-05-27 06:38:17,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:17,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:17,916 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:18,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:18,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:18,302 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:18,368 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:18,394 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:18,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhd2iuso', purging
2023-05-27 06:38:18,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2sp0vuem', purging
2023-05-27 06:38:18,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5qcesfk', purging
2023-05-27 06:38:18,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:18,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:18,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:18,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:19,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:19,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:19,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:19,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:19,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:19,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:20,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:20,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:20,258 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:20,994 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:21,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b28qwrl2', purging
2023-05-27 06:38:21,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-388zb5x9', purging
2023-05-27 06:38:21,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:21,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:21,844 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:21,900 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:21,930 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:21,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:22,018 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:22,044 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:22,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y7bn4eht', purging
2023-05-27 06:38:22,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0yppb60', purging
2023-05-27 06:38:22,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1syy2sts', purging
2023-05-27 06:38:22,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hh31tgo5', purging
2023-05-27 06:38:22,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9d1uwnlb', purging
2023-05-27 06:38:22,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g1psc2o9', purging
2023-05-27 06:38:22,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:22,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:23,216 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:23,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uecjam2b', purging
2023-05-27 06:38:23,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:23,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:23,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:23,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:23,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:23,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:23,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:24,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:24,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:25,307 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:25,733 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,775 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,834 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,875 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,904 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:25,936 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:26,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ix5tgfll', purging
2023-05-27 06:38:26,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l6to4sl7', purging
2023-05-27 06:38:26,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ganuvgnp', purging
2023-05-27 06:38:26,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_4h83pb', purging
2023-05-27 06:38:26,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmxrc77u', purging
2023-05-27 06:38:26,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__yoot6v', purging
2023-05-27 06:38:26,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dzvv9_sm', purging
2023-05-27 06:38:26,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:26,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:27,343 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:27,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1eovo3l0', purging
2023-05-27 06:38:27,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:27,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:27,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:27,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:27,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:27,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:27,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:28,514 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:28,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b05y_hr5', purging
2023-05-27 06:38:28,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:28,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:29,290 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:29,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:29,453 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:29,639 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:30,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjtxraxf', purging
2023-05-27 06:38:30,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kselpb4m', purging
2023-05-27 06:38:30,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8ujk7r_', purging
2023-05-27 06:38:30,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hnplih6', purging
2023-05-27 06:38:30,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fy_h0iae', purging
2023-05-27 06:38:30,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:30,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:30,324 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:30,349 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:30,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9xwptpqa', purging
2023-05-27 06:38:30,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:30,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:31,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:31,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:31,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:31,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:31,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d0met62o', purging
2023-05-27 06:38:31,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:31,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:31,343 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:31,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:31,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:31,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:31,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:32,370 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:32,413 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:32,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwgtenqn', purging
2023-05-27 06:38:32,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58700p19', purging
2023-05-27 06:38:32,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yu716327', purging
2023-05-27 06:38:32,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgfxykqb', purging
2023-05-27 06:38:32,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:32,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:32,999 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:33,038 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:33,084 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:33,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z8jn9wqs', purging
2023-05-27 06:38:33,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:33,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:33,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:33,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:34,447 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:34,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:34,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4c04e9e', purging
2023-05-27 06:38:34,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4pldmu4_', purging
2023-05-27 06:38:34,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:34,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:34,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:34,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:34,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:34,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:35,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:36,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfmgxu7r', purging
2023-05-27 06:38:36,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:36,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:36,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:36,228 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:36,311 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:36,312 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:36,358 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:36,415 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:37,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htqi8l_p', purging
2023-05-27 06:38:37,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ju9iw5go', purging
2023-05-27 06:38:37,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0uhmf9f', purging
2023-05-27 06:38:37,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ac062ors', purging
2023-05-27 06:38:37,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odw1pzky', purging
2023-05-27 06:38:37,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:37,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:37,776 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:37,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mv5wsfj', purging
2023-05-27 06:38:37,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_ymdhvv', purging
2023-05-27 06:38:37,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:37,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:37,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:37,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:37,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:37,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:37,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:37,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:37,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:38,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:38,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:39,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:39,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:39,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:39,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:40,050 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:40,083 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:40,124 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:40,176 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:40,204 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:40,573 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:41,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:41,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:41,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6p7q9ch', purging
2023-05-27 06:38:41,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8nl93ky', purging
2023-05-27 06:38:41,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-um8wuvl9', purging
2023-05-27 06:38:41,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91ooj85_', purging
2023-05-27 06:38:41,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1l9aukru', purging
2023-05-27 06:38:41,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fqgn01w', purging
2023-05-27 06:38:41,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ba9kuwj', purging
2023-05-27 06:38:41,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bbsnqzkd', purging
2023-05-27 06:38:41,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:41,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:41,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:41,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:41,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:41,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:41,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:41,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:41,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:41,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:42,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:42,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:42,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:42,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:42,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:42,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:43,756 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:43,838 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:43,870 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:44,103 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:44,303 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:44,711 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:45,322 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:45,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9zckmpb_', purging
2023-05-27 06:38:45,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfz3zpo6', purging
2023-05-27 06:38:45,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hysnh7k4', purging
2023-05-27 06:38:45,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ehjb90iv', purging
2023-05-27 06:38:45,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4po5dc7n', purging
2023-05-27 06:38:45,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5sw5tc9', purging
2023-05-27 06:38:45,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9b76x90i', purging
2023-05-27 06:38:45,329 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4sqoz9kz', purging
2023-05-27 06:38:45,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:45,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:45,362 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:45,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:45,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:45,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:45,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:45,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:45,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:45,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:45,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:46,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:46,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:46,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:46,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:46,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:46,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:47,218 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:47,327 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:47,490 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:47,767 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:47,988 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:48,094 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:48,193 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:48,357 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:48,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75wmba4g', purging
2023-05-27 06:38:48,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwvmflz7', purging
2023-05-27 06:38:48,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pfoxh643', purging
2023-05-27 06:38:48,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z89i3iuj', purging
2023-05-27 06:38:48,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5x3re8jt', purging
2023-05-27 06:38:48,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4fojfbpc', purging
2023-05-27 06:38:48,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-906y4gg0', purging
2023-05-27 06:38:48,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i51wdf2m', purging
2023-05-27 06:38:48,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:48,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:48,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:48,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:48,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:48,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:49,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:49,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:49,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:49,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:49,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:49,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:49,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:49,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:49,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:49,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:50,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:50,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:50,456 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:51,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:51,094 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:51,127 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:51,204 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:51,458 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:51,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7tsrv9k7', purging
2023-05-27 06:38:51,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-if_zv5ur', purging
2023-05-27 06:38:51,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vkhevkk8', purging
2023-05-27 06:38:51,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fe3a9pkb', purging
2023-05-27 06:38:51,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnyu9342', purging
2023-05-27 06:38:51,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lm7wb4h6', purging
2023-05-27 06:38:51,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z6non0t_', purging
2023-05-27 06:38:51,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5kaqqlu', purging
2023-05-27 06:38:51,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:51,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:51,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:51,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:52,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:52,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:53,235 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,040 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,071 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:54,395 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,451 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,476 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,500 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,660 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:54,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lgdyeeoc', purging
2023-05-27 06:38:54,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7a0lmul9', purging
2023-05-27 06:38:54,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zlslfzix', purging
2023-05-27 06:38:54,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxutg76j', purging
2023-05-27 06:38:54,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdhs3app', purging
2023-05-27 06:38:54,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_r_6xtoz', purging
2023-05-27 06:38:54,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-em68p75y', purging
2023-05-27 06:38:54,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1b08h8u', purging
2023-05-27 06:38:54,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:54,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:55,484 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:55,546 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f87t564f', purging
2023-05-27 06:38:55,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:55,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:55,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:55,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:55,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:55,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:55,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:55,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:55,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:55,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:56,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:56,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:56,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:56,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:56,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wlcblf_', purging
2023-05-27 06:38:56,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ywhaqgha', purging
2023-05-27 06:38:56,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:56,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:57,191 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:57,218 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:57,941 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:57,963 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:57,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:58,015 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:58,042 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:58,345 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:58,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-towkzk_m', purging
2023-05-27 06:38:58,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h38u2im', purging
2023-05-27 06:38:58,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ruoddzt6', purging
2023-05-27 06:38:58,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h83noul4', purging
2023-05-27 06:38:58,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urmhnvth', purging
2023-05-27 06:38:58,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gta4j8m', purging
2023-05-27 06:38:58,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:58,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:58,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:58,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:38:59,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:38:59,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qud4fwxf', purging
2023-05-27 06:38:59,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_wh5h95c', purging
2023-05-27 06:38:59,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:38:59,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:38:59,935 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:00,776 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:01,169 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:01,229 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:01,256 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:01,283 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:01,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-llelw6ig', purging
2023-05-27 06:39:01,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ebjcp040', purging
2023-05-27 06:39:01,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8kwlajf', purging
2023-05-27 06:39:01,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oml__8du', purging
2023-05-27 06:39:01,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b5hldyhb', purging
2023-05-27 06:39:01,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:01,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:01,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:01,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:01,547 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:02,297 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d4a125_8', purging
2023-05-27 06:39:02,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:02,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:02,367 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:02,544 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:02,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mopmodpj', purging
2023-05-27 06:39:02,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oaybbnxe', purging
2023-05-27 06:39:02,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:02,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:02,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:02,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:02,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:02,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:02,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:02,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:03,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:03,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:03,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4u8ruevf', purging
2023-05-27 06:39:03,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:03,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:03,933 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:04,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kr0o7amv', purging
2023-05-27 06:39:04,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:04,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:04,186 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:04,381 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:04,434 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:04,652 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:04,703 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:05,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:05,246 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:05,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uki44d59', purging
2023-05-27 06:39:05,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b02j3abl', purging
2023-05-27 06:39:05,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_xke9cd', purging
2023-05-27 06:39:05,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cmvbn8z6', purging
2023-05-27 06:39:05,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2eeert_', purging
2023-05-27 06:39:05,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h451uhwi', purging
2023-05-27 06:39:05,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:05,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:05,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:05,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:05,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:05,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:05,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:05,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:06,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:06,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:06,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:06,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:06,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:06,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:06,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:06,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:06,953 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:06,979 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:07,618 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:07,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:07,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:07,884 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:08,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:08,257 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:08,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lm9r1shp', purging
2023-05-27 06:39:08,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57z22uy_', purging
2023-05-27 06:39:08,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ihrsutg7', purging
2023-05-27 06:39:08,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kc68rnl0', purging
2023-05-27 06:39:08,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4j1h5_oh', purging
2023-05-27 06:39:08,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpy3yj63', purging
2023-05-27 06:39:08,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i5k_1plt', purging
2023-05-27 06:39:08,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acuyhdh2', purging
2023-05-27 06:39:08,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:08,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:08,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:08,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:09,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,483 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:09,504 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:09,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nknckav1', purging
2023-05-27 06:39:09,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-29hsqn0o', purging
2023-05-27 06:39:09,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:09,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:09,991 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:10,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:10,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:10,812 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:10,995 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yvo86bu8', purging
2023-05-27 06:39:10,995 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5n4pdjz', purging
2023-05-27 06:39:10,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ylj2__x6', purging
2023-05-27 06:39:10,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-anvav0ds', purging
2023-05-27 06:39:10,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6s57bcze', purging
2023-05-27 06:39:10,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:10,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:11,005 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:11,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:11,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:11,233 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:11,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edo6_itj', purging
2023-05-27 06:39:11,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:11,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:12,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nsjlz8nq', purging
2023-05-27 06:39:12,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:12,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:12,227 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:12,263 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:12,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hp1edivt', purging
2023-05-27 06:39:12,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:12,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:12,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:12,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:12,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vd7irp6a', purging
2023-05-27 06:39:12,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:12,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:12,557 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:12,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:12,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:13,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:13,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:13,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:13,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:13,983 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:14,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2mme1zb', purging
2023-05-27 06:39:14,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yitrifrh', purging
2023-05-27 06:39:14,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:14,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:14,028 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:14,089 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:14,111 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:14,136 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:14,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:14,915 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:15,163 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:15,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t57l5hii', purging
2023-05-27 06:39:15,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p4n7nah6', purging
2023-05-27 06:39:15,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gp2hee46', purging
2023-05-27 06:39:15,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gt6stdk8', purging
2023-05-27 06:39:15,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pb7yjoum', purging
2023-05-27 06:39:15,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xm7sw5u2', purging
2023-05-27 06:39:15,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:15,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:15,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:15,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:15,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:15,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:15,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:15,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:15,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:15,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:16,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:16,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:16,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:16,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:16,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:16,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:17,342 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:17,546 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:17,572 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:17,597 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:17,628 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:17,986 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:18,026 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:18,211 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:18,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_uip6fr', purging
2023-05-27 06:39:18,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgs_oiy6', purging
2023-05-27 06:39:18,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g13dbfjv', purging
2023-05-27 06:39:18,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jygc_o0i', purging
2023-05-27 06:39:18,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5t3sjq_', purging
2023-05-27 06:39:18,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-za4ya8vn', purging
2023-05-27 06:39:18,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mb7bi9s', purging
2023-05-27 06:39:18,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dl46k5hu', purging
2023-05-27 06:39:18,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:18,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:19,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2z28d9j9', purging
2023-05-27 06:39:19,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:19,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:19,832 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:20,421 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:20,863 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:21,037 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:21,121 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:21,236 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:21,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:21,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-heo48tzm', purging
2023-05-27 06:39:21,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_akrqhi', purging
2023-05-27 06:39:21,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03rlpbar', purging
2023-05-27 06:39:21,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_m8w3f2z', purging
2023-05-27 06:39:21,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an8a58m6', purging
2023-05-27 06:39:21,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0_07j3y', purging
2023-05-27 06:39:21,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:21,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:21,470 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:21,862 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-exlvcye3', purging
2023-05-27 06:39:21,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:21,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:22,199 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:22,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x3oarrxl', purging
2023-05-27 06:39:22,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:22,473 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:22,590 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-so7t7_u7', purging
2023-05-27 06:39:22,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:22,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:22,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:22,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:22,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:22,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:23,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:23,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:23,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:23,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:24,085 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:24,126 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:24,156 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:24,721 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:24,749 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:24,778 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:24,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:25,140 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:25,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7guy_dk', purging
2023-05-27 06:39:25,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k4nksakm', purging
2023-05-27 06:39:25,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g1scdvol', purging
2023-05-27 06:39:25,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7heusqoc', purging
2023-05-27 06:39:25,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-madd6mkg', purging
2023-05-27 06:39:25,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r8nxwbkv', purging
2023-05-27 06:39:25,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yb0kqbv3', purging
2023-05-27 06:39:25,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d33uqmsh', purging
2023-05-27 06:39:25,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:25,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:25,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:25,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:25,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:25,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:26,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:26,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:26,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:26,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:26,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:26,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:26,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:26,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:26,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:26,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:27,300 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:27,499 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:27,523 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:27,991 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:28,043 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:28,069 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:28,095 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:28,298 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:28,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c295o3i2', purging
2023-05-27 06:39:28,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kknacskv', purging
2023-05-27 06:39:28,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxj7c1b3', purging
2023-05-27 06:39:28,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ga72x95', purging
2023-05-27 06:39:28,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fi8qlz7w', purging
2023-05-27 06:39:28,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p19f60wl', purging
2023-05-27 06:39:28,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6xjr_e0', purging
2023-05-27 06:39:28,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05w3dd8b', purging
2023-05-27 06:39:28,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:28,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:28,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:28,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:29,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:29,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:30,137 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:30,961 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:30,993 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:31,313 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:31,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:31,363 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:31,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:31,561 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:31,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntxz6wof', purging
2023-05-27 06:39:31,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bf2_l_i', purging
2023-05-27 06:39:31,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_n5x_uh', purging
2023-05-27 06:39:31,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9ww7p2r', purging
2023-05-27 06:39:31,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hpxzi1w', purging
2023-05-27 06:39:31,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-27cqm0x5', purging
2023-05-27 06:39:31,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zf25i2qa', purging
2023-05-27 06:39:31,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5dz84yw', purging
2023-05-27 06:39:31,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:31,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:32,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:32,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldcpjw3m', purging
2023-05-27 06:39:32,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:32,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:32,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:32,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:32,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:32,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:32,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:33,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:33,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:33,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:33,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:34,033 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:34,235 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:34,734 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:34,764 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:34,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:34,817 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:34,844 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:35,145 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:35,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2fjyl5qy', purging
2023-05-27 06:39:35,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-syo1ft9c', purging
2023-05-27 06:39:35,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an1pl_fj', purging
2023-05-27 06:39:35,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37oillco', purging
2023-05-27 06:39:35,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8awa0g4v', purging
2023-05-27 06:39:35,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mr1bn2vh', purging
2023-05-27 06:39:35,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j414t6y', purging
2023-05-27 06:39:35,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-590dola1', purging
2023-05-27 06:39:35,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:35,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:35,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:35,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:36,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:36,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:36,928 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:36,957 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:37,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:38,014 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:38,039 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:38,085 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:38,120 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:38,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:38,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j629p_qw', purging
2023-05-27 06:39:38,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fc2dr_6', purging
2023-05-27 06:39:38,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zl5hhcie', purging
2023-05-27 06:39:38,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tx0ko2o', purging
2023-05-27 06:39:38,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-640_gtsq', purging
2023-05-27 06:39:38,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ocs892lf', purging
2023-05-27 06:39:38,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pe20x2ef', purging
2023-05-27 06:39:38,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20bxn9k9', purging
2023-05-27 06:39:38,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:38,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:38,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:38,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:39,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:39,459 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:39,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ki7vipx0', purging
2023-05-27 06:39:39,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p425p_l2', purging
2023-05-27 06:39:39,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:39,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:39,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:39,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:39,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:39,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:39,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:40,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:40,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:40,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:40,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:41,375 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:41,535 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:41,560 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:41,588 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:41,626 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:41,648 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:41,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:42,141 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:42,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2gkbs1h', purging
2023-05-27 06:39:42,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7s28w_8o', purging
2023-05-27 06:39:42,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-356ei1ek', purging
2023-05-27 06:39:42,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1rssrk71', purging
2023-05-27 06:39:42,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2w_xyht2', purging
2023-05-27 06:39:42,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oqe5kobm', purging
2023-05-27 06:39:42,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-le_bdsgx', purging
2023-05-27 06:39:42,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzxcr4fh', purging
2023-05-27 06:39:42,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:42,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:43,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:43,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:45,022 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,051 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,075 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,101 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:45,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:45,548 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:46,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jf5qtkse', purging
2023-05-27 06:39:46,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bb8upi4a', purging
2023-05-27 06:39:46,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2s81cr5f', purging
2023-05-27 06:39:46,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9swcgeq0', purging
2023-05-27 06:39:46,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5f0b0_08', purging
2023-05-27 06:39:46,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04aidqyy', purging
2023-05-27 06:39:46,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75t2segw', purging
2023-05-27 06:39:46,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d66thieo', purging
2023-05-27 06:39:46,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:46,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:46,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:47,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:47,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:48,442 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:48,653 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:48,693 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:48,725 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:48,744 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:48,791 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:48,935 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:49,108 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:49,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjglyfro', purging
2023-05-27 06:39:49,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e901ov6a', purging
2023-05-27 06:39:49,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-olp_yfr4', purging
2023-05-27 06:39:49,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xzp5r718', purging
2023-05-27 06:39:49,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ro4yex0_', purging
2023-05-27 06:39:49,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka8n54jq', purging
2023-05-27 06:39:49,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0iblamx6', purging
2023-05-27 06:39:49,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g34smrqu', purging
2023-05-27 06:39:49,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:49,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:50,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:50,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:51,595 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,003 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:52,208 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,285 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,287 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:52,371 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:52,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9vrqpqqv', purging
2023-05-27 06:39:52,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0ouv_a3', purging
2023-05-27 06:39:52,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m05wbetz', purging
2023-05-27 06:39:52,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cp157cts', purging
2023-05-27 06:39:52,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2w7xr1fi', purging
2023-05-27 06:39:52,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ex9s14oc', purging
2023-05-27 06:39:52,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fll5nbf3', purging
2023-05-27 06:39:52,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bix1odlx', purging
2023-05-27 06:39:52,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:52,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:53,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:53,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:53,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8187uay', purging
2023-05-27 06:39:53,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:53,819 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:53,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:53,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:53,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:53,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:54,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:54,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:55,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:55,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:55,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:55,773 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:55,814 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:55,842 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:55,866 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:55,894 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:56,091 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:56,365 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:57,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-js4bsw8f', purging
2023-05-27 06:39:57,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1gm6aay', purging
2023-05-27 06:39:57,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-db_u5nu7', purging
2023-05-27 06:39:57,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5lowck46', purging
2023-05-27 06:39:57,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dr9ybh6l', purging
2023-05-27 06:39:57,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-furer7r9', purging
2023-05-27 06:39:57,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wz020ztl', purging
2023-05-27 06:39:57,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5dbzjetw', purging
2023-05-27 06:39:57,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:39:57,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:39:57,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:39:59,641 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,674 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,703 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,755 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,794 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:39:59,857 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:00,130 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:01,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w7j2puky', purging
2023-05-27 06:40:01,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qje18f7x', purging
2023-05-27 06:40:01,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yct_kbzu', purging
2023-05-27 06:40:01,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jolbs__s', purging
2023-05-27 06:40:01,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lisms1cq', purging
2023-05-27 06:40:01,163 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vv7uwkzi', purging
2023-05-27 06:40:01,163 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ttfc8tv8', purging
2023-05-27 06:40:01,163 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-toq1ipgq', purging
2023-05-27 06:40:01,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:01,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:01,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:03,193 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:03,246 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:03,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:03,449 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:03,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:03,497 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:03,527 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:03,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:04,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4q9a31n9', purging
2023-05-27 06:40:04,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8l2wx0jv', purging
2023-05-27 06:40:04,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rfdwzu0', purging
2023-05-27 06:40:04,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z34yi3rk', purging
2023-05-27 06:40:04,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4sj7_4oj', purging
2023-05-27 06:40:04,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8c71w3bk', purging
2023-05-27 06:40:04,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64g__82e', purging
2023-05-27 06:40:04,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k_pmuxbs', purging
2023-05-27 06:40:04,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:04,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:04,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:04,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:04,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:04,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:04,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:04,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:04,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:04,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:05,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:05,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:05,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:05,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:05,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:05,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:06,568 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:06,751 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:06,775 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:06,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:07,006 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:07,085 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:07,116 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:07,296 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:08,038 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x819gpl1', purging
2023-05-27 06:40:08,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b5r2eyu7', purging
2023-05-27 06:40:08,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-776quo32', purging
2023-05-27 06:40:08,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-om0c2y4m', purging
2023-05-27 06:40:08,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-myid98j_', purging
2023-05-27 06:40:08,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7b36a3e', purging
2023-05-27 06:40:08,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh36b38l', purging
2023-05-27 06:40:08,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x66s8ezn', purging
2023-05-27 06:40:08,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:08,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:08,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:09,239 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:10,295 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:10,325 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:10,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:10,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:10,514 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:10,539 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:10,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7mgzfbc', purging
2023-05-27 06:40:10,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka6mshmz', purging
2023-05-27 06:40:10,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pezjtbz0', purging
2023-05-27 06:40:10,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1iskwai', purging
2023-05-27 06:40:10,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ph6o_ys', purging
2023-05-27 06:40:10,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zxb1j_1', purging
2023-05-27 06:40:10,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6727lmf8', purging
2023-05-27 06:40:10,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:10,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:10,743 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:11,488 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:11,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nw7i57ar', purging
2023-05-27 06:40:11,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dx74_97', purging
2023-05-27 06:40:11,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:11,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:11,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:11,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:11,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:11,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:12,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:12,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:12,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:12,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:12,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:12,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:12,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:12,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:12,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:12,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:13,754 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:13,809 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:13,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:14,028 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:14,060 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:14,217 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:14,259 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:14,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:15,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vcq3zdmt', purging
2023-05-27 06:40:15,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1qxtqvl', purging
2023-05-27 06:40:15,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dcjcb9y8', purging
2023-05-27 06:40:15,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jzkdua4', purging
2023-05-27 06:40:15,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4c2l1vys', purging
2023-05-27 06:40:15,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1er98d3m', purging
2023-05-27 06:40:15,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02zu75f9', purging
2023-05-27 06:40:15,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-quhuns63', purging
2023-05-27 06:40:15,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:15,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:15,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:17,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,393 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,408 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,444 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,496 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:17,711 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,750 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:17,923 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:18,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uej0u6xf', purging
2023-05-27 06:40:18,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1bziazm', purging
2023-05-27 06:40:18,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5tdk0_to', purging
2023-05-27 06:40:18,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1g_afitv', purging
2023-05-27 06:40:18,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0awdeqh_', purging
2023-05-27 06:40:18,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uxu_4wo0', purging
2023-05-27 06:40:18,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9iil3cn8', purging
2023-05-27 06:40:18,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kf3yk2lv', purging
2023-05-27 06:40:18,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:18,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:18,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:18,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:18,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:18,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:19,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:19,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:19,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:19,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:19,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:19,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:19,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:19,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:19,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:19,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:20,034 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:20,632 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:21,006 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:21,073 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:21,123 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:21,171 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:21,208 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:21,411 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:21,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jbnf0ji', purging
2023-05-27 06:40:21,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm3hdz0_', purging
2023-05-27 06:40:21,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wusnm_0z', purging
2023-05-27 06:40:21,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ff24rt09', purging
2023-05-27 06:40:21,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l8rj8ho3', purging
2023-05-27 06:40:21,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xp57cjfj', purging
2023-05-27 06:40:21,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5wzsn9e', purging
2023-05-27 06:40:21,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nc511rz6', purging
2023-05-27 06:40:21,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:21,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:22,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:22,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k143a98q', purging
2023-05-27 06:40:22,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:22,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:22,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:23,618 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:23,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ny7flct6', purging
2023-05-27 06:40:23,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:23,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:24,189 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:24,264 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:24,412 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:24,646 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:24,673 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:24,715 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:25,002 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:25,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68af9m62', purging
2023-05-27 06:40:25,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqsrri27', purging
2023-05-27 06:40:25,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ip9lasp', purging
2023-05-27 06:40:25,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37k1k57c', purging
2023-05-27 06:40:25,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ty8lzso', purging
2023-05-27 06:40:25,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-82czk7rd', purging
2023-05-27 06:40:25,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dukorlyk', purging
2023-05-27 06:40:25,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:25,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:25,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:25,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:25,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:25,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:25,877 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:25,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ecg1f4xp', purging
2023-05-27 06:40:25,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:25,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:26,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:26,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:26,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:26,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:26,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:26,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:26,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:26,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:27,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:27,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:27,487 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:27,522 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:27,715 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:27,960 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:28,167 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:28,197 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:28,248 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:28,525 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:28,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfhz0dnw', purging
2023-05-27 06:40:28,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x2f6_jtr', purging
2023-05-27 06:40:28,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntpcb8lc', purging
2023-05-27 06:40:28,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqw2jfth', purging
2023-05-27 06:40:28,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4rfgpasr', purging
2023-05-27 06:40:28,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-voi02unu', purging
2023-05-27 06:40:28,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4so0mkp4', purging
2023-05-27 06:40:28,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kffxx951', purging
2023-05-27 06:40:28,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:28,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:29,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:29,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:30,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:30,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:30,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:30,855 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:30,898 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:31,369 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:31,423 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:31,465 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:31,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:31,641 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:32,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5xzi3n23', purging
2023-05-27 06:40:32,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_alx6xy7', purging
2023-05-27 06:40:32,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78m5rq26', purging
2023-05-27 06:40:32,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hiushs82', purging
2023-05-27 06:40:32,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wt1v70ke', purging
2023-05-27 06:40:32,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9z__zsv5', purging
2023-05-27 06:40:32,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u9c76hy2', purging
2023-05-27 06:40:32,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iov6ht65', purging
2023-05-27 06:40:32,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:32,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:32,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:32,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:32,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:32,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:32,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:33,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:33,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:33,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:33,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:33,569 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:34,077 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:34,432 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:34,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:34,810 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:34,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:34,861 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:35,008 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:35,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6b6by0ji', purging
2023-05-27 06:40:35,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0izdv4z', purging
2023-05-27 06:40:35,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wj5u7kh', purging
2023-05-27 06:40:35,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0rp8n73', purging
2023-05-27 06:40:35,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asy5z_e8', purging
2023-05-27 06:40:35,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sb0srrjx', purging
2023-05-27 06:40:35,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktytcxnz', purging
2023-05-27 06:40:35,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-us9q1agj', purging
2023-05-27 06:40:35,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:35,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:35,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:35,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:35,828 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:35,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pm5c6_mo', purging
2023-05-27 06:40:35,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:35,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:36,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:36,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:36,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:36,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:36,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:36,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:36,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:36,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:36,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:36,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:36,732 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:37,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b_ic13qu', purging
2023-05-27 06:40:37,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tej7fg78', purging
2023-05-27 06:40:37,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:37,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:37,430 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:37,893 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:37,958 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:37,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:38,048 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:38,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ry5cvbio', purging
2023-05-27 06:40:38,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6v4_8r1w', purging
2023-05-27 06:40:38,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5f38p00', purging
2023-05-27 06:40:38,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vfb_ru7m', purging
2023-05-27 06:40:38,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:38,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:38,339 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:38,558 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:38,843 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:38,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0rkqbi8b', purging
2023-05-27 06:40:38,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2haxrer', purging
2023-05-27 06:40:38,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rt_rdi5n', purging
2023-05-27 06:40:38,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:38,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:39,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:39,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:39,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:39,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:39,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:39,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:39,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:39,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:39,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:39,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:40,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0m9cn2ox', purging
2023-05-27 06:40:40,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:40,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:40,256 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:40,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:40,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:40,700 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:40,935 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:40,977 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:40:41,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:41,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qrwycdb9', purging
2023-05-27 06:40:41,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ew14y2mp', purging
2023-05-27 06:40:41,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97tr3vm2', purging
2023-05-27 06:40:41,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ybnix4ww', purging
2023-05-27 06:40:41,760 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:41,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5wi0qdh', purging
2023-05-27 06:40:41,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xb47ib9f', purging
2023-05-27 06:40:41,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:41,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:41,825 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:42,237 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zb7m23nh', purging
2023-05-27 06:40:42,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:42,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:42,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:42,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:42,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:42,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:42,661 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:42,924 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:43,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:43,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8enx5qt1', purging
2023-05-27 06:40:43,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:43,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hixpn9lz', purging
2023-05-27 06:40:43,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:43,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:43,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:43,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0t2n5v4', purging
2023-05-27 06:40:43,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:43,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:43,535 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:44,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-og0s3ma_', purging
2023-05-27 06:40:44,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:44,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:44,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:44,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:44,705 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:44,756 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:44,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9fymrz1l', purging
2023-05-27 06:40:44,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-guldaubf', purging
2023-05-27 06:40:44,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pzu2ai0y', purging
2023-05-27 06:40:44,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:44,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:44,781 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:45,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:45,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:45,076 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:45,354 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:45,607 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:45,838 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:46,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9dpcaivm', purging
2023-05-27 06:40:46,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z6z06w9m', purging
2023-05-27 06:40:46,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c4ai896q', purging
2023-05-27 06:40:46,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yjai15h0', purging
2023-05-27 06:40:46,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:46,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:46,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:46,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:46,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:46,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:46,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:46,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:46,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:46,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:47,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:47,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:47,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:47,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:47,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:47,828 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:47,868 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:48,245 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:48,273 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:48,314 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:48,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:49,223 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3xhyllxu', purging
2023-05-27 06:40:49,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vth_phan', purging
2023-05-27 06:40:49,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aocwuoj0', purging
2023-05-27 06:40:49,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwnfo405', purging
2023-05-27 06:40:49,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q84704s9', purging
2023-05-27 06:40:49,225 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68ey5o8v', purging
2023-05-27 06:40:49,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gaw57hlh', purging
2023-05-27 06:40:49,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:49,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:49,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:49,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:49,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:49,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:49,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:50,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:50,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:51,014 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:51,063 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:51,076 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:51,382 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:51,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:51,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:51,638 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:52,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4b03xzj0', purging
2023-05-27 06:40:52,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ayhdw_1y', purging
2023-05-27 06:40:52,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4sl4j7_', purging
2023-05-27 06:40:52,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hml_g0cq', purging
2023-05-27 06:40:52,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpgca21d', purging
2023-05-27 06:40:52,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-01okbpvy', purging
2023-05-27 06:40:52,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idkmz3wu', purging
2023-05-27 06:40:52,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:52,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:52,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:52,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:52,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:52,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:52,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:53,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:53,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:54,290 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:54,326 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:54,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:54,627 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:54,652 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:54,820 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:55,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5e4odd5b', purging
2023-05-27 06:40:55,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jk_lrnbr', purging
2023-05-27 06:40:55,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofetanui', purging
2023-05-27 06:40:55,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbpzz93v', purging
2023-05-27 06:40:55,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mcj3njut', purging
2023-05-27 06:40:55,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xlzzymgs', purging
2023-05-27 06:40:55,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwszerm5', purging
2023-05-27 06:40:55,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:55,674 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:55,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:55,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:56,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:56,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:56,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:56,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:56,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:56,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:56,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:56,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:57,225 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:57,255 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:40:57,525 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:57,563 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:57,592 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:57,764 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:40:58,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5955qt7', purging
2023-05-27 06:40:58,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l31gdb2t', purging
2023-05-27 06:40:58,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jx6jz8rp', purging
2023-05-27 06:40:58,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgde7heu', purging
2023-05-27 06:40:58,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-niovmv5i', purging
2023-05-27 06:40:58,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g2pcpoys', purging
2023-05-27 06:40:58,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:58,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:58,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:58,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:58,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:58,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:59,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:59,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:59,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:59,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:40:59,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:40:59,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:00,325 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:00,349 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:00,417 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:00,562 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:00,597 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:00,789 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:01,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cpwy1j5n', purging
2023-05-27 06:41:01,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75lk35_d', purging
2023-05-27 06:41:01,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-38sl9xex', purging
2023-05-27 06:41:01,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lljeg7i1', purging
2023-05-27 06:41:01,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_67eyl5t', purging
2023-05-27 06:41:01,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-34dnpyo_', purging
2023-05-27 06:41:01,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:01,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:01,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:01,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:01,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:01,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:02,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:02,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:02,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:02,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:02,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:02,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:03,430 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:03,453 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:03,483 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:03,505 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:03,548 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:03,838 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:04,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7qxi3614', purging
2023-05-27 06:41:04,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05zv9mqh', purging
2023-05-27 06:41:04,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvjg1ke8', purging
2023-05-27 06:41:04,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gzr9z4f2', purging
2023-05-27 06:41:04,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d462bpj_', purging
2023-05-27 06:41:04,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b3qm5ymd', purging
2023-05-27 06:41:04,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:04,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:04,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:04,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:04,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:04,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:04,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:04,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:05,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:05,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:05,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:05,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:06,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:06,508 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:06,531 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:06,585 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:06,615 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:06,896 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:07,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nghi7976', purging
2023-05-27 06:41:07,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ibrr510', purging
2023-05-27 06:41:07,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akjmtxqq', purging
2023-05-27 06:41:07,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gwk_v0es', purging
2023-05-27 06:41:07,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_2crb_o', purging
2023-05-27 06:41:07,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6h5i4o2_', purging
2023-05-27 06:41:07,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:07,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:07,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:07,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:07,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:07,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:08,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:08,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:08,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:08,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:08,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:08,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:09,703 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:09,765 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:09,798 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:09,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:09,849 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:10,001 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:11,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bs_euu5n', purging
2023-05-27 06:41:11,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkcyjqqx', purging
2023-05-27 06:41:11,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7a_6psg', purging
2023-05-27 06:41:11,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ne5ki58z', purging
2023-05-27 06:41:11,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kr7hj309', purging
2023-05-27 06:41:11,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-anhef0dz', purging
2023-05-27 06:41:11,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:11,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:11,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:11,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:11,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:11,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:11,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:12,866 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:12,925 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:12,954 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:12,976 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:13,005 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:13,184 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:14,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8uajkc1', purging
2023-05-27 06:41:14,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ayi3_ctj', purging
2023-05-27 06:41:14,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3aw_ov1e', purging
2023-05-27 06:41:14,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_daiosq', purging
2023-05-27 06:41:14,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p58ac8qx', purging
2023-05-27 06:41:14,254 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-okulgaie', purging
2023-05-27 06:41:14,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:14,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:14,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:14,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:14,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:14,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:14,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:15,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:15,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:16,031 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:16,044 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:16,091 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:16,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:17,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-awuvck6f', purging
2023-05-27 06:41:17,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gr9vjgey', purging
2023-05-27 06:41:17,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_eh77pie', purging
2023-05-27 06:41:17,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5kijhrhv', purging
2023-05-27 06:41:17,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkh5firr', purging
2023-05-27 06:41:17,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ehx1g6_x', purging
2023-05-27 06:41:17,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:17,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:17,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:17,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:17,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:17,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:17,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:19,027 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:19,051 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:19,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:19,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:19,155 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:19,440 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:20,521 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7p6a79c9', purging
2023-05-27 06:41:20,521 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k56ioj41', purging
2023-05-27 06:41:20,521 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7dh4rb_j', purging
2023-05-27 06:41:20,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qwu1k_ng', purging
2023-05-27 06:41:20,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngx12pz2', purging
2023-05-27 06:41:20,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvvf5oy5', purging
2023-05-27 06:41:20,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:20,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:20,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:20,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:20,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:20,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:20,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:22,267 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:22,295 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:22,332 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:22,359 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:22,379 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:22,560 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:23,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-efi48x18', purging
2023-05-27 06:41:23,768 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_69p38f1', purging
2023-05-27 06:41:23,768 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1l32g9uc', purging
2023-05-27 06:41:23,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9l2ig2z', purging
2023-05-27 06:41:23,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5r1tus58', purging
2023-05-27 06:41:23,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tb0ntyu', purging
2023-05-27 06:41:23,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:23,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:23,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:23,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:23,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:23,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:23,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:23,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:23,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:23,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:24,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:24,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:25,468 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:25,529 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:25,557 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:25,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:25,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:25,755 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:26,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jrm92cqo', purging
2023-05-27 06:41:26,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-34fhum2r', purging
2023-05-27 06:41:26,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbyg3gzy', purging
2023-05-27 06:41:26,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9vs59e6x', purging
2023-05-27 06:41:26,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1cg6dnvj', purging
2023-05-27 06:41:26,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93r1yos7', purging
2023-05-27 06:41:26,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:26,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:27,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:27,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:27,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:27,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:27,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:27,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:27,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:27,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:27,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:27,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:28,657 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:28,719 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:28,741 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:28,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:28,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:28,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:30,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqkbui9a', purging
2023-05-27 06:41:30,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ch_3thfv', purging
2023-05-27 06:41:30,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djmu0p28', purging
2023-05-27 06:41:30,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24s0f4s5', purging
2023-05-27 06:41:30,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7eer6pos', purging
2023-05-27 06:41:30,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z5aq1kr6', purging
2023-05-27 06:41:30,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:30,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:30,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:30,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:30,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:30,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:30,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:31,932 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:31,986 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:32,008 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:32,034 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:32,060 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:32,231 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:33,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m685bdzd', purging
2023-05-27 06:41:33,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yjonhih', purging
2023-05-27 06:41:33,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8m6hm8f', purging
2023-05-27 06:41:33,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zz4c3ah5', purging
2023-05-27 06:41:33,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gi6nff5h', purging
2023-05-27 06:41:33,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jgjte1d6', purging
2023-05-27 06:41:33,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:33,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:33,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:33,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:33,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:33,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:33,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:35,211 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:35,242 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:35,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:35,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:35,332 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:35,478 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:36,646 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvm8rpaa', purging
2023-05-27 06:41:36,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uo7xpo_e', purging
2023-05-27 06:41:36,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-49i3r1dc', purging
2023-05-27 06:41:36,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wyj34zq7', purging
2023-05-27 06:41:36,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-icrx030u', purging
2023-05-27 06:41:36,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofai6fa2', purging
2023-05-27 06:41:36,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,649 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:36,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:36,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:36,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:36,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:36,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:36,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:38,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:38,440 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:38,462 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:38,491 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:38,513 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:38,661 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:39,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ruh8pgyh', purging
2023-05-27 06:41:39,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c5kjje03', purging
2023-05-27 06:41:39,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j97e3il8', purging
2023-05-27 06:41:39,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-812a4qac', purging
2023-05-27 06:41:39,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9vc_2xid', purging
2023-05-27 06:41:39,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrhruegm', purging
2023-05-27 06:41:39,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:39,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:39,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:39,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:39,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:39,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:39,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:39,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:39,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:39,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:40,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:40,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:41,614 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:41,667 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:41,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:41,721 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:41,742 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:41,891 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:43,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-glughkzo', purging
2023-05-27 06:41:43,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b95jnoey', purging
2023-05-27 06:41:43,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2cpa2gb', purging
2023-05-27 06:41:43,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vqz92msy', purging
2023-05-27 06:41:43,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_cozqgur', purging
2023-05-27 06:41:43,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_kdw68n', purging
2023-05-27 06:41:43,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:43,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:43,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:43,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:43,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:43,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:43,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:44,876 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:44,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:44,937 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:44,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:44,989 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:45,156 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:46,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-giv0l8x1', purging
2023-05-27 06:41:46,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h7t7zaye', purging
2023-05-27 06:41:46,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzkiaj6q', purging
2023-05-27 06:41:46,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mzccr3vd', purging
2023-05-27 06:41:46,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-luwghbie', purging
2023-05-27 06:41:46,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ro1udw1j', purging
2023-05-27 06:41:46,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:46,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:46,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:46,471 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,471 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:46,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:46,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:46,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:48,112 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:48,174 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:48,196 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:48,228 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:48,246 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:48,417 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:49,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9o4y0f7', purging
2023-05-27 06:41:49,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3o2jl6tj', purging
2023-05-27 06:41:49,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqdbidp4', purging
2023-05-27 06:41:49,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sq2cwtz', purging
2023-05-27 06:41:49,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cjzsqmg3', purging
2023-05-27 06:41:49,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dloo30ab', purging
2023-05-27 06:41:49,610 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,610 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:49,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:49,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:49,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:49,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:49,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:49,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:51,344 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:51,377 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:51,396 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:51,438 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:51,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:51,617 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:52,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xeqmgt0w', purging
2023-05-27 06:41:52,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5i8cao76', purging
2023-05-27 06:41:52,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_g285zl', purging
2023-05-27 06:41:52,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwqpruk4', purging
2023-05-27 06:41:52,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5hsyr93', purging
2023-05-27 06:41:52,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pp4ou9v5', purging
2023-05-27 06:41:52,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:52,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:52,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:52,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:52,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:52,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:52,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:52,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:52,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:52,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:53,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:53,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:54,463 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:54,524 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:54,560 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:54,571 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:54,612 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:54,775 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:55,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kb5m213f', purging
2023-05-27 06:41:55,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmx4m0zn', purging
2023-05-27 06:41:55,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1_21ode', purging
2023-05-27 06:41:55,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2958_7hx', purging
2023-05-27 06:41:55,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sxn37w91', purging
2023-05-27 06:41:55,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-435iphhw', purging
2023-05-27 06:41:55,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:55,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:56,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:56,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:56,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:56,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:56,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:56,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:56,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:56,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:56,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:56,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:41:57,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:57,749 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:57,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:57,825 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:57,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:57,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:41:59,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fxv_m77', purging
2023-05-27 06:41:59,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9ypxu83', purging
2023-05-27 06:41:59,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9vkd586', purging
2023-05-27 06:41:59,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uthe_rm4', purging
2023-05-27 06:41:59,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lnku9x59', purging
2023-05-27 06:41:59,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8jsi84hn', purging
2023-05-27 06:41:59,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:59,242 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:59,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:59,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:59,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:41:59,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:41:59,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:00,851 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:00,913 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:42:01,093 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:01,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:01,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:02,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7kuspq0e', purging
2023-05-27 06:42:02,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqlvqc0w', purging
2023-05-27 06:42:02,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4tlqrlt', purging
2023-05-27 06:42:02,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nsqibyjm', purging
2023-05-27 06:42:02,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fvryq4mg', purging
2023-05-27 06:42:02,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pq_pb9cm', purging
2023-05-27 06:42:02,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:02,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:02,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:02,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:02,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:02,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:02,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:02,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:02,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:02,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:03,551 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:03,578 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:03,753 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:03,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:03,968 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:04,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7ttdhc7', purging
2023-05-27 06:42:04,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh3yhzgz', purging
2023-05-27 06:42:04,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ukq30pqe', purging
2023-05-27 06:42:04,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0zeh1tbp', purging
2023-05-27 06:42:04,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kipcv9to', purging
2023-05-27 06:42:04,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:04,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:05,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:05,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:05,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:05,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:05,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:05,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:05,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:05,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:06,378 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:06,404 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:06,449 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:06,476 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:06,773 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:07,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zn60b9wt', purging
2023-05-27 06:42:07,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sgz_3l6', purging
2023-05-27 06:42:07,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_eu8xz6z', purging
2023-05-27 06:42:07,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijq33600', purging
2023-05-27 06:42:07,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8kignj7c', purging
2023-05-27 06:42:07,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:07,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:07,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:07,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:07,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:07,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:07,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:07,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:08,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:08,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:09,255 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:09,310 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:09,348 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:09,358 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:09,632 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:10,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmybuz_4', purging
2023-05-27 06:42:10,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-87tll32q', purging
2023-05-27 06:42:10,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xzca836t', purging
2023-05-27 06:42:10,738 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37g64gdb', purging
2023-05-27 06:42:10,738 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apm9rauc', purging
2023-05-27 06:42:10,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:10,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:10,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:10,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:10,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:10,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:10,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:10,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:11,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:11,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:12,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:12,259 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:12,302 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:42:12,544 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:13,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_11mpo9', purging
2023-05-27 06:42:13,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7a25smn', purging
2023-05-27 06:42:13,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x0jqk9n7', purging
2023-05-27 06:42:13,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y30glys3', purging
2023-05-27 06:42:13,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_v33xxx1', purging
2023-05-27 06:42:13,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:13,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:13,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:13,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:13,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:13,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:13,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:13,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:14,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:14,774 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:14,810 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:15,087 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:16,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2or5dwam', purging
2023-05-27 06:42:16,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvncx_4z', purging
2023-05-27 06:42:16,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wrwh7mif', purging
2023-05-27 06:42:16,135 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-osgxwn7f', purging
2023-05-27 06:42:16,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:16,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:16,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:16,166 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:16,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:16,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:16,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:16,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:17,397 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:17,423 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:17,445 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:17,688 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:18,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3nn5l01k', purging
2023-05-27 06:42:18,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xqsux2e', purging
2023-05-27 06:42:18,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_xypjjy', purging
2023-05-27 06:42:18,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5z_4e_u', purging
2023-05-27 06:42:18,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:18,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:18,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:18,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:18,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:18,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:19,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:19,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:20,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:20,118 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:20,142 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:20,311 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:21,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csp703_f', purging
2023-05-27 06:42:21,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_wt7zyc', purging
2023-05-27 06:42:21,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-la0mpavs', purging
2023-05-27 06:42:21,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kgextdqe', purging
2023-05-27 06:42:21,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:21,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:21,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:21,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:21,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:21,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:21,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:21,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:22,766 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:22,788 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:22,826 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:22,986 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:24,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tt2z7njo', purging
2023-05-27 06:42:24,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-35p2ucmo', purging
2023-05-27 06:42:24,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uy13lzuy', purging
2023-05-27 06:42:24,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o5yjey2x', purging
2023-05-27 06:42:24,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:24,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:24,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:24,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:24,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:24,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:24,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:24,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:25,367 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:25,394 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:25,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:25,582 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:26,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2q6t3atv', purging
2023-05-27 06:42:26,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-niv0lo10', purging
2023-05-27 06:42:26,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3u5cihcj', purging
2023-05-27 06:42:26,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2rd6hmao', purging
2023-05-27 06:42:26,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:26,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:26,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:26,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:26,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:26,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:27,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:27,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:28,019 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:28,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:28,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:28,253 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:29,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zg5nmqpy', purging
2023-05-27 06:42:29,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7t571lf', purging
2023-05-27 06:42:29,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-28j5w1qt', purging
2023-05-27 06:42:29,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t8zh41v3', purging
2023-05-27 06:42:29,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:29,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:29,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:29,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:29,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:29,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:29,658 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:29,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:30,675 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:30,707 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:30,734 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:30,910 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:32,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dz1gebw9', purging
2023-05-27 06:42:32,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s6oqhkny', purging
2023-05-27 06:42:32,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b1bi76yc', purging
2023-05-27 06:42:32,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whh6rxth', purging
2023-05-27 06:42:32,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:32,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:32,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:32,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:32,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:32,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:32,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:32,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:33,345 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:33,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:33,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:33,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:34,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8pgpfy4', purging
2023-05-27 06:42:34,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwlb1fmp', purging
2023-05-27 06:42:34,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5s6c9o0t', purging
2023-05-27 06:42:34,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xcxsh933', purging
2023-05-27 06:42:34,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:34,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:34,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:34,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:34,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:34,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:34,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:34,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:36,034 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:36,063 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:36,084 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:36,242 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:37,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldhh6gxv', purging
2023-05-27 06:42:37,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tsbtl0ny', purging
2023-05-27 06:42:37,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ym4xp2x', purging
2023-05-27 06:42:37,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tlqhtep_', purging
2023-05-27 06:42:37,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:37,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:37,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:37,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:37,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:37,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:37,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:37,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:38,678 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:38,726 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:38,751 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:38,915 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:40,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ame72a41', purging
2023-05-27 06:42:40,114 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9kpa3lqa', purging
2023-05-27 06:42:40,114 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ta4mayc3', purging
2023-05-27 06:42:40,114 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_z_39d_k', purging
2023-05-27 06:42:40,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:40,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:40,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:40,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:40,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:40,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:40,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:40,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:41,405 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:41,431 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:41,454 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:41,615 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:42,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0eheu7cr', purging
2023-05-27 06:42:42,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fyu168i3', purging
2023-05-27 06:42:42,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljgxdkje', purging
2023-05-27 06:42:42,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2b_24dfp', purging
2023-05-27 06:42:42,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:42,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:42,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:42,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:42,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:42,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:43,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:43,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:44,107 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:44,149 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:44,173 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:44,353 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:45,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7iohy0u', purging
2023-05-27 06:42:45,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmyoxiay', purging
2023-05-27 06:42:45,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dnt8uy63', purging
2023-05-27 06:42:45,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nuzpwmz0', purging
2023-05-27 06:42:45,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:45,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:45,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:45,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:45,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:45,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:45,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:45,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:46,783 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:46,809 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:46,833 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:47,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:48,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y0gmpn49', purging
2023-05-27 06:42:48,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dl7r09uy', purging
2023-05-27 06:42:48,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frnss0vj', purging
2023-05-27 06:42:48,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7o76suad', purging
2023-05-27 06:42:48,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:48,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:48,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:48,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:48,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:48,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:48,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:48,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:49,480 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:49,529 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:49,559 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:49,711 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:50,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4odyevs2', purging
2023-05-27 06:42:50,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9fqm20p', purging
2023-05-27 06:42:50,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0auv22_y', purging
2023-05-27 06:42:50,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdjct_lx', purging
2023-05-27 06:42:50,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:50,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:50,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:50,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:50,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:50,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:51,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:51,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:52,133 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:52,178 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:52,201 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:52,357 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:53,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7l9mxe9a', purging
2023-05-27 06:42:53,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kx3akiup', purging
2023-05-27 06:42:53,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w2z_rv5_', purging
2023-05-27 06:42:53,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_oh1gqo', purging
2023-05-27 06:42:53,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:53,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:53,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:53,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:53,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:53,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:53,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:53,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:54,815 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:54,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:54,872 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:55,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:56,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bcq9hr9', purging
2023-05-27 06:42:56,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-caf1hd58', purging
2023-05-27 06:42:56,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wnvjn0gn', purging
2023-05-27 06:42:56,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ho7tdndm', purging
2023-05-27 06:42:56,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:56,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:56,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:56,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:56,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:56,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:56,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:56,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:42:57,544 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:57,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:57,611 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:57,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:42:58,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nny1hxd7', purging
2023-05-27 06:42:58,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_lirjejx', purging
2023-05-27 06:42:58,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dad806_e', purging
2023-05-27 06:42:58,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmhx_mtf', purging
2023-05-27 06:42:58,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:58,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:58,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:58,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:58,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:58,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:42:59,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:42:59,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:00,245 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:00,294 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:00,296 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:00,463 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:01,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8610sl56', purging
2023-05-27 06:43:01,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-po6qxsdx', purging
2023-05-27 06:43:01,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tc_k9xcq', purging
2023-05-27 06:43:01,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mrvb2nzz', purging
2023-05-27 06:43:01,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:01,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:01,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:01,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:01,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:01,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:01,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:01,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:02,874 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:02,920 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:02,946 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:03,126 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:04,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahlzz4ms', purging
2023-05-27 06:43:04,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0jajvqa', purging
2023-05-27 06:43:04,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w82s840i', purging
2023-05-27 06:43:04,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x0mtu496', purging
2023-05-27 06:43:04,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:04,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:04,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:04,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:04,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:04,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:04,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:04,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:05,528 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:05,567 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:05,584 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:05,764 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:06,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-egzu7igh', purging
2023-05-27 06:43:06,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-393igvu4', purging
2023-05-27 06:43:06,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21saye_0', purging
2023-05-27 06:43:06,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k5j2f1do', purging
2023-05-27 06:43:06,915 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:06,915 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:06,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:06,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:06,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:06,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:07,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:07,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:08,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:08,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:08,230 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:08,411 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:09,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aa8u2d3l', purging
2023-05-27 06:43:09,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oe9xdp9k', purging
2023-05-27 06:43:09,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ac7_t9f', purging
2023-05-27 06:43:09,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufl49dxb', purging
2023-05-27 06:43:09,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:09,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:09,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:09,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:09,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:09,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:09,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:09,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:10,834 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:10,878 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:10,917 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:11,070 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:12,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqt24tyo', purging
2023-05-27 06:43:12,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zzyg5otj', purging
2023-05-27 06:43:12,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nj_1hnd6', purging
2023-05-27 06:43:12,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2dw7tau', purging
2023-05-27 06:43:12,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:12,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:12,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:12,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:12,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:12,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:12,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:12,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:13,452 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:13,490 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:13,521 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:13,675 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:14,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7y2uj_6m', purging
2023-05-27 06:43:14,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ckugm7oq', purging
2023-05-27 06:43:14,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2wn1eam', purging
2023-05-27 06:43:14,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6jcte6zi', purging
2023-05-27 06:43:14,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:14,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:14,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:14,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:14,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:14,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:15,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:15,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:16,108 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:16,153 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:16,177 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:16,334 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:17,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rttjnsc3', purging
2023-05-27 06:43:17,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17d6h0aj', purging
2023-05-27 06:43:17,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yl9jd8gp', purging
2023-05-27 06:43:17,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bcezickm', purging
2023-05-27 06:43:17,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:17,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:17,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:17,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:17,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:17,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:17,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:17,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:18,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:18,814 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:18,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:19,006 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:20,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sxe_83b4', purging
2023-05-27 06:43:20,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ci3ose8i', purging
2023-05-27 06:43:20,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yi4z6lv_', purging
2023-05-27 06:43:20,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0wevkqp', purging
2023-05-27 06:43:20,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:20,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:20,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:20,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:20,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:20,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:20,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:20,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:21,512 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:21,556 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:21,582 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:21,751 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:22,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9gzl_cvn', purging
2023-05-27 06:43:22,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zqpy0z87', purging
2023-05-27 06:43:22,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovkjj5v_', purging
2023-05-27 06:43:22,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_1rp89q', purging
2023-05-27 06:43:22,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:22,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:22,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:22,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:22,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:22,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:23,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:23,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:24,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:24,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:24,232 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:24,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:25,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxt6pvi1', purging
2023-05-27 06:43:25,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x0jp_9mj', purging
2023-05-27 06:43:25,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_deq0tfb', purging
2023-05-27 06:43:25,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4raxtuy8', purging
2023-05-27 06:43:25,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:25,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:25,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:25,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:25,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:25,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:25,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:25,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:26,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:26,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:26,944 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:27,095 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:28,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ty_o5u9a', purging
2023-05-27 06:43:28,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j4dekm2i', purging
2023-05-27 06:43:28,303 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gw8_lzq', purging
2023-05-27 06:43:28,303 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-810tbdcw', purging
2023-05-27 06:43:28,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:28,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:28,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:28,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:28,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:28,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:28,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:28,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:29,587 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:43:29,679 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:29,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:30,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7g6i_ya', purging
2023-05-27 06:43:30,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8jhf8at9', purging
2023-05-27 06:43:30,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nw5yqd32', purging
2023-05-27 06:43:30,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_83hyipf', purging
2023-05-27 06:43:30,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:30,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:31,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:31,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:31,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:31,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:32,020 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:32,056 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:32,215 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:33,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ncj6o2u', purging
2023-05-27 06:43:33,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-km8yijfm', purging
2023-05-27 06:43:33,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_l7ytqpg', purging
2023-05-27 06:43:33,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:33,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:33,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:33,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:33,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:33,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:34,462 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:34,509 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:34,662 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:35,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8hp8zsh', purging
2023-05-27 06:43:35,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkxv23w0', purging
2023-05-27 06:43:35,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bygrb3m1', purging
2023-05-27 06:43:35,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:35,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:35,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:35,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:36,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:36,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:36,884 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:36,910 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:37,076 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:38,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngpa5qu2', purging
2023-05-27 06:43:38,275 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mn6ow2_w', purging
2023-05-27 06:43:38,275 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5yxkgpw', purging
2023-05-27 06:43:38,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:38,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:38,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:38,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:38,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:38,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:39,344 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:39,369 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:39,533 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:40,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xf7x59ec', purging
2023-05-27 06:43:40,740 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mtmdnzhf', purging
2023-05-27 06:43:40,740 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkx6ju7s', purging
2023-05-27 06:43:40,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:40,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:40,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:40,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:40,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:40,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:41,810 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:41,970 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:43,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gn0zm1d_', purging
2023-05-27 06:43:43,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3218hve', purging
2023-05-27 06:43:43,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w2wp001', purging
2023-05-27 06:43:43,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:43,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:43,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:43,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:44,026 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:44,187 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:45,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cy83jp3a', purging
2023-05-27 06:43:45,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7sa0_3k', purging
2023-05-27 06:43:45,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:45,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:45,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:45,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:46,213 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:46,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:47,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42rvd75q', purging
2023-05-27 06:43:47,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8msmvnvx', purging
2023-05-27 06:43:47,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:47,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:47,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:47,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:48,395 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:48,554 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:49,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vw4nn7f7', purging
2023-05-27 06:43:49,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vaaxy03y', purging
2023-05-27 06:43:49,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:49,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:49,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:49,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:50,609 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:50,776 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:51,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43__dl3r', purging
2023-05-27 06:43:51,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i2anasei', purging
2023-05-27 06:43:51,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:51,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:52,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:52,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:52,831 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:52,999 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:54,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9_fa4de', purging
2023-05-27 06:43:54,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s37p8k6h', purging
2023-05-27 06:43:54,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:54,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:54,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:54,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:54,961 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:55,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:56,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xc9rm5f3', purging
2023-05-27 06:43:56,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zc6bh0ml', purging
2023-05-27 06:43:56,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:56,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:56,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:56,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:57,136 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:57,302 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:58,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xzdaznk', purging
2023-05-27 06:43:58,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-14723qhp', purging
2023-05-27 06:43:58,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:58,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:43:58,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:43:58,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:43:59,301 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:43:59,474 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:00,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dac8krpj', purging
2023-05-27 06:44:00,662 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6e9q97e', purging
2023-05-27 06:44:00,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:00,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:00,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:00,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:01,499 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:01,672 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:02,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36lbsuln', purging
2023-05-27 06:44:02,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3r_mp594', purging
2023-05-27 06:44:02,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:02,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:03,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:03,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:03,663 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:03,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:04,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3l6bnobg', purging
2023-05-27 06:44:04,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-azen2fw7', purging
2023-05-27 06:44:04,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:04,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:05,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:05,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:05,795 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:05,965 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:07,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ehzsv61', purging
2023-05-27 06:44:07,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9srsq3kr', purging
2023-05-27 06:44:07,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:07,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:07,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:07,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:08,014 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:08,184 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:09,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wne92_ro', purging
2023-05-27 06:44:09,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htyll0sw', purging
2023-05-27 06:44:09,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:09,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:09,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:09,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:10,311 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:10,490 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:11,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cu8qdhi', purging
2023-05-27 06:44:11,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mr7dmn4_', purging
2023-05-27 06:44:11,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:11,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:11,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:11,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:12,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:12,681 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:13,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8bm_l087', purging
2023-05-27 06:44:13,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8b86di1o', purging
2023-05-27 06:44:13,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:13,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:14,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:14,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:14,752 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:14,924 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:16,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wv669x23', purging
2023-05-27 06:44:16,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhb0vwbh', purging
2023-05-27 06:44:16,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:16,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:16,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:16,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:16,930 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:17,106 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:18,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqcm966w', purging
2023-05-27 06:44:18,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynslpi_u', purging
2023-05-27 06:44:18,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:18,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:18,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:18,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:19,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:19,283 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:20,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bl0o46y1', purging
2023-05-27 06:44:20,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-raa0ljad', purging
2023-05-27 06:44:20,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:20,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:20,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:20,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:21,318 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:21,507 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:22,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8f5o0oqn', purging
2023-05-27 06:44:22,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0e9jqa2m', purging
2023-05-27 06:44:22,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:22,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:22,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:22,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:23,459 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:23,635 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:24,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2879k38w', purging
2023-05-27 06:44:24,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1uk__s7f', purging
2023-05-27 06:44:24,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:24,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:24,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:24,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:25,608 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:25,788 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:26,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgim_zru', purging
2023-05-27 06:44:26,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkr2xg4u', purging
2023-05-27 06:44:26,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:26,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:27,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:27,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:27,774 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:27,937 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:29,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32uky2sr', purging
2023-05-27 06:44:29,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1vaqgo1', purging
2023-05-27 06:44:29,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:29,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:29,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:29,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:29,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:30,120 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:31,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0prlzq0n', purging
2023-05-27 06:44:31,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gblafzq8', purging
2023-05-27 06:44:31,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:31,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:31,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:31,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:32,108 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:32,277 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:33,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wxef8of', purging
2023-05-27 06:44:33,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6krx1rq1', purging
2023-05-27 06:44:33,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:33,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:33,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:33,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:34,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:34,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:35,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bopxy6h5', purging
2023-05-27 06:44:35,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8cjdhx87', purging
2023-05-27 06:44:35,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:35,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:35,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:35,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:36,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:36,579 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:37,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xa2lpgoh', purging
2023-05-27 06:44:37,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-26lcinhv', purging
2023-05-27 06:44:37,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:37,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:37,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:37,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:38,616 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:38,781 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:39,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-giwd3ob7', purging
2023-05-27 06:44:39,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ute9p986', purging
2023-05-27 06:44:39,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:39,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:40,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:40,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:40,799 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:40,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:42,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1fty4k5', purging
2023-05-27 06:44:42,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vzta22h', purging
2023-05-27 06:44:42,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:42,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:42,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:42,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:42,943 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:43,111 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:44,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l8tcp72k', purging
2023-05-27 06:44:44,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkfdolrk', purging
2023-05-27 06:44:44,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:44,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:44,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:44,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:45,063 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:45,232 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:46,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvf49g64', purging
2023-05-27 06:44:46,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wtzny_tg', purging
2023-05-27 06:44:46,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:46,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:46,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:46,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:47,264 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:47,439 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:48,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_dzjncff', purging
2023-05-27 06:44:48,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-phlonvzw', purging
2023-05-27 06:44:48,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:48,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:48,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:48,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:49,443 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:49,604 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:50,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1uyurbs7', purging
2023-05-27 06:44:50,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nz2ikgt_', purging
2023-05-27 06:44:50,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:50,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:50,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:50,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:51,621 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:51,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:52,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74xoi8ue', purging
2023-05-27 06:44:52,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_dwwfnod', purging
2023-05-27 06:44:52,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:52,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:53,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:53,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:53,823 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:53,988 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:55,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxspiojz', purging
2023-05-27 06:44:55,195 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fnr_jmkb', purging
2023-05-27 06:44:55,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:55,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:55,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:55,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:56,030 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:56,205 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:57,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_84972p', purging
2023-05-27 06:44:57,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zz0q668_', purging
2023-05-27 06:44:57,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:57,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:57,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:57,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:44:58,199 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:58,381 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:44:59,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfz51dla', purging
2023-05-27 06:44:59,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bpko6nvc', purging
2023-05-27 06:44:59,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:59,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:44:59,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:44:59,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:00,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:00,595 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:01,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9n8_ftc', purging
2023-05-27 06:45:01,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rp922wfc', purging
2023-05-27 06:45:01,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:01,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:01,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:01,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:02,653 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:02,816 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:03,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-luhxnyzn', purging
2023-05-27 06:45:03,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3pf44aqf', purging
2023-05-27 06:45:03,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:03,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:04,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:04,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:04,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:04,968 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:06,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7jen95r', purging
2023-05-27 06:45:06,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-84bkqxhu', purging
2023-05-27 06:45:06,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:06,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:06,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:06,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:06,981 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:07,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:08,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-smfzbwqn', purging
2023-05-27 06:45:08,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1lm33a0t', purging
2023-05-27 06:45:08,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:08,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:08,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:08,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:09,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:09,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:10,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o6wf5fk4', purging
2023-05-27 06:45:10,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlvdv_87', purging
2023-05-27 06:45:10,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:10,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:10,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:10,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:11,260 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:11,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:12,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f1glm_y_', purging
2023-05-27 06:45:12,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-028hd1e_', purging
2023-05-27 06:45:12,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:12,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:12,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:12,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:13,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:13,611 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:14,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jrv1s_7v', purging
2023-05-27 06:45:14,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i429adfg', purging
2023-05-27 06:45:14,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:14,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:14,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:14,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:15,612 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:15,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:16,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3u075ng', purging
2023-05-27 06:45:16,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r21uga_9', purging
2023-05-27 06:45:16,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:16,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:17,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:17,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:17,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:18,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:19,158 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpw7co46', purging
2023-05-27 06:45:19,158 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eop3az5d', purging
2023-05-27 06:45:19,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:19,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:19,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:19,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:19,979 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:20,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:21,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djftm14w', purging
2023-05-27 06:45:21,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41khjq2y', purging
2023-05-27 06:45:21,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:21,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:21,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:21,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:22,142 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:22,312 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:23,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oy4gj08n', purging
2023-05-27 06:45:23,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4je_ij9c', purging
2023-05-27 06:45:23,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:23,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:23,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:23,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:24,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:24,443 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:25,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6c757pwz', purging
2023-05-27 06:45:25,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jlpx5t__', purging
2023-05-27 06:45:25,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:25,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:25,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:25,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:26,452 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:26,625 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:27,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwj2mi8o', purging
2023-05-27 06:45:27,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3m_dnakg', purging
2023-05-27 06:45:27,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:27,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:28,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:28,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:28,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:28,785 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:29,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_u2ktzs', purging
2023-05-27 06:45:29,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cylrig1p', purging
2023-05-27 06:45:29,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:29,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:30,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:30,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:30,743 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:30,915 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:32,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duz3tv8c', purging
2023-05-27 06:45:32,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rz19i_zc', purging
2023-05-27 06:45:32,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:32,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:32,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:32,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:32,874 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:33,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:34,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4mvfy9wj', purging
2023-05-27 06:45:34,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7irzc9w8', purging
2023-05-27 06:45:34,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:34,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:34,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:34,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:35,079 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:35,255 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:36,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cuapp0to', purging
2023-05-27 06:45:36,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-efg70d0n', purging
2023-05-27 06:45:36,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:36,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:36,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:36,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:37,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:37,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:38,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fwjy1251', purging
2023-05-27 06:45:38,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nj2k4dwl', purging
2023-05-27 06:45:38,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:38,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:38,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:38,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:39,424 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:39,584 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:40,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m67zop4c', purging
2023-05-27 06:45:40,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-teksh8zt', purging
2023-05-27 06:45:40,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:40,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:40,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:40,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:41,563 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:41,732 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:42,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2h6eenv', purging
2023-05-27 06:45:42,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7a0tkco', purging
2023-05-27 06:45:42,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:42,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:43,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:43,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:43,713 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:43,881 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:45,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouqw0pc0', purging
2023-05-27 06:45:45,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1iul369g', purging
2023-05-27 06:45:45,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:45,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:45,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:45,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:45,883 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:46,061 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:47,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-44sfwwmj', purging
2023-05-27 06:45:47,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9b3zu58', purging
2023-05-27 06:45:47,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:47,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:47,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:47,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:48,086 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:48,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:49,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-144ucb24', purging
2023-05-27 06:45:49,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rvd_80j9', purging
2023-05-27 06:45:49,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:49,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:49,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:49,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:50,264 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:50,428 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:51,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v3sq5abu', purging
2023-05-27 06:45:51,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n058nuh3', purging
2023-05-27 06:45:51,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:51,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:51,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:51,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:52,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:52,655 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:53,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6f1995t7', purging
2023-05-27 06:45:53,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6k6h9e2a', purging
2023-05-27 06:45:53,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:53,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:53,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:53,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:54,636 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:54,809 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:55,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ltaw1x3g', purging
2023-05-27 06:45:55,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fzeanl7', purging
2023-05-27 06:45:55,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:55,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:56,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:56,166 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:56,840 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:57,026 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:58,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obyol2ny', purging
2023-05-27 06:45:58,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brqqk4c0', purging
2023-05-27 06:45:58,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:58,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:45:58,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:45:58,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:45:59,065 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:45:59,246 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:00,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21hl68vm', purging
2023-05-27 06:46:00,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9y9il57e', purging
2023-05-27 06:46:00,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:00,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:00,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:00,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:01,258 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:01,421 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:02,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnjsjnlf', purging
2023-05-27 06:46:02,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxc97f8g', purging
2023-05-27 06:46:02,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:02,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:02,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:02,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:03,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:03,566 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:04,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ybrgehcz', purging
2023-05-27 06:46:04,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a597ahsi', purging
2023-05-27 06:46:04,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:04,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:04,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:04,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:05,570 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:05,736 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:06,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ason_cn3', purging
2023-05-27 06:46:06,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qgcjstlk', purging
2023-05-27 06:46:06,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:06,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:07,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:07,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:07,776 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:07,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:09,115 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ruujxuyv', purging
2023-05-27 06:46:09,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4eo5lmts', purging
2023-05-27 06:46:09,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:09,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:09,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:09,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:09,922 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:10,096 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:11,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xp3_y14j', purging
2023-05-27 06:46:11,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vr4to2xi', purging
2023-05-27 06:46:11,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:11,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:11,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:11,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:12,114 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:12,288 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:13,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr9sdt5p', purging
2023-05-27 06:46:13,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g87mx2l5', purging
2023-05-27 06:46:13,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:13,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:13,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:13,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:14,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:14,448 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:15,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77ewoonz', purging
2023-05-27 06:46:15,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kalz4tcu', purging
2023-05-27 06:46:15,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:15,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:15,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:15,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:16,472 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:16,639 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:17,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5pvqrku', purging
2023-05-27 06:46:17,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwz9qlrf', purging
2023-05-27 06:46:17,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:17,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:17,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:17,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:18,656 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:18,823 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:19,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_qk7zi_1', purging
2023-05-27 06:46:19,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f3oef2x', purging
2023-05-27 06:46:19,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:19,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:20,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:20,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:20,836 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:21,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:22,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jm1vxx3q', purging
2023-05-27 06:46:22,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xz4q71ep', purging
2023-05-27 06:46:22,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:22,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:22,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:22,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:23,033 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:23,198 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:24,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tw33qemy', purging
2023-05-27 06:46:24,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa4keu7x', purging
2023-05-27 06:46:24,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:24,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:24,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:24,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:25,238 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:25,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:26,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2jlgwin', purging
2023-05-27 06:46:26,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g53xtmhs', purging
2023-05-27 06:46:26,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:26,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:26,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:26,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:27,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:27,600 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:28,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uydmpvwl', purging
2023-05-27 06:46:28,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9m0yhdiv', purging
2023-05-27 06:46:28,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:28,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:28,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:28,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:29,687 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:29,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:31,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvywbl9j', purging
2023-05-27 06:46:31,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9inf9r6i', purging
2023-05-27 06:46:31,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:31,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:31,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:31,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:31,905 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:32,073 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:33,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spva2b87', purging
2023-05-27 06:46:33,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqpvln85', purging
2023-05-27 06:46:33,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:33,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:33,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:33,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:34,102 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:34,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:35,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o8ly7vlq', purging
2023-05-27 06:46:35,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-349_x4b4', purging
2023-05-27 06:46:35,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:35,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:35,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:35,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:36,303 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:36,478 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:37,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_c_c268y', purging
2023-05-27 06:46:37,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e929mns1', purging
2023-05-27 06:46:37,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:37,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:37,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:37,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:38,497 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:38,663 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:39,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s8o_58j3', purging
2023-05-27 06:46:39,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nv_wnp1i', purging
2023-05-27 06:46:39,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:39,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:40,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:40,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:40,688 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:40,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:42,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qflqwzfu', purging
2023-05-27 06:46:42,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pf1b6jdf', purging
2023-05-27 06:46:42,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:42,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:42,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:42,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:42,886 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:43,061 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:44,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cw9ql4fw', purging
2023-05-27 06:46:44,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88y6k3vo', purging
2023-05-27 06:46:44,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:44,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:44,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:44,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:45,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:45,238 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:46,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqvifa7y', purging
2023-05-27 06:46:46,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-61rvszmx', purging
2023-05-27 06:46:46,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:46,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:46,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:46,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:47,275 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:47,437 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:48,629 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dyf22n5u', purging
2023-05-27 06:46:48,629 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfjngq9_', purging
2023-05-27 06:46:48,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:48,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:48,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:48,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:49,451 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:49,620 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:50,839 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v3ozgf10', purging
2023-05-27 06:46:50,839 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-361t7qmf', purging
2023-05-27 06:46:50,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:50,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:50,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:50,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:51,684 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:51,851 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:53,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rjbj8lp9', purging
2023-05-27 06:46:53,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u3peeyl5', purging
2023-05-27 06:46:53,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:53,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:53,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:53,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:53,877 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:54,035 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:55,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bfcvvz97', purging
2023-05-27 06:46:55,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jnvenmy0', purging
2023-05-27 06:46:55,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:55,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:55,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:55,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:56,062 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:56,230 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:57,425 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7ahakij', purging
2023-05-27 06:46:57,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mxnpxc6', purging
2023-05-27 06:46:57,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:57,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:57,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:57,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:46:58,256 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:58,421 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:46:59,584 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4u_hzi_4', purging
2023-05-27 06:46:59,584 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-usi3pe7a', purging
2023-05-27 06:46:59,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:59,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:46:59,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:46:59,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:00,401 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:00,567 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:01,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1xjieaoq', purging
2023-05-27 06:47:01,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u9ugf3yg', purging
2023-05-27 06:47:01,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:01,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:47:01,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:01,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:02,627 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:02,798 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:04,019 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vppwby2i', purging
2023-05-27 06:47:04,019 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jsa5oq4', purging
2023-05-27 06:47:04,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:04,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:47:04,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:04,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:04,850 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:05,020 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:06,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b1fp4fh6', purging
2023-05-27 06:47:06,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4mc889ll', purging
2023-05-27 06:47:06,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:06,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:47:06,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:06,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:07,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:07,218 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:08,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9zeto0jk', purging
2023-05-27 06:47:08,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdvtgmqp', purging
2023-05-27 06:47:08,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:08,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:47:08,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:08,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:09,232 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:09,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:10,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1q_ds1_t', purging
2023-05-27 06:47:10,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_k31u61c', purging
2023-05-27 06:47:10,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:10,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:47:10,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:10,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:11,432 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:47:12,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0s5xamhc', purging
2023-05-27 06:47:12,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eb2s03g3', purging
2023-05-27 06:47:12,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:12,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:13,565 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:14,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ju1hdnx', purging
2023-05-27 06:47:14,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:14,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:15,688 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:17,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zsin0oz5', purging
2023-05-27 06:47:17,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:17,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:17,780 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:19,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2vh2e44q', purging
2023-05-27 06:47:19,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:19,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:19,885 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:21,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o5rcp_6i', purging
2023-05-27 06:47:21,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:21,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:22,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:23,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qymra3p2', purging
2023-05-27 06:47:23,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:23,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:24,119 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:25,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7isvpvt', purging
2023-05-27 06:47:25,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:25,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:26,229 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:27,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b8oc47qo', purging
2023-05-27 06:47:27,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:27,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:28,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:29,620 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ztphe49x', purging
2023-05-27 06:47:29,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:29,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:30,384 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:31,710 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30esoqc1', purging
2023-05-27 06:47:31,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:31,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:32,485 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:33,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m2m1i1jx', purging
2023-05-27 06:47:33,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:33,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:34,591 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:35,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9e96m2i', purging
2023-05-27 06:47:35,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:35,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:36,727 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:38,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bbf70rme', purging
2023-05-27 06:47:38,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:38,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:38,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:40,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f35hri_r', purging
2023-05-27 06:47:40,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:40,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:40,909 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:42,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yczfr5ij', purging
2023-05-27 06:47:42,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:42,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:43,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:44,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-on6qagsz', purging
2023-05-27 06:47:44,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:44,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:45,152 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:46,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntmj3ouz', purging
2023-05-27 06:47:46,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:46,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:47,249 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:48,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iq4mu3pj', purging
2023-05-27 06:47:48,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:48,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:49,367 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:50,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g1pchsr6', purging
2023-05-27 06:47:50,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:50,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:51,483 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:52,829 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vbsy_741', purging
2023-05-27 06:47:52,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:52,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:53,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:54,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bp490dzu', purging
2023-05-27 06:47:54,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:54,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:55,726 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:57,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1lombadd', purging
2023-05-27 06:47:57,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:57,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:57,838 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:47:59,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gv3puykr', purging
2023-05-27 06:47:59,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:47:59,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:47:59,919 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:01,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftuzg_2q', purging
2023-05-27 06:48:01,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:01,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:02,029 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:03,345 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jwp7t9x', purging
2023-05-27 06:48:03,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:03,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:04,110 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:05,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0lc7hnz7', purging
2023-05-27 06:48:05,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:05,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:06,221 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:07,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pp_aojyg', purging
2023-05-27 06:48:07,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:07,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:08,339 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:09,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iz3ozurl', purging
2023-05-27 06:48:09,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:09,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:10,466 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:11,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2vvy3t6', purging
2023-05-27 06:48:11,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:11,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:12,618 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:13,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n16ei2vd', purging
2023-05-27 06:48:13,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:13,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:14,739 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:16,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8jn97j1', purging
2023-05-27 06:48:16,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:16,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:16,867 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:18,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vf0u5btt', purging
2023-05-27 06:48:18,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:18,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:18,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:20,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uc09j9wa', purging
2023-05-27 06:48:20,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:20,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:21,064 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:22,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18pm2fjd', purging
2023-05-27 06:48:22,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:22,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:23,193 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:24,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ht1ovau', purging
2023-05-27 06:48:24,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:24,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:25,308 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:26,646 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dox9bsek', purging
2023-05-27 06:48:26,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:26,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:27,416 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:28,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fky4ai7t', purging
2023-05-27 06:48:28,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:28,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:29,534 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:30,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_ixhozk', purging
2023-05-27 06:48:30,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:30,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:31,643 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:32,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6d5xvrb', purging
2023-05-27 06:48:32,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:32,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:33,754 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:35,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-50yz1ec0', purging
2023-05-27 06:48:35,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:35,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:35,872 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:37,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zludxesn', purging
2023-05-27 06:48:37,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:37,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:37,981 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:39,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fzs7_6xi', purging
2023-05-27 06:48:39,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:39,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:40,056 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:41,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbt013vu', purging
2023-05-27 06:48:41,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:41,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:42,165 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:43,497 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sjhssbld', purging
2023-05-27 06:48:43,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:43,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:44,267 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:45,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q68hso0t', purging
2023-05-27 06:48:45,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:45,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:46,372 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:47,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lgrv2f1o', purging
2023-05-27 06:48:47,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:47,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:48,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:49,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-utb3szlf', purging
2023-05-27 06:48:49,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:49,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:50,630 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:51,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iiyuma16', purging
2023-05-27 06:48:51,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:51,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:52,768 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:54,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rxdbity3', purging
2023-05-27 06:48:54,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:54,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:54,871 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:56,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bqbq11c', purging
2023-05-27 06:48:56,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:56,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:56,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:48:58,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8qgwe96c', purging
2023-05-27 06:48:58,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:48:58,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:48:59,089 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:00,421 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_8btx8t', purging
2023-05-27 06:49:00,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:00,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:01,206 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:02,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-80f905l5', purging
2023-05-27 06:49:02,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:02,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:03,322 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:04,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eivlkrwa', purging
2023-05-27 06:49:04,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:04,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:05,440 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:06,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lfdzkmfa', purging
2023-05-27 06:49:06,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:06,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:07,560 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:08,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3q1br__s', purging
2023-05-27 06:49:08,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:08,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:09,674 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:10,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4ps72ru', purging
2023-05-27 06:49:10,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:10,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:11,775 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:13,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jt73d_2j', purging
2023-05-27 06:49:13,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:13,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:13,873 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:15,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-96mtooym', purging
2023-05-27 06:49:15,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:15,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:15,990 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:17,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-biznkgpp', purging
2023-05-27 06:49:17,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:17,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:18,053 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:19,377 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xx1gwgs6', purging
2023-05-27 06:49:19,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:19,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:20,160 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:21,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qst3khaf', purging
2023-05-27 06:49:21,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:21,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:22,303 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:23,642 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ul8ggt9c', purging
2023-05-27 06:49:23,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:23,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:24,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:25,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3626rokh', purging
2023-05-27 06:49:25,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:25,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:26,506 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:27,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0vemvyk', purging
2023-05-27 06:49:27,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:27,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:28,615 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:29,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rq3d4x_d', purging
2023-05-27 06:49:29,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:29,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:30,740 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:32,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7xsp9c58', purging
2023-05-27 06:49:32,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:32,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:32,835 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:34,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvth0p0o', purging
2023-05-27 06:49:34,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:34,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:34,949 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:36,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-umtmsn49', purging
2023-05-27 06:49:36,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:36,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:37,062 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:38,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wib2m84z', purging
2023-05-27 06:49:38,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:38,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:39,167 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:40,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-etz31wqb', purging
2023-05-27 06:49:40,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:40,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:41,299 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:42,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3n1jv1y8', purging
2023-05-27 06:49:42,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:42,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:43,433 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:44,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8djdecmb', purging
2023-05-27 06:49:44,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:44,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:45,553 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:46,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vroh9zbf', purging
2023-05-27 06:49:46,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:46,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:47,665 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:48,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1aexzdan', purging
2023-05-27 06:49:48,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:48,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:49,772 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:51,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzcyta5d', purging
2023-05-27 06:49:51,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:51,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:51,901 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:53,238 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cagrb4kz', purging
2023-05-27 06:49:53,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:53,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:54,019 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:55,345 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uj5x_88_', purging
2023-05-27 06:49:55,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:55,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:56,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:57,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fikgrnqv', purging
2023-05-27 06:49:57,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:57,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:49:58,255 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:49:59,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z4ateiev', purging
2023-05-27 06:49:59,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:49:59,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:00,333 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:01,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fhfr_ntl', purging
2023-05-27 06:50:01,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:01,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:02,450 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:03,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qyyxnxyg', purging
2023-05-27 06:50:03,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:03,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:04,570 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:05,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lhxmhuhz', purging
2023-05-27 06:50:05,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:05,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:06,678 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:08,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kep8kmay', purging
2023-05-27 06:50:08,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:08,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:08,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:10,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_xyfwmf9', purging
2023-05-27 06:50:10,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:10,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:10,913 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:12,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-10c1rr4q', purging
2023-05-27 06:50:12,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:12,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:12,983 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:14,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c37an6cn', purging
2023-05-27 06:50:14,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:14,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:15,092 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:16,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wk9ckl_f', purging
2023-05-27 06:50:16,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:16,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:17,205 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:18,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9kwbvp5', purging
2023-05-27 06:50:18,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:18,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:19,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:20,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04ysd4to', purging
2023-05-27 06:50:20,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:20,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:21,415 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:22,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqagxwsp', purging
2023-05-27 06:50:22,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:22,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:23,545 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:24,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i4h_8c4s', purging
2023-05-27 06:50:24,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:24,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:25,670 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:27,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ixmrtm9a', purging
2023-05-27 06:50:27,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:27,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:27,789 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:29,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5lgr8zb', purging
2023-05-27 06:50:29,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:29,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:29,872 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:31,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qa7civhc', purging
2023-05-27 06:50:31,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:31,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:31,998 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:33,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l0rqoyzg', purging
2023-05-27 06:50:33,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:33,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:34,123 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:35,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prndkijs', purging
2023-05-27 06:50:35,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:35,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:36,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:37,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chfy5d8v', purging
2023-05-27 06:50:37,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:37,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:38,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:39,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59fge3zi', purging
2023-05-27 06:50:39,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:39,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:40,422 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:41,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dmzz8fnv', purging
2023-05-27 06:50:41,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:41,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:42,535 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:43,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb0o8ntb', purging
2023-05-27 06:50:43,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:43,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:44,651 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:46,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-for2_5vb', purging
2023-05-27 06:50:46,002 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:46,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:46,782 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:48,115 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oy3mzlch', purging
2023-05-27 06:50:48,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:48,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:48,895 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:50,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c4m7n8i8', purging
2023-05-27 06:50:50,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:50,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:50,996 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:52,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2gmqi398', purging
2023-05-27 06:50:52,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:52,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:53,113 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:54,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgl8u5j3', purging
2023-05-27 06:50:54,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:54,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:55,233 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:56,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udmqmdyi', purging
2023-05-27 06:50:56,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:56,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:57,348 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:50:58,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-135h3fzo', purging
2023-05-27 06:50:58,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:50:58,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:50:59,456 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:00,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v_n23m3q', purging
2023-05-27 06:51:00,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:00,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:01,566 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:02,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5o55j5i4', purging
2023-05-27 06:51:02,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:02,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:03,670 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:05,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kxfboqox', purging
2023-05-27 06:51:05,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:05,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:05,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:07,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijb5tuof', purging
2023-05-27 06:51:07,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:07,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:07,923 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:09,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gbu7m76', purging
2023-05-27 06:51:09,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:09,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:10,063 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:11,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2a_ofkz', purging
2023-05-27 06:51:11,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:11,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:12,193 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:13,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u4cphvi8', purging
2023-05-27 06:51:13,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:13,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:14,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:15,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfg_xjkh', purging
2023-05-27 06:51:15,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:15,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:16,450 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:17,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xsd42748', purging
2023-05-27 06:51:17,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:17,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:18,586 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:19,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxz10xnj', purging
2023-05-27 06:51:19,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:19,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:20,684 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:22,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh75s3sc', purging
2023-05-27 06:51:22,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:22,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:22,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:24,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20so47zp', purging
2023-05-27 06:51:24,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:24,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:24,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:26,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4h07l2zo', purging
2023-05-27 06:51:26,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:26,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:27,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:28,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tabdn5t8', purging
2023-05-27 06:51:28,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:28,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:29,194 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:30,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w2b0sx7c', purging
2023-05-27 06:51:30,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:30,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:31,307 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:32,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kojn4t8h', purging
2023-05-27 06:51:32,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:32,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:33,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:34,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3v3h5xl', purging
2023-05-27 06:51:34,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:34,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:35,540 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:36,883 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t57ymmf8', purging
2023-05-27 06:51:36,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:36,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:37,659 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:39,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7dh8m5f', purging
2023-05-27 06:51:39,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:39,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:39,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:41,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_583yes', purging
2023-05-27 06:51:41,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:41,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:41,921 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:43,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sqn_3qe2', purging
2023-05-27 06:51:43,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:43,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:44,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:45,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_t5ue5u', purging
2023-05-27 06:51:45,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:45,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:46,163 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:47,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wiwxgi6o', purging
2023-05-27 06:51:47,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:47,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:48,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:49,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1buzl8pv', purging
2023-05-27 06:51:49,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:49,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:50,407 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:51,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zv2wv00g', purging
2023-05-27 06:51:51,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:51,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:52,536 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:53,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c41l3yw9', purging
2023-05-27 06:51:53,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:53,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:54,674 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:56,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5d173nl', purging
2023-05-27 06:51:56,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:56,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:56,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:51:58,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7od7cyr', purging
2023-05-27 06:51:58,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:51:58,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:51:58,911 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:00,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r9kdhrn9', purging
2023-05-27 06:52:00,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:00,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:01,031 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:02,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_og9f2n2', purging
2023-05-27 06:52:02,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:02,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:03,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:04,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3h80vzdk', purging
2023-05-27 06:52:04,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:04,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:05,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:06,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ypgxj0d9', purging
2023-05-27 06:52:06,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:06,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:07,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:08,749 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oeadbzwu', purging
2023-05-27 06:52:08,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:08,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:09,511 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:10,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkhj8x3h', purging
2023-05-27 06:52:10,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:10,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:11,658 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:12,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccfqo1je', purging
2023-05-27 06:52:12,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:12,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:13,773 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:15,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23yd3v2s', purging
2023-05-27 06:52:15,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:15,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:15,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:17,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dwshgotd', purging
2023-05-27 06:52:17,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:17,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:18,003 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:19,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l1b66i6p', purging
2023-05-27 06:52:19,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:19,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:20,134 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:21,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5kryj1w', purging
2023-05-27 06:52:21,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:21,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:22,272 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:23,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-giahu8_s', purging
2023-05-27 06:52:23,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:23,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:24,408 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:25,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me9kiy8s', purging
2023-05-27 06:52:25,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:25,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:26,549 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:27,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dxtnnple', purging
2023-05-27 06:52:27,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:27,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:28,675 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:30,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r208ie3j', purging
2023-05-27 06:52:30,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:30,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:30,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:32,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-719_fpwm', purging
2023-05-27 06:52:32,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:32,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:32,913 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:34,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k08m5wb_', purging
2023-05-27 06:52:34,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:34,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:35,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:36,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1rfh7_bg', purging
2023-05-27 06:52:36,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:36,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:37,168 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:38,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udw3l77h', purging
2023-05-27 06:52:38,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:38,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:39,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:40,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-380464j4', purging
2023-05-27 06:52:40,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:40,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:41,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:42,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8tn3fb_', purging
2023-05-27 06:52:42,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:42,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:43,530 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:44,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i0stcpq1', purging
2023-05-27 06:52:44,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:44,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:45,663 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:47,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_mldzou', purging
2023-05-27 06:52:47,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:47,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:47,793 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:49,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hdw35pu', purging
2023-05-27 06:52:49,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:49,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:49,902 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:52:51,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka27jk1c', purging
2023-05-27 06:52:51,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:52:51,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:52:52,036 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 909 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
