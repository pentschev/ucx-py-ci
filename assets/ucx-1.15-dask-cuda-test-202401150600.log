============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-15 06:37:30,630 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:30,635 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-15 06:37:30,638 - distributed.scheduler - INFO - State start
2024-01-15 06:37:30,661 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:30,662 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-15 06:37:30,663 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-15 06:37:30,663 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:37:30,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34477'
2024-01-15 06:37:30,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36039'
2024-01-15 06:37:30,909 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39833'
2024-01-15 06:37:30,917 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45243'
2024-01-15 06:37:31,147 - distributed.scheduler - INFO - Receive client connection: Client-8da02ea6-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:31,160 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58574
2024-01-15 06:37:32,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:32,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:32,695 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:32,696 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46545
2024-01-15 06:37:32,696 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46545
2024-01-15 06:37:32,696 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38773
2024-01-15 06:37:32,696 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-15 06:37:32,696 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,696 - distributed.worker - INFO -               Threads:                          4
2024-01-15 06:37:32,696 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-15 06:37:32,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-yj4b0eba
2024-01-15 06:37:32,696 - distributed.worker - INFO - Starting Worker plugin PreImport-63eb61a3-a084-495e-9e8a-4a5a4af2b392
2024-01-15 06:37:32,696 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e99a002-325f-4683-9a02-76d0c58bb01f
2024-01-15 06:37:32,697 - distributed.worker - INFO - Starting Worker plugin RMMSetup-24ddce29-b791-4a23-9c19-f770d9dba320
2024-01-15 06:37:32,697 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:32,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:32,736 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:32,737 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45147
2024-01-15 06:37:32,737 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45147
2024-01-15 06:37:32,737 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40209
2024-01-15 06:37:32,737 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-15 06:37:32,737 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,737 - distributed.worker - INFO -               Threads:                          4
2024-01-15 06:37:32,737 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-15 06:37:32,737 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-sm508b06
2024-01-15 06:37:32,737 - distributed.worker - INFO - Starting Worker plugin PreImport-2ca58b5a-bd14-4d1e-8cb4-29b4187a21f2
2024-01-15 06:37:32,738 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-633ee64e-0f6d-45ed-9d35-2cc2c1ae6290
2024-01-15 06:37:32,738 - distributed.worker - INFO - Starting Worker plugin RMMSetup-960f7fc9-ca45-40e7-976c-9549da2456a8
2024-01-15 06:37:32,738 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:32,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:32,777 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:32,777 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41419
2024-01-15 06:37:32,777 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41419
2024-01-15 06:37:32,777 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33133
2024-01-15 06:37:32,777 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-15 06:37:32,777 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,778 - distributed.worker - INFO -               Threads:                          4
2024-01-15 06:37:32,778 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-15 06:37:32,778 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-t509rft1
2024-01-15 06:37:32,778 - distributed.worker - INFO - Starting Worker plugin PreImport-829c86db-50b7-4c58-b970-f05499382a3d
2024-01-15 06:37:32,778 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c2d7f70-c3f1-438e-b260-ee10a6541350
2024-01-15 06:37:32,778 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d176019-5516-4b7d-a176-1126c7a86be1
2024-01-15 06:37:32,778 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:32,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:32,789 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:32,790 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43755
2024-01-15 06:37:32,790 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43755
2024-01-15 06:37:32,790 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36223
2024-01-15 06:37:32,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-15 06:37:32,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:32,790 - distributed.worker - INFO -               Threads:                          4
2024-01-15 06:37:32,790 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-15 06:37:32,790 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-fz7cua3k
2024-01-15 06:37:32,791 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cce63f23-4c0f-4d3c-b0fc-b79796d268b7
2024-01-15 06:37:32,791 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7db7f951-6b1c-4b9f-b44b-0b11fa660950
2024-01-15 06:37:32,791 - distributed.worker - INFO - Starting Worker plugin PreImport-df14657c-54f6-4791-b1b8-267b23e9aee0
2024-01-15 06:37:32,791 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:33,390 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45147', status: init, memory: 0, processing: 0>
2024-01-15 06:37:33,393 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45147
2024-01-15 06:37:33,393 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58602
2024-01-15 06:37:33,394 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:33,394 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43755', status: init, memory: 0, processing: 0>
2024-01-15 06:37:33,394 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43755
2024-01-15 06:37:33,394 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-15 06:37:33,394 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58606
2024-01-15 06:37:33,394 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:33,395 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41419', status: init, memory: 0, processing: 0>
2024-01-15 06:37:33,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:33,396 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41419
2024-01-15 06:37:33,396 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-15 06:37:33,396 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58604
2024-01-15 06:37:33,396 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-15 06:37:33,396 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:33,396 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:33,397 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-15 06:37:33,397 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:33,397 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-15 06:37:33,398 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-15 06:37:33,405 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46545', status: init, memory: 0, processing: 0>
2024-01-15 06:37:33,406 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46545
2024-01-15 06:37:33,406 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58592
2024-01-15 06:37:33,407 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:33,408 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-15 06:37:33,408 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:33,409 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-15 06:37:33,449 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-15 06:37:33,449 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-15 06:37:33,449 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-15 06:37:33,449 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-15 06:37:33,455 - distributed.scheduler - INFO - Remove client Client-8da02ea6-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:33,455 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58574; closing.
2024-01-15 06:37:33,455 - distributed.scheduler - INFO - Remove client Client-8da02ea6-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:33,456 - distributed.scheduler - INFO - Close client connection: Client-8da02ea6-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:33,456 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34477'. Reason: nanny-close
2024-01-15 06:37:33,457 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:33,457 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36039'. Reason: nanny-close
2024-01-15 06:37:33,458 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:33,458 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39833'. Reason: nanny-close
2024-01-15 06:37:33,458 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46545. Reason: nanny-close
2024-01-15 06:37:33,458 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:33,459 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45243'. Reason: nanny-close
2024-01-15 06:37:33,459 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45147. Reason: nanny-close
2024-01-15 06:37:33,459 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:33,459 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43755. Reason: nanny-close
2024-01-15 06:37:33,459 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41419. Reason: nanny-close
2024-01-15 06:37:33,460 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58592; closing.
2024-01-15 06:37:33,460 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-15 06:37:33,460 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46545', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300653.4606273')
2024-01-15 06:37:33,460 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-15 06:37:33,461 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-15 06:37:33,461 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-15 06:37:33,461 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58606; closing.
2024-01-15 06:37:33,461 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:33,462 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:33,462 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43755', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300653.4622397')
2024-01-15 06:37:33,462 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:33,462 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58602; closing.
2024-01-15 06:37:33,462 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:33,462 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:58606>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:58606>: Stream is closed
2024-01-15 06:37:33,465 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58604; closing.
2024-01-15 06:37:33,465 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45147', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300653.4657202')
2024-01-15 06:37:33,466 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41419', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300653.466086')
2024-01-15 06:37:33,466 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:37:34,222 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:37:34,223 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:37:34,223 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:37:34,225 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-15 06:37:34,225 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-15 06:37:36,699 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:36,703 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-15 06:37:36,707 - distributed.scheduler - INFO - State start
2024-01-15 06:37:36,732 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:36,733 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:37:36,734 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-15 06:37:36,734 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:37:36,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40599'
2024-01-15 06:37:36,791 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35957'
2024-01-15 06:37:36,802 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33511'
2024-01-15 06:37:36,817 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45547'
2024-01-15 06:37:36,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33179'
2024-01-15 06:37:36,831 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44853'
2024-01-15 06:37:36,839 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36905'
2024-01-15 06:37:36,848 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34019'
2024-01-15 06:37:37,788 - distributed.scheduler - INFO - Receive client connection: Client-9115c683-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:37,804 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56926
2024-01-15 06:37:38,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,650 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,651 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41343
2024-01-15 06:37:38,651 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41343
2024-01-15 06:37:38,651 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33519
2024-01-15 06:37:38,651 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,651 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,651 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,651 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,652 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xkop20u0
2024-01-15 06:37:38,652 - distributed.worker - INFO - Starting Worker plugin PreImport-f27680d5-1743-426a-af8c-72fb782a9046
2024-01-15 06:37:38,652 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b1e75c0-3646-45b1-8c71-6d4129a6668f
2024-01-15 06:37:38,652 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e321ba20-f130-492b-a3c8-7cce9e781093
2024-01-15 06:37:38,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,706 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,707 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37759
2024-01-15 06:37:38,707 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37759
2024-01-15 06:37:38,707 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44703
2024-01-15 06:37:38,707 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,707 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,707 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,708 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,708 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lxhgwjdo
2024-01-15 06:37:38,708 - distributed.worker - INFO - Starting Worker plugin PreImport-a5f80218-a83a-481c-b05d-2a7f275550ca
2024-01-15 06:37:38,708 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f86da984-6e3d-47b1-b603-deb0980f168a
2024-01-15 06:37:38,708 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41abbbb0-7233-4efc-b336-719054b717ef
2024-01-15 06:37:38,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,722 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,723 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37649
2024-01-15 06:37:38,723 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37649
2024-01-15 06:37:38,723 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40165
2024-01-15 06:37:38,723 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,723 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,723 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,723 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,723 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_a61xsip
2024-01-15 06:37:38,723 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34921
2024-01-15 06:37:38,723 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34921
2024-01-15 06:37:38,723 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37587
2024-01-15 06:37:38,724 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,724 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fd24ba1a-8937-4291-8a9d-d4d3bb2d4bda
2024-01-15 06:37:38,724 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,724 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,724 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,724 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,724 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yow6i9p8
2024-01-15 06:37:38,724 - distributed.worker - INFO - Starting Worker plugin PreImport-619d571b-f18a-427b-a343-a7db40b9ccd4
2024-01-15 06:37:38,724 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fcf90d21-5cc6-45b1-9830-da6a035433e9
2024-01-15 06:37:38,724 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d0bb30d6-6880-45cd-aeef-64a6d39a8434
2024-01-15 06:37:38,724 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45853
2024-01-15 06:37:38,724 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45853
2024-01-15 06:37:38,725 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43587
2024-01-15 06:37:38,725 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,725 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,725 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,725 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,725 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l53se7rn
2024-01-15 06:37:38,725 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c0079e09-58b0-4111-a877-60fe805f27e5
2024-01-15 06:37:38,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,897 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46781
2024-01-15 06:37:38,897 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46781
2024-01-15 06:37:38,897 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37647
2024-01-15 06:37:38,897 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,898 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,898 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,898 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,898 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k3r2tg87
2024-01-15 06:37:38,898 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4331f502-ea8e-41f8-8615-94c1456c438e
2024-01-15 06:37:38,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,928 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,929 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39943
2024-01-15 06:37:38,930 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39943
2024-01-15 06:37:38,930 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41559
2024-01-15 06:37:38,930 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,930 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,930 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,930 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,930 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3ru7g24i
2024-01-15 06:37:38,930 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26da5e73-533b-4c34-93a6-0ef3fd6b88ce
2024-01-15 06:37:38,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:38,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:38,956 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:38,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41157
2024-01-15 06:37:38,957 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41157
2024-01-15 06:37:38,958 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35593
2024-01-15 06:37:38,958 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:38,958 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:38,958 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:38,958 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:38,958 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y3m8dsqs
2024-01-15 06:37:38,958 - distributed.worker - INFO - Starting Worker plugin RMMSetup-81baa315-fc49-449a-ab39-8c48fc2df579
2024-01-15 06:37:39,189 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:39,212 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41343', status: init, memory: 0, processing: 0>
2024-01-15 06:37:39,213 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41343
2024-01-15 06:37:39,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56932
2024-01-15 06:37:39,214 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:39,215 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:39,215 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:39,217 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,225 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,249 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f0c91f28-cf74-40c6-a568-e47d0f22620e
2024-01-15 06:37:41,249 - distributed.worker - INFO - Starting Worker plugin PreImport-286ee6a9-6014-4371-b5a8-4bb740d81ff1
2024-01-15 06:37:41,250 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,258 - distributed.worker - INFO - Starting Worker plugin PreImport-99323509-1184-4e4f-9218-3393c7cfb4a7
2024-01-15 06:37:41,259 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-67ef350f-b7b4-45e8-99f8-72393b1c8605
2024-01-15 06:37:41,264 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37759', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,264 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37759
2024-01-15 06:37:41,264 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49298
2024-01-15 06:37:41,264 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,265 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-643598cd-2e33-4f9c-aedd-7ed05067a9b9
2024-01-15 06:37:41,265 - distributed.worker - INFO - Starting Worker plugin PreImport-7b6586ad-7c8b-4df8-9bd1-805aaf8d6e42
2024-01-15 06:37:41,266 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,266 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,267 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,267 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,269 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,282 - distributed.worker - INFO - Starting Worker plugin PreImport-3395587e-fc93-486e-8247-00e1f7304fc9
2024-01-15 06:37:41,283 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad5c76ee-aef5-4104-9567-b8984dc2a2eb
2024-01-15 06:37:41,284 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a8af616c-f5fe-4a86-acfd-03d54fecd90a
2024-01-15 06:37:41,285 - distributed.worker - INFO - Starting Worker plugin PreImport-c3c000c6-56db-4a3d-b668-69ca8277b476
2024-01-15 06:37:41,286 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,288 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,289 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46781', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,290 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46781
2024-01-15 06:37:41,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49300
2024-01-15 06:37:41,291 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37649', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,292 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37649
2024-01-15 06:37:41,292 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49302
2024-01-15 06:37:41,292 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,293 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,293 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,294 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,294 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,295 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,296 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,301 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45853', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,302 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45853
2024-01-15 06:37:41,302 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49308
2024-01-15 06:37:41,304 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,305 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,305 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,307 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,309 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39943', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39943
2024-01-15 06:37:41,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49336
2024-01-15 06:37:41,310 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,311 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,312 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,313 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34921', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,314 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34921
2024-01-15 06:37:41,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49346
2024-01-15 06:37:41,315 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41157', status: init, memory: 0, processing: 0>
2024-01-15 06:37:41,315 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,315 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41157
2024-01-15 06:37:41,315 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49322
2024-01-15 06:37:41,316 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,316 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,316 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:41,317 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,317 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:41,317 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:41,319 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:41,325 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,325 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,325 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,325 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,326 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,326 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,326 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,326 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:41,330 - distributed.scheduler - INFO - Remove client Client-9115c683-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:41,331 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56926; closing.
2024-01-15 06:37:41,331 - distributed.scheduler - INFO - Remove client Client-9115c683-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:41,331 - distributed.scheduler - INFO - Close client connection: Client-9115c683-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:41,332 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40599'. Reason: nanny-close
2024-01-15 06:37:41,332 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,333 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35957'. Reason: nanny-close
2024-01-15 06:37:41,333 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33511'. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37759. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45547'. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33179'. Reason: nanny-close
2024-01-15 06:37:41,334 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41343. Reason: nanny-close
2024-01-15 06:37:41,335 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44853'. Reason: nanny-close
2024-01-15 06:37:41,335 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37649. Reason: nanny-close
2024-01-15 06:37:41,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36905'. Reason: nanny-close
2024-01-15 06:37:41,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34019'. Reason: nanny-close
2024-01-15 06:37:41,336 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46781. Reason: nanny-close
2024-01-15 06:37:41,336 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49298; closing.
2024-01-15 06:37:41,336 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,337 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,337 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37759', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3370793')
2024-01-15 06:37:41,337 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,337 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56932; closing.
2024-01-15 06:37:41,338 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,338 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,338 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,338 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,338 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41343', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3389127')
2024-01-15 06:37:41,339 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49302; closing.
2024-01-15 06:37:41,340 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49300; closing.
2024-01-15 06:37:41,340 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3403568')
2024-01-15 06:37:41,340 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,340 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46781', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.340721')
2024-01-15 06:37:41,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34921. Reason: nanny-close
2024-01-15 06:37:41,353 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39943. Reason: nanny-close
2024-01-15 06:37:41,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:41,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49346; closing.
2024-01-15 06:37:41,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49336; closing.
2024-01-15 06:37:41,355 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45853. Reason: nanny-close
2024-01-15 06:37:41,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,355 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41157. Reason: nanny-close
2024-01-15 06:37:41,356 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34921', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3559675')
2024-01-15 06:37:41,356 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39943', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3563733')
2024-01-15 06:37:41,356 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,357 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,358 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49322; closing.
2024-01-15 06:37:41,358 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,358 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41157', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3583064')
2024-01-15 06:37:41,358 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49308; closing.
2024-01-15 06:37:41,358 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:41,359 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45853', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300661.3591297')
2024-01-15 06:37:41,359 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:37:41,359 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:41,361 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:42,350 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:37:42,350 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:37:42,350 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:37:42,351 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:37:42,352 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-15 06:37:44,517 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:44,521 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34227 instead
  warnings.warn(
2024-01-15 06:37:44,525 - distributed.scheduler - INFO - State start
2024-01-15 06:37:44,729 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:44,729 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:37:44,730 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34227/status
2024-01-15 06:37:44,730 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:37:44,844 - distributed.scheduler - INFO - Receive client connection: Client-95dcf371-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:44,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49428
2024-01-15 06:37:44,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45937'
2024-01-15 06:37:44,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39323'
2024-01-15 06:37:44,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38295'
2024-01-15 06:37:44,895 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38441'
2024-01-15 06:37:44,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39697'
2024-01-15 06:37:44,914 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42723'
2024-01-15 06:37:44,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38593'
2024-01-15 06:37:44,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39835'
2024-01-15 06:37:46,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,729 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:46,730 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39787
2024-01-15 06:37:46,730 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39787
2024-01-15 06:37:46,730 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37305
2024-01-15 06:37:46,730 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:46,730 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:46,730 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:46,730 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:46,730 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6qd42aa4
2024-01-15 06:37:46,731 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1a9c8f74-2099-4772-a194-266ed9a889e8
2024-01-15 06:37:46,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:46,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:46,788 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39485
2024-01-15 06:37:46,788 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39561
2024-01-15 06:37:46,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39485
2024-01-15 06:37:46,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39561
2024-01-15 06:37:46,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38917
2024-01-15 06:37:46,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45449
2024-01-15 06:37:46,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:46,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:46,788 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:46,788 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:46,788 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:46,788 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:46,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:46,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:46,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rlv2m1wr
2024-01-15 06:37:46,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6ru3la3f
2024-01-15 06:37:46,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-870b6828-46a9-49fb-803f-dddc99a70090
2024-01-15 06:37:46,788 - distributed.worker - INFO - Starting Worker plugin PreImport-8a2c8a86-6fb6-4bf3-93da-cb7a99ff1f3b
2024-01-15 06:37:46,788 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eed304ba-fc50-4fb3-ab16-01daa7639721
2024-01-15 06:37:46,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,789 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92fc612f-1bab-4bf4-94bb-0f73dfa809f1
2024-01-15 06:37:46,793 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:46,793 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:46,794 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33439
2024-01-15 06:37:46,794 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33439
2024-01-15 06:37:46,794 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34937
2024-01-15 06:37:46,794 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34937
2024-01-15 06:37:46,794 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42393
2024-01-15 06:37:46,794 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:46,794 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33917
2024-01-15 06:37:46,794 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:46,794 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:46,794 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:46,794 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:46,794 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:46,794 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:46,794 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:46,794 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eh9_hr00
2024-01-15 06:37:46,794 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ir_nz_6e
2024-01-15 06:37:46,794 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b308b6c4-5e5e-4bc8-98f4-ea718414ea0b
2024-01-15 06:37:46,794 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28d624b7-5673-4008-8b09-fb8ec271bf36
2024-01-15 06:37:46,795 - distributed.worker - INFO - Starting Worker plugin PreImport-0ba51610-e7c8-4398-96f5-e9a11606294b
2024-01-15 06:37:46,795 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9b6233c1-1015-4d7f-a31b-6f35a90a451a
2024-01-15 06:37:46,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:46,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:46,999 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:47,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35155
2024-01-15 06:37:47,000 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35155
2024-01-15 06:37:47,001 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36379
2024-01-15 06:37:47,001 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:47,001 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:47,001 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:47,001 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:47,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jf8xawpd
2024-01-15 06:37:47,001 - distributed.worker - INFO - Starting Worker plugin PreImport-9e65cd2f-4bf5-4bc9-b768-0109c88836cc
2024-01-15 06:37:47,001 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:47,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7239ec7b-8cf0-45e9-ac11-4d66246bd70b
2024-01-15 06:37:47,001 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31a0bc4a-a58d-4b15-88b7-fef84dcd6bdd
2024-01-15 06:37:47,002 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:47,002 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33827
2024-01-15 06:37:47,002 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33827
2024-01-15 06:37:47,002 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40631
2024-01-15 06:37:47,002 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:47,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:47,002 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:47,002 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:47,003 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5sbem4_e
2024-01-15 06:37:47,003 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44229
2024-01-15 06:37:47,003 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44229
2024-01-15 06:37:47,003 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40873
2024-01-15 06:37:47,003 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae2fd111-fbf1-45b9-a74f-3bc9bee188a2
2024-01-15 06:37:47,003 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:47,003 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:47,003 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:47,003 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:47,003 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ccxb9ev0
2024-01-15 06:37:47,003 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e61aae50-8a50-4c64-839d-baedc8606731
2024-01-15 06:37:47,189 - distributed.worker - INFO - Starting Worker plugin PreImport-ea311c1a-29ad-45fd-b166-4e86989e103b
2024-01-15 06:37:47,190 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-961cbcf2-6aa2-47dd-be95-55b2e401bed2
2024-01-15 06:37:47,190 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:47,215 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39787', status: init, memory: 0, processing: 0>
2024-01-15 06:37:47,217 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39787
2024-01-15 06:37:47,217 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49520
2024-01-15 06:37:47,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:47,218 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:47,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:47,220 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,786 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,788 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05bca6a7-6228-428e-8d59-7b6e8660c251
2024-01-15 06:37:48,788 - distributed.worker - INFO - Starting Worker plugin PreImport-b94144b3-2bde-43c0-8737-a5b135f8d6a4
2024-01-15 06:37:48,789 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,822 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34937', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,823 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34937
2024-01-15 06:37:48,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49530
2024-01-15 06:37:48,825 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33439', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,825 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,826 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,826 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,826 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33439
2024-01-15 06:37:48,827 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49546
2024-01-15 06:37:48,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,828 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,829 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,829 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,831 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,841 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,847 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a32147c5-57b8-40bb-9d81-fb310f601b5d
2024-01-15 06:37:48,848 - distributed.worker - INFO - Starting Worker plugin PreImport-c047845a-767e-4980-8f4d-b7b3da285610
2024-01-15 06:37:48,848 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,854 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d89c37f-4159-4ee2-bc38-4f9bfacd545f
2024-01-15 06:37:48,855 - distributed.worker - INFO - Starting Worker plugin PreImport-90bf6d5d-192d-4743-aa9d-48fa36d9a0ec
2024-01-15 06:37:48,856 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,865 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b735ae3-13a3-4125-8463-92d5729e5176
2024-01-15 06:37:48,865 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35155', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,866 - distributed.worker - INFO - Starting Worker plugin PreImport-1a36d4ff-8386-4ba1-9eb8-5ef7d8b1df51
2024-01-15 06:37:48,866 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35155
2024-01-15 06:37:48,866 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49554
2024-01-15 06:37:48,866 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,867 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,868 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,868 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,872 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33827', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,872 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33827
2024-01-15 06:37:48,872 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49560
2024-01-15 06:37:48,873 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,874 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,874 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,882 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39561', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,883 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39561
2024-01-15 06:37:48,883 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49572
2024-01-15 06:37:48,885 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,886 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,886 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,888 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44229', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,888 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,889 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44229
2024-01-15 06:37:48,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49586
2024-01-15 06:37:48,890 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,891 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,891 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,892 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39485', status: init, memory: 0, processing: 0>
2024-01-15 06:37:48,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,893 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39485
2024-01-15 06:37:48,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49576
2024-01-15 06:37:48,894 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:48,895 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:48,895 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:48,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:48,961 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,962 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,962 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,962 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,962 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,963 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,963 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,963 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:48,968 - distributed.scheduler - INFO - Remove client Client-95dcf371-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:48,968 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49428; closing.
2024-01-15 06:37:48,968 - distributed.scheduler - INFO - Remove client Client-95dcf371-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:48,969 - distributed.scheduler - INFO - Close client connection: Client-95dcf371-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:48,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45937'. Reason: nanny-close
2024-01-15 06:37:48,970 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39323'. Reason: nanny-close
2024-01-15 06:37:48,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38295'. Reason: nanny-close
2024-01-15 06:37:48,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39561. Reason: nanny-close
2024-01-15 06:37:48,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,972 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38441'. Reason: nanny-close
2024-01-15 06:37:48,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39485. Reason: nanny-close
2024-01-15 06:37:48,972 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,972 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39697'. Reason: nanny-close
2024-01-15 06:37:48,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39787. Reason: nanny-close
2024-01-15 06:37:48,973 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,973 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42723'. Reason: nanny-close
2024-01-15 06:37:48,973 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35155. Reason: nanny-close
2024-01-15 06:37:48,973 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,973 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38593'. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34937. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39835'. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33439. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44229. Reason: nanny-close
2024-01-15 06:37:48,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,975 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,975 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33827. Reason: nanny-close
2024-01-15 06:37:48,975 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49572; closing.
2024-01-15 06:37:48,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49554; closing.
2024-01-15 06:37:48,976 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39561', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.976072')
2024-01-15 06:37:48,976 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,976 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,976 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,977 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49520; closing.
2024-01-15 06:37:48,976 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,977 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49576; closing.
2024-01-15 06:37:48,977 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:48,977 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35155', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9778337')
2024-01-15 06:37:48,978 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,978 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,978 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,978 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39787', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9788165')
2024-01-15 06:37:48,978 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:48,979 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39485', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9792483')
2024-01-15 06:37:48,980 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49530; closing.
2024-01-15 06:37:48,980 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49586; closing.
2024-01-15 06:37:48,980 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49546; closing.
2024-01-15 06:37:48,981 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49576>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-15 06:37:48,982 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49520>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-15 06:37:48,983 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34937', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9834118')
2024-01-15 06:37:48,983 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44229', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9838083')
2024-01-15 06:37:48,984 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33439', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9842083')
2024-01-15 06:37:48,984 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49560; closing.
2024-01-15 06:37:48,985 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300668.9851124')
2024-01-15 06:37:48,985 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:37:49,936 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:37:49,936 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:37:49,937 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:37:49,938 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:37:49,939 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-15 06:37:52,052 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:52,056 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36075 instead
  warnings.warn(
2024-01-15 06:37:52,060 - distributed.scheduler - INFO - State start
2024-01-15 06:37:52,087 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:37:52,088 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:37:52,088 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36075/status
2024-01-15 06:37:52,089 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:37:52,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44741'
2024-01-15 06:37:52,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40737'
2024-01-15 06:37:52,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42789'
2024-01-15 06:37:52,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37675'
2024-01-15 06:37:52,702 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36179'
2024-01-15 06:37:52,711 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42007'
2024-01-15 06:37:52,720 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41569'
2024-01-15 06:37:52,730 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39397'
2024-01-15 06:37:52,859 - distributed.scheduler - INFO - Receive client connection: Client-9a70492e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:52,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54638
2024-01-15 06:37:54,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,577 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,578 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40689
2024-01-15 06:37:54,578 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40689
2024-01-15 06:37:54,578 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38471
2024-01-15 06:37:54,578 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,578 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,578 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,579 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,579 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zf8pscxu
2024-01-15 06:37:54,579 - distributed.worker - INFO - Starting Worker plugin PreImport-c57925ae-4968-479e-892f-7d5c79ed8b10
2024-01-15 06:37:54,579 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-baa19f85-825e-4e91-a833-c3d4960cd9cb
2024-01-15 06:37:54,579 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bdf93804-b5ed-4b12-8054-2514b916a36d
2024-01-15 06:37:54,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,603 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36945
2024-01-15 06:37:54,604 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36945
2024-01-15 06:37:54,604 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44489
2024-01-15 06:37:54,604 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,604 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,604 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,604 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,604 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9ipu1gqf
2024-01-15 06:37:54,604 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8f133614-863e-40c6-beee-72b2d85ec2ed
2024-01-15 06:37:54,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,627 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,628 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36363
2024-01-15 06:37:54,628 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36363
2024-01-15 06:37:54,628 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33673
2024-01-15 06:37:54,628 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,628 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,628 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1qzh8igj
2024-01-15 06:37:54,628 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f2d87f4-30ce-4f2b-b380-366322c3a03a
2024-01-15 06:37:54,631 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,632 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32847
2024-01-15 06:37:54,632 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32847
2024-01-15 06:37:54,632 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40421
2024-01-15 06:37:54,632 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,632 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,632 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,632 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,632 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hj44fhus
2024-01-15 06:37:54,633 - distributed.worker - INFO - Starting Worker plugin PreImport-e6e9f573-212f-4add-9445-32686b44958d
2024-01-15 06:37:54,633 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71dca752-f3fb-4c39-9abd-87baaf627434
2024-01-15 06:37:54,633 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1eb79c38-6aaf-42c8-b5bf-e4145918dc54
2024-01-15 06:37:54,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,638 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,639 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35943
2024-01-15 06:37:54,639 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35943
2024-01-15 06:37:54,639 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33691
2024-01-15 06:37:54,639 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,639 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,639 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,639 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,639 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,640 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f74zwnmq
2024-01-15 06:37:54,640 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be1204e3-49df-4c6d-87d4-5815d4d4bc4d
2024-01-15 06:37:54,640 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43051
2024-01-15 06:37:54,640 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43051
2024-01-15 06:37:54,640 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41473
2024-01-15 06:37:54,640 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,640 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,640 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,640 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,640 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_i31h7nb
2024-01-15 06:37:54,641 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dc394748-b4e5-4116-a2c1-4ccabaa35831
2024-01-15 06:37:54,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,699 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,700 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37705
2024-01-15 06:37:54,700 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37705
2024-01-15 06:37:54,700 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34811
2024-01-15 06:37:54,700 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,701 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,701 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,701 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,701 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fuw8mvwv
2024-01-15 06:37:54,701 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fe32ec7c-dff6-4345-994d-4c4f6f6dae27
2024-01-15 06:37:54,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:37:54,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:37:54,716 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:37:54,717 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35441
2024-01-15 06:37:54,717 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35441
2024-01-15 06:37:54,717 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37023
2024-01-15 06:37:54,717 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:37:54,717 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:54,717 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:37:54,717 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:37:54,717 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yef9uur7
2024-01-15 06:37:54,717 - distributed.worker - INFO - Starting Worker plugin RMMSetup-abdb6841-e2d1-4119-822c-08a43b16af22
2024-01-15 06:37:56,756 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,790 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40689', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,792 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40689
2024-01-15 06:37:56,792 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54654
2024-01-15 06:37:56,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,794 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,795 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,796 - distributed.worker - INFO - Starting Worker plugin PreImport-1e905ac7-0b5f-4768-967f-c7070cc2ce1a
2024-01-15 06:37:56,796 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,797 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce246074-01f9-4f93-8844-7ffdd0e44ed8
2024-01-15 06:37:56,798 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,801 - distributed.worker - INFO - Starting Worker plugin PreImport-357f4dc9-fbf3-4e92-87f0-abba5c8891bb
2024-01-15 06:37:56,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e91e0bba-520d-47d1-bbac-343f919e2bed
2024-01-15 06:37:56,803 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,825 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,826 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14de8829-1a16-41b9-a02d-28660cca6ea3
2024-01-15 06:37:56,827 - distributed.worker - INFO - Starting Worker plugin PreImport-6996e29e-2eb7-4b1b-9391-a7970ac2419a
2024-01-15 06:37:56,828 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,832 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36363', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,833 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36363
2024-01-15 06:37:56,833 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54668
2024-01-15 06:37:56,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,836 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,838 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,838 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36945', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,839 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36945
2024-01-15 06:37:56,839 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54670
2024-01-15 06:37:56,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,842 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,842 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,843 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-49c8d092-d971-4390-a989-b224f0b3be27
2024-01-15 06:37:56,844 - distributed.worker - INFO - Starting Worker plugin PreImport-1df95c90-9037-4165-ad78-32affd5c5e6f
2024-01-15 06:37:56,844 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,844 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,845 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bb352d7c-8034-4f32-9bd2-b23a5d389580
2024-01-15 06:37:56,846 - distributed.worker - INFO - Starting Worker plugin PreImport-5906eddf-51a8-4760-be0c-361080a8b369
2024-01-15 06:37:56,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,854 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32847', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,854 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32847
2024-01-15 06:37:56,854 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54686
2024-01-15 06:37:56,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,857 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,857 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,858 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,862 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43051', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,863 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43051
2024-01-15 06:37:56,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54696
2024-01-15 06:37:56,864 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,866 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,866 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,866 - distributed.worker - INFO - Starting Worker plugin PreImport-1a5cc039-cebb-4557-82b2-0fed532df937
2024-01-15 06:37:56,867 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a93d711-4632-4624-ab2b-b7890e1a4aaf
2024-01-15 06:37:56,868 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,868 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,869 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37705', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,870 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37705
2024-01-15 06:37:56,870 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54714
2024-01-15 06:37:56,871 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,871 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35943', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,871 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,872 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,872 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35943
2024-01-15 06:37:56,872 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54700
2024-01-15 06:37:56,873 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,874 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,874 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,893 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35441', status: init, memory: 0, processing: 0>
2024-01-15 06:37:56,893 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35441
2024-01-15 06:37:56,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54728
2024-01-15 06:37:56,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:37:56,896 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:37:56,896 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:37:56,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:37:56,916 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,917 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,917 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,917 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,917 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:37:56,930 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,930 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,930 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,930 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,931 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,931 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,931 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,931 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:37:56,939 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:37:56,941 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:37:56,944 - distributed.scheduler - INFO - Remove client Client-9a70492e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:56,944 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54638; closing.
2024-01-15 06:37:56,944 - distributed.scheduler - INFO - Remove client Client-9a70492e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:56,944 - distributed.scheduler - INFO - Close client connection: Client-9a70492e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:37:56,945 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44741'. Reason: nanny-close
2024-01-15 06:37:56,946 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,946 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40737'. Reason: nanny-close
2024-01-15 06:37:56,947 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,947 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42789'. Reason: nanny-close
2024-01-15 06:37:56,947 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36945. Reason: nanny-close
2024-01-15 06:37:56,947 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37675'. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40689. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36179'. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37705. Reason: nanny-close
2024-01-15 06:37:56,948 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42007'. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35943. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41569'. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43051. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,949 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39397'. Reason: nanny-close
2024-01-15 06:37:56,950 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,950 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:37:56,950 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36363. Reason: nanny-close
2024-01-15 06:37:56,950 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,950 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54670; closing.
2024-01-15 06:37:56,950 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35441. Reason: nanny-close
2024-01-15 06:37:56,950 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,950 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,950 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54700; closing.
2024-01-15 06:37:56,950 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32847. Reason: nanny-close
2024-01-15 06:37:56,951 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36945', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9511018')
2024-01-15 06:37:56,951 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,952 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,952 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,952 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35943', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9522731')
2024-01-15 06:37:56,952 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,952 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,952 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,952 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,953 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:37:56,953 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54714; closing.
2024-01-15 06:37:56,953 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54654; closing.
2024-01-15 06:37:56,954 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,954 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,954 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,955 - distributed.nanny - INFO - Worker closed
2024-01-15 06:37:56,955 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37705', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9552546')
2024-01-15 06:37:56,955 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.955836')
2024-01-15 06:37:56,956 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54696; closing.
2024-01-15 06:37:56,958 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43051', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9579766')
2024-01-15 06:37:56,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54668; closing.
2024-01-15 06:37:56,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54728; closing.
2024-01-15 06:37:56,959 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54686; closing.
2024-01-15 06:37:56,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36363', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9597445')
2024-01-15 06:37:56,960 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35441', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9603622')
2024-01-15 06:37:56,961 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300676.9609225')
2024-01-15 06:37:56,961 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:37:58,062 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:37:58,063 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:37:58,063 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:37:58,064 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:37:58,065 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-15 06:38:00,216 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:00,221 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44675 instead
  warnings.warn(
2024-01-15 06:38:00,225 - distributed.scheduler - INFO - State start
2024-01-15 06:38:00,248 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:00,249 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:00,250 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44675/status
2024-01-15 06:38:00,250 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:00,589 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34449'
2024-01-15 06:38:00,602 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32887'
2024-01-15 06:38:00,613 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42615'
2024-01-15 06:38:00,626 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44885'
2024-01-15 06:38:00,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40821'
2024-01-15 06:38:00,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38065'
2024-01-15 06:38:00,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37333'
2024-01-15 06:38:00,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33335'
2024-01-15 06:38:01,216 - distributed.scheduler - INFO - Receive client connection: Client-9f414f26-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:01,232 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59556
2024-01-15 06:38:02,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,538 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,539 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37687
2024-01-15 06:38:02,539 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37687
2024-01-15 06:38:02,539 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38495
2024-01-15 06:38:02,539 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,539 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,539 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,539 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,539 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nngc_igv
2024-01-15 06:38:02,540 - distributed.worker - INFO - Starting Worker plugin RMMSetup-355ec7dc-35e3-45d0-bc9d-cf3f75eb9a81
2024-01-15 06:38:02,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,545 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46187
2024-01-15 06:38:02,546 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46187
2024-01-15 06:38:02,546 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40587
2024-01-15 06:38:02,546 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,546 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,546 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,546 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0wk604ro
2024-01-15 06:38:02,546 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1f4ef3d-0d24-499d-8020-c9bda851e8f5
2024-01-15 06:38:02,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,556 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,557 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35885
2024-01-15 06:38:02,557 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35885
2024-01-15 06:38:02,557 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46251
2024-01-15 06:38:02,557 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,558 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,558 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,558 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,558 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j0mqr_x4
2024-01-15 06:38:02,558 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4b903577-1054-4f8f-8849-ec2b9f1e3904
2024-01-15 06:38:02,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,571 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,572 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35031
2024-01-15 06:38:02,572 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35031
2024-01-15 06:38:02,572 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37957
2024-01-15 06:38:02,572 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,572 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,572 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,572 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ocbucic2
2024-01-15 06:38:02,573 - distributed.worker - INFO - Starting Worker plugin PreImport-04a3e56f-098c-4307-95e1-41527a83c25a
2024-01-15 06:38:02,573 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3eba536-c54c-4ea1-b9b1-1ff4be5834ed
2024-01-15 06:38:02,573 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e1912195-3849-4131-a0ff-1969716839e0
2024-01-15 06:38:02,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,583 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,584 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38609
2024-01-15 06:38:02,584 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38609
2024-01-15 06:38:02,584 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40395
2024-01-15 06:38:02,584 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,584 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,584 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,584 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,584 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6q3c80c0
2024-01-15 06:38:02,584 - distributed.worker - INFO - Starting Worker plugin PreImport-1f41efb2-dc08-4327-b539-b145c08ebab2
2024-01-15 06:38:02,584 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a86e024b-286b-4513-85b6-1b7dbe0e3bdc
2024-01-15 06:38:02,584 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f364e573-7911-45c1-a5c3-a5a34a56cc91
2024-01-15 06:38:02,585 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,586 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40711
2024-01-15 06:38:02,586 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40711
2024-01-15 06:38:02,586 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39359
2024-01-15 06:38:02,586 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,586 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,586 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,586 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,586 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7t0e_im7
2024-01-15 06:38:02,587 - distributed.worker - INFO - Starting Worker plugin RMMSetup-522262cc-61d2-4c2c-aed2-1a35b184b84b
2024-01-15 06:38:02,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,629 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,630 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44453
2024-01-15 06:38:02,630 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44453
2024-01-15 06:38:02,630 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34393
2024-01-15 06:38:02,630 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,630 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,630 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,630 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,630 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4inpj93r
2024-01-15 06:38:02,631 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e34669e-1825-4731-935d-d09dcb5b8ad2
2024-01-15 06:38:02,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:02,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:02,636 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:02,637 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41123
2024-01-15 06:38:02,637 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41123
2024-01-15 06:38:02,637 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41019
2024-01-15 06:38:02,637 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:02,637 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:02,637 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:02,637 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:02,638 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4xf6lkim
2024-01-15 06:38:02,638 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3f0f6f5c-129f-4d24-9127-d5a52f7ee936
2024-01-15 06:38:04,744 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c141a403-06ba-40ad-bdf8-bba68f46728a
2024-01-15 06:38:04,744 - distributed.worker - INFO - Starting Worker plugin PreImport-348b7ba1-0418-4c67-9462-a2caf448c97c
2024-01-15 06:38:04,745 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,750 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-362044d1-fb2c-4231-82ee-f86d8c21214c
2024-01-15 06:38:04,751 - distributed.worker - INFO - Starting Worker plugin PreImport-35c3572d-4ec0-4109-8c33-a803fa5b6414
2024-01-15 06:38:04,752 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,756 - distributed.worker - INFO - Starting Worker plugin PreImport-dc116192-474e-43fa-b88e-45b10d1cd86e
2024-01-15 06:38:04,756 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e23cf049-a4b5-428d-a70d-5f4e22aa4d8a
2024-01-15 06:38:04,758 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,770 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37687', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,771 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37687
2024-01-15 06:38:04,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59564
2024-01-15 06:38:04,773 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,774 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,774 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,775 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,786 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46187', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,786 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46187
2024-01-15 06:38:04,787 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59566
2024-01-15 06:38:04,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,789 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,789 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,790 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35885', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,791 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35885
2024-01-15 06:38:04,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59570
2024-01-15 06:38:04,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,792 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,794 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,794 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,820 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,823 - distributed.worker - INFO - Starting Worker plugin PreImport-735ba01e-4274-46b0-a851-767dfe724109
2024-01-15 06:38:04,824 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77631e76-2ea3-41f1-8410-f328ffa9750f
2024-01-15 06:38:04,825 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,839 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37406dd3-68f1-41ae-b1e0-d4ac7531d097
2024-01-15 06:38:04,840 - distributed.worker - INFO - Starting Worker plugin PreImport-d188b439-4207-4ccd-8141-f0de6a90d38b
2024-01-15 06:38:04,840 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,844 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38609', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,844 - distributed.worker - INFO - Starting Worker plugin PreImport-49f12fc3-f111-4854-9758-6e7c1e7d21c8
2024-01-15 06:38:04,845 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38609
2024-01-15 06:38:04,845 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59578
2024-01-15 06:38:04,845 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3d3a2ee-9b25-48d2-8dc9-2b10a01060bc
2024-01-15 06:38:04,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,847 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,847 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,848 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,855 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40711', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,856 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40711
2024-01-15 06:38:04,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59588
2024-01-15 06:38:04,857 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,858 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,858 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,859 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,863 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44453', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,864 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44453
2024-01-15 06:38:04,864 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59598
2024-01-15 06:38:04,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,866 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,866 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,868 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,878 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41123', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,878 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41123
2024-01-15 06:38:04,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59602
2024-01-15 06:38:04,879 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35031', status: init, memory: 0, processing: 0>
2024-01-15 06:38:04,880 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35031
2024-01-15 06:38:04,880 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59618
2024-01-15 06:38:04,880 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,881 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,881 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,881 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:04,883 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:04,883 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:04,883 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,885 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,954 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,955 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,955 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,966 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,966 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,966 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,966 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,967 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,967 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,967 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,967 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:04,975 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,977 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:04,979 - distributed.scheduler - INFO - Remove client Client-9f414f26-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:04,979 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59556; closing.
2024-01-15 06:38:04,980 - distributed.scheduler - INFO - Remove client Client-9f414f26-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:04,980 - distributed.scheduler - INFO - Close client connection: Client-9f414f26-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:04,981 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34449'. Reason: nanny-close
2024-01-15 06:38:04,981 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32887'. Reason: nanny-close
2024-01-15 06:38:04,982 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42615'. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35885. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44885'. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35031. Reason: nanny-close
2024-01-15 06:38:04,983 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40821'. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44453. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38065'. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37687. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,984 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37333'. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33335'. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46187. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41123. Reason: nanny-close
2024-01-15 06:38:04,985 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,985 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,985 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40711. Reason: nanny-close
2024-01-15 06:38:04,986 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59570; closing.
2024-01-15 06:38:04,986 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59598; closing.
2024-01-15 06:38:04,986 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38609. Reason: nanny-close
2024-01-15 06:38:04,986 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,986 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35885', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.986436')
2024-01-15 06:38:04,986 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44453', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.986995')
2024-01-15 06:38:04,987 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,987 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,987 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:04,988 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59566; closing.
2024-01-15 06:38:04,988 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,988 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59564; closing.
2024-01-15 06:38:04,989 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59618; closing.
2024-01-15 06:38:04,989 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,989 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,989 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,990 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:04,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46187', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9899502')
2024-01-15 06:38:04,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37687', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9903352')
2024-01-15 06:38:04,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59602; closing.
2024-01-15 06:38:04,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9908803')
2024-01-15 06:38:04,991 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59588; closing.
2024-01-15 06:38:04,991 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59578; closing.
2024-01-15 06:38:04,991 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41123', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9917064')
2024-01-15 06:38:04,992 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40711', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9920862')
2024-01-15 06:38:04,992 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38609', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300684.9924276')
2024-01-15 06:38:04,992 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:06,198 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:06,198 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:06,199 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:06,200 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:06,200 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-15 06:38:08,493 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:08,498 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-15 06:38:08,502 - distributed.scheduler - INFO - State start
2024-01-15 06:38:08,524 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:08,525 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:08,526 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-15 06:38:08,526 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:08,688 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35511'
2024-01-15 06:38:08,707 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42203'
2024-01-15 06:38:08,720 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46083'
2024-01-15 06:38:08,735 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41015'
2024-01-15 06:38:08,738 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42539'
2024-01-15 06:38:08,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37885'
2024-01-15 06:38:08,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40839'
2024-01-15 06:38:08,768 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38945'
2024-01-15 06:38:09,694 - distributed.scheduler - INFO - Receive client connection: Client-a41756fb-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:09,709 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59766
2024-01-15 06:38:10,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,611 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,612 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46623
2024-01-15 06:38:10,612 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46623
2024-01-15 06:38:10,612 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37859
2024-01-15 06:38:10,612 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,613 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,613 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,613 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,613 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7nc1pbvx
2024-01-15 06:38:10,613 - distributed.worker - INFO - Starting Worker plugin PreImport-5babfe8d-52d9-4e03-b3d2-c1dc3b6ee281
2024-01-15 06:38:10,613 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-88de3559-8fb5-40c2-b436-810734dc80d7
2024-01-15 06:38:10,614 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2bb01dab-39d9-4c44-bd1b-2caca8dff615
2024-01-15 06:38:10,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,670 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,671 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41269
2024-01-15 06:38:10,671 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41269
2024-01-15 06:38:10,671 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43963
2024-01-15 06:38:10,671 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,671 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,671 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,671 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,671 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iokl_e7a
2024-01-15 06:38:10,672 - distributed.worker - INFO - Starting Worker plugin RMMSetup-061c9881-f433-49ba-8c83-9b29a65ea7b4
2024-01-15 06:38:10,672 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,673 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33231
2024-01-15 06:38:10,673 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33231
2024-01-15 06:38:10,673 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45971
2024-01-15 06:38:10,673 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,673 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,673 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,673 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,673 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u97j00ww
2024-01-15 06:38:10,673 - distributed.worker - INFO - Starting Worker plugin RMMSetup-12a07fa6-4806-4937-8f3b-7e7431fae69f
2024-01-15 06:38:10,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,677 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,678 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35961
2024-01-15 06:38:10,678 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35961
2024-01-15 06:38:10,678 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35915
2024-01-15 06:38:10,678 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,678 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,678 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,678 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,678 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hpdpo3wy
2024-01-15 06:38:10,678 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e3e1fb20-f5e9-47fa-a000-ada2fbd9b2a8
2024-01-15 06:38:10,679 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,680 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35705
2024-01-15 06:38:10,680 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35705
2024-01-15 06:38:10,680 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39431
2024-01-15 06:38:10,680 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,680 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,680 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,680 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,680 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5vga_41u
2024-01-15 06:38:10,680 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6f24b8d-6347-42dd-9697-e546047df21e
2024-01-15 06:38:10,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,686 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,687 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44667
2024-01-15 06:38:10,687 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44667
2024-01-15 06:38:10,687 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46309
2024-01-15 06:38:10,687 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,687 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,687 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,687 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,688 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3tfmhh5j
2024-01-15 06:38:10,688 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6793cb1-6bba-4f26-a027-440feafadc4c
2024-01-15 06:38:10,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:10,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:10,745 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,746 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:10,746 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46171
2024-01-15 06:38:10,746 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46171
2024-01-15 06:38:10,746 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46279
2024-01-15 06:38:10,746 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,746 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,746 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,747 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,747 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-epxcu1r8
2024-01-15 06:38:10,747 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41069
2024-01-15 06:38:10,747 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41069
2024-01-15 06:38:10,747 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42229
2024-01-15 06:38:10,747 - distributed.worker - INFO - Starting Worker plugin PreImport-19c1867b-3b1e-4e05-8283-b86f0b37c85e
2024-01-15 06:38:10,747 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:10,747 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:10,747 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:10,747 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-563f9d21-5408-4b40-b514-f9cebb40faee
2024-01-15 06:38:10,747 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:10,747 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0pvkgsu2
2024-01-15 06:38:10,747 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f74248b0-e58f-4c8a-a8a8-d9bb172f5966
2024-01-15 06:38:10,747 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3c8e7828-c3fe-4280-bbec-f69c6347737f
2024-01-15 06:38:12,838 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-635510ce-5851-4699-a4a1-b7e5e9e43fd2
2024-01-15 06:38:12,839 - distributed.worker - INFO - Starting Worker plugin PreImport-9da2ed68-5bbe-4c1e-9141-abe70cd660e3
2024-01-15 06:38:12,839 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,858 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,865 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41269', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,866 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41269
2024-01-15 06:38:12,866 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38104
2024-01-15 06:38:12,867 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,868 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,868 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,870 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e55bf65-cd1a-4a72-b24d-be97677d36cb
2024-01-15 06:38:12,871 - distributed.worker - INFO - Starting Worker plugin PreImport-42599362-e81a-482f-854c-497a2dbd7419
2024-01-15 06:38:12,871 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,877 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f887eb65-1d13-44a5-aafe-3ad47ec662a0
2024-01-15 06:38:12,878 - distributed.worker - INFO - Starting Worker plugin PreImport-1f75a40c-3f2e-4f2f-a5a9-02dbe78d0725
2024-01-15 06:38:12,879 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,892 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46623', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,892 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46623
2024-01-15 06:38:12,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38110
2024-01-15 06:38:12,893 - distributed.worker - INFO - Starting Worker plugin PreImport-ed54110a-1cc6-43a2-953f-daaa70412ee8
2024-01-15 06:38:12,894 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ae4318f-f5b6-4179-8cc3-c1851955ad1e
2024-01-15 06:38:12,894 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,895 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,895 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,896 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,896 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44667', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,897 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44667
2024-01-15 06:38:12,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38120
2024-01-15 06:38:12,898 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,899 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,899 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,900 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,901 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,901 - distributed.worker - INFO - Starting Worker plugin PreImport-3eef58ea-cb0f-402d-989b-482b9675ff07
2024-01-15 06:38:12,902 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a196f8b7-c2c3-4127-80c3-b37362fa89f2
2024-01-15 06:38:12,903 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,913 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,913 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35705', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,914 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35705
2024-01-15 06:38:12,914 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38122
2024-01-15 06:38:12,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,917 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,917 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,931 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35961', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,932 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35961
2024-01-15 06:38:12,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38136
2024-01-15 06:38:12,933 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,935 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,935 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,934 - distributed.worker - INFO - Starting Worker plugin PreImport-946536e3-bea5-406c-91b3-b5effe3d7141
2024-01-15 06:38:12,935 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f96f253c-18af-4ca9-9d75-3968b48f47fb
2024-01-15 06:38:12,936 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,937 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,939 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33231', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,939 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33231
2024-01-15 06:38:12,939 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38140
2024-01-15 06:38:12,940 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46171', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,941 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46171
2024-01-15 06:38:12,941 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38148
2024-01-15 06:38:12,941 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,942 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,942 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,942 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,943 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,943 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,944 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,944 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:12,956 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41069', status: init, memory: 0, processing: 0>
2024-01-15 06:38:12,957 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41069
2024-01-15 06:38:12,957 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38150
2024-01-15 06:38:12,958 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:12,959 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:12,959 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:12,960 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,022 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,023 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:13,029 - distributed.scheduler - INFO - Remove client Client-a41756fb-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:13,029 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59766; closing.
2024-01-15 06:38:13,029 - distributed.scheduler - INFO - Remove client Client-a41756fb-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:13,029 - distributed.scheduler - INFO - Close client connection: Client-a41756fb-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:13,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35511'. Reason: nanny-close
2024-01-15 06:38:13,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42203'. Reason: nanny-close
2024-01-15 06:38:13,032 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46083'. Reason: nanny-close
2024-01-15 06:38:13,032 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33231. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41015'. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46623. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42539'. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41269. Reason: nanny-close
2024-01-15 06:38:13,033 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,034 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37885'. Reason: nanny-close
2024-01-15 06:38:13,034 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44667. Reason: nanny-close
2024-01-15 06:38:13,034 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,035 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40839'. Reason: nanny-close
2024-01-15 06:38:13,035 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35705. Reason: nanny-close
2024-01-15 06:38:13,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,035 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38140; closing.
2024-01-15 06:38:13,035 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,035 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38945'. Reason: nanny-close
2024-01-15 06:38:13,035 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33231', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0358777')
2024-01-15 06:38:13,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,036 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,036 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35961. Reason: nanny-close
2024-01-15 06:38:13,036 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:13,036 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41069. Reason: nanny-close
2024-01-15 06:38:13,037 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,037 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46171. Reason: nanny-close
2024-01-15 06:38:13,037 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,037 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,037 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,037 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38120; closing.
2024-01-15 06:38:13,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38110; closing.
2024-01-15 06:38:13,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38104; closing.
2024-01-15 06:38:13,038 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,038 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,039 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44667', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.03948')
2024-01-15 06:38:13,039 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,039 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,039 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:13,039 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46623', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0398874')
2024-01-15 06:38:13,040 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41269', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0402734')
2024-01-15 06:38:13,040 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,040 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38122; closing.
2024-01-15 06:38:13,041 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,041 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35705', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0412726')
2024-01-15 06:38:13,041 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:13,041 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38150; closing.
2024-01-15 06:38:13,042 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41069', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0423427')
2024-01-15 06:38:13,042 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38136; closing.
2024-01-15 06:38:13,042 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38148; closing.
2024-01-15 06:38:13,043 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35961', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0432043')
2024-01-15 06:38:13,043 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46171', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300693.0435705')
2024-01-15 06:38:13,043 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:14,047 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:14,047 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:14,048 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:14,049 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:14,049 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-15 06:38:16,312 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:16,317 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45545 instead
  warnings.warn(
2024-01-15 06:38:16,320 - distributed.scheduler - INFO - State start
2024-01-15 06:38:16,348 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:16,349 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:16,349 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45545/status
2024-01-15 06:38:16,349 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:16,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37463'
2024-01-15 06:38:16,468 - distributed.scheduler - INFO - Receive client connection: Client-a8daf461-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:16,482 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38242
2024-01-15 06:38:18,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:18,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:18,679 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:18,680 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37083
2024-01-15 06:38:18,681 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37083
2024-01-15 06:38:18,681 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-15 06:38:18,681 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:18,681 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:18,681 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:18,681 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-15 06:38:18,681 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ggwjee9w
2024-01-15 06:38:18,681 - distributed.worker - INFO - Starting Worker plugin PreImport-2b0673b6-54ee-442b-8adc-3fca64d6e09b
2024-01-15 06:38:18,681 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-39ffd221-0cc7-4ad3-a92d-1523f2b67b58
2024-01-15 06:38:18,682 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1718989c-ed48-48bc-b917-11d215c69a12
2024-01-15 06:38:18,682 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:18,745 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37083', status: init, memory: 0, processing: 0>
2024-01-15 06:38:18,746 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37083
2024-01-15 06:38:18,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38264
2024-01-15 06:38:18,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:18,748 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:18,748 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:18,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:18,784 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:18,787 - distributed.scheduler - INFO - Remove client Client-a8daf461-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:18,787 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38242; closing.
2024-01-15 06:38:18,787 - distributed.scheduler - INFO - Remove client Client-a8daf461-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:18,788 - distributed.scheduler - INFO - Close client connection: Client-a8daf461-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:18,789 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37463'. Reason: nanny-close
2024-01-15 06:38:18,797 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:18,799 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37083. Reason: nanny-close
2024-01-15 06:38:18,800 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:18,801 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38264; closing.
2024-01-15 06:38:18,801 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37083', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300698.8013911')
2024-01-15 06:38:18,801 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:18,802 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:19,554 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:19,554 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:19,555 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:19,556 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:19,557 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-15 06:38:23,814 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:23,819 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42675 instead
  warnings.warn(
2024-01-15 06:38:23,823 - distributed.scheduler - INFO - State start
2024-01-15 06:38:23,845 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:23,846 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:23,847 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42675/status
2024-01-15 06:38:23,847 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:24,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34797'
2024-01-15 06:38:25,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:25,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:26,389 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:26,390 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41605
2024-01-15 06:38:26,390 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41605
2024-01-15 06:38:26,390 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42191
2024-01-15 06:38:26,390 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:26,390 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:26,390 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:26,390 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-15 06:38:26,390 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b2s6fgq2
2024-01-15 06:38:26,390 - distributed.worker - INFO - Starting Worker plugin PreImport-26370212-410b-4664-9f33-0a7ef7bda742
2024-01-15 06:38:26,392 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f80e625-ad27-4cde-aefb-ccd631148982
2024-01-15 06:38:26,392 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6eef38fd-7573-4aed-8ff2-cbebb35accd1
2024-01-15 06:38:26,392 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:26,486 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41605', status: init, memory: 0, processing: 0>
2024-01-15 06:38:26,520 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:26,520 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41605
2024-01-15 06:38:26,520 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41674
2024-01-15 06:38:26,520 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:26,521 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:26,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:28,324 - distributed.scheduler - INFO - Receive client connection: Client-ad437523-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:28,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41690
2024-01-15 06:38:28,331 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:28,337 - distributed.scheduler - INFO - Remove client Client-ad437523-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:28,338 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41690; closing.
2024-01-15 06:38:28,338 - distributed.scheduler - INFO - Remove client Client-ad437523-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:28,338 - distributed.scheduler - INFO - Close client connection: Client-ad437523-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:28,339 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34797'. Reason: nanny-close
2024-01-15 06:38:28,340 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:28,341 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41605. Reason: nanny-close
2024-01-15 06:38:28,343 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:28,343 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41674; closing.
2024-01-15 06:38:28,343 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41605', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300708.343533')
2024-01-15 06:38:28,344 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:28,344 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:29,255 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:29,256 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:29,257 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:29,258 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:29,259 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-15 06:38:31,655 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:31,660 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45795 instead
  warnings.warn(
2024-01-15 06:38:31,664 - distributed.scheduler - INFO - State start
2024-01-15 06:38:31,687 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:31,688 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:31,688 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45795/status
2024-01-15 06:38:31,689 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:34,220 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:45626'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4440, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:45626>: Stream is closed
2024-01-15 06:38:34,506 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:34,506 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:34,506 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:34,507 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:34,510 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-15 06:38:36,793 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:36,798 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39501 instead
  warnings.warn(
2024-01-15 06:38:36,802 - distributed.scheduler - INFO - State start
2024-01-15 06:38:36,825 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:36,826 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-15 06:38:36,826 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39501/status
2024-01-15 06:38:36,827 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:36,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40369'
2024-01-15 06:38:38,302 - distributed.scheduler - INFO - Receive client connection: Client-b501717e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:38,326 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38846
2024-01-15 06:38:38,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:38,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:38,636 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:38,637 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43643
2024-01-15 06:38:38,637 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43643
2024-01-15 06:38:38,637 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43581
2024-01-15 06:38:38,637 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-15 06:38:38,637 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:38,637 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:38,637 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-15 06:38:38,637 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-rdrw2ueg
2024-01-15 06:38:38,637 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3d305e7-47bb-4653-ac6c-d5bd46b2a62c
2024-01-15 06:38:38,638 - distributed.worker - INFO - Starting Worker plugin PreImport-34c916ac-e625-43cf-9379-8f8d3fd28ec8
2024-01-15 06:38:38,638 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb17258e-b267-4a3f-a15d-a806a3d77194
2024-01-15 06:38:38,638 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:38,704 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43643', status: init, memory: 0, processing: 0>
2024-01-15 06:38:38,705 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43643
2024-01-15 06:38:38,705 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38860
2024-01-15 06:38:38,706 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:38,707 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-15 06:38:38,707 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:38,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-15 06:38:38,718 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:38,720 - distributed.scheduler - INFO - Remove client Client-b501717e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:38,720 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38846; closing.
2024-01-15 06:38:38,721 - distributed.scheduler - INFO - Remove client Client-b501717e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:38,721 - distributed.scheduler - INFO - Close client connection: Client-b501717e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:38,722 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40369'. Reason: nanny-close
2024-01-15 06:38:38,727 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:38,728 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43643. Reason: nanny-close
2024-01-15 06:38:38,730 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-15 06:38:38,730 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38860; closing.
2024-01-15 06:38:38,730 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43643', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300718.730245')
2024-01-15 06:38:38,730 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:38,731 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:39,387 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:39,388 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:39,388 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:39,389 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-15 06:38:39,390 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-15 06:38:41,579 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:41,583 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38187 instead
  warnings.warn(
2024-01-15 06:38:41,587 - distributed.scheduler - INFO - State start
2024-01-15 06:38:41,610 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:41,611 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:41,612 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38187/status
2024-01-15 06:38:41,612 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:41,824 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37669'
2024-01-15 06:38:41,839 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34601'
2024-01-15 06:38:41,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42907'
2024-01-15 06:38:41,865 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43017'
2024-01-15 06:38:41,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45689'
2024-01-15 06:38:41,878 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32803'
2024-01-15 06:38:41,888 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46003'
2024-01-15 06:38:41,899 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39931'
2024-01-15 06:38:43,197 - distributed.scheduler - INFO - Receive client connection: Client-b7e7c0de-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:43,214 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45874
2024-01-15 06:38:43,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,748 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,749 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39513
2024-01-15 06:38:43,749 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39513
2024-01-15 06:38:43,749 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35109
2024-01-15 06:38:43,749 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,749 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,749 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,750 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,750 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ghfbaa2v
2024-01-15 06:38:43,750 - distributed.worker - INFO - Starting Worker plugin PreImport-53cc8ee5-0645-4447-9ba4-292c69cf9a94
2024-01-15 06:38:43,750 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c4c8cad-b658-406a-bcc6-6e582263a515
2024-01-15 06:38:43,751 - distributed.worker - INFO - Starting Worker plugin RMMSetup-84caadc1-1df5-4eb2-8ecd-cda0fefbb396
2024-01-15 06:38:43,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,774 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,774 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40831
2024-01-15 06:38:43,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40831
2024-01-15 06:38:43,774 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40537
2024-01-15 06:38:43,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,774 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,774 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46251
2024-01-15 06:38:43,774 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46251
2024-01-15 06:38:43,775 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,775 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33793
2024-01-15 06:38:43,775 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_hvy9gex
2024-01-15 06:38:43,775 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,775 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,775 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6a1d46ba-7b70-42e2-904c-bfa6224145fc
2024-01-15 06:38:43,775 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,775 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-as5nqv_4
2024-01-15 06:38:43,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93d26cd0-b359-4526-939c-5240e9bb734a
2024-01-15 06:38:43,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,822 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,823 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41283
2024-01-15 06:38:43,823 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41283
2024-01-15 06:38:43,824 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45635
2024-01-15 06:38:43,824 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,824 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,824 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,824 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,824 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ylu2zis6
2024-01-15 06:38:43,824 - distributed.worker - INFO - Starting Worker plugin RMMSetup-09f1b549-c736-40d5-8e99-0264c2f3e4ff
2024-01-15 06:38:43,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,838 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,838 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41033
2024-01-15 06:38:43,838 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41033
2024-01-15 06:38:43,839 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45301
2024-01-15 06:38:43,839 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,839 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,839 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,839 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,839 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ydxm92pg
2024-01-15 06:38:43,839 - distributed.worker - INFO - Starting Worker plugin PreImport-27931b9c-9f42-4a88-b8c7-3017ee547d07
2024-01-15 06:38:43,839 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-605a7192-010f-4193-9c3c-f4a780102a4d
2024-01-15 06:38:43,839 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6fe48d94-fa8f-4367-b96e-67286d36ea0b
2024-01-15 06:38:43,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:43,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:43,854 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,855 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41167
2024-01-15 06:38:43,855 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41167
2024-01-15 06:38:43,856 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46231
2024-01-15 06:38:43,856 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,856 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,856 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,856 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,856 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-42hytqtw
2024-01-15 06:38:43,856 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,856 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9898f774-cf75-4637-a406-47d0497ea68f
2024-01-15 06:38:43,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45593
2024-01-15 06:38:43,857 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45593
2024-01-15 06:38:43,857 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34267
2024-01-15 06:38:43,857 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,857 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,857 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,857 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,857 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b0eier2k
2024-01-15 06:38:43,857 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0fa9474b-946f-48c9-8983-02f2334e0f6d
2024-01-15 06:38:43,857 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:43,858 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38289
2024-01-15 06:38:43,858 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38289
2024-01-15 06:38:43,858 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39941
2024-01-15 06:38:43,859 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:43,859 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:43,859 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:43,859 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-15 06:38:43,859 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b590ygti
2024-01-15 06:38:43,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9452920b-80ac-4996-956a-e245e89f1913
2024-01-15 06:38:45,807 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,840 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39513', status: init, memory: 0, processing: 0>
2024-01-15 06:38:45,842 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39513
2024-01-15 06:38:45,842 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45904
2024-01-15 06:38:45,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:45,844 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:45,844 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,846 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:45,919 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7106261f-a0c9-4632-b568-fecf18c6c55f
2024-01-15 06:38:45,920 - distributed.worker - INFO - Starting Worker plugin PreImport-1c9609bc-9353-40ff-b413-b7da82303af1
2024-01-15 06:38:45,921 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,939 - distributed.worker - INFO - Starting Worker plugin PreImport-993b9c0a-8f84-4e62-9d33-32ba14120f56
2024-01-15 06:38:45,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-202010fa-668c-4b2e-88f8-4b4e028ee445
2024-01-15 06:38:45,941 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,956 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46251', status: init, memory: 0, processing: 0>
2024-01-15 06:38:45,957 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46251
2024-01-15 06:38:45,957 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45914
2024-01-15 06:38:45,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:45,960 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:45,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,963 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:45,977 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40831', status: init, memory: 0, processing: 0>
2024-01-15 06:38:45,977 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40831
2024-01-15 06:38:45,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45926
2024-01-15 06:38:45,979 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:45,980 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:45,980 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,982 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:45,989 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ec11af92-b2e8-4506-8205-2e3fbe95047a
2024-01-15 06:38:45,989 - distributed.worker - INFO - Starting Worker plugin PreImport-944e5134-d733-4880-9d92-64ee46fbd57c
2024-01-15 06:38:45,990 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:45,997 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,014 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41283', status: init, memory: 0, processing: 0>
2024-01-15 06:38:46,015 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41283
2024-01-15 06:38:46,015 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45938
2024-01-15 06:38:46,016 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:46,017 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:46,017 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,018 - distributed.worker - INFO - Starting Worker plugin PreImport-d603591c-13b7-4755-a1a6-ec587084c1d7
2024-01-15 06:38:46,019 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8e53761b-8e3f-48cf-af1a-70926cd6e084
2024-01-15 06:38:46,019 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:46,020 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,022 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41033', status: init, memory: 0, processing: 0>
2024-01-15 06:38:46,022 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41033
2024-01-15 06:38:46,022 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45952
2024-01-15 06:38:46,023 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:46,023 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f9a92fc-28e2-4a2e-b5bd-6d817fdbdbc9
2024-01-15 06:38:46,024 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:46,024 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,024 - distributed.worker - INFO - Starting Worker plugin PreImport-957a1f62-e23a-49b0-8091-327a9d8b6d1d
2024-01-15 06:38:46,025 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,026 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:46,039 - distributed.worker - INFO - Starting Worker plugin PreImport-312d865e-4b36-4317-b5a3-341cc686663f
2024-01-15 06:38:46,040 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b26ec8a-706f-40e9-8a9c-132df6c8512e
2024-01-15 06:38:46,041 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,044 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38289', status: init, memory: 0, processing: 0>
2024-01-15 06:38:46,044 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38289
2024-01-15 06:38:46,045 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45964
2024-01-15 06:38:46,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:46,047 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:46,047 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,049 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:46,053 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41167', status: init, memory: 0, processing: 0>
2024-01-15 06:38:46,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41167
2024-01-15 06:38:46,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45970
2024-01-15 06:38:46,054 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:46,055 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:46,056 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:46,068 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45593', status: init, memory: 0, processing: 0>
2024-01-15 06:38:46,069 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45593
2024-01-15 06:38:46,069 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45986
2024-01-15 06:38:46,070 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:46,071 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:46,071 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:46,073 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:46,177 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,177 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,178 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-15 06:38:46,191 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,192 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:46,196 - distributed.scheduler - INFO - Remove client Client-b7e7c0de-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:46,197 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45874; closing.
2024-01-15 06:38:46,197 - distributed.scheduler - INFO - Remove client Client-b7e7c0de-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:46,197 - distributed.scheduler - INFO - Close client connection: Client-b7e7c0de-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:46,198 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37669'. Reason: nanny-close
2024-01-15 06:38:46,199 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,199 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34601'. Reason: nanny-close
2024-01-15 06:38:46,199 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,200 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42907'. Reason: nanny-close
2024-01-15 06:38:46,200 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40831. Reason: nanny-close
2024-01-15 06:38:46,200 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,200 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43017'. Reason: nanny-close
2024-01-15 06:38:46,200 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39513. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45689'. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41167. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32803'. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41283. Reason: nanny-close
2024-01-15 06:38:46,201 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46003'. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46251. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39931'. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45593. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,202 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38289. Reason: nanny-close
2024-01-15 06:38:46,202 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,203 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45926; closing.
2024-01-15 06:38:46,203 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,203 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40831', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2034204')
2024-01-15 06:38:46,203 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41033. Reason: nanny-close
2024-01-15 06:38:46,203 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,203 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45970; closing.
2024-01-15 06:38:46,204 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,204 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,204 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41167', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2045968')
2024-01-15 06:38:46,204 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,204 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,204 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,205 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45904; closing.
2024-01-15 06:38:46,205 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,205 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:46,205 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,206 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,206 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39513', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2062056')
2024-01-15 06:38:46,206 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,206 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,206 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45914; closing.
2024-01-15 06:38:46,206 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:46,206 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45938; closing.
2024-01-15 06:38:46,207 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:45970>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-15 06:38:46,209 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46251', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.208996')
2024-01-15 06:38:46,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45986; closing.
2024-01-15 06:38:46,209 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41283', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2095833')
2024-01-15 06:38:46,209 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45964; closing.
2024-01-15 06:38:46,210 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45593', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2103765')
2024-01-15 06:38:46,210 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38289', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2108853')
2024-01-15 06:38:46,211 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45952; closing.
2024-01-15 06:38:46,211 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300726.2117276')
2024-01-15 06:38:46,211 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:47,164 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:47,165 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:47,165 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:47,167 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:47,167 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-15 06:38:49,286 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:49,293 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36829 instead
  warnings.warn(
2024-01-15 06:38:49,300 - distributed.scheduler - INFO - State start
2024-01-15 06:38:49,333 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:49,334 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:49,336 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36829/status
2024-01-15 06:38:49,336 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:49,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42279'
2024-01-15 06:38:51,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:51,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:51,388 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:51,389 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44645
2024-01-15 06:38:51,389 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44645
2024-01-15 06:38:51,389 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39879
2024-01-15 06:38:51,389 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:51,389 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:51,389 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:51,389 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-15 06:38:51,389 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z9jchxho
2024-01-15 06:38:51,390 - distributed.worker - INFO - Starting Worker plugin PreImport-f82f5a66-4b06-413d-85eb-4227e87a3b87
2024-01-15 06:38:51,390 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c899b376-5018-4d11-8182-ebfb25871ce3
2024-01-15 06:38:51,390 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7272e800-7735-4e0a-9626-b9876a9ec22e
2024-01-15 06:38:51,696 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:51,742 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44645', status: init, memory: 0, processing: 0>
2024-01-15 06:38:51,757 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44645
2024-01-15 06:38:51,757 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38240
2024-01-15 06:38:51,758 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:51,759 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:51,759 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:51,760 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:51,980 - distributed.scheduler - INFO - Receive client connection: Client-bc82f771-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:51,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38242
2024-01-15 06:38:51,986 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:51,991 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:51,992 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:51,995 - distributed.scheduler - INFO - Remove client Client-bc82f771-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:51,995 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38242; closing.
2024-01-15 06:38:51,995 - distributed.scheduler - INFO - Remove client Client-bc82f771-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:51,996 - distributed.scheduler - INFO - Close client connection: Client-bc82f771-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:51,996 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42279'. Reason: nanny-close
2024-01-15 06:38:51,997 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:51,998 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44645. Reason: nanny-close
2024-01-15 06:38:52,000 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:52,000 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38240; closing.
2024-01-15 06:38:52,000 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44645', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300732.0008779')
2024-01-15 06:38:52,001 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:52,002 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:52,712 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:52,712 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:52,713 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:52,714 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:52,715 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-15 06:38:55,102 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:55,106 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45685 instead
  warnings.warn(
2024-01-15 06:38:55,110 - distributed.scheduler - INFO - State start
2024-01-15 06:38:55,135 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-15 06:38:55,136 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-15 06:38:55,136 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45685/status
2024-01-15 06:38:55,136 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-15 06:38:55,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41363'
2024-01-15 06:38:55,611 - distributed.scheduler - INFO - Receive client connection: Client-bfe9241e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:55,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38378
2024-01-15 06:38:56,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-15 06:38:56,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-15 06:38:56,874 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-15 06:38:56,875 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36787
2024-01-15 06:38:56,875 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36787
2024-01-15 06:38:56,875 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42089
2024-01-15 06:38:56,875 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-15 06:38:56,875 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:56,875 - distributed.worker - INFO -               Threads:                          1
2024-01-15 06:38:56,875 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-15 06:38:56,875 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a8tve8ln
2024-01-15 06:38:56,875 - distributed.worker - INFO - Starting Worker plugin PreImport-8e000216-00f8-40b8-a75e-5b9664fedc5f
2024-01-15 06:38:56,875 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a29cc73-0d61-4672-801e-d2280f3de390
2024-01-15 06:38:56,876 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad4fafa9-2c3a-45d7-9b96-137ba8ea4ea7
2024-01-15 06:38:57,194 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:57,271 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36787', status: init, memory: 0, processing: 0>
2024-01-15 06:38:57,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36787
2024-01-15 06:38:57,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38384
2024-01-15 06:38:57,273 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-15 06:38:57,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-15 06:38:57,274 - distributed.worker - INFO - -------------------------------------------------
2024-01-15 06:38:57,276 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-15 06:38:57,365 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-15 06:38:57,370 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-15 06:38:57,374 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:57,376 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-15 06:38:57,378 - distributed.scheduler - INFO - Remove client Client-bfe9241e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:57,378 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38378; closing.
2024-01-15 06:38:57,379 - distributed.scheduler - INFO - Remove client Client-bfe9241e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:57,379 - distributed.scheduler - INFO - Close client connection: Client-bfe9241e-b370-11ee-b07e-d8c49764f6bb
2024-01-15 06:38:57,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41363'. Reason: nanny-close
2024-01-15 06:38:57,380 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-15 06:38:57,382 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36787. Reason: nanny-close
2024-01-15 06:38:57,383 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38384; closing.
2024-01-15 06:38:57,383 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-15 06:38:57,384 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36787', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1705300737.384168')
2024-01-15 06:38:57,384 - distributed.scheduler - INFO - Lost all workers
2024-01-15 06:38:57,385 - distributed.nanny - INFO - Worker closed
2024-01-15 06:38:58,045 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-15 06:38:58,046 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-15 06:38:58,046 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-15 06:38:58,047 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-15 06:38:58,049 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37893 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44913 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43967 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38657 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36099 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41539 instead
  warnings.warn(
2024-01-15 06:39:59,869 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 439, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 445, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36917 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45289 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33937 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36593 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40199 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41601 instead
  warnings.warn(
2024-01-15 06:41:16,497 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-15 06:41:16,498 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2024-01-15 06:41:16,508 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucxx://10.33.225.163:51836', name: 2, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43457 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34249 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33687 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38659 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39969 instead
  warnings.warn(
2024-01-15 06:42:10,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-15 06:42:10,787 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'ucxx://127.0.0.1:53515'.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35153 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35933 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35299 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35517 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45035 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42345 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46075 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40125 instead
  warnings.warn(
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7fcd71a4e180, tag: 0x1eaa3f9081f23fb7>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7fcd71a4e180, tag: 0x1eaa3f9081f23fb7>: 
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-5423' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42231 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35963 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42693 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35991 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32787 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41991 instead
  warnings.warn(
[1705301330.895628] [dgx13:75239:0]            sock.c:470  UCX  ERROR bind(fd=123 addr=0.0.0.0:40594) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45735 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42071 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37303 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43517 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45857 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44855 instead
  warnings.warn(
2024-01-15 06:51:26,153 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40628 remote=tcp://127.0.0.1:37467>: Stream is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32837 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40231 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40087 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35297 instead
  warnings.warn(
[1705301562.979622] [dgx13:79047:0]            sock.c:470  UCX  ERROR bind(fd=161 addr=0.0.0.0:37652) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43029 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38575 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33161 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45393 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35425 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34787 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41939 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36617 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38121 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35153 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33383 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43203 instead
  warnings.warn(
[1705301899.763006] [dgx13:83603:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:52928) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43377 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43695 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41677 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41271 instead
  warnings.warn(
[1705301946.179996] [dgx13:84134:0]            sock.c:470  UCX  ERROR bind(fd=161 addr=0.0.0.0:58966) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38223 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35445 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39613 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38575 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46751 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38585 instead
  warnings.warn(
[1705302047.174591] [dgx13:85445:0]    cuda_copy_ep.c:53   UCX  ERROR cudaStreamCreateWithFlags(stream, 0x01)() failed: out of memory
[dgx13:85445:0:85459]          dt.c:59   Fatal: mem type unpack failed to uct_ep_put_short() Input/output error
==== backtrace (tid:  85459) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd6b415a07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fd6b4157c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7fd6b4157dbc]
 3  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_mem_type_unpack+0x189) [0x7fd6b4215829]
 4  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_eager_only_handler+0x42d) [0x7fd6b424977d]
 5  /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0(+0x3e3f5) [0x7fd6a5c9f3f5]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_worker_progress+0x5a) [0x7fd6b42128da]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker12progressOnceEv+0xe) [0x7fd6b42e959e]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker15progressPendingEv+0x1c) [0x7fd6b42e95cc]
 9  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker8progressEv+0x17) [0x7fd6b42ea397]
10  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker19progressWorkerEventEi+0x25) [0x7fd6b42ea485]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx20WorkerProgressThread17progressUntilSyncESt8functionIFbvEERKbS1_IFvPvEES6_St10shared_ptrINS_27DelayedSubmissionCollectionEE+0x57) [0x7fd6b42ef6e7]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x56e0e) [0x7fd6b42efe0e]
13  /opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/_lib/../../../../libstdc++.so.6(+0xd3e95) [0x7fd6b7fabe95]
14  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7fd6bd89c609]
15  /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7fd6bd667353]
=================================
[1705302047.227840] [dgx13:85440:0]    cuda_copy_ep.c:53   UCX  ERROR cudaStreamCreateWithFlags(stream, 0x01)() failed: out of memory
[dgx13:85440:0:85458]          dt.c:59   Fatal: mem type unpack failed to uct_ep_put_short() Input/output error
==== backtrace (tid:  85458) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa32c85307d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fa32c850c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7fa32c850dbc]
 3  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_mem_type_unpack+0x189) [0x7fa32c90e829]
 4  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_tag_recv_nbx+0x9ee) [0x7fa32c94e16e]
 5  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x47c9c) [0x7fa32cc80c9c]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx10RequestTag7requestEv+0xb9) [0x7fa32cc81219]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx10RequestTag25populateDelayedSubmissionEv+0x79) [0x7fa32cc812f9]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx27DelayedSubmissionCollection10processPreEv+0x10a) [0x7fa32cc6956a]
 9  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx20WorkerProgressThread17progressUntilSyncESt8functionIFbvEERKbS1_IFvPvEES6_St10shared_ptrINS_27DelayedSubmissionCollectionEE+0x4a) [0x7fa32cc8f6da]
10  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x56e0e) [0x7fa32cc8fe0e]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/_lib/../../../../libstdc++.so.6(+0xd3e95) [0x7fa330cd7e95]
12  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7fa3365c8609]
13  /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7fa336393353]
=================================
2024-01-15 07:00:55,662 - distributed.nanny - WARNING - Restarting worker
2024-01-15 07:00:56,971 - distributed.nanny - WARNING - Restarting worker
[1705302063.749544] [dgx13:85490:0]    cuda_copy_ep.c:53   UCX  ERROR cudaStreamCreateWithFlags(stream, 0x01)() failed: out of memory
[dgx13:85490:0:85501]          dt.c:59   Fatal: mem type unpack failed to uct_ep_put_short() Input/output error
==== backtrace (tid:  85501) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb0b89f807d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fb0b89f5c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7fb0b89f5dbc]
 3  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_mem_type_unpack+0x189) [0x7fb0b8ab3829]
 4  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_eager_only_handler+0x42d) [0x7fb0b8ae777d]
 5  /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0(+0x3e3f5) [0x7fb0b88933f5]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_worker_progress+0x5a) [0x7fb0b8ab08da]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker12progressOnceEv+0xe) [0x7fb0b8e2e59e]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker15progressPendingEv+0x1c) [0x7fb0b8e2e5cc]
 9  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker8progressEv+0x17) [0x7fb0b8e2f397]
10  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker19progressWorkerEventEi+0x25) [0x7fb0b8e2f485]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx20WorkerProgressThread17progressUntilSyncESt8functionIFbvEERKbS1_IFvPvEES6_St10shared_ptrINS_27DelayedSubmissionCollectionEE+0x57) [0x7fb0b8e346e7]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x56e0e) [0x7fb0b8e34e0e]
13  /opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/_lib/../../../../libstdc++.so.6(+0xd3e95) [0x7fb0bce7ce95]
14  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7fb0c276d609]
15  /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7fb0c2538353]
=================================
2024-01-15 07:01:06,108 - distributed.worker - ERROR - failed during get data with ucxx://127.0.0.1:41142 -> ucxx://127.0.0.1:44829
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1780, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39405 instead
  warnings.warn(
2024-01-15 07:01:46,723 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-5f75be6b611af5f0f314ef71d7b084aa', 1)
Function:  subgraph_callable-d33fb9e2-f142-4ff1-840b-c05c8d86
args:      (    key  payload1
8     8         8
9     9         9
10   10        10
11   11        11
12   12        12
13   13        13
14   14        14
15   15        15, '_partitions', 'getitem-283d6bb332aaae6b8c9cd0db9318a971', ['key'])
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

[1705302106.864465] [dgx13:85693:0]    cuda_copy_ep.c:53   UCX  ERROR cudaStreamCreateWithFlags(stream, 0x01)() failed: out of memory
[dgx13:85693:0:85727]          dt.c:59   Fatal: mem type unpack failed to uct_ep_put_short() Input/output error
==== backtrace (tid:  85727) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7ff695b7d07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7ff695b7ac21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7ff695b7adbc]
 3  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_mem_type_unpack+0x189) [0x7ff695c38829]
 4  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_eager_only_handler+0x42d) [0x7ff695c6c77d]
 5  /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0(+0x3e3f5) [0x7ff695a183f5]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_worker_progress+0x5a) [0x7ff695c358da]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker12progressOnceEv+0xe) [0x7ff69c30559e]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker15progressPendingEv+0x1c) [0x7ff69c3055cc]
 9  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker8progressEv+0x17) [0x7ff69c306397]
10  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx6Worker19progressWorkerEventEi+0x25) [0x7ff69c306485]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx20WorkerProgressThread17progressUntilSyncESt8functionIFbvEERKbS1_IFvPvEES6_St10shared_ptrINS_27DelayedSubmissionCollectionEE+0x57) [0x7ff69c30b6e7]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x56e0e) [0x7ff69c30be0e]
13  /opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/_lib/../../../../libstdc++.so.6(+0xd3e95) [0x7ff69e00fe95]
14  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7ff6a3900609]
15  /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7ff6a36cb353]
=================================
2024-01-15 07:01:49,020 - distributed.worker - ERROR - failed during get data with ucxx://127.0.0.1:34265 -> ucxx://127.0.0.1:53239
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1780, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-15 07:01:50,847 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-5f75be6b611af5f0f314ef71d7b084aa', 3)
Function:  subgraph_callable-d33fb9e2-f142-4ff1-840b-c05c8d86
args:      (    key  payload1
24   24        24
25   25        25
26   26        26
27   27        27
28   28        28
29   29        29
30   30        30
31   31        31, '_partitions', 'getitem-283d6bb332aaae6b8c9cd0db9318a971', ['key'])
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

[1705302110.941132] [dgx13:85703:0]    cuda_copy_ep.c:53   UCX  ERROR cudaStreamCreateWithFlags(stream, 0x01)() failed: out of memory
[dgx13:85703:0:85726]          dt.c:59   Fatal: mem type unpack failed to uct_ep_put_short() Input/output error
==== backtrace (tid:  85726) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f8bd2ebf07d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f8bd2ebcc21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f8bd2ebcdbc]
 3  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_mem_type_unpack+0x189) [0x7f8bd2f7a829]
 4  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucp.so.0(ucp_tag_recv_nbx+0x9ee) [0x7f8bd2fba16e]
 5  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x47c9c) [0x7f8bd8326c9c]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx10RequestTag7requestEv+0xb9) [0x7f8bd8327219]
 7  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx10RequestTag25populateDelayedSubmissionEv+0x79) [0x7f8bd83272f9]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx27DelayedSubmissionCollection10processPreEv+0x10a) [0x7f8bd830f56a]
 9  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(_ZN4ucxx20WorkerProgressThread17progressUntilSyncESt8functionIFbvEERKbS1_IFvPvEES6_St10shared_ptrINS_27DelayedSubmissionCollectionEE+0x4a) [0x7f8bd83356da]
10  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib/../../../../libucxx.so(+0x56e0e) [0x7f8bd8335e0e]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/_lib/../../../../libstdc++.so.6(+0xd3e95) [0x7f8bdb37be95]
12  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7f8be0c6c609]
13  /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7f8be0a37353]
=================================
2024-01-15 07:01:51,184 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-5f75be6b611af5f0f314ef71d7b084aa', 4)
Function:  subgraph_callable-d33fb9e2-f142-4ff1-840b-c05c8d86
args:      (    key  payload1
32   32        32
33   33        33
34   34        34
35   35        35
36   36        36
37   37        37
38   38        38
39   39        39, '_partitions', 'getitem-283d6bb332aaae6b8c9cd0db9318a971', ['key'])
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-15 07:01:52,900 - distributed.nanny - WARNING - Restarting worker
2024-01-15 07:01:53,117 - distributed.worker - ERROR - failed during get data with ucxx://127.0.0.1:34265 -> ucxx://127.0.0.1:44809
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 836, in wait
  File "libucxx.pyx", line 820, in wait_yield
  File "libucxx.pyx", line 815, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1780, in get_data
    response = await comm.read(deserializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-15 07:01:54,016 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-5f75be6b611af5f0f314ef71d7b084aa', 0)
Function:  subgraph_callable-d33fb9e2-f142-4ff1-840b-c05c8d86
args:      (   key  payload1
0    0         0
1    1         1
2    2         2
3    3         3
4    4         4
5    5         5
6    6         6
7    7         7, '_partitions', 'getitem-283d6bb332aaae6b8c9cd0db9318a971', ['key'])
kwargs:    {}
Exception: "RuntimeError('This program was not compiled for SM 70  \\n: cudaErrorInvalidDevice: invalid device ordinal')"

2024-01-15 07:01:56,739 - distributed.nanny - WARNING - Restarting worker
2024-01-15 07:01:58,346 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-5f75be6b611af5f0f314ef71d7b084aa', 2)
Function:  subgraph_callable-d33fb9e2-f142-4ff1-840b-c05c8d86
args:      (    key  payload1
16   16        16
17   17        17
18   18        18
19   19        19
20   20        20
21   21        21
22   22        22
23   23        23, '_partitions', 'getitem-283d6bb332aaae6b8c9cd0db9318a971', ['key'])
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
