2023-06-12 06:19:45,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:45,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:45,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:71050:0:71050] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71050) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f60f02fd80d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f60f02fda04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f60f02fdbca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f6182af9420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f60f036f987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f60f038e549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f60f02ba9cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f60f02bdbf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f60f0305df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f60f02bcbbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f60f036d36a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f60f040c17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55af607fbb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55af607ec112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55af607f6c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55af6080b70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f61026992fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55af607ef2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55af607a2817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55af607edf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55af607ebd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55af607f6c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55af607eafa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55af60804935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55af60805104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55af608cbfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55af607ef2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55af607ea1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55af60804c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55af607ea1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55af607f6c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55af607e681b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55af607f6ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55af607e6568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55af607f6c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55af607e73cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55af607e527a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55af607e4f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55af607e4eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55af608958bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55af608c3adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55af608bfc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55af608b77ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55af608b76bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55af608b68a2]
=================================
[dgx13:71056:0:71056] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71056) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f6cc4ec980d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f6cc4ec9a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f6cc4ec9bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f6d656a2420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f6cc4f3b987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f6cc4f5a549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f6cc4e869cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f6cc4e89bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f6cc4ed1df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f6cc4e88bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f6cc4f3936a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f6cc4fd817a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5642408abb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56424089c112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5642408a6c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5642408bb70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f6ce52432fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56424089f2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x564240852817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56424089df83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56424089bd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5642408a6c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56424089afa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5642408b4935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5642408b5104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56424097bfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56424089f2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56424089a1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5642408b4c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56424089a1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5642408a6c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56424089681b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5642408a6ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x564240896568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5642408a6c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5642408973cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56424089527a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x564240894f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x564240894eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5642409458bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x564240973adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56424096fc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5642409677ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5642409676bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5642409668a2]
=================================
[dgx13:71053:0:71053] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71053) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f42dc91b80d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f42dc91ba04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f42dc91bbca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f436f0fc420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f42dc98d987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f42dc9ac549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f42dc8d89cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f42dc8dbbf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f42dc923df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f42dc8dabbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f42dc98b36a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f42dca2a17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5579ad4c8b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5579ad4b9112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5579ad4c3c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x5579ad4d1a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x5579ad5e19b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5579ad46f817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5579ad4baf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5579ad4b8d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5579ad4c3c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5579ad4b7fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5579ad4d1935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5579ad4d2104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5579ad598fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5579ad4bc2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5579ad4b71bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5579ad4d1c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5579ad4b71bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5579ad4c3c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5579ad4b381b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5579ad4c3ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5579ad4b3568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5579ad4c3c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5579ad4b43cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5579ad4b227a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5579ad4b1f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5579ad4b1eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5579ad5628bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5579ad590adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5579ad58cc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5579ad5847ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5579ad5846bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5579ad5838a2]
=================================
Task exception was never retrieved
future: <Task finished name='Task-815' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
Task exception was never retrieved
future: <Task finished name='Task-829' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-06-12 06:19:54,177 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53029
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa871013240, tag: 0xb47fffd641e1f86d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa871013240, tag: 0xb47fffd641e1f86d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,179 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49401 -> ucx://127.0.0.1:53029
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa871013100, tag: 0x4e8a71d7a9854d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:19:54,177 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53029
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f43b8780240, tag: 0xd19694c38fda73d5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f43b8780240, tag: 0xd19694c38fda73d5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:53029 after 30 s
2023-06-12 06:19:54,183 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53029
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
Task exception was never retrieved
future: <Task finished name='Task-814' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
Task exception was never retrieved
future: <Task finished name='Task-831' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
2023-06-12 06:19:54,209 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48983
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-06-12 06:19:54,214 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37541 -> ucx://127.0.0.1:48983
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f43b8780100, tag: 0x19792c1e51eb4c7c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:19:54,183 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53029
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-06-12 06:19:54,239 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48983
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f43b8780300, tag: 0xb4b3f462da1fcacd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f43b8780300, tag: 0xb4b3f462da1fcacd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,255 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:19:54,273 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fcdbcff1140, tag: 0x2e1deb9943975e60, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fcdbcff1140, tag: 0x2e1deb9943975e60, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-12 06:19:54,209 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48983
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
Task exception was never retrieved
future: <Task finished name='Task-830' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
Task exception was never retrieved
future: <Task finished name='Task-829' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Endpoint timeout')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Endpoint timeout
Task exception was never retrieved
future: <Task finished name='Task-813' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-06-12 06:19:54,301 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8734a15140, tag: 0xa6f7fd24b64f23ea, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8734a15140, tag: 0xa6f7fd24b64f23ea, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[dgx13:71048:0:71048] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71048) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f952f14680d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f952f146a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f952f146bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f95df92b420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f952f1b8987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f952f1d7549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f952f1039cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f952f106bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f952f14edf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f952f105bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f952f1b636a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f952f25517a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5624cf658b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5624cf649112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5624cf653c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5624cf66870e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f955f4ce2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5624cf64c2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5624cf5ff817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5624cf64af83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5624cf648d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5624cf653c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5624cf647fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5624cf661935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5624cf662104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5624cf728fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5624cf64c2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5624cf6471bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5624cf661c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5624cf6471bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5624cf653c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5624cf64381b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5624cf653ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5624cf643568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5624cf653c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5624cf6443cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5624cf64227a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5624cf641f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5624cf641eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5624cf6f28bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5624cf720adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5624cf71cc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5624cf7147ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5624cf7146bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5624cf7138a2]
=================================
2023-06-12 06:19:54,317 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:19:54,326 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa871013280, tag: 0x1c4ee733d8ddf4d4, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa871013280, tag: 0x1c4ee733d8ddf4d4, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,298 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37541 -> ucx://127.0.0.1:53599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f43b8780180, tag: 0xc730bd40f76aa154, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:19:54,380 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f43b87802c0, tag: 0xc6a34611661eb8e9, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f43b87802c0, tag: 0xc6a34611661eb8e9, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,381 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:19:54,528 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f43b8780200, tag: 0x65f2b772d91dbeda, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f43b8780200, tag: 0x65f2b772d91dbeda, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,528 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8734a15100, tag: 0x47e28e978a22883b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8734a15100, tag: 0x47e28e978a22883b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-12 06:19:54,528 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7fa871013200, tag: 0xe49e8d89f5136aa5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7fa871013200, tag: 0xe49e8d89f5136aa5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-12 06:19:54,529 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37541 -> ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f43b87803c0, tag: 0x5336fe0213b152af, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:19:54,537 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41005 -> ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcdbcff1440, tag: 0x8107de478ef2539a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:19:54,538 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43591
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fcdbcff11c0, tag: 0x89698d60d614bdd, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fcdbcff11c0, tag: 0x89698d60d614bdd, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-06-12 06:19:54,582 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:19:55,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:55,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:55,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:55,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:55,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:55,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:19:56,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:19:56,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:20:23,806 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48983
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:48983 after 30 s
[dgx13:71571:0:71571] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71571) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f58784a680d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f58784a6a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f58784a6bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f5918b3c420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f5878518987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f5878537549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f58784639cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f5878466bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f58784aedf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f5878465bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f587851636a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f58785b517a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55de38766b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55de38757112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55de38761c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55de3876fa16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55de3887f9b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55de3870d817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55de38758f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55de38756d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55de38761c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55de38755fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55de3876f935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55de38770104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55de38836fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55de3875a2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55de387551bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55de3876fc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55de387551bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55de38761c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55de3875181b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55de38761ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55de38751568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55de38761c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55de387523cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55de3875027a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55de3874ff07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55de3874feb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55de388008bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55de3882eadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55de3882ac24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55de388227ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55de388226bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55de388218a2]
=================================
2023-06-12 06:20:24,422 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49401 -> ucx://127.0.0.1:48209
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa871013200, tag: 0x72ace49c4ecd3d8f, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,490 - distributed.nanny - WARNING - Restarting worker
[dgx13:71565:0:71565] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71565) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f575781480d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f5757814a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f5757814bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f57fbece420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f5757886987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f57578a5549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f57577d19cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f57577d4bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f575781cdf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f57577d3bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f575788436a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f575792317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5628b3af2b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5628b3ae3112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5628b3aedc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x5628b3afba16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x5628b3c0b9b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5628b3a99817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5628b3ae4f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5628b3ae2d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5628b3aedc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5628b3ae1fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5628b3afb935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5628b3afc104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5628b3bc2fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5628b3ae62bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5628b3ae11bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5628b3afbc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5628b3ae11bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5628b3aedc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5628b3add81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5628b3aedef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5628b3add568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5628b3aedc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5628b3ade3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5628b3adc27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5628b3adbf07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5628b3adbeb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5628b3b8c8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5628b3bbaadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5628b3bb6c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5628b3bae7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5628b3bae6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5628b3bad8a2]
=================================
[dgx13:71576:0:71576] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71576) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd98dd1580d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7fd98dd15a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7fd98dd15bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fda32403420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fd98dd87987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fd98dda6549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7fd9a003b9cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7fd9a003ebf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fd98dd1ddf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fd9a003dbbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fd98dd8536a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fd98de2417a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55635cdfbb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55635cdec112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55635cdf6c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55635ce04a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55635cf149b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55635cda2817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55635cdedf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55635cdebd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55635cdf6c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55635cdeafa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55635ce04935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55635ce05104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55635cecbfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55635cdef2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55635cdea1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55635ce04c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55635cdea1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55635cdf6c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55635cde681b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55635cdf6ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55635cde6568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55635cdf6c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55635cde73cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55635cde527a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55635cde4f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55635cde4eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55635ce958bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55635cec3adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55635cebfc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55635ceb77ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55635ceb76bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55635ceb68a2]
=================================
[dgx13:71568:0:71568] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  71568) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f4734c1280d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f4734c12a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f4734c12bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f47d52ae420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f4734c84987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f4734ca3549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f4734bcf9cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f4734bd2bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f4734c1adf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f4734bd1bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f4734c8236a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f4734d2117a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x562efd452b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x562efd443112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x562efd44dc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x562efd46270e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f4754e4f2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x562efd4462bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x562efd3f9817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x562efd444f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x562efd442d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x562efd44dc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x562efd441fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x562efd45b935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x562efd45c104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x562efd522fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x562efd4462bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x562efd4411bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x562efd45bc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x562efd4411bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x562efd44dc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x562efd43d81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x562efd44def3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x562efd43d568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x562efd44dc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x562efd43e3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x562efd43c27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x562efd43bf07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x562efd43beb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x562efd4ec8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x562efd51aadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x562efd516c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x562efd50e7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x562efd50e6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x562efd50d8a2]
=================================
2023-06-12 06:20:24,792 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41231 -> ucx://127.0.0.1:34299
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8734a151c0, tag: 0xe3fdc22a183c2c51, nbytes: 99992920, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,794 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41005 -> ucx://127.0.0.1:45489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcdbcff1300, tag: 0xa2ffddee43dd6098, nbytes: 99987912, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,794 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37541 -> ucx://127.0.0.1:45489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f43b8780200, tag: 0xa6fdc424baaa02d2, nbytes: 99977512, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,794 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:41231 -> ucx://127.0.0.1:45489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8734a15100, tag: 0xb9f08eeb0353807a, nbytes: 99974584, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,846 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:20:24,859 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-6b7af13ee6a16bd9d1657f57b31f8972', 4)
Function:  <dask.layers.CallableLazyImport object at 0x7fa31c
args:      ([               key   payload
shuffle                     
0            42538  16230950
0            57418  53673758
0            29259  66706049
0            91085  60721834
0           907145  55379612
...            ...       ...
0        799571093  48835148
0        799645927   9309512
0        799662139  43961942
0        799926283  65136603
0        799867939  93476772

[12503392 rows x 2 columns],                key   payload
shuffle                     
1           361620  18804367
1           342576  48901182
1           323467  21897368
1            43306  97519263
1            56086  94757624
...            ...       ...
1        799893276  64038218
1        799742131  16875705
1        799930172  66946786
1        799813657  54388021
1        799869782  41049485

[12500389 rows x 2 columns],                key   payload
shuffle                     
2           415055  94903224
2           622107  72628900
2           611328  51202658
2           424406  69266436
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-12 06:20:24,860 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49401 -> ucx://127.0.0.1:34299
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa871013280, tag: 0xfe3850613844655e, nbytes: 100019112, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,862 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49401 -> ucx://127.0.0.1:36321
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa871013100, tag: 0x6acc05fdb733d2fb, nbytes: 99959896, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-12 06:20:24,899 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:20:24,941 - distributed.nanny - WARNING - Restarting worker
2023-06-12 06:20:25,140 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0)
Function:  <dask.layers.CallableLazyImport object at 0x7fa31c
args:      ([                key   payload
52352     300143644  20321415
59915     848210296  97067656
52371     607309620   4421508
59921     841170777  19241212
32386     807161904  54641893
...             ...       ...
99976626  851042591  28362837
99976627  810556639  66716928
99976628  863199283  80246934
99976633  851954218  58773095
99996452  858034903  10678976

[12497168 rows x 2 columns],                 key   payload
77473     942251803   4231339
202855    949475889  66954728
77478     929257273  23218569
202858    901124426   8121817
77497     912355530  85125695
...             ...       ...
99995956  943421457  66442765
99969504  909822194  90238159
99969505  938144775  24221296
99969524  523981866  44686114
99969532  959265504  31870262

[12502889 rows x 2 columns],                  key   payload
84097     1013948662  45182841
84110     1041515700   6718735
84112     1050651084  24088571
84118     1046117895  79659667
2288       725375998  72912967
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-12 06:20:25,249 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:25,250 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:25,428 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-0268e39dc424971e2d23e4387a546f0c', 2)
Function:  subgraph_callable-e755c3b6-071d-4068-a0a4-aea45221
args:      (               key   payload
shuffle                     
0            57396  70048483
0            57403  92951858
0               99  40275813
0            20196  16604096
0            96530  60937936
...            ...       ...
7        799983656  32204867
7        799990075  20645283
7        799997941  52920133
7        799972005  13088247
7        799954944  99401531

[99996471 rows x 2 columns],                  key   payload
52355      301988235  91081418
59906      850454766  55635603
52365      853925328  16743116
59907      202850929  39571851
32385      835668444  81362521
...              ...       ...
99992520  1544343852  46974968
99992454    96924157  49251511
99992464  1529120781  27894594
99992472  1511049004  16235730
99992477   592296219  54596792

[100013945 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-12 06:20:25,514 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:25,514 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:25,550 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7f3e67
args:      ([                key   payload
52356     107015767  65816641
59920     848888253  44330414
52363     860285758  91329192
32399     809185486  81105569
52364     847487724  64866791
...             ...       ...
99996510  308702909  14488634
99976614  823360526  25080886
99996469  861463079  94111070
99996475  851036737   7535939
99996476  611481811  68615087

[12497796 rows x 2 columns],                 key   payload
77480     946478093  38096887
202859    903560069  47379252
77482     943849979  46151353
202863    947324419  89066133
77489     907008817   1341408
...             ...       ...
99969510  914461966  44140120
99969512  910678016   3454059
99969521  909889524  87446554
99969528  413023523  99612721
99969533  514106850  38087731

[12497151 rows x 2 columns],                  key   payload
84107     1059832036  23765989
84108      326254364  26249071
2292       533234817  35765050
2298      1025634983  98066872
39584     1025580225  37797774
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-12 06:20:25,698 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:25,698 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-12 06:20:26,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:20:26,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:20:26,275 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 3)
Function:  <dask.layers.CallableLazyImport object at 0x7fa31c
args:      ([                key   payload
52361     845874532  49972219
59914       9533172  22423415
59916     400529268  71931018
32409       5106925  60072158
32415     829405152  89459553
...             ...       ...
99976625  868399730  64694649
99976638  510736047  11683560
99996449  865721893   3287640
99996473  512233865   3665479
99996474  504139752  76363248

[12498632 rows x 2 columns],                 key   payload
77481     910280713  11172484
202853    946188362  80063587
77484     964235953  68688438
202872    620772986  66963144
77486      13505489  13896521
...             ...       ...
99995949  961566528    530497
99995951  944691240  98343899
99995963  961238833  21735386
99995965  719810882  23901508
99969506  415644282  12287089

[12502237 rows x 2 columns],                  key   payload
84096     1066733129  37321043
84099     1049490063  50968849
84106     1054698443  93766284
84111       32638402  36330902
84127     1058736870  42760396
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-12 06:20:26,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:20:26,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:20:26,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:20:26,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-12 06:20:26,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-12 06:20:26,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
