2023-06-18 05:52:56,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:52:56,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:52:56,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73407:0:73407] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73407) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe14805880d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7fe148058a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7fe148058bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe1e879e420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fe141f8e987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe141fad549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7fe141f329cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7fe141f35bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe148060df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe141f34bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe141f8c36a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fe1480b417a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55747ee7ab08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55747ee6b112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55747ee75c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55747ee8a70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fe1dc0252fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55747ee6e2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55747ee21817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55747ee6cf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55747ee6ad36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55747ee75c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55747ee69fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55747ee83935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55747ee84104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55747ef4afc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55747ee6e2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55747ee691bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55747ee83c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55747ee691bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55747ee75c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55747ee6581b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55747ee75ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55747ee65568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55747ee75c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55747ee663cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55747ee6427a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55747ee63f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55747ee63eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55747ef148bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55747ef42adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55747ef3ec24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55747ef367ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55747ef366bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55747ef358a2]
=================================
2023-06-18 05:53:05,156 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48699 -> ucx://127.0.0.1:58429
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f63f12ca100, tag: 0xa565f56edabec251, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-18 05:53:05,238 - distributed.nanny - WARNING - Restarting worker
[dgx13:73411:0:73411] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73411) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f54450f380d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f54450f3a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f54450f3bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f54d7794420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f5445165987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f5445184549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f54450b09cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f54450b3bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f54450fbdf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f54450b2bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f544516336a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f544520217a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5636d2b4cb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5636d2b3d112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5636d2b47c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x5636d2b55a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x5636d2c659b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5636d2af3817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5636d2b3ef83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5636d2b3cd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5636d2b47c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5636d2b3bfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5636d2b55935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5636d2b56104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5636d2c1cfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5636d2b402bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5636d2b3b1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5636d2b55c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5636d2b3b1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5636d2b47c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5636d2b3781b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5636d2b47ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5636d2b37568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5636d2b47c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5636d2b383cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5636d2b3627a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5636d2b35f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5636d2b35eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5636d2be68bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5636d2c14adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5636d2c10c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5636d2c087ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5636d2c086bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5636d2c078a2]
=================================
2023-06-18 05:53:05,550 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:47321 -> ucx://127.0.0.1:58221
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6ef6cf8100, tag: 0xf19226f63cdc3362, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-18 05:53:05,625 - distributed.nanny - WARNING - Restarting worker
[dgx13:73424:0:73424] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73424) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f63f1df480d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f63f1df4a04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f63f1df4bca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f64945f0420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f63f1e66987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f63f1e85549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f63f1db19cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f63f1db4bf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f63f1dfcdf9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f63f1db3bbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f63f1e6436a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f63f1f0317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55edf2039b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55edf202a112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55edf2034c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55edf204970e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f64141782fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55edf202d2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55edf1fe0817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55edf202bf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55edf2029d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55edf2034c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55edf2028fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55edf2042935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55edf2043104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55edf2109fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55edf202d2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55edf20281bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55edf2042c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55edf20281bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55edf2034c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55edf202481b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55edf2034ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55edf2024568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55edf2034c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55edf20253cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55edf202327a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55edf2022f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55edf2022eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55edf20d38bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55edf2101adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55edf20fdc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55edf20f57ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55edf20f56bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55edf20f48a2]
=================================
[dgx13:73403:0:73403] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73403) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0bd785d80d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f0bd785da04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f0bd785dbca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f0c7c063420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f0bd78cf987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f0bd78ee549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f0bd781a9cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f0bd781dbf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0bd7865df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f0bd781cbbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0bd78cd36a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f0bd796c17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5588a3d45b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5588a3d36112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5588a3d40c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x5588a3d4ea16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x5588a3e5e9b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5588a3cec817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5588a3d37f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5588a3d35d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5588a3d40c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5588a3d34fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5588a3d4e935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5588a3d4f104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5588a3e15fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5588a3d392bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5588a3d341bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5588a3d4ec72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5588a3d341bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5588a3d40c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5588a3d3081b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5588a3d40ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5588a3d30568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5588a3d40c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5588a3d313cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5588a3d2f27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5588a3d2ef07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5588a3d2eeb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5588a3ddf8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5588a3e0dadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5588a3e09c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5588a3e017ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5588a3e016bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5588a3e008a2]
=================================
[dgx13:73416:0:73416] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73416) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f3051c5e80d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a04) [0x7f3051c5ea04]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28bca) [0x7f3051c5ebca]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f30f445d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f3051cd0987]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f3051cef549]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x1e9cf) [0x7f3051c1b9cf]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x21bf8) [0x7f3051c1ebf8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f3051c66df9]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f3051c1dbbd]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f3051cce36a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f3051d6d17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55f8a02f8b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55f8a02e9112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f8a02f3c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55f8a0301a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55f8a04119b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f8a029f817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f8a02eaf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f8a02e8d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f8a02f3c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f8a02e7fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f8a0301935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f8a0302104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f8a03c8fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f8a02ec2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f8a02e71bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f8a0301c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f8a02e71bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f8a02f3c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f8a02e381b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f8a02f3ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f8a02e3568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f8a02f3c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f8a02e43cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f8a02e227a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55f8a02e1f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f8a02e1eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f8a03928bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55f8a03c0adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55f8a03bcc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55f8a03b47ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55f8a03b46bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55f8a03b38a2]
=================================
2023-06-18 05:53:06,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:06,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:53:06,830 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49613
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #017] ep: 0x7f6ef6cf8180, tag: 0xb76a98f55fb4ed34, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #017] ep: 0x7f6ef6cf8180, tag: 0xb76a98f55fb4ed34, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-18 05:53:06,835 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:47321 -> ucx://127.0.0.1:55533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f6ef6cf8300, tag: 0x19ca9b3b119b4f1b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-18 05:53:06,836 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f6ef6cf81c0, tag: 0xbbae8fc9698cf583, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f6ef6cf81c0, tag: 0xbbae8fc9698cf583, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-06-18 05:53:06,846 - distributed.nanny - WARNING - Restarting worker
2023-06-18 05:53:06,906 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49613
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fdfec166280, tag: 0x7e0ade616145e335, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fdfec166280, tag: 0x7e0ade616145e335, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-06-18 05:53:06,906 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34285 -> ucx://127.0.0.1:49613
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f43784a5300, tag: 0x4f8f55708744ff99, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-18 05:53:06,908 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fdfec166200, tag: 0xbe69ef71baac864e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fdfec166200, tag: 0xbe69ef71baac864e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-8779' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-06-18 05:53:06,908 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49613
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f43784a5180, tag: 0xee4ab44cfb3c8b31, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f43784a5180, tag: 0xee4ab44cfb3c8b31, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-06-18 05:53:06,909 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55533
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f43784a5200, tag: 0xc26f40d235db09ad, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f43784a5200, tag: 0xc26f40d235db09ad, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-06-18 05:53:06,983 - distributed.nanny - WARNING - Restarting worker
2023-06-18 05:53:06,985 - distributed.nanny - WARNING - Restarting worker
2023-06-18 05:53:07,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:07,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-18 05:53:08,390 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47321
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #043] ep: 0x7f43784a5100, tag: 0xce4f5dca188783e1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #043] ep: 0x7f43784a5100, tag: 0xce4f5dca188783e1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-18 05:53:08,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofjoe5xz', purging
2023-06-18 05:53:08,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:08,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:53:08,478 - distributed.nanny - WARNING - Restarting worker
2023-06-18 05:53:08,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:08,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:53:08,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:08,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-18 05:53:09,553 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 1)
Function:  generate_chunk
args:      (1, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-06-18 05:53:09,796 - distributed.core - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-18 05:53:09,797 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-18 05:53:10,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-18 05:53:10,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-18 05:53:10,376 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: '_DeadlockError("deadlock detected by _ModuleLock(\'cudf.core.dataframe\') at 139633687426576")'

2023-06-18 05:53:10,845 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/cuda.py", line 34, in cuda_loads
    typ = pickle.loads(header["type-serialized"])
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 96, in loads
    return pickle.loads(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py", line 41, in <module>
    import cudf
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 28, in <module>
    from cudf.core.dataframe import DataFrame, from_dataframe, from_pandas, merge
ImportError: cannot import name 'DataFrame' from partially initialized module 'cudf.core.dataframe' (most likely due to a circular import) (/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py)
2023-06-18 05:53:11,007 - distributed.core - ERROR - cannot import name 'DataFrame' from partially initialized module 'cudf.core.dataframe' (most likely due to a circular import) (/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = await offload(_from_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1442, in run_in_executor_with_context
    return await loop.run_in_executor(
  File "/opt/conda/envs/gdf/lib/python3.9/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1443, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/cuda.py", line 34, in cuda_loads
    typ = pickle.loads(header["type-serialized"])
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 96, in loads
    return pickle.loads(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py", line 41, in <module>
    import cudf
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 28, in <module>
    from cudf.core.dataframe import DataFrame, from_dataframe, from_pandas, merge
ImportError: cannot import name 'DataFrame' from partially initialized module 'cudf.core.dataframe' (most likely due to a circular import) (/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py)
2023-06-18 05:53:11,008 - distributed.worker - ERROR - cannot import name 'DataFrame' from partially initialized module 'cudf.core.dataframe' (most likely due to a circular import) (/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = await offload(_from_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1442, in run_in_executor_with_context
    return await loop.run_in_executor(
  File "/opt/conda/envs/gdf/lib/python3.9/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1443, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 138, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 501, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 428, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/cuda.py", line 34, in cuda_loads
    typ = pickle.loads(header["type-serialized"])
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 96, in loads
    return pickle.loads(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py", line 41, in <module>
    import cudf
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 28, in <module>
    from cudf.core.dataframe import DataFrame, from_dataframe, from_pandas, merge
ImportError: cannot import name 'DataFrame' from partially initialized module 'cudf.core.dataframe' (most likely due to a circular import) (/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/dataframe.py)
2023-06-18 05:53:11,824 - distributed.core - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-18 05:53:11,825 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
