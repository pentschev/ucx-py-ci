============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-12-03 06:37:41,649 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:37:41,653 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-12-03 06:37:41,656 - distributed.scheduler - INFO - State start
2023-12-03 06:37:41,677 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:37:41,678 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-12-03 06:37:41,678 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:37:41,679 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-12-03 06:37:41,830 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42941'
2023-12-03 06:37:41,850 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32859'
2023-12-03 06:37:41,852 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38949'
2023-12-03 06:37:41,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37417'
2023-12-03 06:37:43,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:37:43,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:37:43,521 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:37:43,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:37:43,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:37:43,525 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:37:43,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:37:43,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:37:43,546 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:37:43,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:37:43,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:37:43,553 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-12-03 06:37:43,576 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43353
2023-12-03 06:37:43,576 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43353
2023-12-03 06:37:43,576 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38351
2023-12-03 06:37:43,576 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:37:43,577 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:43,577 - distributed.worker - INFO -               Threads:                          4
2023-12-03 06:37:43,577 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-03 06:37:43,577 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-en7ii94y
2023-12-03 06:37:43,577 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff8c36a1-d97b-4cf7-b99b-742b59da1275
2023-12-03 06:37:43,577 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-660440a7-2268-42f7-839d-032a754ff5ab
2023-12-03 06:37:43,577 - distributed.worker - INFO - Starting Worker plugin PreImport-5624f3f0-425e-4828-832d-b36c1e2fdbac
2023-12-03 06:37:43,577 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,771 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43775
2023-12-03 06:37:44,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43775
2023-12-03 06:37:44,772 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42631
2023-12-03 06:37:44,772 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40635
2023-12-03 06:37:44,772 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34483
2023-12-03 06:37:44,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42631
2023-12-03 06:37:44,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40635
2023-12-03 06:37:44,772 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:37:44,772 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35925
2023-12-03 06:37:44,772 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44913
2023-12-03 06:37:44,772 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:37:44,772 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,773 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,773 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:37:44,773 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,773 - distributed.worker - INFO -               Threads:                          4
2023-12-03 06:37:44,773 - distributed.worker - INFO -               Threads:                          4
2023-12-03 06:37:44,773 - distributed.worker - INFO -               Threads:                          4
2023-12-03 06:37:44,773 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-03 06:37:44,773 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-03 06:37:44,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-je1v7xpw
2023-12-03 06:37:44,773 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-03 06:37:44,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-lw18c8p7
2023-12-03 06:37:44,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-h2gs1_9e
2023-12-03 06:37:44,773 - distributed.worker - INFO - Starting Worker plugin PreImport-5771332e-fb22-4333-8706-b65109fbc8ed
2023-12-03 06:37:44,773 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a6066952-143c-43ec-81bc-47f69277d5ad
2023-12-03 06:37:44,773 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f5c1526-ce09-4b59-8f6f-6d11f4413b9a
2023-12-03 06:37:44,773 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73fbcdb2-01de-4d13-a35f-24675afff07c
2023-12-03 06:37:44,773 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5bc67b39-bf17-4953-b273-4ae25a2aad50
2023-12-03 06:37:44,774 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ede70e15-db7a-4fc6-a543-cb4242976398
2023-12-03 06:37:44,774 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6177a74c-16f9-404d-ab8f-7a367ce23b17
2023-12-03 06:37:44,774 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,774 - distributed.worker - INFO - Starting Worker plugin PreImport-e937326b-4094-460a-9cba-6c6a7ee9e9e7
2023-12-03 06:37:44,774 - distributed.worker - INFO - Starting Worker plugin PreImport-2fbe9bc4-9558-45d4-9992-94fb7ac6f4cc
2023-12-03 06:37:44,774 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:37:44,774 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:13,223 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42941'. Reason: nanny-close
2023-12-03 06:38:13,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32859'. Reason: nanny-close
2023-12-03 06:38:13,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38949'. Reason: nanny-close
2023-12-03 06:38:13,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37417'. Reason: nanny-close
2023-12-03 06:38:13,579 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:38:14,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:38:14,775 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:38:14,776 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-12-03 06:38:45,579 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:38:45,583 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35987 instead
  warnings.warn(
2023-12-03 06:38:45,586 - distributed.scheduler - INFO - State start
2023-12-03 06:38:45,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-je1v7xpw', purging
2023-12-03 06:38:45,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-h2gs1_9e', purging
2023-12-03 06:38:45,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-lw18c8p7', purging
2023-12-03 06:38:45,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/mockworker-en7ii94y', purging
2023-12-03 06:38:45,609 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:38:45,610 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:38:45,610 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35987/status
2023-12-03 06:38:45,610 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:38:45,727 - distributed.scheduler - INFO - Receive client connection: Client-9a880c8f-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:38:45,741 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36220
2023-12-03 06:38:45,845 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45351'
2023-12-03 06:38:45,860 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37313'
2023-12-03 06:38:45,876 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42949'
2023-12-03 06:38:45,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37601'
2023-12-03 06:38:45,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40659'
2023-12-03 06:38:45,898 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35967'
2023-12-03 06:38:45,907 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38483'
2023-12-03 06:38:45,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38587'
2023-12-03 06:38:47,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,694 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,733 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,746 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,755 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,768 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,810 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:47,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:47,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:47,836 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:51,763 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35847
2023-12-03 06:38:51,764 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35847
2023-12-03 06:38:51,765 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44489
2023-12-03 06:38:51,765 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:51,765 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:51,765 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:51,765 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:51,765 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k5og7w4j
2023-12-03 06:38:51,766 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6042dffe-20e1-4904-9513-7ef3e204e475
2023-12-03 06:38:51,766 - distributed.worker - INFO - Starting Worker plugin PreImport-585fcbd6-6490-4ee6-99f0-15987bf09f21
2023-12-03 06:38:51,766 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4b00a79c-9a00-4211-ad53-efc9b4375d7b
2023-12-03 06:38:51,769 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35813
2023-12-03 06:38:51,770 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35813
2023-12-03 06:38:51,770 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34511
2023-12-03 06:38:51,770 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:51,770 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:51,770 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:51,770 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:51,770 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-24zeuyqn
2023-12-03 06:38:51,771 - distributed.worker - INFO - Starting Worker plugin PreImport-b4e28bbf-b5f3-4367-8d8e-d06e7fed0c0b
2023-12-03 06:38:51,771 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33b148ff-8371-4b4b-8168-d92c3fb86b04
2023-12-03 06:38:51,772 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bff7d5d4-3b12-4192-ad62-456c6ae67e44
2023-12-03 06:38:51,791 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41019
2023-12-03 06:38:51,791 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41019
2023-12-03 06:38:51,792 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37699
2023-12-03 06:38:51,792 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:51,792 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:51,792 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:51,792 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:51,792 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oxwy_wdn
2023-12-03 06:38:51,792 - distributed.worker - INFO - Starting Worker plugin PreImport-8fbdb11f-6844-47cc-b69a-e49a38b71a32
2023-12-03 06:38:51,793 - distributed.worker - INFO - Starting Worker plugin RMMSetup-273875ff-d0ce-4fc0-8623-11be57a991eb
2023-12-03 06:38:52,074 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38001
2023-12-03 06:38:52,075 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38001
2023-12-03 06:38:52,075 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35715
2023-12-03 06:38:52,075 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,075 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,075 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:52,075 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:52,075 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hp9da7pm
2023-12-03 06:38:52,076 - distributed.worker - INFO - Starting Worker plugin PreImport-8cacec36-7098-4d6d-8b30-78eb3c5301a3
2023-12-03 06:38:52,076 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e88456f0-4c87-4cfb-9a0a-f67f73ea9b61
2023-12-03 06:38:52,080 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35453
2023-12-03 06:38:52,081 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35453
2023-12-03 06:38:52,081 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38559
2023-12-03 06:38:52,081 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,081 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,081 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:52,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:52,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ixjezf8m
2023-12-03 06:38:52,082 - distributed.worker - INFO - Starting Worker plugin PreImport-b8d3d5e2-fbf8-4a85-83d2-3950ad2523a3
2023-12-03 06:38:52,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a00e28dd-7d81-446e-b281-17e2d196ab37
2023-12-03 06:38:52,178 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b87f4b8-c138-40d7-b3e3-d0b2294f51fd
2023-12-03 06:38:52,179 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,211 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41019', status: init, memory: 0, processing: 0>
2023-12-03 06:38:52,213 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41019
2023-12-03 06:38:52,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42266
2023-12-03 06:38:52,214 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:52,215 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,215 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:52,228 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,249 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,265 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35813', status: init, memory: 0, processing: 0>
2023-12-03 06:38:52,266 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35813
2023-12-03 06:38:52,266 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42274
2023-12-03 06:38:52,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:52,276 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,276 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,278 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:52,291 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35847', status: init, memory: 0, processing: 0>
2023-12-03 06:38:52,292 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35847
2023-12-03 06:38:52,292 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42276
2023-12-03 06:38:52,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:52,303 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,303 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:52,452 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4197aff7-a523-42d5-9658-8068b5690c62
2023-12-03 06:38:52,452 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed0c9163-24d1-468a-a98c-a58e1d6d80bc
2023-12-03 06:38:52,452 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,453 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,487 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35453', status: init, memory: 0, processing: 0>
2023-12-03 06:38:52,488 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35453
2023-12-03 06:38:52,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42286
2023-12-03 06:38:52,489 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:52,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,490 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,494 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:52,499 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38001', status: init, memory: 0, processing: 0>
2023-12-03 06:38:52,500 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38001
2023-12-03 06:38:52,500 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42298
2023-12-03 06:38:52,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:52,502 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,502 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,510 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:52,917 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41083
2023-12-03 06:38:52,918 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41083
2023-12-03 06:38:52,918 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32957
2023-12-03 06:38:52,918 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,918 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,918 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:52,919 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:52,919 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-787flavx
2023-12-03 06:38:52,920 - distributed.worker - INFO - Starting Worker plugin PreImport-6254c3bb-a219-4ee1-a139-935269ce307b
2023-12-03 06:38:52,920 - distributed.worker - INFO - Starting Worker plugin RMMSetup-adc7ff0f-7724-4841-9fac-6080b1a1207a
2023-12-03 06:38:52,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43137
2023-12-03 06:38:52,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43137
2023-12-03 06:38:52,973 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34869
2023-12-03 06:38:52,973 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,973 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,974 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:52,974 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:52,974 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ajwtjl4d
2023-12-03 06:38:52,974 - distributed.worker - INFO - Starting Worker plugin PreImport-7cbd77cf-8e4d-4dce-b8ef-9da7cc908f62
2023-12-03 06:38:52,975 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1ec389dc-ef79-4f5a-89a7-10b5471cd130
2023-12-03 06:38:52,975 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b542bfaa-32f5-442b-bce7-b09de80e12c6
2023-12-03 06:38:52,979 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38357
2023-12-03 06:38:52,980 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38357
2023-12-03 06:38:52,980 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37733
2023-12-03 06:38:52,980 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:38:52,980 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:52,980 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:38:52,981 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:38:52,981 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-061uuh7t
2023-12-03 06:38:52,981 - distributed.worker - INFO - Starting Worker plugin PreImport-9d3bbc77-5dc2-4343-9ae9-0e91fac9a952
2023-12-03 06:38:52,981 - distributed.worker - INFO - Starting Worker plugin RMMSetup-234be114-d8b6-4313-9e38-0771df3ec344
2023-12-03 06:38:53,131 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-74e0a011-604d-4fae-a1ad-377b6d66ddab
2023-12-03 06:38:53,132 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,151 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,151 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e0bf93f-70e8-46f3-abdb-8b1c6d96b294
2023-12-03 06:38:53,152 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41083', status: init, memory: 0, processing: 0>
2023-12-03 06:38:53,165 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41083
2023-12-03 06:38:53,165 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42310
2023-12-03 06:38:53,166 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:53,167 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:53,167 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,174 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43137', status: init, memory: 0, processing: 0>
2023-12-03 06:38:53,174 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43137
2023-12-03 06:38:53,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42322
2023-12-03 06:38:53,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:53,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:53,176 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:53,176 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,180 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:53,358 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38357', status: init, memory: 0, processing: 0>
2023-12-03 06:38:53,358 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38357
2023-12-03 06:38:53,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42338
2023-12-03 06:38:53,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:38:53,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:38:53,362 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:38:53,371 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:38:53,465 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,465 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,466 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:38:53,470 - distributed.scheduler - INFO - Remove client Client-9a880c8f-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:38:53,470 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36220; closing.
2023-12-03 06:38:53,471 - distributed.scheduler - INFO - Remove client Client-9a880c8f-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:38:53,471 - distributed.scheduler - INFO - Close client connection: Client-9a880c8f-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:38:53,472 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45351'. Reason: nanny-close
2023-12-03 06:38:53,472 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,473 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37313'. Reason: nanny-close
2023-12-03 06:38:53,473 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,473 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35847. Reason: nanny-close
2023-12-03 06:38:53,473 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42949'. Reason: nanny-close
2023-12-03 06:38:53,474 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,474 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38001. Reason: nanny-close
2023-12-03 06:38:53,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37601'. Reason: nanny-close
2023-12-03 06:38:53,474 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35453. Reason: nanny-close
2023-12-03 06:38:53,474 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,475 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40659'. Reason: nanny-close
2023-12-03 06:38:53,475 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41019. Reason: nanny-close
2023-12-03 06:38:53,475 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42276; closing.
2023-12-03 06:38:53,475 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35967'. Reason: nanny-close
2023-12-03 06:38:53,476 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.476097')
2023-12-03 06:38:53,476 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,476 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,476 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38357. Reason: nanny-close
2023-12-03 06:38:53,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38483'. Reason: nanny-close
2023-12-03 06:38:53,476 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,476 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,477 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35813. Reason: nanny-close
2023-12-03 06:38:53,477 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38587'. Reason: nanny-close
2023-12-03 06:38:53,477 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:38:53,477 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41083. Reason: nanny-close
2023-12-03 06:38:53,477 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,477 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,478 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42286; closing.
2023-12-03 06:38:53,478 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42298; closing.
2023-12-03 06:38:53,478 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,478 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,478 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43137. Reason: nanny-close
2023-12-03 06:38:53,479 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35453', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.479024')
2023-12-03 06:38:53,479 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,479 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38001', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.4794471')
2023-12-03 06:38:53,479 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42266; closing.
2023-12-03 06:38:53,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,480 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.4803612')
2023-12-03 06:38:53,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,481 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:38:53,481 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42338; closing.
2023-12-03 06:38:53,481 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42274; closing.
2023-12-03 06:38:53,481 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,482 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38357', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.4822876')
2023-12-03 06:38:53,482 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,482 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,482 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35813', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.4825823')
2023-12-03 06:38:53,482 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42310; closing.
2023-12-03 06:38:53,483 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42322; closing.
2023-12-03 06:38:53,483 - distributed.nanny - INFO - Worker closed
2023-12-03 06:38:53,483 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41083', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.483456')
2023-12-03 06:38:53,483 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43137', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585533.4838204')
2023-12-03 06:38:53,484 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:38:55,591 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:38:55,591 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:38:55,592 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:38:55,593 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:38:55,593 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-12-03 06:38:57,784 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:38:57,788 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35513 instead
  warnings.warn(
2023-12-03 06:38:57,792 - distributed.scheduler - INFO - State start
2023-12-03 06:38:57,814 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:38:57,815 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:38:57,816 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35513/status
2023-12-03 06:38:57,816 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:38:57,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36913'
2023-12-03 06:38:57,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34693'
2023-12-03 06:38:57,981 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37473'
2023-12-03 06:38:57,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41825'
2023-12-03 06:38:57,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46867'
2023-12-03 06:38:57,998 - distributed.scheduler - INFO - Receive client connection: Client-a1c9c003-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:38:58,006 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35675'
2023-12-03 06:38:58,013 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42522
2023-12-03 06:38:58,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33927'
2023-12-03 06:38:58,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34883'
2023-12-03 06:38:59,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,970 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,973 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,979 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,980 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,981 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,983 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:38:59,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:38:59,987 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:38:59,988 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:02,924 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41539
2023-12-03 06:39:02,925 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41539
2023-12-03 06:39:02,925 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43025
2023-12-03 06:39:02,925 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:02,925 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:02,925 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:02,926 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:02,926 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ynd7rkpp
2023-12-03 06:39:02,926 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-780ef566-97fc-4470-8a98-ec37a487429b
2023-12-03 06:39:02,927 - distributed.worker - INFO - Starting Worker plugin PreImport-33d29735-135c-43b4-8053-e13b3946e540
2023-12-03 06:39:02,927 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2efcaa01-c94b-4401-8967-89bc8e4eafa8
2023-12-03 06:39:03,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34687
2023-12-03 06:39:03,000 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34687
2023-12-03 06:39:03,000 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38991
2023-12-03 06:39:03,001 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,001 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,001 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,001 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s_0vntax
2023-12-03 06:39:03,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b43d48d3-6f9d-4ca4-ac41-380018640fef
2023-12-03 06:39:03,002 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3897d880-44a4-48fe-b76c-2a776250ef98
2023-12-03 06:39:03,010 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44973
2023-12-03 06:39:03,011 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44973
2023-12-03 06:39:03,011 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43179
2023-12-03 06:39:03,011 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,011 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,011 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,011 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,012 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f9py2qoi
2023-12-03 06:39:03,012 - distributed.worker - INFO - Starting Worker plugin PreImport-d7fd55f7-8ea1-4d9d-9e2a-325b3eb795f4
2023-12-03 06:39:03,012 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5c213d5c-9ed5-4181-b157-150e47c89054
2023-12-03 06:39:03,014 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34859
2023-12-03 06:39:03,015 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34859
2023-12-03 06:39:03,015 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34143
2023-12-03 06:39:03,015 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,015 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,015 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,016 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,016 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-koc55w04
2023-12-03 06:39:03,016 - distributed.worker - INFO - Starting Worker plugin PreImport-8ad9af62-f162-4837-b5c9-cdb6f08df3bf
2023-12-03 06:39:03,016 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13a8d679-22bd-4e5e-80a0-a37e6f366025
2023-12-03 06:39:03,018 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33537
2023-12-03 06:39:03,018 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33537
2023-12-03 06:39:03,019 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37263
2023-12-03 06:39:03,019 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,019 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,019 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,019 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,019 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yrmlfsiy
2023-12-03 06:39:03,019 - distributed.worker - INFO - Starting Worker plugin PreImport-5e3c36b6-ee57-42ed-9c59-becc0ec7b8bc
2023-12-03 06:39:03,020 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8d16417-7218-45c1-8019-baa83509a7cd
2023-12-03 06:39:03,025 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36727
2023-12-03 06:39:03,026 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36727
2023-12-03 06:39:03,026 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36411
2023-12-03 06:39:03,026 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,026 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,026 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,026 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,026 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jtgds1ev
2023-12-03 06:39:03,027 - distributed.worker - INFO - Starting Worker plugin PreImport-247a99e9-e66a-4e95-ad56-d336f2345ede
2023-12-03 06:39:03,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33f96913-1f9e-486b-bcd0-7f64c855452b
2023-12-03 06:39:03,030 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36229
2023-12-03 06:39:03,031 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36229
2023-12-03 06:39:03,031 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37729
2023-12-03 06:39:03,031 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,031 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,031 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,032 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,032 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gg386gdj
2023-12-03 06:39:03,032 - distributed.worker - INFO - Starting Worker plugin PreImport-e9fc827c-20cb-43d6-b241-0863fd2f49f0
2023-12-03 06:39:03,032 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-255efacc-be41-406c-b30b-b092fd28d09b
2023-12-03 06:39:03,031 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35445
2023-12-03 06:39:03,033 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35445
2023-12-03 06:39:03,033 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44355
2023-12-03 06:39:03,033 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,033 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,033 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:03,033 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:03,033 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c7qxrhvt
2023-12-03 06:39:03,034 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc87f7f4-3344-4843-a4e6-d702ebf4e688
2023-12-03 06:39:03,034 - distributed.worker - INFO - Starting Worker plugin PreImport-13c03fa1-8cfc-4816-aec0-8cc33b4a977c
2023-12-03 06:39:03,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6bc86c0a-9704-4429-bfe9-e3f55bba128d
2023-12-03 06:39:03,047 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,056 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d8ac6393-15ae-4a64-a3dc-654ef41c8990
2023-12-03 06:39:03,056 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,058 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,058 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dd152b69-43e5-4e54-a539-ec18addda2b9
2023-12-03 06:39:03,059 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,060 - distributed.worker - INFO - Starting Worker plugin PreImport-d2efbb2d-9824-4daa-b579-889ef24483c6
2023-12-03 06:39:03,061 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,061 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-518721f7-285b-46c2-8118-fdbce828ae1b
2023-12-03 06:39:03,061 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,061 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e5087cc-e362-4130-8007-3914b76035dd
2023-12-03 06:39:03,062 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb283e06-7d99-4e74-bda9-854a5a8c4d15
2023-12-03 06:39:03,063 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,064 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,085 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34859', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,086 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34859
2023-12-03 06:39:03,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41102
2023-12-03 06:39:03,087 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,088 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41539', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,088 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41539
2023-12-03 06:39:03,088 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41098
2023-12-03 06:39:03,088 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,088 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,089 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44973', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,089 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44973
2023-12-03 06:39:03,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41116
2023-12-03 06:39:03,090 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34687', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,091 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,091 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34687
2023-12-03 06:39:03,091 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41108
2023-12-03 06:39:03,092 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,092 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,092 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36229', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,092 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,093 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36229
2023-12-03 06:39:03,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41106
2023-12-03 06:39:03,093 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,093 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,095 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35445', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,095 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,096 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,096 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35445
2023-12-03 06:39:03,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41138
2023-12-03 06:39:03,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,097 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,098 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,098 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33537', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,098 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,098 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,098 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33537
2023-12-03 06:39:03,099 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41120
2023-12-03 06:39:03,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,100 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,101 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,101 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,102 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36727', status: init, memory: 0, processing: 0>
2023-12-03 06:39:03,102 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36727
2023-12-03 06:39:03,102 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41136
2023-12-03 06:39:03,103 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:03,105 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:03,105 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:03,106 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,108 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,112 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:03,124 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,124 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,124 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,124 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,124 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,125 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,125 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,125 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:03,129 - distributed.scheduler - INFO - Remove client Client-a1c9c003-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:03,129 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42522; closing.
2023-12-03 06:39:03,129 - distributed.scheduler - INFO - Remove client Client-a1c9c003-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:03,129 - distributed.scheduler - INFO - Close client connection: Client-a1c9c003-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:03,134 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36913'. Reason: nanny-close
2023-12-03 06:39:03,135 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34693'. Reason: nanny-close
2023-12-03 06:39:03,135 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,136 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37473'. Reason: nanny-close
2023-12-03 06:39:03,136 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,136 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36229. Reason: nanny-close
2023-12-03 06:39:03,137 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34859. Reason: nanny-close
2023-12-03 06:39:03,137 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41825'. Reason: nanny-close
2023-12-03 06:39:03,137 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,138 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46867'. Reason: nanny-close
2023-12-03 06:39:03,138 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44973. Reason: nanny-close
2023-12-03 06:39:03,138 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,139 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41106; closing.
2023-12-03 06:39:03,139 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,139 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36229', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.139307')
2023-12-03 06:39:03,139 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35675'. Reason: nanny-close
2023-12-03 06:39:03,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33927'. Reason: nanny-close
2023-12-03 06:39:03,139 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33537. Reason: nanny-close
2023-12-03 06:39:03,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34883'. Reason: nanny-close
2023-12-03 06:39:03,140 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,141 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,141 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41102; closing.
2023-12-03 06:39:03,141 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,142 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34859', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.1420114')
2023-12-03 06:39:03,142 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,142 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41116; closing.
2023-12-03 06:39:03,142 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,142 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44973', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.142824')
2023-12-03 06:39:03,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,143 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,143 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36727. Reason: nanny-close
2023-12-03 06:39:03,144 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,144 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34687. Reason: nanny-close
2023-12-03 06:39:03,144 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41120; closing.
2023-12-03 06:39:03,144 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:03,145 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41539. Reason: nanny-close
2023-12-03 06:39:03,145 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35445. Reason: nanny-close
2023-12-03 06:39:03,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,146 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33537', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.1459963')
2023-12-03 06:39:03,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,147 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,147 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:03,147 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41136; closing.
2023-12-03 06:39:03,147 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,147 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41108; closing.
2023-12-03 06:39:03,148 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,149 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,149 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:03,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36727', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.149362')
2023-12-03 06:39:03,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34687', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.149791')
2023-12-03 06:39:03,150 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41098; closing.
2023-12-03 06:39:03,150 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41138; closing.
2023-12-03 06:39:03,151 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41539', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.1512048')
2023-12-03 06:39:03,151 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35445', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585543.1516373')
2023-12-03 06:39:03,151 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:04,597 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:04,598 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:04,598 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:04,599 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:04,600 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-12-03 06:39:06,939 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:06,944 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40633 instead
  warnings.warn(
2023-12-03 06:39:06,948 - distributed.scheduler - INFO - State start
2023-12-03 06:39:07,049 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:07,050 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:39:07,051 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40633/status
2023-12-03 06:39:07,051 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:39:07,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40597'
2023-12-03 06:39:07,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44971'
2023-12-03 06:39:07,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44645'
2023-12-03 06:39:07,302 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46795'
2023-12-03 06:39:07,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35597'
2023-12-03 06:39:07,313 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35169'
2023-12-03 06:39:07,327 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39205'
2023-12-03 06:39:07,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38759'
2023-12-03 06:39:08,272 - distributed.scheduler - INFO - Receive client connection: Client-a7358e70-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:08,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41334
2023-12-03 06:39:09,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,278 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,278 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,278 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,281 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,282 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,351 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,400 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:09,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:09,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:09,471 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:15,165 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42643
2023-12-03 06:39:15,166 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42643
2023-12-03 06:39:15,166 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36505
2023-12-03 06:39:15,166 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,166 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,166 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,166 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,166 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mpx5b64a
2023-12-03 06:39:15,167 - distributed.worker - INFO - Starting Worker plugin PreImport-2a6891a5-5348-4f59-99a0-b7e3e12f9d5a
2023-12-03 06:39:15,167 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9d5fb1b-d75c-49c6-b21f-a099c8d46c02
2023-12-03 06:39:15,167 - distributed.worker - INFO - Starting Worker plugin RMMSetup-376ea204-701d-4fef-b6db-4c14771a3052
2023-12-03 06:39:15,167 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36713
2023-12-03 06:39:15,168 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36713
2023-12-03 06:39:15,168 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37499
2023-12-03 06:39:15,168 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,168 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,168 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,169 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,169 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i9pb4pe0
2023-12-03 06:39:15,169 - distributed.worker - INFO - Starting Worker plugin PreImport-fc052310-fb53-43f1-b2b9-d2fc6f98cf44
2023-12-03 06:39:15,169 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fa72fff3-c527-40b9-808d-4abb4c5e4b36
2023-12-03 06:39:15,169 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c4ed6488-e314-4057-a512-fb027d12fc23
2023-12-03 06:39:15,205 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43427
2023-12-03 06:39:15,206 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43427
2023-12-03 06:39:15,206 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38783
2023-12-03 06:39:15,206 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,206 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,206 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,206 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,206 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3x8ikp4q
2023-12-03 06:39:15,207 - distributed.worker - INFO - Starting Worker plugin PreImport-0379facc-bc15-4272-905a-3c3aa790843c
2023-12-03 06:39:15,207 - distributed.worker - INFO - Starting Worker plugin RMMSetup-50ae1bf4-90b1-437e-a388-9dbd407ba0fe
2023-12-03 06:39:15,228 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46297
2023-12-03 06:39:15,230 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46297
2023-12-03 06:39:15,230 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40005
2023-12-03 06:39:15,230 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,230 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,230 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,230 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,230 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ikdcvfqk
2023-12-03 06:39:15,231 - distributed.worker - INFO - Starting Worker plugin PreImport-857f2ce6-0257-481b-9943-6465df8d1dec
2023-12-03 06:39:15,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-578ebb2c-c53b-4ade-8fc6-3bd627d9d0d9
2023-12-03 06:39:15,234 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35247
2023-12-03 06:39:15,235 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35247
2023-12-03 06:39:15,235 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35373
2023-12-03 06:39:15,235 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,235 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,235 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,235 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,236 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-emmmmlp6
2023-12-03 06:39:15,236 - distributed.worker - INFO - Starting Worker plugin PreImport-e43d1e77-32bc-4f6a-aa3a-3019597f09f9
2023-12-03 06:39:15,236 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa3d9c4a-394f-4480-9369-8fcb6e80138f
2023-12-03 06:39:15,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41581
2023-12-03 06:39:15,239 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41581
2023-12-03 06:39:15,239 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43039
2023-12-03 06:39:15,239 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,239 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,239 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,239 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gg9y5t_d
2023-12-03 06:39:15,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35075
2023-12-03 06:39:15,239 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35075
2023-12-03 06:39:15,239 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45015
2023-12-03 06:39:15,239 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,239 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,239 - distributed.worker - INFO - Starting Worker plugin PreImport-13385539-9dc7-4475-9ce2-d4212e75c4ad
2023-12-03 06:39:15,239 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,240 - distributed.worker - INFO - Starting Worker plugin RMMSetup-245a6b69-818f-4c74-840b-6496b59d74be
2023-12-03 06:39:15,240 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,240 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oca48ziu
2023-12-03 06:39:15,240 - distributed.worker - INFO - Starting Worker plugin PreImport-5d58bb18-e374-4c5a-baef-2aba4b0dc48a
2023-12-03 06:39:15,240 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f596cffa-553f-4dd1-9082-3f48705e67a5
2023-12-03 06:39:15,241 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32809
2023-12-03 06:39:15,243 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32809
2023-12-03 06:39:15,244 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42631
2023-12-03 06:39:15,244 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:15,244 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:15,244 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:15,244 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:15,244 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vkv1iaum
2023-12-03 06:39:15,245 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-888ecca5-dcaa-4965-b4d4-0fa6ea3fbdf6
2023-12-03 06:39:15,245 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9869e923-6dd3-480d-940f-96e1f4f1058b
2023-12-03 06:39:16,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a97ba0d2-e4c9-4812-80e1-3cdfef405942
2023-12-03 06:39:16,887 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35247', status: init, memory: 0, processing: 0>
2023-12-03 06:39:16,920 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35247
2023-12-03 06:39:16,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53564
2023-12-03 06:39:16,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:16,925 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:16,925 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:16,929 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,931 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e353ec7f-0777-4505-b837-c03409277fee
2023-12-03 06:39:16,931 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,961 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,962 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba53ad9f-7758-46f8-a6f5-447d59e17c72
2023-12-03 06:39:16,963 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43427', status: init, memory: 0, processing: 0>
2023-12-03 06:39:16,963 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,963 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43427
2023-12-03 06:39:16,964 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53568
2023-12-03 06:39:16,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:16,969 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:16,969 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,970 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:16,974 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36713', status: init, memory: 0, processing: 0>
2023-12-03 06:39:16,975 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36713
2023-12-03 06:39:16,975 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53584
2023-12-03 06:39:16,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:16,987 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:16,987 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,989 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:16,993 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42643', status: init, memory: 0, processing: 0>
2023-12-03 06:39:16,994 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42643
2023-12-03 06:39:16,994 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53590
2023-12-03 06:39:16,995 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:16,996 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:16,996 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:16,997 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:16,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35075', status: init, memory: 0, processing: 0>
2023-12-03 06:39:16,999 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35075
2023-12-03 06:39:16,999 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53592
2023-12-03 06:39:17,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:17,008 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:17,008 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,010 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:17,014 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fc7afc8b-7c06-4645-aa2b-4173aae83306
2023-12-03 06:39:17,015 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,027 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-426b7df2-67b3-40cf-b894-f2f73cb397e6
2023-12-03 06:39:17,031 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,059 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41581', status: init, memory: 0, processing: 0>
2023-12-03 06:39:17,060 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41581
2023-12-03 06:39:17,060 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53604
2023-12-03 06:39:17,061 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:17,065 - distributed.worker - INFO - Starting Worker plugin PreImport-832fdf30-63fa-4427-986d-5094983bae84
2023-12-03 06:39:17,065 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,069 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:17,069 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,071 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:17,078 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46297', status: init, memory: 0, processing: 0>
2023-12-03 06:39:17,079 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46297
2023-12-03 06:39:17,079 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53606
2023-12-03 06:39:17,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:17,090 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:17,090 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,091 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:17,107 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32809', status: init, memory: 0, processing: 0>
2023-12-03 06:39:17,108 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32809
2023-12-03 06:39:17,108 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53612
2023-12-03 06:39:17,109 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:17,114 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:17,114 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:17,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:17,141 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,141 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,142 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:17,155 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,155 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,156 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:17,163 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:17,165 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:17,167 - distributed.scheduler - INFO - Remove client Client-a7358e70-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:17,167 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41334; closing.
2023-12-03 06:39:17,168 - distributed.scheduler - INFO - Remove client Client-a7358e70-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:17,168 - distributed.scheduler - INFO - Close client connection: Client-a7358e70-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:17,169 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40597'. Reason: nanny-close
2023-12-03 06:39:17,170 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,170 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44971'. Reason: nanny-close
2023-12-03 06:39:17,171 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,171 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32809. Reason: nanny-close
2023-12-03 06:39:17,171 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44645'. Reason: nanny-close
2023-12-03 06:39:17,171 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,171 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35075. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46795'. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43427. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35597'. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,172 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35247. Reason: nanny-close
2023-12-03 06:39:17,173 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35169'. Reason: nanny-close
2023-12-03 06:39:17,173 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,173 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,173 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53612; closing.
2023-12-03 06:39:17,173 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41581. Reason: nanny-close
2023-12-03 06:39:17,173 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39205'. Reason: nanny-close
2023-12-03 06:39:17,173 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1738')
2023-12-03 06:39:17,173 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,174 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,174 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,174 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36713. Reason: nanny-close
2023-12-03 06:39:17,174 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38759'. Reason: nanny-close
2023-12-03 06:39:17,174 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:17,174 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,174 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46297. Reason: nanny-close
2023-12-03 06:39:17,175 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42643. Reason: nanny-close
2023-12-03 06:39:17,175 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,175 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53564; closing.
2023-12-03 06:39:17,175 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,175 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,175 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53592; closing.
2023-12-03 06:39:17,176 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53568; closing.
2023-12-03 06:39:17,176 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,176 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,176 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35247', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1766443')
2023-12-03 06:39:17,176 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,177 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35075', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.177024')
2023-12-03 06:39:17,177 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,177 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43427', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1773796')
2023-12-03 06:39:17,177 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:17,178 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,178 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53604; closing.
2023-12-03 06:39:17,178 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,178 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,178 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41581', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1788316')
2023-12-03 06:39:17,179 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53584; closing.
2023-12-03 06:39:17,179 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:17,179 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53606; closing.
2023-12-03 06:39:17,179 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53590; closing.
2023-12-03 06:39:17,179 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36713', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1798687')
2023-12-03 06:39:17,180 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1802447')
2023-12-03 06:39:17,180 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42643', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585557.1806157')
2023-12-03 06:39:17,180 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:19,087 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:19,088 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:19,088 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:19,090 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:19,090 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-12-03 06:39:21,329 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:21,333 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43441 instead
  warnings.warn(
2023-12-03 06:39:21,338 - distributed.scheduler - INFO - State start
2023-12-03 06:39:21,359 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:21,360 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:39:21,361 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43441/status
2023-12-03 06:39:21,361 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:39:21,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37593'
2023-12-03 06:39:21,549 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35249'
2023-12-03 06:39:21,558 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44105'
2023-12-03 06:39:21,572 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36389'
2023-12-03 06:39:21,575 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42127'
2023-12-03 06:39:21,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34771'
2023-12-03 06:39:21,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37131'
2023-12-03 06:39:21,601 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41127'
2023-12-03 06:39:22,939 - distributed.scheduler - INFO - Receive client connection: Client-afde1865-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:22,953 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51754
2023-12-03 06:39:23,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:23,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:23,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:23,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:23,575 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:23,578 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:23,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:23,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:23,590 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:24,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:24,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:24,137 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:24,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:24,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:24,148 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:24,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:24,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:24,162 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:24,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:24,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:24,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:24,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:24,168 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:24,169 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:30,261 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39245
2023-12-03 06:39:30,262 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39245
2023-12-03 06:39:30,262 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46691
2023-12-03 06:39:30,262 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,262 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,262 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,262 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pahhp2l1
2023-12-03 06:39:30,263 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0b03bb37-0709-4750-bc4b-5a748d7bc668
2023-12-03 06:39:30,263 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e199d026-4905-4300-8a43-f3460a4fd38f
2023-12-03 06:39:30,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42481
2023-12-03 06:39:30,383 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42481
2023-12-03 06:39:30,383 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38931
2023-12-03 06:39:30,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34441
2023-12-03 06:39:30,383 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,383 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34441
2023-12-03 06:39:30,383 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,383 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33215
2023-12-03 06:39:30,383 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,383 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,383 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,383 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yv_8gz09
2023-12-03 06:39:30,383 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,384 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,384 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-urbcfki2
2023-12-03 06:39:30,384 - distributed.worker - INFO - Starting Worker plugin PreImport-e3cb017f-faa8-41f0-8115-c22f3b4dbda6
2023-12-03 06:39:30,384 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fc254f4d-816c-4043-8d69-8737ce5ce2af
2023-12-03 06:39:30,384 - distributed.worker - INFO - Starting Worker plugin PreImport-6b9cfb82-81bb-430f-bd60-279042113919
2023-12-03 06:39:30,384 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dec7f85f-c682-4adb-b27f-21d687cb7c55
2023-12-03 06:39:30,384 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f54ace2-9921-4a85-8ecc-efaf7bc0aa38
2023-12-03 06:39:30,388 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44249
2023-12-03 06:39:30,389 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44249
2023-12-03 06:39:30,389 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36599
2023-12-03 06:39:30,389 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,389 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,389 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,389 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,389 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ofcqyprq
2023-12-03 06:39:30,390 - distributed.worker - INFO - Starting Worker plugin PreImport-2f4962d4-9410-409b-9186-1d9e5beffff0
2023-12-03 06:39:30,390 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8ab50ba7-2a8a-4687-b6c0-1fae04bc7782
2023-12-03 06:39:30,620 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41419
2023-12-03 06:39:30,621 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41419
2023-12-03 06:39:30,621 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43943
2023-12-03 06:39:30,621 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,621 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,621 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,621 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,621 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s88yrcy1
2023-12-03 06:39:30,622 - distributed.worker - INFO - Starting Worker plugin PreImport-a0c8d642-aca4-4aef-b4ef-308252929617
2023-12-03 06:39:30,622 - distributed.worker - INFO - Starting Worker plugin RMMSetup-80d0b544-9703-45b0-99b5-ad727de81b84
2023-12-03 06:39:30,625 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38881
2023-12-03 06:39:30,626 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38881
2023-12-03 06:39:30,626 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35655
2023-12-03 06:39:30,626 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,626 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,626 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,626 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,626 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-70be3vqm
2023-12-03 06:39:30,627 - distributed.worker - INFO - Starting Worker plugin PreImport-079e9694-41eb-4c95-842e-540678901dbc
2023-12-03 06:39:30,627 - distributed.worker - INFO - Starting Worker plugin RMMSetup-acaecdae-835e-4074-bf86-a10138fb736d
2023-12-03 06:39:30,627 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40015
2023-12-03 06:39:30,628 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40015
2023-12-03 06:39:30,628 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39749
2023-12-03 06:39:30,628 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,628 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,628 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fi0efina
2023-12-03 06:39:30,629 - distributed.worker - INFO - Starting Worker plugin PreImport-107b1273-ebb7-4588-a6a8-e292d316feed
2023-12-03 06:39:30,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aca8ada0-24ba-4de5-94b0-0b450114e01b
2023-12-03 06:39:30,730 - distributed.worker - INFO - Starting Worker plugin PreImport-bc584caf-91b2-4b37-80fa-2985c1e9b4f8
2023-12-03 06:39:30,730 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,733 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69f289d0-a6e9-47af-86e1-ae45efd7776d
2023-12-03 06:39:30,734 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a6621941-77d7-4df0-b31c-5229615eb0b7
2023-12-03 06:39:30,735 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,735 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,736 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,771 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39245', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,772 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39245
2023-12-03 06:39:30,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58086
2023-12-03 06:39:30,773 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,778 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,778 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34441', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,778 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,779 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34441
2023-12-03 06:39:30,779 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58088
2023-12-03 06:39:30,779 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,780 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,781 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,781 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,783 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44249', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,784 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44249
2023-12-03 06:39:30,784 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58102
2023-12-03 06:39:30,785 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42481', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,786 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42481
2023-12-03 06:39:30,786 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58104
2023-12-03 06:39:30,787 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,788 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,789 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,795 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,795 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,797 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,844 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42709
2023-12-03 06:39:30,846 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42709
2023-12-03 06:39:30,847 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43413
2023-12-03 06:39:30,847 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,847 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,847 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:30,847 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:30,847 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5vigu967
2023-12-03 06:39:30,848 - distributed.worker - INFO - Starting Worker plugin PreImport-0cbb323f-2ae0-483b-8eaf-fd538c2198ef
2023-12-03 06:39:30,849 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e90689c9-4da9-4872-967c-a760a142f559
2023-12-03 06:39:30,870 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-582e055b-2cea-401f-b62c-46867d4722ad
2023-12-03 06:39:30,871 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad29bcdd-6031-471f-a92b-9d56caa31220
2023-12-03 06:39:30,871 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e601b50a-c535-433f-a46d-947e485ac0f9
2023-12-03 06:39:30,871 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,871 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,872 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,900 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41419', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,901 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41419
2023-12-03 06:39:30,901 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58116
2023-12-03 06:39:30,902 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,902 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,902 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,917 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40015', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,917 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40015
2023-12-03 06:39:30,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58132
2023-12-03 06:39:30,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38881', status: init, memory: 0, processing: 0>
2023-12-03 06:39:30,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38881
2023-12-03 06:39:30,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58118
2023-12-03 06:39:30,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,921 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,921 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:30,922 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:30,922 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:30,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:30,993 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5bbc88b7-4f38-45cc-b20d-94cacdcd0735
2023-12-03 06:39:30,994 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:31,022 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42709', status: init, memory: 0, processing: 0>
2023-12-03 06:39:31,023 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42709
2023-12-03 06:39:31,023 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58144
2023-12-03 06:39:31,024 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:31,025 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:31,025 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:31,027 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:31,075 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,075 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,075 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,075 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,076 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,076 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,076 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,076 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,087 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,087 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,087 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,087 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,087 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,088 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,088 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,088 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:39:31,094 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,095 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:31,097 - distributed.scheduler - INFO - Remove client Client-afde1865-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:31,098 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51754; closing.
2023-12-03 06:39:31,098 - distributed.scheduler - INFO - Remove client Client-afde1865-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:31,098 - distributed.scheduler - INFO - Close client connection: Client-afde1865-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:31,099 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37593'. Reason: nanny-close
2023-12-03 06:39:31,100 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,101 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35249'. Reason: nanny-close
2023-12-03 06:39:31,101 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38881. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44105'. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36389'. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42481. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,102 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34441. Reason: nanny-close
2023-12-03 06:39:31,103 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42127'. Reason: nanny-close
2023-12-03 06:39:31,103 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42709. Reason: nanny-close
2023-12-03 06:39:31,103 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,104 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34771'. Reason: nanny-close
2023-12-03 06:39:31,104 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,104 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,104 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58118; closing.
2023-12-03 06:39:31,104 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44249. Reason: nanny-close
2023-12-03 06:39:31,104 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37131'. Reason: nanny-close
2023-12-03 06:39:31,104 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,104 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1046672')
2023-12-03 06:39:31,104 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,105 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40015. Reason: nanny-close
2023-12-03 06:39:31,105 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41127'. Reason: nanny-close
2023-12-03 06:39:31,105 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,105 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:31,105 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39245. Reason: nanny-close
2023-12-03 06:39:31,105 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,105 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58144; closing.
2023-12-03 06:39:31,105 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58088; closing.
2023-12-03 06:39:31,106 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41419. Reason: nanny-close
2023-12-03 06:39:31,106 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,106 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,106 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,106 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,106 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42709', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.106779')
2023-12-03 06:39:31,107 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34441', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1071372')
2023-12-03 06:39:31,107 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58104; closing.
2023-12-03 06:39:31,107 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,107 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,108 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,108 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:31,108 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,109 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,108 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58144>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58144>: Stream is closed
2023-12-03 06:39:31,109 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,109 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:31,109 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42481', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1097054')
2023-12-03 06:39:31,110 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58102; closing.
2023-12-03 06:39:31,110 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58132; closing.
2023-12-03 06:39:31,111 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58086; closing.
2023-12-03 06:39:31,111 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44249', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1114836')
2023-12-03 06:39:31,112 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40015', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1119378')
2023-12-03 06:39:31,112 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1123915')
2023-12-03 06:39:31,112 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58116; closing.
2023-12-03 06:39:31,113 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41419', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585571.1131933')
2023-12-03 06:39:31,113 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:32,968 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:32,968 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:32,969 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:32,970 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:32,970 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-12-03 06:39:35,050 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:35,056 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39513 instead
  warnings.warn(
2023-12-03 06:39:35,060 - distributed.scheduler - INFO - State start
2023-12-03 06:39:35,084 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:35,085 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:39:35,085 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39513/status
2023-12-03 06:39:35,086 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:39:35,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43965'
2023-12-03 06:39:35,401 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43667'
2023-12-03 06:39:35,418 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34913'
2023-12-03 06:39:35,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38799'
2023-12-03 06:39:35,434 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39105'
2023-12-03 06:39:35,444 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38723'
2023-12-03 06:39:35,453 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44305'
2023-12-03 06:39:35,462 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36287'
2023-12-03 06:39:35,582 - distributed.scheduler - INFO - Receive client connection: Client-b8196449-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:35,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58294
2023-12-03 06:39:37,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,353 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,361 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,361 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,362 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,369 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:37,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:37,376 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:37,377 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:40,224 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42535
2023-12-03 06:39:40,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42535
2023-12-03 06:39:40,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43753
2023-12-03 06:39:40,225 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,225 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,225 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,225 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,225 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ad9hqflw
2023-12-03 06:39:40,226 - distributed.worker - INFO - Starting Worker plugin PreImport-87ba9ffc-a461-42d5-ac21-b775b7d35d52
2023-12-03 06:39:40,226 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d778acdd-84b3-4334-b63e-c097e123f741
2023-12-03 06:39:40,230 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38227
2023-12-03 06:39:40,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38227
2023-12-03 06:39:40,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38139
2023-12-03 06:39:40,231 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,231 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,232 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lt9dj4y0
2023-12-03 06:39:40,232 - distributed.worker - INFO - Starting Worker plugin PreImport-8029ab25-d0bb-410f-a3a2-e9b590f57707
2023-12-03 06:39:40,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e7d281e-b363-4208-97ab-904979dc815a
2023-12-03 06:39:40,233 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37763
2023-12-03 06:39:40,234 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37763
2023-12-03 06:39:40,234 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33309
2023-12-03 06:39:40,234 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,234 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,234 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,234 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,234 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dan27yw4
2023-12-03 06:39:40,235 - distributed.worker - INFO - Starting Worker plugin PreImport-b8a4d877-b47f-47f1-9052-3aba4e68d739
2023-12-03 06:39:40,235 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f2b35367-a16f-49ff-98ae-645edb412c79
2023-12-03 06:39:40,249 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33883
2023-12-03 06:39:40,251 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33883
2023-12-03 06:39:40,251 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44949
2023-12-03 06:39:40,251 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,251 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,251 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,251 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,251 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hez7mdak
2023-12-03 06:39:40,252 - distributed.worker - INFO - Starting Worker plugin PreImport-a3fa64be-c76d-42ea-8ea7-77cb0de4b2aa
2023-12-03 06:39:40,252 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd0b5eae-1129-4be9-9c1c-55b9abe011ff
2023-12-03 06:39:40,255 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8de867f-dcc3-4d7a-8387-ecf5a0f7d204
2023-12-03 06:39:40,255 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45757
2023-12-03 06:39:40,256 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45757
2023-12-03 06:39:40,256 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39271
2023-12-03 06:39:40,256 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,256 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,256 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,257 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,257 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dc3ktiqr
2023-12-03 06:39:40,257 - distributed.worker - INFO - Starting Worker plugin PreImport-627aae2f-9617-4f14-9d94-8ed5e5c8255c
2023-12-03 06:39:40,257 - distributed.worker - INFO - Starting Worker plugin RMMSetup-947daeed-4dd4-4bcb-b0c8-2842bf8e8a21
2023-12-03 06:39:40,257 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42441
2023-12-03 06:39:40,258 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42441
2023-12-03 06:39:40,258 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44625
2023-12-03 06:39:40,258 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,258 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,258 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,258 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,259 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0dmlpk3j
2023-12-03 06:39:40,259 - distributed.worker - INFO - Starting Worker plugin PreImport-0c05922e-a5af-4d2e-b8b8-406d78ce0225
2023-12-03 06:39:40,259 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d519fad-e189-4b22-ad39-636072ba91ca
2023-12-03 06:39:40,259 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f783cb1-ab1c-4e18-a91d-0bcae1566e21
2023-12-03 06:39:40,445 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33079
2023-12-03 06:39:40,445 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36655
2023-12-03 06:39:40,445 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36655
2023-12-03 06:39:40,445 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33079
2023-12-03 06:39:40,445 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34849
2023-12-03 06:39:40,445 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40569
2023-12-03 06:39:40,446 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,446 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:40,446 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,446 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,446 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,446 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:40,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:39:40,446 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-01mrtkwb
2023-12-03 06:39:40,446 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wx0i5jbx
2023-12-03 06:39:40,446 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ec9eb14b-9fa2-47c0-95d7-b79331f2d0f0
2023-12-03 06:39:40,446 - distributed.worker - INFO - Starting Worker plugin PreImport-1c3d9164-da84-4bfb-b9ec-f8f746585de2
2023-12-03 06:39:40,447 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6445cc7a-dba2-41c8-8dea-82ae9c6259c6
2023-12-03 06:39:40,447 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2307aae-062c-4dec-8a01-b005ddfc04ed
2023-12-03 06:39:40,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-237d0f0e-ff20-44a4-970f-098c81bfc301
2023-12-03 06:39:40,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f96e0906-16e0-4717-80a0-507e4b512f5f
2023-12-03 06:39:40,911 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e58ecc03-718e-4fd9-9ce4-be0ed443e0ae
2023-12-03 06:39:40,911 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,911 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,911 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:40,923 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aaaa1a2e-2e89-43b0-a91d-2c5d57d1cd89
2023-12-03 06:39:40,925 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,107 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,107 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-371d07a4-3c30-4598-829b-72c5e213115d
2023-12-03 06:39:41,108 - distributed.worker - INFO - Starting Worker plugin PreImport-aee215e2-55ee-40e5-9ae4-40cc79883af0
2023-12-03 06:39:41,108 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,109 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,109 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42441', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,110 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42441
2023-12-03 06:39:41,111 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57304
2023-12-03 06:39:41,112 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,114 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42535', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,115 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42535
2023-12-03 06:39:41,115 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57332
2023-12-03 06:39:41,115 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,116 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,116 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38227', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38227
2023-12-03 06:39:41,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57338
2023-12-03 06:39:41,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,117 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37763', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,118 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37763
2023-12-03 06:39:41,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57326
2023-12-03 06:39:41,119 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,120 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,120 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,121 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,121 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45757', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,122 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45757
2023-12-03 06:39:41,122 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57318
2023-12-03 06:39:41,123 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,123 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,124 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,124 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,125 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,126 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,127 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,127 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,129 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,155 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33883', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33883
2023-12-03 06:39:41,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57342
2023-12-03 06:39:41,156 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33079', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,157 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33079
2023-12-03 06:39:41,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57360
2023-12-03 06:39:41,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,157 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36655', status: init, memory: 0, processing: 0>
2023-12-03 06:39:41,158 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36655
2023-12-03 06:39:41,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,158 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57352
2023-12-03 06:39:41,159 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,159 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:41,160 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,161 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,161 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:41,161 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:41,163 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,166 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,234 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:39:41,239 - distributed.scheduler - INFO - Remove client Client-b8196449-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:41,239 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58294; closing.
2023-12-03 06:39:41,239 - distributed.scheduler - INFO - Remove client Client-b8196449-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:41,240 - distributed.scheduler - INFO - Close client connection: Client-b8196449-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:41,241 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43965'. Reason: nanny-close
2023-12-03 06:39:41,241 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43667'. Reason: nanny-close
2023-12-03 06:39:41,242 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,242 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36655. Reason: nanny-close
2023-12-03 06:39:41,243 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34913'. Reason: nanny-close
2023-12-03 06:39:41,243 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,243 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33079. Reason: nanny-close
2023-12-03 06:39:41,243 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38799'. Reason: nanny-close
2023-12-03 06:39:41,243 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42535. Reason: nanny-close
2023-12-03 06:39:41,244 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39105'. Reason: nanny-close
2023-12-03 06:39:41,244 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37763. Reason: nanny-close
2023-12-03 06:39:41,244 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38723'. Reason: nanny-close
2023-12-03 06:39:41,245 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,245 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57352; closing.
2023-12-03 06:39:41,245 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,245 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38227. Reason: nanny-close
2023-12-03 06:39:41,245 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36655', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2453728')
2023-12-03 06:39:41,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44305'. Reason: nanny-close
2023-12-03 06:39:41,245 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,245 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,245 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,245 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33883. Reason: nanny-close
2023-12-03 06:39:41,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36287'. Reason: nanny-close
2023-12-03 06:39:41,246 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:41,246 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45757. Reason: nanny-close
2023-12-03 06:39:41,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,246 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,246 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57360; closing.
2023-12-03 06:39:41,247 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42441. Reason: nanny-close
2023-12-03 06:39:41,247 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,247 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57332; closing.
2023-12-03 06:39:41,247 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,247 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,247 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,247 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33079', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.247848')
2023-12-03 06:39:41,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,248 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57326; closing.
2023-12-03 06:39:41,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,248 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42535', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2483675')
2023-12-03 06:39:41,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:41,249 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37763', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2490807')
2023-12-03 06:39:41,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57338; closing.
2023-12-03 06:39:41,249 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,249 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,249 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,250 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38227', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.250167')
2023-12-03 06:39:41,250 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:41,250 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57342; closing.
2023-12-03 06:39:41,250 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57318; closing.
2023-12-03 06:39:41,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2511966')
2023-12-03 06:39:41,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45757', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2515879')
2023-12-03 06:39:41,251 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57304; closing.
2023-12-03 06:39:41,252 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42441', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585581.2523043')
2023-12-03 06:39:41,252 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:43,109 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:43,109 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:43,110 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:43,111 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:43,112 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-12-03 06:39:45,341 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:45,346 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44519 instead
  warnings.warn(
2023-12-03 06:39:45,350 - distributed.scheduler - INFO - State start
2023-12-03 06:39:45,420 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:45,421 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:39:45,422 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44519/status
2023-12-03 06:39:45,422 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:39:45,504 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42467'
2023-12-03 06:39:47,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:47,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:47,873 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:49,099 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33917
2023-12-03 06:39:49,102 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33917
2023-12-03 06:39:49,102 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-12-03 06:39:49,103 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:49,103 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:49,103 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:49,103 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-03 06:39:49,103 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t6np7sj_
2023-12-03 06:39:49,104 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-72226af8-2e75-46f2-b5cc-d48079a499fe
2023-12-03 06:39:49,105 - distributed.worker - INFO - Starting Worker plugin PreImport-7c4bcf8b-2101-4f85-a2cb-7157cc236a63
2023-12-03 06:39:49,105 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa176cbf-b9b5-4bca-9678-2c17b59a640e
2023-12-03 06:39:49,106 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:49,142 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33917', status: init, memory: 0, processing: 0>
2023-12-03 06:39:49,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33917
2023-12-03 06:39:49,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57472
2023-12-03 06:39:49,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:49,157 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:49,157 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:49,160 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:49,950 - distributed.scheduler - INFO - Receive client connection: Client-be275d9c-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:49,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45130
2023-12-03 06:39:49,958 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:49,963 - distributed.scheduler - INFO - Remove client Client-be275d9c-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:49,964 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45130; closing.
2023-12-03 06:39:49,964 - distributed.scheduler - INFO - Remove client Client-be275d9c-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:49,964 - distributed.scheduler - INFO - Close client connection: Client-be275d9c-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:49,965 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42467'. Reason: nanny-close
2023-12-03 06:39:49,966 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:49,967 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33917. Reason: nanny-close
2023-12-03 06:39:49,969 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57472; closing.
2023-12-03 06:39:49,969 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:49,970 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33917', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585589.9700437')
2023-12-03 06:39:49,970 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:49,971 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:51,082 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:51,082 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:51,082 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:51,083 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:51,084 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-12-03 06:39:54,958 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:54,962 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44111 instead
  warnings.warn(
2023-12-03 06:39:54,965 - distributed.scheduler - INFO - State start
2023-12-03 06:39:55,298 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:39:55,299 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:39:55,300 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44111/status
2023-12-03 06:39:55,300 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:39:55,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45845'
2023-12-03 06:39:56,242 - distributed.scheduler - INFO - Receive client connection: Client-c3f7461b-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:56,255 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45258
2023-12-03 06:39:57,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:39:57,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:39:57,588 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:39:58,435 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39807
2023-12-03 06:39:58,436 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39807
2023-12-03 06:39:58,436 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33503
2023-12-03 06:39:58,436 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:39:58,436 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:58,436 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:39:58,436 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-03 06:39:58,436 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ok90ba5
2023-12-03 06:39:58,437 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f70c4d0c-64fd-43b6-b1b9-c76a05bfd24c
2023-12-03 06:39:58,437 - distributed.worker - INFO - Starting Worker plugin PreImport-0750f1f5-659a-45c3-9417-8d29537aadbc
2023-12-03 06:39:58,439 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aeb2cf06-488f-45dd-bd47-7b9970fd725f
2023-12-03 06:39:58,440 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:58,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39807', status: init, memory: 0, processing: 0>
2023-12-03 06:39:58,469 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39807
2023-12-03 06:39:58,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45276
2023-12-03 06:39:58,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:39:58,470 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:39:58,470 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:39:58,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:39:58,496 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:39:58,499 - distributed.scheduler - INFO - Remove client Client-c3f7461b-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:58,499 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45258; closing.
2023-12-03 06:39:58,500 - distributed.scheduler - INFO - Remove client Client-c3f7461b-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:58,500 - distributed.scheduler - INFO - Close client connection: Client-c3f7461b-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:39:58,501 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45845'. Reason: nanny-close
2023-12-03 06:39:58,501 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:39:58,503 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39807. Reason: nanny-close
2023-12-03 06:39:58,505 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45276; closing.
2023-12-03 06:39:58,505 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:39:58,505 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585598.5053608')
2023-12-03 06:39:58,505 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:39:58,506 - distributed.nanny - INFO - Worker closed
2023-12-03 06:39:59,718 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:39:59,718 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:39:59,719 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:39:59,720 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:39:59,720 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-12-03 06:40:01,815 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:01,820 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39407 instead
  warnings.warn(
2023-12-03 06:40:01,824 - distributed.scheduler - INFO - State start
2023-12-03 06:40:01,846 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:01,847 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:40:01,848 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39407/status
2023-12-03 06:40:01,848 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:40:07,248 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:49490'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49490>: Stream is closed
2023-12-03 06:40:07,596 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:40:07,597 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:40:07,597 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:40:07,598 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:40:07,598 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-12-03 06:40:09,785 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:09,789 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45507 instead
  warnings.warn(
2023-12-03 06:40:09,793 - distributed.scheduler - INFO - State start
2023-12-03 06:40:09,813 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:09,814 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-12-03 06:40:09,815 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45507/status
2023-12-03 06:40:09,816 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:40:09,851 - distributed.scheduler - INFO - Receive client connection: Client-ccbca25e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:09,864 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35838
2023-12-03 06:40:09,898 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44911'
2023-12-03 06:40:11,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:11,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:11,450 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:12,285 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41823
2023-12-03 06:40:12,285 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41823
2023-12-03 06:40:12,285 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45625
2023-12-03 06:40:12,285 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-03 06:40:12,286 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:12,286 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:12,286 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-03 06:40:12,286 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-5aunq_hp
2023-12-03 06:40:12,286 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-373b19a3-693e-4999-9e6d-4ab83bf5426e
2023-12-03 06:40:12,286 - distributed.worker - INFO - Starting Worker plugin PreImport-c4738f72-28eb-434f-a30f-796c78d4b2d3
2023-12-03 06:40:12,286 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9aefe96a-667b-44ac-9b4a-e97c1bec6a11
2023-12-03 06:40:12,287 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:12,318 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41823', status: init, memory: 0, processing: 0>
2023-12-03 06:40:12,319 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41823
2023-12-03 06:40:12,319 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38098
2023-12-03 06:40:12,320 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:12,320 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-03 06:40:12,321 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:12,322 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-03 06:40:12,389 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:12,392 - distributed.scheduler - INFO - Remove client Client-ccbca25e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:12,392 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35838; closing.
2023-12-03 06:40:12,392 - distributed.scheduler - INFO - Remove client Client-ccbca25e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:12,393 - distributed.scheduler - INFO - Close client connection: Client-ccbca25e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:12,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44911'. Reason: nanny-close
2023-12-03 06:40:12,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:12,395 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41823. Reason: nanny-close
2023-12-03 06:40:12,397 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-03 06:40:12,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38098; closing.
2023-12-03 06:40:12,397 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41823', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585612.3976202')
2023-12-03 06:40:12,397 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:40:12,398 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:13,560 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:40:13,560 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:40:13,561 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:40:13,562 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-12-03 06:40:13,562 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-12-03 06:40:15,788 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:15,792 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40627 instead
  warnings.warn(
2023-12-03 06:40:15,796 - distributed.scheduler - INFO - State start
2023-12-03 06:40:15,884 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:15,886 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:40:15,886 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40627/status
2023-12-03 06:40:15,887 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:40:16,146 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45743'
2023-12-03 06:40:16,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37307'
2023-12-03 06:40:16,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37373'
2023-12-03 06:40:16,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41919'
2023-12-03 06:40:16,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38411'
2023-12-03 06:40:16,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39399'
2023-12-03 06:40:16,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42711'
2023-12-03 06:40:16,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33977'
2023-12-03 06:40:18,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,036 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,043 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,048 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,112 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,132 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,134 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:18,137 - distributed.scheduler - INFO - Receive client connection: Client-d04ed626-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:18,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39770
2023-12-03 06:40:18,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:18,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:18,162 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:21,104 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37627
2023-12-03 06:40:21,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37627
2023-12-03 06:40:21,105 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33551
2023-12-03 06:40:21,105 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:21,105 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:21,105 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:21,105 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:21,105 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_mdtoh4n
2023-12-03 06:40:21,106 - distributed.worker - INFO - Starting Worker plugin PreImport-b557bb62-2f00-473e-9cc7-d666f0b0910f
2023-12-03 06:40:21,106 - distributed.worker - INFO - Starting Worker plugin RMMSetup-38f11c7d-93a0-43d5-88b1-f44ef3973432
2023-12-03 06:40:21,600 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1323841e-c07c-43ed-8791-e96fd8699f65
2023-12-03 06:40:21,601 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:21,767 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37627', status: init, memory: 0, processing: 0>
2023-12-03 06:40:21,769 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37627
2023-12-03 06:40:21,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50710
2023-12-03 06:40:21,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:21,774 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:21,774 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:21,775 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,212 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46495
2023-12-03 06:40:22,213 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46495
2023-12-03 06:40:22,213 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36085
2023-12-03 06:40:22,213 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,213 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,213 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,214 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,214 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c844j4xy
2023-12-03 06:40:22,215 - distributed.worker - INFO - Starting Worker plugin PreImport-82c98980-e216-4289-9e97-c35fd2bffa1e
2023-12-03 06:40:22,215 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6211d5db-c1bd-4a38-a073-8f43707c3130
2023-12-03 06:40:22,221 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40071
2023-12-03 06:40:22,222 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40071
2023-12-03 06:40:22,222 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46235
2023-12-03 06:40:22,222 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,222 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,222 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,222 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,222 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z0blq0p_
2023-12-03 06:40:22,222 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7276d952-c48a-4110-8ef2-27d5beb5a274
2023-12-03 06:40:22,223 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a0470327-6931-4e28-b887-e21e55d5d10d
2023-12-03 06:40:22,226 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34495
2023-12-03 06:40:22,227 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34495
2023-12-03 06:40:22,227 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32847
2023-12-03 06:40:22,227 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,227 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,227 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,227 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,228 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bhksu4f4
2023-12-03 06:40:22,228 - distributed.worker - INFO - Starting Worker plugin PreImport-25628eef-4481-4db9-8762-c44b9ed22b0d
2023-12-03 06:40:22,228 - distributed.worker - INFO - Starting Worker plugin RMMSetup-326b03d6-8579-4d0b-9883-7b0580c62dc2
2023-12-03 06:40:22,234 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34163
2023-12-03 06:40:22,235 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34163
2023-12-03 06:40:22,235 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38619
2023-12-03 06:40:22,235 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,235 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,235 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,235 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,235 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-twy2sfsw
2023-12-03 06:40:22,236 - distributed.worker - INFO - Starting Worker plugin PreImport-93644a72-4068-4d5a-ab3b-32f42e57a37a
2023-12-03 06:40:22,236 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-599deb23-a213-4cdf-b6a7-72ac14703b74
2023-12-03 06:40:22,236 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0a2ddc1c-a4fa-4155-acb6-2043b7be9bcf
2023-12-03 06:40:22,236 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38339
2023-12-03 06:40:22,237 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38339
2023-12-03 06:40:22,237 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33641
2023-12-03 06:40:22,237 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,237 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,237 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,238 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,237 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43223
2023-12-03 06:40:22,238 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t7ma0git
2023-12-03 06:40:22,238 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43223
2023-12-03 06:40:22,238 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45823
2023-12-03 06:40:22,238 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,238 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,238 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,238 - distributed.worker - INFO - Starting Worker plugin PreImport-5fe837c5-2037-465e-baed-afd50a6fe54f
2023-12-03 06:40:22,238 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,238 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tk0gofbf
2023-12-03 06:40:22,238 - distributed.worker - INFO - Starting Worker plugin RMMSetup-986e9362-71b6-47f2-9cb8-77130c944958
2023-12-03 06:40:22,238 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46873
2023-12-03 06:40:22,239 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46873
2023-12-03 06:40:22,239 - distributed.worker - INFO - Starting Worker plugin PreImport-671b1aef-761d-48f2-9a12-bb82c7661a97
2023-12-03 06:40:22,239 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34405
2023-12-03 06:40:22,239 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-62ee7d27-cb5a-4ae8-8bfa-a48953d1ff33
2023-12-03 06:40:22,239 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,239 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:22,239 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-03 06:40:22,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-poyp_oqf
2023-12-03 06:40:22,240 - distributed.worker - INFO - Starting Worker plugin PreImport-0722cf44-86b3-451a-b16a-316c4c693b80
2023-12-03 06:40:22,240 - distributed.worker - INFO - Starting Worker plugin RMMSetup-66457f35-e9fc-4bad-a387-1717454d1f81
2023-12-03 06:40:22,648 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2333f1ea-ae48-4052-bbeb-71d90fd0464e
2023-12-03 06:40:22,649 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,649 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,649 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-40ba48f3-4174-4a1c-8964-6b9d3e9ecde1
2023-12-03 06:40:22,650 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,650 - distributed.worker - INFO - Starting Worker plugin PreImport-54feaa3c-1bb5-46a2-880f-f9ffd04f5ba0
2023-12-03 06:40:22,650 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-833a8583-de5c-47c9-918f-22a948ab4ec4
2023-12-03 06:40:22,651 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9f8aaad-5808-4695-a5d1-921452b27cad
2023-12-03 06:40:22,651 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,651 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,651 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42276774-feca-4066-a073-f3eb84798ca8
2023-12-03 06:40:22,651 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,652 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43223', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,682 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43223
2023-12-03 06:40:22,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50742
2023-12-03 06:40:22,683 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34495', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,683 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34495
2023-12-03 06:40:22,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50744
2023-12-03 06:40:22,684 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40071', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,684 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,684 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40071
2023-12-03 06:40:22,684 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50734
2023-12-03 06:40:22,685 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,686 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,686 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,688 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,688 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,689 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38339', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,689 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,689 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,690 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38339
2023-12-03 06:40:22,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50760
2023-12-03 06:40:22,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,691 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34163', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34163
2023-12-03 06:40:22,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50720
2023-12-03 06:40:22,693 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,693 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46495', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,694 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46495
2023-12-03 06:40:22,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50718
2023-12-03 06:40:22,695 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46873', status: init, memory: 0, processing: 0>
2023-12-03 06:40:22,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46873
2023-12-03 06:40:22,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50770
2023-12-03 06:40:22,698 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:22,700 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,700 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,700 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,700 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,700 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,700 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,705 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:22,705 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:22,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:22,798 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,798 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,798 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,798 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,799 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,799 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,799 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,799 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,813 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,814 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:22,818 - distributed.scheduler - INFO - Remove client Client-d04ed626-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:22,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39770; closing.
2023-12-03 06:40:22,818 - distributed.scheduler - INFO - Remove client Client-d04ed626-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:22,818 - distributed.scheduler - INFO - Close client connection: Client-d04ed626-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:22,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45743'. Reason: nanny-close
2023-12-03 06:40:22,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,820 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37307'. Reason: nanny-close
2023-12-03 06:40:22,821 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46495. Reason: nanny-close
2023-12-03 06:40:22,821 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37373'. Reason: nanny-close
2023-12-03 06:40:22,821 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34163. Reason: nanny-close
2023-12-03 06:40:22,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41919'. Reason: nanny-close
2023-12-03 06:40:22,822 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43223. Reason: nanny-close
2023-12-03 06:40:22,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38411'. Reason: nanny-close
2023-12-03 06:40:22,822 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37627. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39399'. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,823 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50718; closing.
2023-12-03 06:40:22,823 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38339. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42711'. Reason: nanny-close
2023-12-03 06:40:22,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8238158')
2023-12-03 06:40:22,824 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,824 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46873. Reason: nanny-close
2023-12-03 06:40:22,824 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33977'. Reason: nanny-close
2023-12-03 06:40:22,824 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:22,824 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40071. Reason: nanny-close
2023-12-03 06:40:22,825 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,825 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,825 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34495. Reason: nanny-close
2023-12-03 06:40:22,825 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,825 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50742; closing.
2023-12-03 06:40:22,825 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,825 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50720; closing.
2023-12-03 06:40:22,826 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,826 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50710; closing.
2023-12-03 06:40:22,826 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,826 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43223', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8266485')
2023-12-03 06:40:22,826 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,826 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34163', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8270056')
2023-12-03 06:40:22,827 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:22,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37627', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8276231')
2023-12-03 06:40:22,827 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,828 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50760; closing.
2023-12-03 06:40:22,828 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,828 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,828 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:22,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38339', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8287828')
2023-12-03 06:40:22,829 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50770; closing.
2023-12-03 06:40:22,829 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50734; closing.
2023-12-03 06:40:22,829 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46873', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.829836')
2023-12-03 06:40:22,830 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40071', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.830211')
2023-12-03 06:40:22,830 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50744; closing.
2023-12-03 06:40:22,830 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585622.8309271')
2023-12-03 06:40:22,831 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:40:24,437 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:40:24,437 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:40:24,437 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:40:24,438 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:40:24,439 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-12-03 06:40:26,570 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:26,574 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37781 instead
  warnings.warn(
2023-12-03 06:40:26,578 - distributed.scheduler - INFO - State start
2023-12-03 06:40:26,601 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:26,602 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:40:26,603 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37781/status
2023-12-03 06:40:26,603 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:40:26,717 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35291'
2023-12-03 06:40:27,009 - distributed.scheduler - INFO - Receive client connection: Client-d6b98582-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:27,022 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50864
2023-12-03 06:40:28,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:28,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:28,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:31,908 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38411
2023-12-03 06:40:31,910 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38411
2023-12-03 06:40:31,910 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33785
2023-12-03 06:40:31,911 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:31,911 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:31,911 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:31,911 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-03 06:40:31,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_5lv6avy
2023-12-03 06:40:31,912 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-820c2041-b968-432e-a40e-2667ccb39217
2023-12-03 06:40:31,912 - distributed.worker - INFO - Starting Worker plugin PreImport-220021d3-8db3-418c-874d-6754d3c29920
2023-12-03 06:40:31,913 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed3853e3-5d66-4ea3-bb89-fffd618019ca
2023-12-03 06:40:32,076 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:32,109 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38411', status: init, memory: 0, processing: 0>
2023-12-03 06:40:32,110 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38411
2023-12-03 06:40:32,110 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34286
2023-12-03 06:40:32,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:32,112 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:32,112 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:32,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:32,123 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:40:32,126 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:32,128 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:32,130 - distributed.scheduler - INFO - Remove client Client-d6b98582-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:32,130 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50864; closing.
2023-12-03 06:40:32,130 - distributed.scheduler - INFO - Remove client Client-d6b98582-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:32,131 - distributed.scheduler - INFO - Close client connection: Client-d6b98582-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:32,132 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35291'. Reason: nanny-close
2023-12-03 06:40:32,132 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:32,134 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38411. Reason: nanny-close
2023-12-03 06:40:32,135 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34286; closing.
2023-12-03 06:40:32,135 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:32,136 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38411', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585632.135968')
2023-12-03 06:40:32,136 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:40:32,137 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:33,148 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:40:33,149 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:40:33,149 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:40:33,150 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:40:33,150 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-12-03 06:40:35,326 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:35,331 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35071 instead
  warnings.warn(
2023-12-03 06:40:35,334 - distributed.scheduler - INFO - State start
2023-12-03 06:40:35,355 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-03 06:40:35,356 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-03 06:40:35,357 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35071/status
2023-12-03 06:40:35,357 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-03 06:40:35,421 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33885'
2023-12-03 06:40:35,534 - distributed.scheduler - INFO - Receive client connection: Client-dbfaf83e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:35,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34390
2023-12-03 06:40:36,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-03 06:40:36,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-03 06:40:36,892 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-03 06:40:37,774 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42241
2023-12-03 06:40:37,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42241
2023-12-03 06:40:37,774 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34923
2023-12-03 06:40:37,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-03 06:40:37,774 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:37,774 - distributed.worker - INFO -               Threads:                          1
2023-12-03 06:40:37,774 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-03 06:40:37,774 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vcu04sd6
2023-12-03 06:40:37,775 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c565aa1-99f0-4270-938a-9a6a5f4da1b9
2023-12-03 06:40:37,775 - distributed.worker - INFO - Starting Worker plugin PreImport-adedd846-a7fe-4827-8cb7-46c7861ec8a0
2023-12-03 06:40:37,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd88038d-596d-4fc4-a02e-65528db133d1
2023-12-03 06:40:37,887 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:37,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42241', status: init, memory: 0, processing: 0>
2023-12-03 06:40:37,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42241
2023-12-03 06:40:37,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34402
2023-12-03 06:40:37,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-03 06:40:37,921 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-03 06:40:37,921 - distributed.worker - INFO - -------------------------------------------------
2023-12-03 06:40:37,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-03 06:40:37,935 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-12-03 06:40:37,939 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-03 06:40:37,942 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:37,943 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-03 06:40:37,945 - distributed.scheduler - INFO - Remove client Client-dbfaf83e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:37,946 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34390; closing.
2023-12-03 06:40:37,946 - distributed.scheduler - INFO - Remove client Client-dbfaf83e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:37,946 - distributed.scheduler - INFO - Close client connection: Client-dbfaf83e-91a6-11ee-b37c-d8c49764f6bb
2023-12-03 06:40:37,947 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33885'. Reason: nanny-close
2023-12-03 06:40:37,950 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-03 06:40:37,951 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42241. Reason: nanny-close
2023-12-03 06:40:37,953 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-03 06:40:37,953 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34402; closing.
2023-12-03 06:40:37,953 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1701585637.9534423')
2023-12-03 06:40:37,953 - distributed.scheduler - INFO - Lost all workers
2023-12-03 06:40:37,954 - distributed.nanny - INFO - Worker closed
2023-12-03 06:40:38,913 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-03 06:40:38,913 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-03 06:40:38,914 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-03 06:40:38,915 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-03 06:40:38,915 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35785 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33363 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39517 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34451 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46721 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46147 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41869 instead
  warnings.warn(
2023-12-03 06:42:02,062 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-12-03 06:42:02,066 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-12-03 06:42:02,071 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43663 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42055 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39763 instead
  warnings.warn(
2023-12-03 06:42:34,714 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #018] ep: 0x7f7dfc1cf0c0, tag: 0xaa7f155fedd9efe, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #018] ep: 0x7f7dfc1cf0c0, tag: 0xaa7f155fedd9efe, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42727 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42887 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38965 instead
  warnings.warn(
2023-12-03 06:43:25,918 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-12-03 06:43:25,922 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:43473', name: 2, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40405 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45237 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38601 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33589 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34369 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41925 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40851 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36859 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38849 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39511 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36855 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:47:48,316 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 63, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:47:48,326 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-b2e0b2b3-4fe5-413d-9a36-8750f16b7115
Function:  _run_coroutine_on_worker
args:      (259055763743852405451278410606048559399, <function shuffle_task at 0x7fbf5926c040>, ('explicit-comms-shuffle-e097386536174eabd41defafccacc725', {0: set(), 1: {('from_pandas-042f56ad2fd1cc4d095a550ce07a5908', 0)}}, {0: {0}, 1: set()}, ['key'], 1, False, 1, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

Process SpawnProcess-28:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 146, in _test_dataframe_shuffle
    result = ddf.map_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 342, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 628, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 101, in _run_coroutine_on_worker
    return executor.submit(_run).result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 98, in _run
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 379, in shuffle_task
    await send_recv_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 296, in send_recv_partitions
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 124, in recv
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 120, in read_msg
    msg: Dict[int, DataFrame] = nested_deserialize(await eps[rank].read())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
    ret = unpack_construct(&ctx, buf, buf_len, &off)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 63, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
FAILED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:48:02,227 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 63, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:48:02,243 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-78955f3a-fae8-4846-b73b-0b66118c7edf
Function:  _run_coroutine_on_worker
args:      (124242879762158302514963236261020875397, <function shuffle_task at 0x7f70985cc160>, ('explicit-comms-shuffle-e097386536174eabd41defafccacc725', {0: set(), 1: set(), 2: {('from_pandas-042f56ad2fd1cc4d095a550ce07a5908', 0)}}, {0: {0}, 1: set(), 2: set()}, ['key'], 1, False, 1, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

Process SpawnProcess-29:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 146, in _test_dataframe_shuffle
    result = ddf.map_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 342, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 628, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 101, in _run_coroutine_on_worker
    return executor.submit(_run).result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 98, in _run
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 379, in shuffle_task
    await send_recv_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 296, in send_recv_partitions
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 124, in recv
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 120, in read_msg
    msg: Dict[int, DataFrame] = nested_deserialize(await eps[rank].read())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
    ret = unpack_construct(&ctx, buf, buf_len, &off)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 63, in dask_loads
    return loads(header["sub-header"], frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 29, in dask_deserialize_cudf_object
    return Serializable.host_deserialize(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
FAILED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] 2023-12-03 06:49:20,953 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:49:21,158 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:49:21,185 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'ucx://127.0.0.1:53227'.
2023-12-03 06:49:21,185 - distributed.worker - ERROR - Scheduler was unaware of this worker 'ucx://127.0.0.1:53227'. Shutting down.
2023-12-03 06:49:21,213 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fa4e0b77e80>>, <Task finished name='Task-15' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-15' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-03 06:49:23,217 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
