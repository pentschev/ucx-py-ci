============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-28 05:38:13,576 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:13,581 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39805 instead
  warnings.warn(
2023-10-28 05:38:13,586 - distributed.scheduler - INFO - State start
2023-10-28 05:38:13,610 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:13,611 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-28 05:38:13,612 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39805/status
2023-10-28 05:38:13,612 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:13,720 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36973'
2023-10-28 05:38:13,741 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39661'
2023-10-28 05:38:13,744 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34451'
2023-10-28 05:38:13,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45745'
2023-10-28 05:38:13,923 - distributed.scheduler - INFO - Receive client connection: Client-2ed6d3c7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:13,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47836
2023-10-28 05:38:15,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:15,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:15,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:15,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:15,501 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:15,501 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:15,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:15,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:15,528 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:15,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:15,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:15,610 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-28 05:38:15,634 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38951
2023-10-28 05:38:15,634 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38951
2023-10-28 05:38:15,634 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34885
2023-10-28 05:38:15,634 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-28 05:38:15,634 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:15,634 - distributed.worker - INFO -               Threads:                          4
2023-10-28 05:38:15,635 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-28 05:38:15,635 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-xjbwdkld
2023-10-28 05:38:15,635 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05863199-3204-4ece-aa6f-ae31d09d0f05
2023-10-28 05:38:15,635 - distributed.worker - INFO - Starting Worker plugin PreImport-8f026d51-e861-43c1-b426-59f3e3671012
2023-10-28 05:38:15,635 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ce60ff8-9f2e-47ea-b2c4-4020495ab1a5
2023-10-28 05:38:15,635 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:16,674 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38951', status: init, memory: 0, processing: 0>
2023-10-28 05:38:16,675 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38951
2023-10-28 05:38:16,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47850
2023-10-28 05:38:16,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:16,677 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-28 05:38:16,677 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:16,679 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-28 05:38:17,381 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38991
2023-10-28 05:38:17,381 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42301
2023-10-28 05:38:17,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38043
2023-10-28 05:38:17,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42301
2023-10-28 05:38:17,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38991
2023-10-28 05:38:17,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38043
2023-10-28 05:38:17,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39393
2023-10-28 05:38:17,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38071
2023-10-28 05:38:17,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41411
2023-10-28 05:38:17,382 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,382 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,382 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,382 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,382 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,382 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,382 - distributed.worker - INFO -               Threads:                          4
2023-10-28 05:38:17,382 - distributed.worker - INFO -               Threads:                          4
2023-10-28 05:38:17,382 - distributed.worker - INFO -               Threads:                          4
2023-10-28 05:38:17,382 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-28 05:38:17,382 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-28 05:38:17,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-cnsf1kc5
2023-10-28 05:38:17,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-961rl5pl
2023-10-28 05:38:17,383 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-28 05:38:17,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-bnqdtbvg
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48f4ed44-4cfd-47fb-ac8c-96adcc8646ab
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0cb74cf-8126-47aa-86ff-6eb9edec428f
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin PreImport-01e91d59-9cd1-4a5e-8f24-609220e9bfc6
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin PreImport-224d335e-145f-4067-b0cd-bd40b652ca29
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33657b7b-3a52-42d3-b7e8-ad618b9bd72b
2023-10-28 05:38:17,383 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f682d400-e70d-42a8-a03e-1395d449251f
2023-10-28 05:38:17,383 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,386 - distributed.worker - INFO - Starting Worker plugin RMMSetup-32c3190b-49e3-443b-aaae-36c1906e3fc7
2023-10-28 05:38:17,386 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,386 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae7d4526-778b-408d-9777-c6f4d284299e
2023-10-28 05:38:17,389 - distributed.worker - INFO - Starting Worker plugin PreImport-1050bd78-6ff7-4a10-b65e-fd71d94bd53a
2023-10-28 05:38:17,390 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,403 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38991', status: init, memory: 0, processing: 0>
2023-10-28 05:38:17,404 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38991
2023-10-28 05:38:17,404 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47856
2023-10-28 05:38:17,405 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:17,405 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,406 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,409 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-28 05:38:17,422 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42301', status: init, memory: 0, processing: 0>
2023-10-28 05:38:17,423 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42301
2023-10-28 05:38:17,423 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47876
2023-10-28 05:38:17,424 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38043', status: init, memory: 0, processing: 0>
2023-10-28 05:38:17,424 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:17,425 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38043
2023-10-28 05:38:17,425 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47872
2023-10-28 05:38:17,426 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,426 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:17,428 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-28 05:38:17,428 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:17,433 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-28 05:38:17,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-28 05:38:17,513 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-28 05:38:17,513 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-28 05:38:17,513 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-28 05:38:17,514 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-28 05:38:17,519 - distributed.scheduler - INFO - Remove client Client-2ed6d3c7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:17,519 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47836; closing.
2023-10-28 05:38:17,519 - distributed.scheduler - INFO - Remove client Client-2ed6d3c7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:17,520 - distributed.scheduler - INFO - Close client connection: Client-2ed6d3c7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:17,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36973'. Reason: nanny-close
2023-10-28 05:38:17,521 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:17,522 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39661'. Reason: nanny-close
2023-10-28 05:38:17,522 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:17,523 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42301. Reason: nanny-close
2023-10-28 05:38:17,523 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34451'. Reason: nanny-close
2023-10-28 05:38:17,523 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:17,523 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38991. Reason: nanny-close
2023-10-28 05:38:17,523 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45745'. Reason: nanny-close
2023-10-28 05:38:17,524 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:17,524 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38043. Reason: nanny-close
2023-10-28 05:38:17,524 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38951. Reason: nanny-close
2023-10-28 05:38:17,525 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47856; closing.
2023-10-28 05:38:17,525 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-28 05:38:17,525 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38991', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471497.5258517')
2023-10-28 05:38:17,526 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-28 05:38:17,526 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-28 05:38:17,526 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47872; closing.
2023-10-28 05:38:17,527 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-28 05:38:17,527 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47876; closing.
2023-10-28 05:38:17,527 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38043', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471497.5277872')
2023-10-28 05:38:17,528 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42301', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471497.528176')
2023-10-28 05:38:17,528 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:17,528 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:17,528 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:17,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47850; closing.
2023-10-28 05:38:17,528 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:17,529 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471497.5290134')
2023-10-28 05:38:17,529 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:38:18,688 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:38:18,688 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:38:18,689 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:38:18,690 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-28 05:38:18,690 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-28 05:38:20,853 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:20,858 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46571 instead
  warnings.warn(
2023-10-28 05:38:20,862 - distributed.scheduler - INFO - State start
2023-10-28 05:38:20,883 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:20,884 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:38:20,885 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46571/status
2023-10-28 05:38:20,885 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:21,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46773'
2023-10-28 05:38:21,082 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41003'
2023-10-28 05:38:21,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45305'
2023-10-28 05:38:21,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39063'
2023-10-28 05:38:21,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38847'
2023-10-28 05:38:21,120 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35235'
2023-10-28 05:38:21,129 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36375'
2023-10-28 05:38:21,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33051'
2023-10-28 05:38:22,661 - distributed.scheduler - INFO - Receive client connection: Client-332701b0-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:22,674 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53396
2023-10-28 05:38:22,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:22,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:22,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:22,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:22,966 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:22,969 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:22,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:22,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:22,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:22,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:22,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:22,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:22,985 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:22,987 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:22,988 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:23,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:23,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:23,034 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:23,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:23,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:23,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:23,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:23,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:23,070 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:25,986 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40797
2023-10-28 05:38:25,987 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40797
2023-10-28 05:38:25,987 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36707
2023-10-28 05:38:25,987 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:25,987 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:25,987 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:25,987 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:25,987 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pn0d6qi5
2023-10-28 05:38:25,988 - distributed.worker - INFO - Starting Worker plugin PreImport-df9394a8-1ab9-4855-a125-4c16c86d4eed
2023-10-28 05:38:25,988 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-81e03643-4f50-421a-915f-9b8f4385340c
2023-10-28 05:38:25,988 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0d002402-394c-4c84-bf0e-23de9d045939
2023-10-28 05:38:25,992 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35385
2023-10-28 05:38:25,993 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35385
2023-10-28 05:38:25,994 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37707
2023-10-28 05:38:25,994 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:25,994 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:25,994 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:25,994 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:25,994 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6uim1urn
2023-10-28 05:38:25,995 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93c1a8c7-7190-4676-9716-7964139be4bd
2023-10-28 05:38:26,003 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45825
2023-10-28 05:38:26,004 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45825
2023-10-28 05:38:26,004 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37813
2023-10-28 05:38:26,004 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,004 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,004 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,005 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,005 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hk4br8ds
2023-10-28 05:38:26,005 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65c7bf87-98ff-43dd-8d9f-ef3e7bda82a8
2023-10-28 05:38:26,140 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,176 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-12b04259-d23b-4a51-bc49-87bb33b5a601
2023-10-28 05:38:26,176 - distributed.worker - INFO - Starting Worker plugin PreImport-03654aea-6adb-4e4a-bfe8-a5ee20ec622c
2023-10-28 05:38:26,176 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,178 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b5a30ab3-85b0-4d9b-94ac-d90ebf9d1002
2023-10-28 05:38:26,178 - distributed.worker - INFO - Starting Worker plugin PreImport-488d1796-eb52-412c-9acd-6d9fd5a7e670
2023-10-28 05:38:26,178 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,180 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40797', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,182 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40797
2023-10-28 05:38:26,182 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53404
2023-10-28 05:38:26,183 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,188 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,188 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,339 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45825', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,339 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45825
2023-10-28 05:38:26,339 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53416
2023-10-28 05:38:26,340 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35385', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,340 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35385
2023-10-28 05:38:26,340 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53422
2023-10-28 05:38:26,341 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,341 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,341 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,341 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37051
2023-10-28 05:38:26,342 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37051
2023-10-28 05:38:26,342 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37429
2023-10-28 05:38:26,342 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,342 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,342 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,342 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,342 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,342 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,342 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pofbd6on
2023-10-28 05:38:26,343 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6526e123-6c18-43b1-94d2-3b17519ffbee
2023-10-28 05:38:26,345 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,346 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,347 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45479
2023-10-28 05:38:26,348 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45479
2023-10-28 05:38:26,348 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44473
2023-10-28 05:38:26,348 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,348 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,348 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,349 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,349 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8k7mq__z
2023-10-28 05:38:26,349 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd68f342-ae1e-4380-ba80-0e8ca5ab8533
2023-10-28 05:38:26,354 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33513
2023-10-28 05:38:26,354 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33513
2023-10-28 05:38:26,355 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33145
2023-10-28 05:38:26,355 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,355 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,355 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,355 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,355 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rytne5qi
2023-10-28 05:38:26,355 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d7782608-52a4-418b-a198-27e30ef2f533
2023-10-28 05:38:26,360 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36975
2023-10-28 05:38:26,361 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36975
2023-10-28 05:38:26,361 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41011
2023-10-28 05:38:26,361 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,361 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,361 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,361 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,361 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jhbudy4x
2023-10-28 05:38:26,362 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b3501fd6-f95c-409a-8023-30c8c1162c42
2023-10-28 05:38:26,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43499
2023-10-28 05:38:26,367 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43499
2023-10-28 05:38:26,367 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33665
2023-10-28 05:38:26,367 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,368 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,368 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:26,368 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:26,368 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rlny7i95
2023-10-28 05:38:26,368 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a019ee63-bde3-4615-bad5-9f1e27590828
2023-10-28 05:38:26,511 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3422b64-75a3-405c-8f31-fcdc7f74a885
2023-10-28 05:38:26,511 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3256f4a0-8ec8-45fe-abb3-2a0603a3e131
2023-10-28 05:38:26,511 - distributed.worker - INFO - Starting Worker plugin PreImport-62d22ee6-f43e-4a18-8a1b-4279f44c767e
2023-10-28 05:38:26,511 - distributed.worker - INFO - Starting Worker plugin PreImport-9dde42f7-fcd5-4bed-8974-f33a237321c9
2023-10-28 05:38:26,511 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,512 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,517 - distributed.worker - INFO - Starting Worker plugin PreImport-04be1c92-d9f2-4a87-b7e4-82884256d29b
2023-10-28 05:38:26,517 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3a69b7e6-c579-4935-b02c-6a9f1bc138d2
2023-10-28 05:38:26,517 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1fff1364-08cf-487e-8ef1-928b8a731269
2023-10-28 05:38:26,517 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,519 - distributed.worker - INFO - Starting Worker plugin PreImport-7bfdb1e1-74cb-4155-9888-37d727e5910d
2023-10-28 05:38:26,520 - distributed.worker - INFO - Starting Worker plugin PreImport-90af24a6-2ae3-41f3-ae92-afe86c1a5fa9
2023-10-28 05:38:26,520 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,520 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6906791b-1712-42d2-b942-c7eb30770c27
2023-10-28 05:38:26,522 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,535 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45479', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,536 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45479
2023-10-28 05:38:26,536 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53426
2023-10-28 05:38:26,537 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,538 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,538 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,541 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36975', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,542 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,542 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36975
2023-10-28 05:38:26,542 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53432
2023-10-28 05:38:26,543 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,544 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,544 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,546 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37051', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,547 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37051
2023-10-28 05:38:26,547 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53430
2023-10-28 05:38:26,548 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,549 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,549 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,552 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43499', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,553 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43499
2023-10-28 05:38:26,553 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53442
2023-10-28 05:38:26,554 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,555 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,555 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,558 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,558 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33513', status: init, memory: 0, processing: 0>
2023-10-28 05:38:26,559 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33513
2023-10-28 05:38:26,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53440
2023-10-28 05:38:26,560 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:26,561 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:26,561 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:26,562 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:26,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,572 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,573 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,573 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,573 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,573 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,573 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,574 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:26,578 - distributed.scheduler - INFO - Remove client Client-332701b0-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:26,578 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53396; closing.
2023-10-28 05:38:26,578 - distributed.scheduler - INFO - Remove client Client-332701b0-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:26,579 - distributed.scheduler - INFO - Close client connection: Client-332701b0-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:26,580 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46773'. Reason: nanny-close
2023-10-28 05:38:26,580 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41003'. Reason: nanny-close
2023-10-28 05:38:26,581 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45305'. Reason: nanny-close
2023-10-28 05:38:26,581 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39063'. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45825. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38847'. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35385. Reason: nanny-close
2023-10-28 05:38:26,583 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35235'. Reason: nanny-close
2023-10-28 05:38:26,583 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36375'. Reason: nanny-close
2023-10-28 05:38:26,583 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40797. Reason: nanny-close
2023-10-28 05:38:26,584 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53416; closing.
2023-10-28 05:38:26,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,584 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45825', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5844924')
2023-10-28 05:38:26,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,583 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33051'. Reason: nanny-close
2023-10-28 05:38:26,585 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,585 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,586 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53422; closing.
2023-10-28 05:38:26,586 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,586 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53404; closing.
2023-10-28 05:38:26,587 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35385', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.586987')
2023-10-28 05:38:26,587 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,587 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40797', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5874166')
2023-10-28 05:38:26,588 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,589 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,589 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37051. Reason: nanny-close
2023-10-28 05:38:26,589 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,590 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33513. Reason: nanny-close
2023-10-28 05:38:26,590 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45479. Reason: nanny-close
2023-10-28 05:38:26,592 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53426; closing.
2023-10-28 05:38:26,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,592 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45479', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5928414')
2023-10-28 05:38:26,593 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53430; closing.
2023-10-28 05:38:26,593 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,593 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37051', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5934718')
2023-10-28 05:38:26,593 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53440; closing.
2023-10-28 05:38:26,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,594 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,594 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33513', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5943074')
2023-10-28 05:38:26,594 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:26,594 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,594 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36975. Reason: nanny-close
2023-10-28 05:38:26,595 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43499. Reason: nanny-close
2023-10-28 05:38:26,595 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,597 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53432; closing.
2023-10-28 05:38:26,597 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,597 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.597275')
2023-10-28 05:38:26,598 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:26,598 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53442; closing.
2023-10-28 05:38:26,598 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43499', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471506.5984')
2023-10-28 05:38:26,598 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:26,598 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:38:26,600 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:28,148 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:38:28,148 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:38:28,149 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:38:28,150 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:38:28,151 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-28 05:38:30,328 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:30,332 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44459 instead
  warnings.warn(
2023-10-28 05:38:30,336 - distributed.scheduler - INFO - State start
2023-10-28 05:38:30,359 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:30,360 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:38:30,361 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44459/status
2023-10-28 05:38:30,361 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:30,482 - distributed.scheduler - INFO - Receive client connection: Client-38d3cb3b-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:30,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49936
2023-10-28 05:38:30,573 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46385'
2023-10-28 05:38:30,586 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32923'
2023-10-28 05:38:30,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36217'
2023-10-28 05:38:30,602 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36061'
2023-10-28 05:38:30,613 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40325'
2023-10-28 05:38:30,622 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41115'
2023-10-28 05:38:30,631 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38509'
2023-10-28 05:38:30,640 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38771'
2023-10-28 05:38:32,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,470 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,470 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,471 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,471 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,517 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:32,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:32,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:32,532 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:35,450 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34537
2023-10-28 05:38:35,451 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34537
2023-10-28 05:38:35,451 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45523
2023-10-28 05:38:35,451 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,451 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,451 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,451 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,452 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_cfitoon
2023-10-28 05:38:35,452 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b2eecf4-e7a8-4655-bf40-0f1964fcdb10
2023-10-28 05:38:35,465 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44359
2023-10-28 05:38:35,466 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44359
2023-10-28 05:38:35,466 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38483
2023-10-28 05:38:35,466 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,466 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,466 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,467 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,467 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-be9onx20
2023-10-28 05:38:35,467 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1fc238c1-58a6-470c-88f4-192f966dd6e9
2023-10-28 05:38:35,467 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42743
2023-10-28 05:38:35,467 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42743
2023-10-28 05:38:35,467 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41639
2023-10-28 05:38:35,468 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,468 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,468 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,468 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,468 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nmkkallc
2023-10-28 05:38:35,468 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ffa9f9e2-70d5-4493-a1de-7a25263cd265
2023-10-28 05:38:35,500 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42487
2023-10-28 05:38:35,502 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42487
2023-10-28 05:38:35,502 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41607
2023-10-28 05:38:35,502 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,502 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,502 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,502 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,502 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m9p1sdco
2023-10-28 05:38:35,503 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d82d2102-f3ac-44d8-b8c1-83f508f43bad
2023-10-28 05:38:35,506 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36687
2023-10-28 05:38:35,506 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36687
2023-10-28 05:38:35,506 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34445
2023-10-28 05:38:35,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,507 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,507 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,507 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,507 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o3aevdoj
2023-10-28 05:38:35,507 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d38d84a5-e1b2-43dc-ba79-419d827a9b67
2023-10-28 05:38:35,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36651
2023-10-28 05:38:35,508 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36651
2023-10-28 05:38:35,508 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36503
2023-10-28 05:38:35,508 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,508 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,508 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,509 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,509 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4_v8vrkn
2023-10-28 05:38:35,509 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1cd3111-5089-47d5-ab24-26a72cb1fb51
2023-10-28 05:38:35,510 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42313
2023-10-28 05:38:35,511 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42313
2023-10-28 05:38:35,511 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38247
2023-10-28 05:38:35,511 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,511 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,511 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,511 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,511 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rzwqes9f
2023-10-28 05:38:35,512 - distributed.worker - INFO - Starting Worker plugin PreImport-393b4434-ca8a-41f1-b47e-6188fd6c3ee2
2023-10-28 05:38:35,512 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c71d8d84-7457-43d7-be32-8e41546a5a49
2023-10-28 05:38:35,512 - distributed.worker - INFO - Starting Worker plugin RMMSetup-02cc2cd8-3947-4916-801f-429c69f24587
2023-10-28 05:38:35,517 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32771
2023-10-28 05:38:35,517 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32771
2023-10-28 05:38:35,517 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33343
2023-10-28 05:38:35,517 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,518 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,518 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:35,518 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:35,518 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-15423i81
2023-10-28 05:38:35,518 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5a6bfcdf-5139-492b-957d-fd90c01855a3
2023-10-28 05:38:35,544 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-79c9fed2-292c-4d6f-b81e-8d79ccfc6a1f
2023-10-28 05:38:35,544 - distributed.worker - INFO - Starting Worker plugin PreImport-64f1e757-151f-4eeb-9a13-93af46938cce
2023-10-28 05:38:35,544 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,545 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-910ca48d-f49d-4969-a5cb-cda8cf6a246a
2023-10-28 05:38:35,547 - distributed.worker - INFO - Starting Worker plugin PreImport-ef44f59e-061e-470d-b20b-eec46441dc8f
2023-10-28 05:38:35,548 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2a21a2e0-47bd-4151-a1f4-b77bdd745521
2023-10-28 05:38:35,550 - distributed.worker - INFO - Starting Worker plugin PreImport-49a9fd50-8878-4152-8701-0814e7be729b
2023-10-28 05:38:35,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e128d018-5e6f-4779-9ec0-defbb7459cbd
2023-10-28 05:38:35,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a8e5dab4-1fe5-483f-81da-01469329b64e
2023-10-28 05:38:35,551 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,551 - distributed.worker - INFO - Starting Worker plugin PreImport-79e380f0-3de3-4946-be65-ab64bcc51fe3
2023-10-28 05:38:35,551 - distributed.worker - INFO - Starting Worker plugin PreImport-354dbc1f-5ae9-4941-b810-9a6472811d89
2023-10-28 05:38:35,551 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,551 - distributed.worker - INFO - Starting Worker plugin PreImport-57615ce2-5f8a-468d-9cb3-8aad43b00e5e
2023-10-28 05:38:35,551 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b47842f-f8a2-4e69-b4cb-56f932e1f5c1
2023-10-28 05:38:35,551 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,552 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,553 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1e351daa-c40e-47c3-be20-56178e9c3957
2023-10-28 05:38:35,553 - distributed.worker - INFO - Starting Worker plugin PreImport-7f96602c-250f-434b-871b-6e481c944d6f
2023-10-28 05:38:35,553 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,555 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,568 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42743', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,570 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42743
2023-10-28 05:38:35,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50008
2023-10-28 05:38:35,571 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,575 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44359', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,575 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,576 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,576 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44359
2023-10-28 05:38:35,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50024
2023-10-28 05:38:35,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,577 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32771', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,577 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32771
2023-10-28 05:38:35,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50064
2023-10-28 05:38:35,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,580 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,581 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,582 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,582 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,582 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42487', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,583 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42487
2023-10-28 05:38:35,583 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50040
2023-10-28 05:38:35,583 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,585 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,585 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,585 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34537', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,585 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34537
2023-10-28 05:38:35,585 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50022
2023-10-28 05:38:35,586 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36687', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,587 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36687
2023-10-28 05:38:35,587 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50046
2023-10-28 05:38:35,588 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36651', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,588 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36651
2023-10-28 05:38:35,588 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50050
2023-10-28 05:38:35,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,589 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42313', status: init, memory: 0, processing: 0>
2023-10-28 05:38:35,589 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,589 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,589 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42313
2023-10-28 05:38:35,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50072
2023-10-28 05:38:35,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,590 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,591 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,591 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:35,592 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,592 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,593 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:35,593 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:35,595 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,597 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,599 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:35,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:35,650 - distributed.scheduler - INFO - Remove client Client-38d3cb3b-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:35,650 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49936; closing.
2023-10-28 05:38:35,650 - distributed.scheduler - INFO - Remove client Client-38d3cb3b-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:35,651 - distributed.scheduler - INFO - Close client connection: Client-38d3cb3b-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:35,652 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46385'. Reason: nanny-close
2023-10-28 05:38:35,652 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,653 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32923'. Reason: nanny-close
2023-10-28 05:38:35,653 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,654 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36651. Reason: nanny-close
2023-10-28 05:38:35,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36217'. Reason: nanny-close
2023-10-28 05:38:35,654 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,654 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36687. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36061'. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42487. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40325'. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,655 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44359. Reason: nanny-close
2023-10-28 05:38:35,656 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41115'. Reason: nanny-close
2023-10-28 05:38:35,656 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,656 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,656 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50050; closing.
2023-10-28 05:38:35,656 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34537. Reason: nanny-close
2023-10-28 05:38:35,656 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38509'. Reason: nanny-close
2023-10-28 05:38:35,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36651', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6569526')
2023-10-28 05:38:35,657 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,657 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,657 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,657 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42313. Reason: nanny-close
2023-10-28 05:38:35,657 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38771'. Reason: nanny-close
2023-10-28 05:38:35,657 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,657 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:35,657 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42743. Reason: nanny-close
2023-10-28 05:38:35,658 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32771. Reason: nanny-close
2023-10-28 05:38:35,658 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,658 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,658 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50024; closing.
2023-10-28 05:38:35,659 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50040; closing.
2023-10-28 05:38:35,659 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,659 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,659 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50046; closing.
2023-10-28 05:38:35,659 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,660 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44359', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6600032')
2023-10-28 05:38:35,660 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,660 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,660 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42487', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.660397')
2023-10-28 05:38:35,660 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:35,660 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36687', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6607678')
2023-10-28 05:38:35,661 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,661 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,661 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50022; closing.
2023-10-28 05:38:35,661 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,662 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:35,662 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34537', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6623762')
2023-10-28 05:38:35,662 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50072; closing.
2023-10-28 05:38:35,663 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50008; closing.
2023-10-28 05:38:35,663 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50064; closing.
2023-10-28 05:38:35,663 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42313', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6635911')
2023-10-28 05:38:35,664 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42743', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6640167')
2023-10-28 05:38:35,664 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471515.6644838')
2023-10-28 05:38:35,664 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:38:37,119 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:38:37,119 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:38:37,120 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:38:37,121 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:38:37,122 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-28 05:38:39,140 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:39,145 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46421 instead
  warnings.warn(
2023-10-28 05:38:39,149 - distributed.scheduler - INFO - State start
2023-10-28 05:38:39,169 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:39,170 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:38:39,171 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46421/status
2023-10-28 05:38:39,171 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:39,496 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38617'
2023-10-28 05:38:39,509 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40227'
2023-10-28 05:38:39,522 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41745'
2023-10-28 05:38:39,534 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33719'
2023-10-28 05:38:39,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44379'
2023-10-28 05:38:39,544 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44197'
2023-10-28 05:38:39,553 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35877'
2023-10-28 05:38:39,561 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36043'
2023-10-28 05:38:39,741 - distributed.scheduler - INFO - Receive client connection: Client-3e2775b8-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:39,753 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50198
2023-10-28 05:38:41,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,284 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,537 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,556 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:41,574 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:41,578 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,579 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,579 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:41,579 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:42,786 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45307
2023-10-28 05:38:42,787 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45307
2023-10-28 05:38:42,787 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39209
2023-10-28 05:38:42,787 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:42,787 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:42,787 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:42,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:42,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4p7dvw65
2023-10-28 05:38:42,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-040c10ad-1184-4d7a-b59e-b0fd1e052eca
2023-10-28 05:38:43,467 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23b50e85-91a2-459a-91d7-06b26201da81
2023-10-28 05:38:43,469 - distributed.worker - INFO - Starting Worker plugin PreImport-256d8340-cfed-41d6-a4d3-676851ef8ea3
2023-10-28 05:38:43,469 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:43,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45307', status: init, memory: 0, processing: 0>
2023-10-28 05:38:43,504 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45307
2023-10-28 05:38:43,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49178
2023-10-28 05:38:43,505 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:43,506 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:43,506 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:43,513 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,013 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37697
2023-10-28 05:38:44,013 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37697
2023-10-28 05:38:44,013 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34173
2023-10-28 05:38:44,014 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,014 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,014 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,014 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,014 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9urpfu8u
2023-10-28 05:38:44,014 - distributed.worker - INFO - Starting Worker plugin PreImport-f60f901c-3f78-48fc-bf95-dd9bcdf32dfc
2023-10-28 05:38:44,015 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b6d87d62-a66f-419a-a5cf-f37f2af41da7
2023-10-28 05:38:44,015 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c9130368-5888-44ce-9c0d-39ac2ce76ca4
2023-10-28 05:38:44,166 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36001
2023-10-28 05:38:44,167 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36001
2023-10-28 05:38:44,167 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35715
2023-10-28 05:38:44,167 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,167 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,167 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,167 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,168 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tijcgio_
2023-10-28 05:38:44,168 - distributed.worker - INFO - Starting Worker plugin RMMSetup-25fa7342-caeb-4c67-a7b7-d5cddc76acf1
2023-10-28 05:38:44,169 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39151
2023-10-28 05:38:44,170 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39151
2023-10-28 05:38:44,170 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44711
2023-10-28 05:38:44,170 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,170 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,170 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,170 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,170 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6zxero1b
2023-10-28 05:38:44,171 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7ef04942-5092-4f60-95b7-76918f90f04f
2023-10-28 05:38:44,174 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35893
2023-10-28 05:38:44,175 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35893
2023-10-28 05:38:44,175 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36491
2023-10-28 05:38:44,175 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,175 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,175 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,176 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,176 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k8p_eifk
2023-10-28 05:38:44,176 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9829f7b6-ebc3-4c91-b9c2-878d00efe398
2023-10-28 05:38:44,177 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46165
2023-10-28 05:38:44,178 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46165
2023-10-28 05:38:44,178 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37289
2023-10-28 05:38:44,178 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,178 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,178 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,179 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,179 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j8i8hbio
2023-10-28 05:38:44,179 - distributed.worker - INFO - Starting Worker plugin PreImport-c24a5402-82f7-4bdc-9ef5-219d2c581b74
2023-10-28 05:38:44,179 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9267d64-7301-40ab-9e57-efd574245cc2
2023-10-28 05:38:44,179 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a50d7d26-173b-4f7b-9a33-8bb2482df8ad
2023-10-28 05:38:44,214 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33633
2023-10-28 05:38:44,215 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33633
2023-10-28 05:38:44,215 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35729
2023-10-28 05:38:44,215 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,215 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,215 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,215 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,215 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s3u7k8ym
2023-10-28 05:38:44,216 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c98ebba-3fb3-457d-8ecf-81c0ab14d15f
2023-10-28 05:38:44,216 - distributed.worker - INFO - Starting Worker plugin PreImport-cf774633-baa2-461b-9dc1-9547c03a6263
2023-10-28 05:38:44,216 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e2ee5d7-08d5-46ae-b0be-6f8f466d5b50
2023-10-28 05:38:44,216 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37313
2023-10-28 05:38:44,217 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37313
2023-10-28 05:38:44,217 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32833
2023-10-28 05:38:44,217 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,217 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,217 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:44,218 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:44,218 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wl5rhs2j
2023-10-28 05:38:44,218 - distributed.worker - INFO - Starting Worker plugin PreImport-acb65c66-1f52-406c-8178-f60c405d2fb9
2023-10-28 05:38:44,218 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9a0b914-9dd8-4227-a53b-74d9759c76a9
2023-10-28 05:38:44,219 - distributed.worker - INFO - Starting Worker plugin RMMSetup-32ed7d40-65bf-4650-94d9-bc80c62b4990
2023-10-28 05:38:44,250 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,278 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37697', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,278 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37697
2023-10-28 05:38:44,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49192
2023-10-28 05:38:44,280 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,280 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,280 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,285 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,407 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f4aa93df-ae44-40e5-a0c4-890802ba9a9d
2023-10-28 05:38:44,408 - distributed.worker - INFO - Starting Worker plugin PreImport-2e0a4d53-6fc5-4069-b72e-df0caa2674a0
2023-10-28 05:38:44,408 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,411 - distributed.worker - INFO - Starting Worker plugin PreImport-838a5415-4fa6-4030-a6d8-96bb5a8d9095
2023-10-28 05:38:44,411 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3b5aa04b-c7ec-49fd-8e34-36e029cd6f9b
2023-10-28 05:38:44,412 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,412 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6bd8fa9b-068f-4e3f-97cb-2b0b64f01057
2023-10-28 05:38:44,413 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,414 - distributed.worker - INFO - Starting Worker plugin PreImport-b5be79f9-aa8a-45d7-8acb-d11132b6d045
2023-10-28 05:38:44,414 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,422 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,423 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,439 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35893', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,439 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35893
2023-10-28 05:38:44,440 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49216
2023-10-28 05:38:44,441 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,441 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,441 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,443 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46165', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,444 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46165
2023-10-28 05:38:44,444 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49226
2023-10-28 05:38:44,445 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,445 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36001', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,446 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36001
2023-10-28 05:38:44,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49200
2023-10-28 05:38:44,446 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,446 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,447 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,448 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,451 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39151', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,451 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39151
2023-10-28 05:38:44,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49228
2023-10-28 05:38:44,453 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,454 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,454 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,456 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33633', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33633
2023-10-28 05:38:44,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49230
2023-10-28 05:38:44,459 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,460 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,460 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,461 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,465 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37313', status: init, memory: 0, processing: 0>
2023-10-28 05:38:44,466 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37313
2023-10-28 05:38:44,466 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49232
2023-10-28 05:38:44,467 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,468 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:44,469 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:44,469 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:44,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,488 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,489 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,489 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:38:44,499 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,499 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,499 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,500 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,500 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,500 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,500 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,500 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:44,506 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:44,508 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:44,511 - distributed.scheduler - INFO - Remove client Client-3e2775b8-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:44,511 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50198; closing.
2023-10-28 05:38:44,512 - distributed.scheduler - INFO - Remove client Client-3e2775b8-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:44,513 - distributed.scheduler - INFO - Close client connection: Client-3e2775b8-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:44,513 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38617'. Reason: nanny-close
2023-10-28 05:38:44,514 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,515 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40227'. Reason: nanny-close
2023-10-28 05:38:44,515 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41745'. Reason: nanny-close
2023-10-28 05:38:44,515 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,515 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33633. Reason: nanny-close
2023-10-28 05:38:44,516 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33719'. Reason: nanny-close
2023-10-28 05:38:44,516 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,516 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37697. Reason: nanny-close
2023-10-28 05:38:44,516 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44379'. Reason: nanny-close
2023-10-28 05:38:44,516 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,517 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46165. Reason: nanny-close
2023-10-28 05:38:44,517 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44197'. Reason: nanny-close
2023-10-28 05:38:44,517 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,517 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39151. Reason: nanny-close
2023-10-28 05:38:44,517 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35877'. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,518 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49192; closing.
2023-10-28 05:38:44,518 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,518 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36001. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49230; closing.
2023-10-28 05:38:44,518 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36043'. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37697', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5186057')
2023-10-28 05:38:44,518 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35893. Reason: nanny-close
2023-10-28 05:38:44,518 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,519 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33633', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5191424')
2023-10-28 05:38:44,519 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45307. Reason: nanny-close
2023-10-28 05:38:44,519 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,520 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,520 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,520 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,520 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,520 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49226; closing.
2023-10-28 05:38:44,521 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,521 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46165', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5216105')
2023-10-28 05:38:44,521 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,521 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,522 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49228; closing.
2023-10-28 05:38:44,522 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,522 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49200; closing.
2023-10-28 05:38:44,522 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49216; closing.
2023-10-28 05:38:44,522 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39151', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5227988')
2023-10-28 05:38:44,522 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,523 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36001', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5230863')
2023-10-28 05:38:44,523 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:44,523 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35893', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5233705')
2023-10-28 05:38:44,524 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49178; closing.
2023-10-28 05:38:44,524 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5243766')
2023-10-28 05:38:44,524 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:44,525 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37313. Reason: nanny-close
2023-10-28 05:38:44,527 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49232; closing.
2023-10-28 05:38:44,527 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:44,527 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37313', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471524.5278842')
2023-10-28 05:38:44,528 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:38:44,529 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:46,081 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:38:46,081 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:38:46,082 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:38:46,083 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:38:46,083 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-28 05:38:48,176 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:48,180 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44593 instead
  warnings.warn(
2023-10-28 05:38:48,185 - distributed.scheduler - INFO - State start
2023-10-28 05:38:48,206 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:48,207 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:38:48,207 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44593/status
2023-10-28 05:38:48,208 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:48,248 - distributed.scheduler - INFO - Receive client connection: Client-4379a239-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:48,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49350
2023-10-28 05:38:48,486 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44505'
2023-10-28 05:38:48,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39753'
2023-10-28 05:38:48,506 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41005'
2023-10-28 05:38:48,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34103'
2023-10-28 05:38:48,526 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43621'
2023-10-28 05:38:48,534 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36753'
2023-10-28 05:38:48,542 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36693'
2023-10-28 05:38:48,550 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42691'
2023-10-28 05:38:50,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,256 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,369 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,386 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:50,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:38:50,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:38:50,641 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:38:52,597 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41869
2023-10-28 05:38:52,597 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41869
2023-10-28 05:38:52,597 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33575
2023-10-28 05:38:52,597 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:52,597 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:52,597 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:52,598 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:52,598 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6g948mxu
2023-10-28 05:38:52,598 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-074ccdb9-7738-46f2-8f94-2fdececf47cd
2023-10-28 05:38:52,598 - distributed.worker - INFO - Starting Worker plugin PreImport-cdbe3ae2-176e-49e2-9feb-856ff384a5fb
2023-10-28 05:38:52,598 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ddcca241-46d6-443f-b339-8b76558b3e42
2023-10-28 05:38:53,442 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:53,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41869', status: init, memory: 0, processing: 0>
2023-10-28 05:38:53,485 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41869
2023-10-28 05:38:53,485 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55106
2023-10-28 05:38:53,486 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:53,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:53,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:53,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:54,067 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42789
2023-10-28 05:38:54,069 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42789
2023-10-28 05:38:54,069 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42431
2023-10-28 05:38:54,069 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,069 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,069 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,069 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,069 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qtqla6ua
2023-10-28 05:38:54,070 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb2e2c10-50fd-4b14-b3f8-aa0ab3c85a06
2023-10-28 05:38:54,273 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43637
2023-10-28 05:38:54,274 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43637
2023-10-28 05:38:54,274 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45991
2023-10-28 05:38:54,274 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,274 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,274 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,274 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,274 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s26ts96n
2023-10-28 05:38:54,275 - distributed.worker - INFO - Starting Worker plugin PreImport-560dba8b-7846-4c5a-b23c-77dead4250eb
2023-10-28 05:38:54,275 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd93b38c-8cdf-4dbc-8f63-93e523b19881
2023-10-28 05:38:54,275 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ba8d5616-3f58-4436-bdc5-3507a1fab68b
2023-10-28 05:38:54,277 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34241
2023-10-28 05:38:54,278 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34241
2023-10-28 05:38:54,278 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43389
2023-10-28 05:38:54,278 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,278 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,278 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,278 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,278 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-11wuc3vg
2023-10-28 05:38:54,279 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1851f2d-eeb0-41f6-a670-644e5ec5068b
2023-10-28 05:38:54,283 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35645
2023-10-28 05:38:54,284 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35645
2023-10-28 05:38:54,284 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45955
2023-10-28 05:38:54,284 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,284 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,284 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,285 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,285 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z0lqkbu_
2023-10-28 05:38:54,285 - distributed.worker - INFO - Starting Worker plugin PreImport-d6fe67d2-ae2e-4a62-aa30-9972d316a3f6
2023-10-28 05:38:54,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-729b6440-974b-4667-9d02-8ba313d2c97e
2023-10-28 05:38:54,286 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee08d32c-e999-469a-82a1-50307fab3928
2023-10-28 05:38:54,293 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43329
2023-10-28 05:38:54,293 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43329
2023-10-28 05:38:54,294 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38059
2023-10-28 05:38:54,294 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,294 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,294 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,294 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,294 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vd_dynqs
2023-10-28 05:38:54,294 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45439
2023-10-28 05:38:54,294 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45439
2023-10-28 05:38:54,294 - distributed.worker - INFO - Starting Worker plugin PreImport-9bbb8b7a-92d0-4d19-b0ff-1b2e01979ef1
2023-10-28 05:38:54,294 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41069
2023-10-28 05:38:54,295 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fc8a5dd8-07eb-40c5-861f-388bb16323b2
2023-10-28 05:38:54,295 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,295 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,295 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d0ca336e-4179-4dd6-9394-26ec61bfbebe
2023-10-28 05:38:54,295 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,295 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,295 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nlex6n5e
2023-10-28 05:38:54,295 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0ff5b250-5a62-4c9f-b7ea-00c6a9b54895
2023-10-28 05:38:54,301 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44199
2023-10-28 05:38:54,302 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44199
2023-10-28 05:38:54,302 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41953
2023-10-28 05:38:54,302 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:38:54,302 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:54,302 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:38:54,302 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:38:54,302 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uiqbiv1b
2023-10-28 05:38:54,303 - distributed.worker - INFO - Starting Worker plugin RMMSetup-029dbf11-b963-4323-84ed-3b701265201c
2023-10-28 05:38:55,135 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-06252222-cf6a-4609-86b2-19a437985536
2023-10-28 05:38:55,137 - distributed.worker - INFO - Starting Worker plugin PreImport-6213f152-62c7-46cc-8954-c4d4da1e0a1b
2023-10-28 05:38:55,137 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,171 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42789', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,172 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42789
2023-10-28 05:38:55,172 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55134
2023-10-28 05:38:55,173 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,179 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,179 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,181 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,290 - distributed.worker - INFO - Starting Worker plugin PreImport-d9852413-890b-4818-b086-777683c755b8
2023-10-28 05:38:55,290 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-75c0bdc7-d4c4-4301-a6ea-bfba00211610
2023-10-28 05:38:55,291 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,309 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,316 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27131293-ac83-41a7-bded-41ee151c97e5
2023-10-28 05:38:55,317 - distributed.worker - INFO - Starting Worker plugin PreImport-141b649a-7bc4-468d-b3b7-f924bd94a0ca
2023-10-28 05:38:55,317 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,318 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,319 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43637', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,320 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43637
2023-10-28 05:38:55,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55142
2023-10-28 05:38:55,321 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,321 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45439', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,322 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45439
2023-10-28 05:38:55,322 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55152
2023-10-28 05:38:55,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,325 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,325 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,326 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,326 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,326 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,328 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,341 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-543227eb-89f0-4548-a91e-cb1af3b067d1
2023-10-28 05:38:55,342 - distributed.worker - INFO - Starting Worker plugin PreImport-2f117aec-b5bb-4ad6-97b4-7802dd4a44a6
2023-10-28 05:38:55,343 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,343 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35645', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,344 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35645
2023-10-28 05:38:55,344 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55160
2023-10-28 05:38:55,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,348 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43329', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,349 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43329
2023-10-28 05:38:55,349 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55174
2023-10-28 05:38:55,350 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,353 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,353 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,354 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,355 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,355 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,369 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34241', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,369 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34241
2023-10-28 05:38:55,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55186
2023-10-28 05:38:55,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,378 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,378 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,381 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,382 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44199', status: init, memory: 0, processing: 0>
2023-10-28 05:38:55,383 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44199
2023-10-28 05:38:55,383 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55188
2023-10-28 05:38:55,384 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:38:55,391 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:38:55,391 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:38:55,393 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,429 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,430 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,443 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,443 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,443 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,444 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,444 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,444 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,444 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,444 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:38:55,452 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,454 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:38:55,457 - distributed.scheduler - INFO - Remove client Client-4379a239-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:55,458 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49350; closing.
2023-10-28 05:38:55,458 - distributed.scheduler - INFO - Remove client Client-4379a239-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:55,458 - distributed.scheduler - INFO - Close client connection: Client-4379a239-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:38:55,461 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44505'. Reason: nanny-close
2023-10-28 05:38:55,461 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,463 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39753'. Reason: nanny-close
2023-10-28 05:38:55,463 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,463 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41869. Reason: nanny-close
2023-10-28 05:38:55,463 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41005'. Reason: nanny-close
2023-10-28 05:38:55,464 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,464 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35645. Reason: nanny-close
2023-10-28 05:38:55,464 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34103'. Reason: nanny-close
2023-10-28 05:38:55,464 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,465 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43637. Reason: nanny-close
2023-10-28 05:38:55,465 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43621'. Reason: nanny-close
2023-10-28 05:38:55,465 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,465 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,465 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43329. Reason: nanny-close
2023-10-28 05:38:55,465 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55106; closing.
2023-10-28 05:38:55,465 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36753'. Reason: nanny-close
2023-10-28 05:38:55,466 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,466 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41869', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4662066')
2023-10-28 05:38:55,466 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36693'. Reason: nanny-close
2023-10-28 05:38:55,466 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,466 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34241. Reason: nanny-close
2023-10-28 05:38:55,466 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,467 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,467 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44199. Reason: nanny-close
2023-10-28 05:38:55,467 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,467 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42691'. Reason: nanny-close
2023-10-28 05:38:55,467 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:38:55,467 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,467 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45439. Reason: nanny-close
2023-10-28 05:38:55,468 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55142; closing.
2023-10-28 05:38:55,468 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55160; closing.
2023-10-28 05:38:55,468 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,468 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,469 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43637', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.469248')
2023-10-28 05:38:55,469 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,469 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42789. Reason: nanny-close
2023-10-28 05:38:55,469 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35645', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4696617')
2023-10-28 05:38:55,470 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55174; closing.
2023-10-28 05:38:55,470 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,470 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,470 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43329', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4704893')
2023-10-28 05:38:55,471 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,471 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55186; closing.
2023-10-28 05:38:55,471 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55188; closing.
2023-10-28 05:38:55,471 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,472 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4721153')
2023-10-28 05:38:55,472 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,472 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44199', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4725144')
2023-10-28 05:38:55,472 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:38:55,472 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55152; closing.
2023-10-28 05:38:55,473 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45439', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4734044')
2023-10-28 05:38:55,473 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55134; closing.
2023-10-28 05:38:55,473 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:55,474 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42789', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471535.4740949')
2023-10-28 05:38:55,474 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:38:55,475 - distributed.nanny - INFO - Worker closed
2023-10-28 05:38:57,179 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:38:57,179 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:38:57,180 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:38:57,181 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:38:57,181 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-28 05:38:59,325 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:59,329 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-28 05:38:59,332 - distributed.scheduler - INFO - State start
2023-10-28 05:38:59,483 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:38:59,484 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:38:59,485 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-28 05:38:59,485 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:38:59,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38505'
2023-10-28 05:38:59,680 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36517'
2023-10-28 05:38:59,693 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36271'
2023-10-28 05:38:59,704 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43231'
2023-10-28 05:38:59,706 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41687'
2023-10-28 05:38:59,714 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45633'
2023-10-28 05:38:59,722 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41769'
2023-10-28 05:38:59,733 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38257'
2023-10-28 05:39:00,680 - distributed.scheduler - INFO - Receive client connection: Client-4a231851-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:00,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39538
2023-10-28 05:39:01,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,497 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,535 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,535 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,536 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,539 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,594 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,595 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:01,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:01,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:01,600 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:04,146 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34943
2023-10-28 05:39:04,148 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34943
2023-10-28 05:39:04,148 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42669
2023-10-28 05:39:04,148 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,148 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,149 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,149 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,149 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-89sd95z_
2023-10-28 05:39:04,150 - distributed.worker - INFO - Starting Worker plugin RMMSetup-272baa8d-e7d0-4cd0-80f4-c0837f0c5f21
2023-10-28 05:39:04,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44657
2023-10-28 05:39:04,307 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44657
2023-10-28 05:39:04,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43153
2023-10-28 05:39:04,307 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,307 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,307 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,307 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u8h7g5zl
2023-10-28 05:39:04,307 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34909
2023-10-28 05:39:04,308 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34909
2023-10-28 05:39:04,308 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44099
2023-10-28 05:39:04,308 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,308 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,308 - distributed.worker - INFO - Starting Worker plugin PreImport-9c5962e9-3a55-4045-8e43-04b4bcff4dcb
2023-10-28 05:39:04,308 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,308 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-034d213f-5b8a-48ce-8413-94600b6f820f
2023-10-28 05:39:04,308 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,308 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b41ayada
2023-10-28 05:39:04,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f43ffbe6-5f24-4e5b-9300-d78b59a2ad78
2023-10-28 05:39:04,309 - distributed.worker - INFO - Starting Worker plugin PreImport-59758501-461a-4163-b7e4-49b4de9d3e25
2023-10-28 05:39:04,309 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9fbdd9e1-4dc3-448a-9ace-b15993664a9f
2023-10-28 05:39:04,309 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4691fc1c-fea1-4df1-a581-7c962475f644
2023-10-28 05:39:04,319 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73a1a5f7-3b88-4b32-bc10-513f32cd26bb
2023-10-28 05:39:04,320 - distributed.worker - INFO - Starting Worker plugin PreImport-a78a0ba2-81b5-497b-b22d-cf563aeb1b8e
2023-10-28 05:39:04,320 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,323 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41871
2023-10-28 05:39:04,323 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41871
2023-10-28 05:39:04,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40133
2023-10-28 05:39:04,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,324 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,324 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-40bcz__0
2023-10-28 05:39:04,324 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7c6b5e9-2c96-4988-8497-caff163f609d
2023-10-28 05:39:04,326 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44963
2023-10-28 05:39:04,327 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44963
2023-10-28 05:39:04,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33615
2023-10-28 05:39:04,327 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,327 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,327 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,328 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,328 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l60faqf5
2023-10-28 05:39:04,329 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8aab7584-5e25-4bf7-a92c-1818639a18a0
2023-10-28 05:39:04,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34943', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,484 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34943
2023-10-28 05:39:04,484 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39546
2023-10-28 05:39:04,485 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,486 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,486 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34299
2023-10-28 05:39:04,490 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34299
2023-10-28 05:39:04,490 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39695
2023-10-28 05:39:04,490 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,490 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nim3uvv7
2023-10-28 05:39:04,491 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42ed4aaa-3161-44fb-9ce0-7fe8f1268bba
2023-10-28 05:39:04,491 - distributed.worker - INFO - Starting Worker plugin PreImport-74e41d1c-6bf8-41d2-9c53-d57a72ebf3e3
2023-10-28 05:39:04,491 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c524466-c848-40f0-883c-bd4c9fdf7a30
2023-10-28 05:39:04,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,499 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33823
2023-10-28 05:39:04,499 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33823
2023-10-28 05:39:04,500 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45359
2023-10-28 05:39:04,500 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,500 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,500 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,500 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,500 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mhy9uqif
2023-10-28 05:39:04,500 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cba173b-b19f-4cb6-9cc2-0eb2c69a9958
2023-10-28 05:39:04,499 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41799
2023-10-28 05:39:04,501 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41799
2023-10-28 05:39:04,501 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34521
2023-10-28 05:39:04,501 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,501 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,501 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:04,501 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:04,501 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-06ht34bq
2023-10-28 05:39:04,502 - distributed.worker - INFO - Starting Worker plugin PreImport-12c6737f-346c-4484-9840-1c4fc34cfae6
2023-10-28 05:39:04,503 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-06c75e51-9f25-4e88-bd6a-fa6212162d9c
2023-10-28 05:39:04,503 - distributed.worker - INFO - Starting Worker plugin RMMSetup-76d961dd-cd1d-4233-8762-a2209c9babdf
2023-10-28 05:39:04,630 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,630 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,642 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,642 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0b631f33-f810-474d-a11c-778f28a66e0d
2023-10-28 05:39:04,643 - distributed.worker - INFO - Starting Worker plugin PreImport-96ed535d-6141-4406-a9f1-2f56f1646669
2023-10-28 05:39:04,644 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,654 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,661 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51cda76c-53f1-4afe-aba5-a5c14554b4dd
2023-10-28 05:39:04,661 - distributed.worker - INFO - Starting Worker plugin PreImport-73aaa421-bf9e-4ea0-b069-5751b6e18ca8
2023-10-28 05:39:04,661 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-98adf7f1-e32d-4c28-9572-d348a4601366
2023-10-28 05:39:04,662 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,662 - distributed.worker - INFO - Starting Worker plugin PreImport-cb9a925b-8d59-4971-8e91-690cc55ded2f
2023-10-28 05:39:04,662 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41799', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,662 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,663 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41799
2023-10-28 05:39:04,663 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39560
2023-10-28 05:39:04,664 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34299', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,664 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34299
2023-10-28 05:39:04,664 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39572
2023-10-28 05:39:04,664 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,666 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,670 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,671 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,672 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,672 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,673 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,674 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,675 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34909', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,676 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34909
2023-10-28 05:39:04,676 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39580
2023-10-28 05:39:04,677 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,679 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44963', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,680 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44963
2023-10-28 05:39:04,680 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39582
2023-10-28 05:39:04,681 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,681 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,681 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,686 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44657', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,686 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44657
2023-10-28 05:39:04,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39598
2023-10-28 05:39:04,688 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,688 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,688 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,690 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41871', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41871
2023-10-28 05:39:04,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39612
2023-10-28 05:39:04,691 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,691 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,692 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,693 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,693 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33823', status: init, memory: 0, processing: 0>
2023-10-28 05:39:04,694 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33823
2023-10-28 05:39:04,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39618
2023-10-28 05:39:04,695 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:04,696 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,696 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,697 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,701 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:04,701 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:04,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:04,768 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,768 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,768 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,768 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,769 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,769 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,769 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,769 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:04,774 - distributed.scheduler - INFO - Remove client Client-4a231851-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:04,774 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39538; closing.
2023-10-28 05:39:04,774 - distributed.scheduler - INFO - Remove client Client-4a231851-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:04,775 - distributed.scheduler - INFO - Close client connection: Client-4a231851-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:04,776 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38505'. Reason: nanny-close
2023-10-28 05:39:04,776 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,778 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36517'. Reason: nanny-close
2023-10-28 05:39:04,778 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,778 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34299. Reason: nanny-close
2023-10-28 05:39:04,778 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36271'. Reason: nanny-close
2023-10-28 05:39:04,779 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,779 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41799. Reason: nanny-close
2023-10-28 05:39:04,779 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43231'. Reason: nanny-close
2023-10-28 05:39:04,779 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,779 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44657. Reason: nanny-close
2023-10-28 05:39:04,780 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41687'. Reason: nanny-close
2023-10-28 05:39:04,780 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,780 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34909. Reason: nanny-close
2023-10-28 05:39:04,780 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45633'. Reason: nanny-close
2023-10-28 05:39:04,781 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,781 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44963. Reason: nanny-close
2023-10-28 05:39:04,781 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39572; closing.
2023-10-28 05:39:04,781 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,781 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41769'. Reason: nanny-close
2023-10-28 05:39:04,781 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,781 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,781 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.781565')
2023-10-28 05:39:04,781 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,781 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33823. Reason: nanny-close
2023-10-28 05:39:04,782 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38257'. Reason: nanny-close
2023-10-28 05:39:04,782 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:04,782 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41871. Reason: nanny-close
2023-10-28 05:39:04,782 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39560; closing.
2023-10-28 05:39:04,782 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,783 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34943. Reason: nanny-close
2023-10-28 05:39:04,783 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,783 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,783 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,783 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,783 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41799', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7837467')
2023-10-28 05:39:04,784 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39580; closing.
2023-10-28 05:39:04,784 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,784 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39598; closing.
2023-10-28 05:39:04,784 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,784 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,785 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,785 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34909', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7851796')
2023-10-28 05:39:04,785 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44657', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7856064')
2023-10-28 05:39:04,785 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:04,786 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39582; closing.
2023-10-28 05:39:04,786 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,786 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,786 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44963', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7865913')
2023-10-28 05:39:04,786 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39618; closing.
2023-10-28 05:39:04,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33823', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7876601')
2023-10-28 05:39:04,787 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:04,788 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39612; closing.
2023-10-28 05:39:04,788 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39546; closing.
2023-10-28 05:39:04,788 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41871', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7887042')
2023-10-28 05:39:04,789 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34943', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471544.7890987')
2023-10-28 05:39:04,789 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:06,294 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:06,294 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:06,294 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:06,296 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:06,296 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-28 05:39:08,393 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:08,398 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-28 05:39:08,401 - distributed.scheduler - INFO - State start
2023-10-28 05:39:08,423 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:08,425 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:08,425 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-28 05:39:08,426 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:08,554 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33689'
2023-10-28 05:39:09,521 - distributed.scheduler - INFO - Receive client connection: Client-4f8429de-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:09,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39718
2023-10-28 05:39:10,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:10,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:10,833 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:11,660 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35279
2023-10-28 05:39:11,660 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35279
2023-10-28 05:39:11,660 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-28 05:39:11,660 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:11,660 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:11,661 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:11,661 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-28 05:39:11,661 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xga44nbq
2023-10-28 05:39:11,661 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ffbbc0ab-dbcb-400c-8778-6386b4ed107e
2023-10-28 05:39:11,661 - distributed.worker - INFO - Starting Worker plugin PreImport-5eb548dd-89c7-4d42-bfdb-b036ffd68a6e
2023-10-28 05:39:11,661 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-72bb959c-5c5f-42d6-aac0-bad83b8ce743
2023-10-28 05:39:11,662 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:11,687 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35279', status: init, memory: 0, processing: 0>
2023-10-28 05:39:11,688 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35279
2023-10-28 05:39:11,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60194
2023-10-28 05:39:11,689 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:11,690 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:11,690 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:11,692 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:11,780 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:11,783 - distributed.scheduler - INFO - Remove client Client-4f8429de-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:11,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39718; closing.
2023-10-28 05:39:11,783 - distributed.scheduler - INFO - Remove client Client-4f8429de-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:11,784 - distributed.scheduler - INFO - Close client connection: Client-4f8429de-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:11,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33689'. Reason: nanny-close
2023-10-28 05:39:11,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:11,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35279. Reason: nanny-close
2023-10-28 05:39:11,788 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60194; closing.
2023-10-28 05:39:11,788 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:11,788 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35279', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471551.7885597')
2023-10-28 05:39:11,788 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:11,790 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:12,851 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:12,851 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:12,852 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:12,852 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:12,853 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-28 05:39:16,912 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:16,916 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41887 instead
  warnings.warn(
2023-10-28 05:39:16,920 - distributed.scheduler - INFO - State start
2023-10-28 05:39:17,095 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:17,096 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:17,096 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41887/status
2023-10-28 05:39:17,096 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:17,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42029'
2023-10-28 05:39:17,254 - distributed.scheduler - INFO - Receive client connection: Client-54a50e39-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:17,265 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60298
2023-10-28 05:39:18,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:18,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:19,391 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:20,440 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35421
2023-10-28 05:39:20,441 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35421
2023-10-28 05:39:20,441 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42671
2023-10-28 05:39:20,441 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:20,441 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:20,441 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:20,441 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-28 05:39:20,441 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ojde3nz5
2023-10-28 05:39:20,441 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b7567398-08f3-4692-8221-48a26ef7fc26
2023-10-28 05:39:20,442 - distributed.worker - INFO - Starting Worker plugin PreImport-89581453-907f-44a3-9f5f-3a78d35a22f9
2023-10-28 05:39:20,443 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-657e2d93-46c4-4410-a9a5-c8360e5ed800
2023-10-28 05:39:20,448 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:20,479 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35421', status: init, memory: 0, processing: 0>
2023-10-28 05:39:20,480 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35421
2023-10-28 05:39:20,480 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53580
2023-10-28 05:39:20,481 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:20,482 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:20,483 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:20,485 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:20,501 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:20,503 - distributed.scheduler - INFO - Remove client Client-54a50e39-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:20,504 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60298; closing.
2023-10-28 05:39:20,504 - distributed.scheduler - INFO - Remove client Client-54a50e39-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:20,504 - distributed.scheduler - INFO - Close client connection: Client-54a50e39-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:20,505 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42029'. Reason: nanny-close
2023-10-28 05:39:20,514 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:20,515 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35421. Reason: nanny-close
2023-10-28 05:39:20,517 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53580; closing.
2023-10-28 05:39:20,517 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:20,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35421', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471560.5182421')
2023-10-28 05:39:20,518 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:20,519 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:21,722 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:21,722 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:21,722 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:21,723 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:21,724 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-28 05:39:23,770 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:23,775 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46721 instead
  warnings.warn(
2023-10-28 05:39:23,779 - distributed.scheduler - INFO - State start
2023-10-28 05:39:23,801 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:23,802 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:23,802 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46721/status
2023-10-28 05:39:23,803 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:27,728 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:53588'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:53588>: Stream is closed
2023-10-28 05:39:28,059 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:28,059 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:28,059 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:28,060 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:28,060 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-28 05:39:30,366 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:30,371 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38255 instead
  warnings.warn(
2023-10-28 05:39:30,376 - distributed.scheduler - INFO - State start
2023-10-28 05:39:30,762 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:30,763 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-28 05:39:30,764 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38255/status
2023-10-28 05:39:30,764 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:30,856 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45599'
2023-10-28 05:39:31,434 - distributed.scheduler - INFO - Receive client connection: Client-5c7a6877-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:31,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44186
2023-10-28 05:39:32,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:32,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:32,478 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:33,328 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45627
2023-10-28 05:39:33,328 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45627
2023-10-28 05:39:33,328 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38581
2023-10-28 05:39:33,328 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-28 05:39:33,328 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:33,329 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:33,329 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-28 05:39:33,329 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-8fpksu1g
2023-10-28 05:39:33,329 - distributed.worker - INFO - Starting Worker plugin PreImport-22c3c1c8-abf7-4249-a76f-87db17eee1ac
2023-10-28 05:39:33,330 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd4eceab-e3ee-4492-b2ab-7a33996c9012
2023-10-28 05:39:33,330 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8e77218a-b377-484b-b09c-531c64d6c281
2023-10-28 05:39:33,330 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:33,359 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45627', status: init, memory: 0, processing: 0>
2023-10-28 05:39:33,360 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45627
2023-10-28 05:39:33,360 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44204
2023-10-28 05:39:33,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:33,362 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-28 05:39:33,362 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:33,364 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-28 05:39:33,387 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:33,390 - distributed.scheduler - INFO - Remove client Client-5c7a6877-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:33,390 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44186; closing.
2023-10-28 05:39:33,390 - distributed.scheduler - INFO - Remove client Client-5c7a6877-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:33,391 - distributed.scheduler - INFO - Close client connection: Client-5c7a6877-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:33,392 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45599'. Reason: nanny-close
2023-10-28 05:39:33,392 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:33,394 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45627. Reason: nanny-close
2023-10-28 05:39:33,396 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44204; closing.
2023-10-28 05:39:33,396 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-28 05:39:33,396 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45627', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471573.396319')
2023-10-28 05:39:33,396 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:33,397 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:34,558 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:34,559 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:34,559 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:34,560 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-28 05:39:34,561 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-28 05:39:36,747 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:36,752 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42221 instead
  warnings.warn(
2023-10-28 05:39:36,755 - distributed.scheduler - INFO - State start
2023-10-28 05:39:36,778 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:36,779 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:36,780 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42221/status
2023-10-28 05:39:36,781 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:36,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45099'
2023-10-28 05:39:36,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41583'
2023-10-28 05:39:36,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44235'
2023-10-28 05:39:36,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41767'
2023-10-28 05:39:36,928 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44581'
2023-10-28 05:39:36,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46065'
2023-10-28 05:39:36,947 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34971'
2023-10-28 05:39:36,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42397'
2023-10-28 05:39:37,603 - distributed.scheduler - INFO - Receive client connection: Client-6066db0f-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:37,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44902
2023-10-28 05:39:38,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,767 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,768 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,833 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:38,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:38,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:38,901 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:41,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39827
2023-10-28 05:39:41,740 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39827
2023-10-28 05:39:41,740 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41357
2023-10-28 05:39:41,740 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,740 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,740 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,740 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,740 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-51dt_p14
2023-10-28 05:39:41,740 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a90945e4-76f0-4a3a-a36a-3c9d30a73589
2023-10-28 05:39:41,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45241
2023-10-28 05:39:41,753 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45241
2023-10-28 05:39:41,753 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46289
2023-10-28 05:39:41,753 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,753 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,753 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,753 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r13t3zhm
2023-10-28 05:39:41,754 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2eb6c09-24fb-4658-9845-490e0a1df907
2023-10-28 05:39:41,766 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39583
2023-10-28 05:39:41,767 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39583
2023-10-28 05:39:41,767 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34931
2023-10-28 05:39:41,767 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,767 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,767 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,768 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,768 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-alhm6cfj
2023-10-28 05:39:41,768 - distributed.worker - INFO - Starting Worker plugin PreImport-a326c969-e7d3-414f-93ab-9cb56f83ca74
2023-10-28 05:39:41,768 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d116dae0-2386-43c5-8df7-9aa695d50a3f
2023-10-28 05:39:41,768 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd48cd64-acdc-40fa-be85-55598a5300d9
2023-10-28 05:39:41,771 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36167
2023-10-28 05:39:41,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36167
2023-10-28 05:39:41,772 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34213
2023-10-28 05:39:41,772 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,772 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,773 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,773 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-naw7i74r
2023-10-28 05:39:41,773 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b3f1faf-5f95-4594-964f-cd1e868bdb4c
2023-10-28 05:39:41,773 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40219
2023-10-28 05:39:41,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40219
2023-10-28 05:39:41,774 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46561
2023-10-28 05:39:41,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,774 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,774 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,775 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,775 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rj42s_oq
2023-10-28 05:39:41,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6f0cc36a-ff64-4c7e-8833-0a034340dab1
2023-10-28 05:39:41,776 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46041
2023-10-28 05:39:41,777 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46041
2023-10-28 05:39:41,777 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34005
2023-10-28 05:39:41,777 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,777 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,777 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,777 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,778 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hpfzij6j
2023-10-28 05:39:41,778 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3b8fd84d-7a24-44bf-b3fe-baa1b9e626c5
2023-10-28 05:39:41,778 - distributed.worker - INFO - Starting Worker plugin PreImport-3dece434-75c3-4fc0-a259-98cf9a160805
2023-10-28 05:39:41,779 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f596d402-90a5-4dc5-96ae-0cb4a1b8adda
2023-10-28 05:39:41,778 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44709
2023-10-28 05:39:41,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44709
2023-10-28 05:39:41,779 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41293
2023-10-28 05:39:41,779 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,779 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,779 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,779 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,779 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kyt0yyw2
2023-10-28 05:39:41,780 - distributed.worker - INFO - Starting Worker plugin PreImport-b80b2c8d-0f50-4c69-8b94-f470bbf4149e
2023-10-28 05:39:41,780 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae9b9dc6-3fd8-402a-8a4b-df0d0ff3f015
2023-10-28 05:39:41,780 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1dde1ba0-aeb8-4a85-a789-27919b671088
2023-10-28 05:39:41,780 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41477
2023-10-28 05:39:41,781 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41477
2023-10-28 05:39:41,781 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36711
2023-10-28 05:39:41,781 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,781 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,781 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:41,782 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-28 05:39:41,782 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jmy4xk_k
2023-10-28 05:39:41,782 - distributed.worker - INFO - Starting Worker plugin PreImport-02945f54-69cf-4026-a833-c9b379c3fb58
2023-10-28 05:39:41,782 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b6ecc8a-2ccc-4dfa-9335-59e3fe168ec8
2023-10-28 05:39:41,783 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be7d2d1a-a31a-4e80-9a76-cf1260106f8a
2023-10-28 05:39:41,932 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-87602e7f-feee-4cd0-be6e-99e4db4d45e9
2023-10-28 05:39:41,932 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38a8a83a-2236-4d5b-9240-bdd83fe8f656
2023-10-28 05:39:41,933 - distributed.worker - INFO - Starting Worker plugin PreImport-e9ec6de6-2469-48cc-9ef8-d3be28336d61
2023-10-28 05:39:41,933 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,933 - distributed.worker - INFO - Starting Worker plugin PreImport-c649c486-d771-4a0f-8f47-b20e11ed202e
2023-10-28 05:39:41,934 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,943 - distributed.worker - INFO - Starting Worker plugin PreImport-245ff96f-a6d5-41af-ad83-4601f5191f63
2023-10-28 05:39:41,943 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,943 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,943 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a40f4bac-07c3-4b39-995d-67e015d203c9
2023-10-28 05:39:41,943 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,948 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,948 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b53fb4eb-706c-4baf-b17f-a64ce3b455c6
2023-10-28 05:39:41,949 - distributed.worker - INFO - Starting Worker plugin PreImport-9b2f8005-8d7f-4117-a5fa-0f51e42032cc
2023-10-28 05:39:41,950 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,961 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39827', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,963 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39827
2023-10-28 05:39:41,963 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53766
2023-10-28 05:39:41,964 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,968 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,968 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,968 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,969 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,970 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40219', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,971 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40219
2023-10-28 05:39:41,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53808
2023-10-28 05:39:41,972 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,972 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39583', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,973 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39583
2023-10-28 05:39:41,973 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53788
2023-10-28 05:39:41,973 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44709', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,974 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,974 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44709
2023-10-28 05:39:41,974 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53796
2023-10-28 05:39:41,975 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,975 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,975 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,976 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45241', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,977 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45241
2023-10-28 05:39:41,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53782
2023-10-28 05:39:41,977 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,977 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,978 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,979 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,979 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,983 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41477', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,984 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41477
2023-10-28 05:39:41,984 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53810
2023-10-28 05:39:41,985 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,985 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,985 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,986 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,986 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,987 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,988 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36167', status: init, memory: 0, processing: 0>
2023-10-28 05:39:41,988 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36167
2023-10-28 05:39:41,988 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53814
2023-10-28 05:39:41,990 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:41,993 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:41,994 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:41,994 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:41,996 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:42,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46041', status: init, memory: 0, processing: 0>
2023-10-28 05:39:42,008 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46041
2023-10-28 05:39:42,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53816
2023-10-28 05:39:42,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:42,016 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:42,016 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:42,018 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:42,027 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,027 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,027 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,027 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,027 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,028 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,028 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,028 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,042 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,043 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,043 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:42,047 - distributed.scheduler - INFO - Remove client Client-6066db0f-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:42,047 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44902; closing.
2023-10-28 05:39:42,048 - distributed.scheduler - INFO - Remove client Client-6066db0f-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:42,048 - distributed.scheduler - INFO - Close client connection: Client-6066db0f-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:42,049 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45099'. Reason: nanny-close
2023-10-28 05:39:42,050 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,050 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41583'. Reason: nanny-close
2023-10-28 05:39:42,051 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,051 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46041. Reason: nanny-close
2023-10-28 05:39:42,051 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44235'. Reason: nanny-close
2023-10-28 05:39:42,051 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,052 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41477. Reason: nanny-close
2023-10-28 05:39:42,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41767'. Reason: nanny-close
2023-10-28 05:39:42,052 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,052 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39583. Reason: nanny-close
2023-10-28 05:39:42,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44581'. Reason: nanny-close
2023-10-28 05:39:42,053 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,053 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44709. Reason: nanny-close
2023-10-28 05:39:42,053 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,053 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53816; closing.
2023-10-28 05:39:42,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46065'. Reason: nanny-close
2023-10-28 05:39:42,053 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,053 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46041', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0537899')
2023-10-28 05:39:42,053 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45241. Reason: nanny-close
2023-10-28 05:39:42,054 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34971'. Reason: nanny-close
2023-10-28 05:39:42,054 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,054 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,054 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,054 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36167. Reason: nanny-close
2023-10-28 05:39:42,054 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42397'. Reason: nanny-close
2023-10-28 05:39:42,054 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53788; closing.
2023-10-28 05:39:42,054 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:42,055 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40219. Reason: nanny-close
2023-10-28 05:39:42,055 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,055 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,055 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39827. Reason: nanny-close
2023-10-28 05:39:42,055 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39583', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0558047')
2023-10-28 05:39:42,055 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,056 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,056 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,056 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53810; closing.
2023-10-28 05:39:42,056 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,057 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,057 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,057 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:42,058 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,056 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:53788>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:53788>: Stream is closed
2023-10-28 05:39:42,058 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53796; closing.
2023-10-28 05:39:42,058 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41477', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0589204')
2023-10-28 05:39:42,059 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,059 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,059 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44709', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0595484')
2023-10-28 05:39:42,059 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:42,060 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53782; closing.
2023-10-28 05:39:42,060 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0605848')
2023-10-28 05:39:42,061 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53814; closing.
2023-10-28 05:39:42,061 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53808; closing.
2023-10-28 05:39:42,061 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36167', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0616279')
2023-10-28 05:39:42,062 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40219', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0620823')
2023-10-28 05:39:42,062 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53766; closing.
2023-10-28 05:39:42,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471582.0630987')
2023-10-28 05:39:42,063 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:42,063 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:53766>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-28 05:39:43,718 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:43,718 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:43,719 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:43,720 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:43,721 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-28 05:39:46,083 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:46,088 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44035 instead
  warnings.warn(
2023-10-28 05:39:46,091 - distributed.scheduler - INFO - State start
2023-10-28 05:39:46,485 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:46,486 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:46,487 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44035/status
2023-10-28 05:39:46,487 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:46,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43581'
2023-10-28 05:39:47,413 - distributed.scheduler - INFO - Receive client connection: Client-65e78dd7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:47,425 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53952
2023-10-28 05:39:48,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:48,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:48,578 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:49,500 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38923
2023-10-28 05:39:49,501 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38923
2023-10-28 05:39:49,501 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41917
2023-10-28 05:39:49,501 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:49,501 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:49,501 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:49,501 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-28 05:39:49,501 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ukj43scb
2023-10-28 05:39:49,501 - distributed.worker - INFO - Starting Worker plugin RMMSetup-044403b5-35cf-4d48-b9a7-f5f886acc795
2023-10-28 05:39:49,604 - distributed.worker - INFO - Starting Worker plugin PreImport-76c705bf-2215-4455-9963-0833793ff4f1
2023-10-28 05:39:49,604 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b981ded2-fd7e-4074-94c4-282c4d90128b
2023-10-28 05:39:49,605 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:49,631 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38923', status: init, memory: 0, processing: 0>
2023-10-28 05:39:49,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38923
2023-10-28 05:39:49,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53964
2023-10-28 05:39:49,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:49,639 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:49,639 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:49,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:49,674 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:39:49,679 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:49,680 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:49,683 - distributed.scheduler - INFO - Remove client Client-65e78dd7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:49,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53952; closing.
2023-10-28 05:39:49,683 - distributed.scheduler - INFO - Remove client Client-65e78dd7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:49,684 - distributed.scheduler - INFO - Close client connection: Client-65e78dd7-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:49,685 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43581'. Reason: nanny-close
2023-10-28 05:39:49,685 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:49,686 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38923. Reason: nanny-close
2023-10-28 05:39:49,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:49,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53964; closing.
2023-10-28 05:39:49,689 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38923', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471589.6889675')
2023-10-28 05:39:49,689 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:49,690 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:50,751 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:50,752 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:50,752 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:50,753 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:50,754 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-28 05:39:53,010 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:53,014 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45377 instead
  warnings.warn(
2023-10-28 05:39:53,019 - distributed.scheduler - INFO - State start
2023-10-28 05:39:53,086 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-28 05:39:53,087 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-28 05:39:53,087 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45377/status
2023-10-28 05:39:53,087 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-28 05:39:53,469 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37933'
2023-10-28 05:39:54,278 - distributed.scheduler - INFO - Receive client connection: Client-6a0d72d9-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:54,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40386
2023-10-28 05:39:55,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-28 05:39:55,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-28 05:39:55,277 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-28 05:39:56,341 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45621
2023-10-28 05:39:56,342 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45621
2023-10-28 05:39:56,342 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43553
2023-10-28 05:39:56,342 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-28 05:39:56,342 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:56,342 - distributed.worker - INFO -               Threads:                          1
2023-10-28 05:39:56,342 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-28 05:39:56,342 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4v0mw826
2023-10-28 05:39:56,342 - distributed.worker - INFO - Starting Worker plugin PreImport-9faef0e4-b6b0-4c9a-a352-83f2c0cfa3b3
2023-10-28 05:39:56,343 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8219447a-2669-4180-8020-d94d965cf840
2023-10-28 05:39:56,343 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23f431ed-7b44-4396-962a-dca63091ac57
2023-10-28 05:39:56,448 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:56,474 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45621', status: init, memory: 0, processing: 0>
2023-10-28 05:39:56,476 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45621
2023-10-28 05:39:56,476 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40406
2023-10-28 05:39:56,477 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-28 05:39:56,478 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-28 05:39:56,478 - distributed.worker - INFO - -------------------------------------------------
2023-10-28 05:39:56,484 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-28 05:39:56,560 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-28 05:39:56,565 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-28 05:39:56,568 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:56,569 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-28 05:39:56,572 - distributed.scheduler - INFO - Remove client Client-6a0d72d9-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:56,572 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40386; closing.
2023-10-28 05:39:56,572 - distributed.scheduler - INFO - Remove client Client-6a0d72d9-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:56,573 - distributed.scheduler - INFO - Close client connection: Client-6a0d72d9-7554-11ee-b377-d8c49764f6bb
2023-10-28 05:39:56,574 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37933'. Reason: nanny-close
2023-10-28 05:39:56,574 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-28 05:39:56,576 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45621. Reason: nanny-close
2023-10-28 05:39:56,577 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40406; closing.
2023-10-28 05:39:56,578 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-28 05:39:56,578 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45621', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698471596.5782125')
2023-10-28 05:39:56,578 - distributed.scheduler - INFO - Lost all workers
2023-10-28 05:39:56,579 - distributed.nanny - INFO - Worker closed
2023-10-28 05:39:57,841 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-28 05:39:57,842 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-28 05:39:57,842 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-28 05:39:57,843 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-28 05:39:57,844 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42191 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36143 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35937 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42269 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40345 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40279 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40857 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43763 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40365 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46225 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44705 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44561 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45077 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40691 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39401 instead
  warnings.warn(
2023-10-28 05:43:39,669 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-28 05:43:39,675 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:45671', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34533 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34077 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42433 instead
  warnings.warn(
[1698471867.919496] [dgx13:70590:0]            sock.c:470  UCX  ERROR bind(fd=134 addr=0.0.0.0:44439) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39703 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38411 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33573 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37157 instead
  warnings.warn(
[1698471946.132630] [dgx13:72224:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:33466) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38657 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40955 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35595 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43115 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41441 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35347 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37535 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45119 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41841 instead
  warnings.warn(
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-4363' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45221 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46225 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37563 instead
  warnings.warn(
[1698472200.184346] [dgx13:76612:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:37563) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43255 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37059 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40045 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46827 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40641 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34349 instead
  warnings.warn(
2023-10-28 05:51:20,889 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:20,892 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:20,894 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:20,900 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:35651'.
2023-10-28 05:51:20,901 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:35651'. Shutting down.
2023-10-28 05:51:20,905 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:42315'.
2023-10-28 05:51:20,904 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f2835b892b0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:20,906 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:42315'. Shutting down.
2023-10-28 05:51:20,909 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fd60c20d2b0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:20,913 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:38343'.
2023-10-28 05:51:20,914 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:38343'. Shutting down.
2023-10-28 05:51:20,918 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f766cd3a280>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-28 05:51:21,473 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-28 05:51:21,483 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:43045'.
2023-10-28 05:51:21,484 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:43045'. Shutting down.
2023-10-28 05:51:21,486 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fcf40ac3280>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-28 05:51:22,908 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-28 05:51:22,913 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-28 05:51:23,489 - distributed.nanny - ERROR - Worker process died unexpectedly
