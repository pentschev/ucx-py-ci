============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-07 06:25:01,734 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:01,739 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:01,743 - distributed.scheduler - INFO - State start
2024-01-07 06:25:01,921 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:01,922 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-07 06:25:01,923 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:01,923 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:01,958 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34901'
2024-01-07 06:25:01,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39505'
2024-01-07 06:25:01,980 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46461'
2024-01-07 06:25:01,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34589'
2024-01-07 06:25:03,109 - distributed.scheduler - INFO - Receive client connection: Client-7bda813b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:03,123 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59352
2024-01-07 06:25:03,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:03,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:03,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:03,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:03,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:03,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:03,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:03,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:03,880 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36893
2024-01-07 06:25:03,880 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45567
2024-01-07 06:25:03,880 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36893
2024-01-07 06:25:03,880 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46651
2024-01-07 06:25:03,880 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45567
2024-01-07 06:25:03,880 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:25:03,880 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38209
2024-01-07 06:25:03,880 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,880 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:25:03,880 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:25:03,880 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,880 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:25:03,880 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:25:03,880 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-4ngotsik
2024-01-07 06:25:03,880 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:25:03,880 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-77x2369l
2024-01-07 06:25:03,880 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-712ee8b7-5ab3-4eb3-bdfb-d31b45b01e10
2024-01-07 06:25:03,880 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd29cd7f-37e9-43f3-a211-e1be8509f404
2024-01-07 06:25:03,881 - distributed.worker - INFO - Starting Worker plugin PreImport-fbb2630b-fe51-4879-b9e8-71e7cfa657c0
2024-01-07 06:25:03,881 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2b72997e-44cf-48d6-aaa0-931c4eaf5f92
2024-01-07 06:25:03,881 - distributed.worker - INFO - Starting Worker plugin PreImport-cb312005-d8f7-4a2d-bc4a-e60dba257e07
2024-01-07 06:25:03,881 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,881 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d50f732d-4625-479c-9c4e-e4f6acb9fe09
2024-01-07 06:25:03,881 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,882 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:03,883 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43941
2024-01-07 06:25:03,883 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43941
2024-01-07 06:25:03,883 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34903
2024-01-07 06:25:03,883 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:25:03,883 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,884 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:25:03,884 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:25:03,884 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zff1pxb0
2024-01-07 06:25:03,884 - distributed.worker - INFO - Starting Worker plugin PreImport-4d25e136-8673-4d89-ad3e-5c27b742253f
2024-01-07 06:25:03,884 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-93744eb4-f36b-4080-af7d-786145c7c17e
2024-01-07 06:25:03,884 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cdc34871-095a-41b6-8ffa-d98f5372c71c
2024-01-07 06:25:03,884 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:03,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:03,932 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:03,933 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35295
2024-01-07 06:25:03,933 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35295
2024-01-07 06:25:03,933 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38427
2024-01-07 06:25:03,933 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:25:03,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:03,933 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:25:03,933 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:25:03,933 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-lfb4qqlw
2024-01-07 06:25:03,933 - distributed.worker - INFO - Starting Worker plugin PreImport-cf5797e4-a809-4ac1-b3dc-e781b378a80b
2024-01-07 06:25:03,934 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c3b53d9-e7d9-438f-8886-55be5541d7e4
2024-01-07 06:25:03,934 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5755ef98-c936-4e67-95c2-ae9ade70d9d3
2024-01-07 06:25:03,934 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:04,000 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36893', status: init, memory: 0, processing: 0>
2024-01-07 06:25:04,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36893
2024-01-07 06:25:04,002 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59390
2024-01-07 06:25:04,003 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45567', status: init, memory: 0, processing: 0>
2024-01-07 06:25:04,003 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:04,003 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45567
2024-01-07 06:25:04,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59384
2024-01-07 06:25:04,004 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:25:04,004 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:04,004 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:04,005 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:25:04,005 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:04,005 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:25:04,006 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:25:04,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43941', status: init, memory: 0, processing: 0>
2024-01-07 06:25:04,008 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43941
2024-01-07 06:25:04,008 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59400
2024-01-07 06:25:04,009 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:04,010 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:25:04,010 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:04,011 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:25:04,028 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35295', status: init, memory: 0, processing: 0>
2024-01-07 06:25:04,029 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35295
2024-01-07 06:25:04,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59408
2024-01-07 06:25:04,030 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:04,031 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:25:04,031 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:04,032 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:25:04,050 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:25:04,050 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:25:04,050 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:25:04,050 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:25:04,055 - distributed.scheduler - INFO - Remove client Client-7bda813b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:04,055 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59352; closing.
2024-01-07 06:25:04,056 - distributed.scheduler - INFO - Remove client Client-7bda813b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:04,056 - distributed.scheduler - INFO - Close client connection: Client-7bda813b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:04,057 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34901'. Reason: nanny-close
2024-01-07 06:25:04,058 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:04,058 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39505'. Reason: nanny-close
2024-01-07 06:25:04,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46461'. Reason: nanny-close
2024-01-07 06:25:04,059 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:04,059 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43941. Reason: nanny-close
2024-01-07 06:25:04,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34589'. Reason: nanny-close
2024-01-07 06:25:04,059 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:04,060 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45567. Reason: nanny-close
2024-01-07 06:25:04,060 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36893. Reason: nanny-close
2024-01-07 06:25:04,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:25:04,061 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59400; closing.
2024-01-07 06:25:04,061 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43941', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608704.061802')
2024-01-07 06:25:04,062 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:25:04,062 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:25:04,062 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:04,062 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59390; closing.
2024-01-07 06:25:04,063 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:04,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36893', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608704.0635056')
2024-01-07 06:25:04,063 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:04,063 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59384; closing.
2024-01-07 06:25:04,064 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:59390>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:59390>: Stream is closed
2024-01-07 06:25:04,065 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45567', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608704.0657818')
2024-01-07 06:25:04,071 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:04,072 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35295. Reason: nanny-close
2024-01-07 06:25:04,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:25:04,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59408; closing.
2024-01-07 06:25:04,074 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35295', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608704.0743325')
2024-01-07 06:25:04,074 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:04,075 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:04,823 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:04,823 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:04,824 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:04,825 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-07 06:25:04,825 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-07 06:25:07,027 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:07,032 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:07,036 - distributed.scheduler - INFO - State start
2024-01-07 06:25:07,059 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:07,060 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:07,061 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:07,061 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:07,292 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37531'
2024-01-07 06:25:07,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38563'
2024-01-07 06:25:07,328 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33591'
2024-01-07 06:25:07,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46337'
2024-01-07 06:25:07,341 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41201'
2024-01-07 06:25:07,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44973'
2024-01-07 06:25:07,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33787'
2024-01-07 06:25:07,367 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40975'
2024-01-07 06:25:07,894 - distributed.scheduler - INFO - Receive client connection: Client-7f0d6906-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:07,911 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44226
2024-01-07 06:25:09,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,259 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37875
2024-01-07 06:25:09,259 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37875
2024-01-07 06:25:09,259 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36805
2024-01-07 06:25:09,259 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,259 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,259 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,259 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,259 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-khlxy45q
2024-01-07 06:25:09,260 - distributed.worker - INFO - Starting Worker plugin PreImport-41487425-c8ea-41dc-ba45-2f77be3f3663
2024-01-07 06:25:09,260 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e90a433b-d6c2-423e-a1c2-984d242d0346
2024-01-07 06:25:09,260 - distributed.worker - INFO - Starting Worker plugin RMMSetup-88ef0e49-146c-46c2-80e7-ab290a640af2
2024-01-07 06:25:09,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,305 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,305 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45845
2024-01-07 06:25:09,306 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45845
2024-01-07 06:25:09,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35121
2024-01-07 06:25:09,306 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34973
2024-01-07 06:25:09,306 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35121
2024-01-07 06:25:09,306 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,306 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,306 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42485
2024-01-07 06:25:09,306 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,306 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,306 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,306 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tmo2vci5
2024-01-07 06:25:09,307 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,307 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ncyxndyg
2024-01-07 06:25:09,307 - distributed.worker - INFO - Starting Worker plugin PreImport-eb27dd83-46ea-4f3f-97aa-6ab7472d8be2
2024-01-07 06:25:09,307 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-099f2599-7897-406c-a4e3-a6a1e474455c
2024-01-07 06:25:09,307 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31f4e854-e449-4046-8d14-d24c0beef187
2024-01-07 06:25:09,307 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a182cb0f-4f7f-460e-b52e-8b9a5fc4d823
2024-01-07 06:25:09,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,320 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,321 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38535
2024-01-07 06:25:09,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38535
2024-01-07 06:25:09,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34571
2024-01-07 06:25:09,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,321 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,321 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,321 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,321 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wxz7bbrh
2024-01-07 06:25:09,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-76d8c78a-5590-4447-86d5-2dd64b715ec6
2024-01-07 06:25:09,323 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44759
2024-01-07 06:25:09,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44759
2024-01-07 06:25:09,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41535
2024-01-07 06:25:09,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,324 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,324 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sso2flaa
2024-01-07 06:25:09,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24ac2e54-1408-4919-8815-15ed579e96a5
2024-01-07 06:25:09,325 - distributed.worker - INFO - Starting Worker plugin PreImport-2c7989e5-287b-4994-9b1e-13279ad14a84
2024-01-07 06:25:09,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-799e9695-ff8d-4a33-b57b-5dc74c059452
2024-01-07 06:25:09,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,331 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,332 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39575
2024-01-07 06:25:09,332 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39575
2024-01-07 06:25:09,332 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39199
2024-01-07 06:25:09,332 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,332 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,332 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,332 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,332 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_tw9w9ac
2024-01-07 06:25:09,333 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ce5371c-e1b0-448e-a08a-db19e0813c43
2024-01-07 06:25:09,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:09,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:09,534 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,535 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39907
2024-01-07 06:25:09,535 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39907
2024-01-07 06:25:09,535 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39635
2024-01-07 06:25:09,535 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,535 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,535 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,535 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,535 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ln6rdgra
2024-01-07 06:25:09,536 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2704890d-6a94-4c0b-936f-158eba53f4cf
2024-01-07 06:25:09,537 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:09,538 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46059
2024-01-07 06:25:09,538 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46059
2024-01-07 06:25:09,538 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40081
2024-01-07 06:25:09,539 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:09,539 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:09,539 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:09,539 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:09,539 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-puz74auc
2024-01-07 06:25:09,539 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ea667cd-7306-48f6-949d-6be61f501b24
2024-01-07 06:25:11,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,111 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37875', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,112 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37875
2024-01-07 06:25:11,113 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47134
2024-01-07 06:25:11,113 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,114 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,114 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,290 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,325 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45845', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,326 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45845
2024-01-07 06:25:11,326 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47140
2024-01-07 06:25:11,328 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,329 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,329 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,331 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,332 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aec5e3d0-0cb0-4f93-b891-0b0da49a826b
2024-01-07 06:25:11,332 - distributed.worker - INFO - Starting Worker plugin PreImport-669e59e4-ba69-49a9-98d7-887065cab28a
2024-01-07 06:25:11,334 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,342 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f3ed2e1-b179-4046-821b-3ce97c431994
2024-01-07 06:25:11,343 - distributed.worker - INFO - Starting Worker plugin PreImport-c98b821d-e10a-495c-99d8-986bd36b9c2e
2024-01-07 06:25:11,345 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,369 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35121', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,370 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35121
2024-01-07 06:25:11,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47148
2024-01-07 06:25:11,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,373 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,373 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,376 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,378 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38535', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,379 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d89769f3-f8f3-4a45-8e8d-f4056bdd96bb
2024-01-07 06:25:11,379 - distributed.worker - INFO - Starting Worker plugin PreImport-bc63b886-fdac-4f1b-bbc9-47cfe2a2c8ac
2024-01-07 06:25:11,379 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38535
2024-01-07 06:25:11,379 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47162
2024-01-07 06:25:11,380 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,381 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,382 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,382 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e8eb833d-e550-4b06-a4ee-2ada552afa60
2024-01-07 06:25:11,384 - distributed.worker - INFO - Starting Worker plugin PreImport-ec85c6ab-d440-4721-9139-c56c253b1059
2024-01-07 06:25:11,384 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,384 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,389 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ec398ef-af11-4058-b7c8-bc3cff18cd8e
2024-01-07 06:25:11,390 - distributed.worker - INFO - Starting Worker plugin PreImport-445783cf-82d9-4619-a5a5-0f0b7442b03c
2024-01-07 06:25:11,391 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,405 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39575', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,404 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,405 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39575
2024-01-07 06:25:11,405 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47170
2024-01-07 06:25:11,406 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,407 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,407 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,408 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46059', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,409 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,409 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46059
2024-01-07 06:25:11,409 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47176
2024-01-07 06:25:11,410 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,411 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,411 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,412 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,421 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39907', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,421 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39907
2024-01-07 06:25:11,421 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47180
2024-01-07 06:25:11,423 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,424 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,432 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44759', status: init, memory: 0, processing: 0>
2024-01-07 06:25:11,433 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44759
2024-01-07 06:25:11,433 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47190
2024-01-07 06:25:11,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:11,435 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:11,435 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:11,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,486 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,487 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:11,491 - distributed.scheduler - INFO - Remove client Client-7f0d6906-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:11,491 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44226; closing.
2024-01-07 06:25:11,492 - distributed.scheduler - INFO - Remove client Client-7f0d6906-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:11,492 - distributed.scheduler - INFO - Close client connection: Client-7f0d6906-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:11,493 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37531'. Reason: nanny-close
2024-01-07 06:25:11,493 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,494 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38563'. Reason: nanny-close
2024-01-07 06:25:11,494 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,494 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33591'. Reason: nanny-close
2024-01-07 06:25:11,494 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44759. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46337'. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37875. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41201'. Reason: nanny-close
2024-01-07 06:25:11,495 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45845. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44973'. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39907. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33787'. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46059. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,496 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47190; closing.
2024-01-07 06:25:11,497 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,497 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40975'. Reason: nanny-close
2024-01-07 06:25:11,497 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39575. Reason: nanny-close
2024-01-07 06:25:11,497 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,497 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:11,497 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44759', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.4972692')
2024-01-07 06:25:11,497 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35121. Reason: nanny-close
2024-01-07 06:25:11,498 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,498 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38535. Reason: nanny-close
2024-01-07 06:25:11,498 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,498 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,498 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,498 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47134; closing.
2024-01-07 06:25:11,498 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,498 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,499 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,499 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,500 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,500 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,500 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,500 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47140; closing.
2024-01-07 06:25:11,500 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.5006628')
2024-01-07 06:25:11,501 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:11,502 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,502 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45845', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.502561')
2024-01-07 06:25:11,503 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:11,503 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47176; closing.
2024-01-07 06:25:11,503 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47180; closing.
2024-01-07 06:25:11,503 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47170; closing.
2024-01-07 06:25:11,504 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46059', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.5045931')
2024-01-07 06:25:11,505 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39907', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.5051298')
2024-01-07 06:25:11,505 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39575', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.5057156')
2024-01-07 06:25:11,506 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47148; closing.
2024-01-07 06:25:11,507 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35121', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.5072305')
2024-01-07 06:25:11,507 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47162; closing.
2024-01-07 06:25:11,508 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38535', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608711.508411')
2024-01-07 06:25:11,508 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:11,509 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47162>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:25:12,559 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:12,560 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:12,560 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:12,561 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:12,562 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-07 06:25:14,943 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:14,948 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:14,952 - distributed.scheduler - INFO - State start
2024-01-07 06:25:14,978 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:14,980 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:14,981 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:14,981 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:15,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39125'
2024-01-07 06:25:15,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34667'
2024-01-07 06:25:15,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38749'
2024-01-07 06:25:15,060 - distributed.scheduler - INFO - Receive client connection: Client-83aa765b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:15,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35251'
2024-01-07 06:25:15,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37437'
2024-01-07 06:25:15,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47374
2024-01-07 06:25:15,081 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41075'
2024-01-07 06:25:15,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40249'
2024-01-07 06:25:15,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42529'
2024-01-07 06:25:17,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,024 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,025 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42483
2024-01-07 06:25:17,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42483
2024-01-07 06:25:17,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33157
2024-01-07 06:25:17,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,025 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,025 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8rqt81u0
2024-01-07 06:25:17,026 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5f28c7a1-c550-4c0f-8d50-771094c60651
2024-01-07 06:25:17,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,081 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,081 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,081 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36673
2024-01-07 06:25:17,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36673
2024-01-07 06:25:17,082 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39043
2024-01-07 06:25:17,082 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,082 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,082 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,082 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,082 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-st6a12xm
2024-01-07 06:25:17,082 - distributed.worker - INFO - Starting Worker plugin PreImport-52ce8153-24ee-40b1-8ac5-04c874c040cb
2024-01-07 06:25:17,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43991
2024-01-07 06:25:17,082 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-651d830d-3c79-494d-afdf-aff9b486fd6b
2024-01-07 06:25:17,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43991
2024-01-07 06:25:17,082 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45503
2024-01-07 06:25:17,082 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43799
2024-01-07 06:25:17,082 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43799
2024-01-07 06:25:17,083 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,083 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42003
2024-01-07 06:25:17,083 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,083 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,083 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tb495vje
2024-01-07 06:25:17,083 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,083 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,083 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,083 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-djziqion
2024-01-07 06:25:17,083 - distributed.worker - INFO - Starting Worker plugin PreImport-8f3a3ee4-e432-4a69-a7ef-06ce2b6ad178
2024-01-07 06:25:17,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d459aa4a-f7a2-4a3e-b759-ad958233e9ae
2024-01-07 06:25:17,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5ca7bf6f-9e09-4b2a-83be-c584ec2332d4
2024-01-07 06:25:17,083 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5937d12-2be0-430b-8fa4-13bc0cc2e333
2024-01-07 06:25:17,083 - distributed.worker - INFO - Starting Worker plugin RMMSetup-22aab4dc-d8f3-47a3-b62c-e3b637c0180f
2024-01-07 06:25:17,084 - distributed.worker - INFO - Starting Worker plugin PreImport-6268e272-2aab-4586-8200-7ba4cc2ecb9d
2024-01-07 06:25:17,084 - distributed.worker - INFO - Starting Worker plugin RMMSetup-150dfa3a-53a8-4c67-9379-0ba8a26a1ba3
2024-01-07 06:25:17,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:17,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:17,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32835
2024-01-07 06:25:17,296 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32835
2024-01-07 06:25:17,296 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40125
2024-01-07 06:25:17,296 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,296 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,296 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,296 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-irk7wvqx
2024-01-07 06:25:17,296 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1580d53f-5d10-4dbd-aa7f-92d757d91ff5
2024-01-07 06:25:17,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:17,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33495
2024-01-07 06:25:17,298 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33495
2024-01-07 06:25:17,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35915
2024-01-07 06:25:17,298 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46827
2024-01-07 06:25:17,298 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35915
2024-01-07 06:25:17,298 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,298 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36917
2024-01-07 06:25:17,299 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,299 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,299 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,299 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,299 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,299 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-094vzvbn
2024-01-07 06:25:17,299 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,299 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39949
2024-01-07 06:25:17,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dqz1x9m0
2024-01-07 06:25:17,299 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39949
2024-01-07 06:25:17,299 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44731
2024-01-07 06:25:17,299 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:17,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4bfe3029-4c4d-46f3-8ee4-43396ffa41e8
2024-01-07 06:25:17,299 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:17,299 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:17,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8df1873-18ed-4fc7-b991-b4bb3aa1526d
2024-01-07 06:25:17,299 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:17,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-imgrj3wn
2024-01-07 06:25:17,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-97aecf6b-8a5f-420e-ac9e-5c73041defa6
2024-01-07 06:25:18,693 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0911aca7-5061-4a8a-95e1-6805639b0296
2024-01-07 06:25:18,694 - distributed.worker - INFO - Starting Worker plugin PreImport-96123985-0480-4faf-9985-ca0df59e5692
2024-01-07 06:25:18,694 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:18,721 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42483', status: init, memory: 0, processing: 0>
2024-01-07 06:25:18,722 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42483
2024-01-07 06:25:18,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47396
2024-01-07 06:25:18,723 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:18,724 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:18,724 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:18,726 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,092 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43991', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,093 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43991
2024-01-07 06:25:19,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47412
2024-01-07 06:25:19,094 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,095 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,095 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,110 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,143 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43799', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,144 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43799
2024-01-07 06:25:19,144 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47424
2024-01-07 06:25:19,145 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,146 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,146 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,166 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,189 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-26742cc1-1fb6-49e2-af99-ae439fa46b7f
2024-01-07 06:25:19,190 - distributed.worker - INFO - Starting Worker plugin PreImport-074dc240-85d3-40d5-b5cb-3477f50e9002
2024-01-07 06:25:19,190 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,192 - distributed.worker - INFO - Starting Worker plugin PreImport-4b893ab3-7853-41fa-be81-4a823acdf408
2024-01-07 06:25:19,193 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cb492347-cf47-4c43-9e29-1720f32f4e82
2024-01-07 06:25:19,193 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,199 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bcee8c21-8502-42cd-952a-5f9ce21327e4
2024-01-07 06:25:19,200 - distributed.worker - INFO - Starting Worker plugin PreImport-719584f1-e8cd-4da1-a689-06ae23cc08c7
2024-01-07 06:25:19,200 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,206 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36673', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,207 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36673
2024-01-07 06:25:19,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47438
2024-01-07 06:25:19,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,210 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,210 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,218 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39949', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,218 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39949
2024-01-07 06:25:19,218 - distributed.worker - INFO - Starting Worker plugin PreImport-2f26f765-43e2-45a3-8098-217c10f5ee7f
2024-01-07 06:25:19,218 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47448
2024-01-07 06:25:19,218 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0902c191-5023-4e6d-8bf4-3f7bc300d085
2024-01-07 06:25:19,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,219 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,220 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,220 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,222 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,229 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32835', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,230 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32835
2024-01-07 06:25:19,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47456
2024-01-07 06:25:19,231 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35915', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,231 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35915
2024-01-07 06:25:19,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,231 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47440
2024-01-07 06:25:19,232 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,232 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,233 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,234 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,234 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,234 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,236 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,242 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33495', status: init, memory: 0, processing: 0>
2024-01-07 06:25:19,242 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33495
2024-01-07 06:25:19,243 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47462
2024-01-07 06:25:19,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:19,245 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:19,245 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:19,246 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:19,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:19,318 - distributed.scheduler - INFO - Remove client Client-83aa765b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:19,318 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47374; closing.
2024-01-07 06:25:19,319 - distributed.scheduler - INFO - Remove client Client-83aa765b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:19,319 - distributed.scheduler - INFO - Close client connection: Client-83aa765b-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:19,320 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39125'. Reason: nanny-close
2024-01-07 06:25:19,320 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,320 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34667'. Reason: nanny-close
2024-01-07 06:25:19,321 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,321 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38749'. Reason: nanny-close
2024-01-07 06:25:19,321 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,321 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43799. Reason: nanny-close
2024-01-07 06:25:19,321 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35251'. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42483. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37437'. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32835. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43991. Reason: nanny-close
2024-01-07 06:25:19,322 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41075'. Reason: nanny-close
2024-01-07 06:25:19,323 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,323 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40249'. Reason: nanny-close
2024-01-07 06:25:19,323 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36673. Reason: nanny-close
2024-01-07 06:25:19,323 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,324 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42529'. Reason: nanny-close
2024-01-07 06:25:19,324 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,324 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,324 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:19,324 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35915. Reason: nanny-close
2024-01-07 06:25:19,324 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,324 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47424; closing.
2024-01-07 06:25:19,324 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39949. Reason: nanny-close
2024-01-07 06:25:19,324 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47396; closing.
2024-01-07 06:25:19,324 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,325 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43799', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.3249598')
2024-01-07 06:25:19,325 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33495. Reason: nanny-close
2024-01-07 06:25:19,325 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42483', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.325556')
2024-01-07 06:25:19,325 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,326 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,326 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47456; closing.
2024-01-07 06:25:19,326 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,326 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,326 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,326 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,326 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32835', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.3266654')
2024-01-07 06:25:19,326 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,327 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47412; closing.
2024-01-07 06:25:19,327 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,327 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:19,328 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43991', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.3279488')
2024-01-07 06:25:19,328 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,328 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,329 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:19,328 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47456>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:25:19,330 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47438; closing.
2024-01-07 06:25:19,331 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47448; closing.
2024-01-07 06:25:19,331 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47440; closing.
2024-01-07 06:25:19,331 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36673', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.331742')
2024-01-07 06:25:19,332 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39949', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.3321683')
2024-01-07 06:25:19,332 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.332525')
2024-01-07 06:25:19,332 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47462; closing.
2024-01-07 06:25:19,333 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608719.3332922')
2024-01-07 06:25:19,333 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:20,336 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:20,336 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:20,337 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:20,338 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:20,338 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-07 06:25:22,701 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:22,705 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:22,709 - distributed.scheduler - INFO - State start
2024-01-07 06:25:22,737 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:22,738 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:22,739 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:22,739 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:22,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38217'
2024-01-07 06:25:22,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33053'
2024-01-07 06:25:22,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37283'
2024-01-07 06:25:22,941 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41859'
2024-01-07 06:25:22,945 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44169'
2024-01-07 06:25:22,953 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46125'
2024-01-07 06:25:22,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33583'
2024-01-07 06:25:22,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37163'
2024-01-07 06:25:24,608 - distributed.scheduler - INFO - Receive client connection: Client-886a1da8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:24,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43124
2024-01-07 06:25:24,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,816 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,817 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35531
2024-01-07 06:25:24,817 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35531
2024-01-07 06:25:24,817 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43139
2024-01-07 06:25:24,817 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,817 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,817 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,817 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,817 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-df7kb7nm
2024-01-07 06:25:24,817 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4fb96792-6d45-4995-b1fa-2fc4868b6f69
2024-01-07 06:25:24,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,819 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37581
2024-01-07 06:25:24,819 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37581
2024-01-07 06:25:24,819 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45199
2024-01-07 06:25:24,819 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,819 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,819 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,819 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,819 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2ot9tmkc
2024-01-07 06:25:24,819 - distributed.worker - INFO - Starting Worker plugin PreImport-f162094c-a76a-460c-a73f-47c853a1b33e
2024-01-07 06:25:24,819 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-afbe9f29-6abc-4b87-9460-bf18cb5b3067
2024-01-07 06:25:24,820 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20fe6cf6-4244-4ebd-848a-54041ccaa710
2024-01-07 06:25:24,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,887 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,888 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44827
2024-01-07 06:25:24,888 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44827
2024-01-07 06:25:24,888 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40107
2024-01-07 06:25:24,888 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,888 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,888 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,888 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,888 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u76s2vgz
2024-01-07 06:25:24,889 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef1e4a03-b147-459f-888b-2421e7a39acf
2024-01-07 06:25:24,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,908 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,909 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43447
2024-01-07 06:25:24,909 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43447
2024-01-07 06:25:24,909 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45947
2024-01-07 06:25:24,909 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,909 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,909 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,909 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,909 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,909 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6pj0iohe
2024-01-07 06:25:24,910 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e32ee30d-baa4-4075-9af2-5b9b6f128f92
2024-01-07 06:25:24,910 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39107
2024-01-07 06:25:24,910 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39107
2024-01-07 06:25:24,910 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41371
2024-01-07 06:25:24,910 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,910 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,910 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,911 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ofsz6l7
2024-01-07 06:25:24,911 - distributed.worker - INFO - Starting Worker plugin PreImport-537b4f5a-d8b4-4863-90e9-f6fb92df5e8a
2024-01-07 06:25:24,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-718ff9d8-6b8d-4e39-92b6-61d13f89806d
2024-01-07 06:25:24,911 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c364d351-96cd-4e50-a4cc-64ef61b07062
2024-01-07 06:25:24,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,917 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,918 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40065
2024-01-07 06:25:24,918 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40065
2024-01-07 06:25:24,918 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46759
2024-01-07 06:25:24,918 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,918 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,918 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,918 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,918 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-te9ugmg9
2024-01-07 06:25:24,919 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e36316ff-e45e-487b-8345-31520e591232
2024-01-07 06:25:24,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,951 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43663
2024-01-07 06:25:24,951 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43663
2024-01-07 06:25:24,951 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43935
2024-01-07 06:25:24,951 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,951 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,951 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,951 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,951 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-omxr4bns
2024-01-07 06:25:24,952 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f1d21964-cc04-4335-b364-416b1e377f69
2024-01-07 06:25:24,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:24,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:24,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:24,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36811
2024-01-07 06:25:24,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36811
2024-01-07 06:25:24,973 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42121
2024-01-07 06:25:24,973 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:24,973 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:24,973 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:24,973 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:24,973 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hlavbo4m
2024-01-07 06:25:24,974 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9255e624-0a9c-4c3b-9194-782415f11914
2024-01-07 06:25:26,976 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:26,985 - distributed.worker - INFO - Starting Worker plugin PreImport-4b0a0f51-ab77-4850-9967-b593404bc164
2024-01-07 06:25:26,985 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3eee6163-945b-4d05-a382-cef078fd439d
2024-01-07 06:25:26,987 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,013 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37581', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,015 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37581
2024-01-07 06:25:27,015 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43140
2024-01-07 06:25:27,016 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,017 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,017 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,019 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,023 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35531', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,023 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1432054a-313e-4e34-ba07-f6b93aa2c8ed
2024-01-07 06:25:27,024 - distributed.worker - INFO - Starting Worker plugin PreImport-36f08fb0-3a66-4b47-b250-5013f8a5dafe
2024-01-07 06:25:27,024 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35531
2024-01-07 06:25:27,024 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43144
2024-01-07 06:25:27,025 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,026 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,027 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,027 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,059 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44827', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,060 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44827
2024-01-07 06:25:27,060 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43158
2024-01-07 06:25:27,061 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,062 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,062 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,064 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,069 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-abe10c99-2cf8-4829-8af1-eb3e768adceb
2024-01-07 06:25:27,069 - distributed.worker - INFO - Starting Worker plugin PreImport-fdd4868b-ff4b-4d46-aa6f-2339b20213be
2024-01-07 06:25:27,070 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,075 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5425e399-e05f-478f-a3ea-4fff215a3d24
2024-01-07 06:25:27,075 - distributed.worker - INFO - Starting Worker plugin PreImport-3d791d74-4f57-4a91-865d-0253ce5c085e
2024-01-07 06:25:27,076 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8fdf9d30-0eaa-465b-8232-2c1703aade3d
2024-01-07 06:25:27,083 - distributed.worker - INFO - Starting Worker plugin PreImport-7688842e-4dce-4fa4-b667-878596ff1f83
2024-01-07 06:25:27,083 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,084 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed686590-0159-4504-bfac-3098acfe84c2
2024-01-07 06:25:27,085 - distributed.worker - INFO - Starting Worker plugin PreImport-c8ba34fb-a356-4694-9a46-80558223a590
2024-01-07 06:25:27,085 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,089 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39107', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,090 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39107
2024-01-07 06:25:27,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43166
2024-01-07 06:25:27,091 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,092 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,092 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,093 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,096 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43447', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,096 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43447
2024-01-07 06:25:27,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43170
2024-01-07 06:25:27,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,098 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,098 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,099 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,109 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43663', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,110 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43663
2024-01-07 06:25:27,110 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43182
2024-01-07 06:25:27,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,111 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,111 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,113 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,113 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36811', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,114 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36811
2024-01-07 06:25:27,114 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43176
2024-01-07 06:25:27,114 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40065', status: init, memory: 0, processing: 0>
2024-01-07 06:25:27,115 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40065
2024-01-07 06:25:27,115 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43196
2024-01-07 06:25:27,115 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:27,116 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,117 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:27,117 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:27,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:27,204 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,204 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,204 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,205 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,209 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:27,221 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,221 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,222 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:27,233 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:27,235 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:27,238 - distributed.scheduler - INFO - Remove client Client-886a1da8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:27,238 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43124; closing.
2024-01-07 06:25:27,238 - distributed.scheduler - INFO - Remove client Client-886a1da8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:27,238 - distributed.scheduler - INFO - Close client connection: Client-886a1da8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:27,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38217'. Reason: nanny-close
2024-01-07 06:25:27,240 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33053'. Reason: nanny-close
2024-01-07 06:25:27,241 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,241 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37283'. Reason: nanny-close
2024-01-07 06:25:27,241 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41859'. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35531. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37581. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44169'. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46125'. Reason: nanny-close
2024-01-07 06:25:27,242 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39107. Reason: nanny-close
2024-01-07 06:25:27,243 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,243 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40065. Reason: nanny-close
2024-01-07 06:25:27,243 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33583'. Reason: nanny-close
2024-01-07 06:25:27,243 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,243 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37163'. Reason: nanny-close
2024-01-07 06:25:27,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36811. Reason: nanny-close
2024-01-07 06:25:27,244 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:27,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43447. Reason: nanny-close
2024-01-07 06:25:27,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43663. Reason: nanny-close
2024-01-07 06:25:27,245 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43140; closing.
2024-01-07 06:25:27,245 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,245 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37581', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.245719')
2024-01-07 06:25:27,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,246 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44827. Reason: nanny-close
2024-01-07 06:25:27,247 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,248 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,248 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,248 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,248 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43170; closing.
2024-01-07 06:25:27,248 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,248 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43144; closing.
2024-01-07 06:25:27,249 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43166; closing.
2024-01-07 06:25:27,249 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43196; closing.
2024-01-07 06:25:27,250 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43447', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.2504263')
2024-01-07 06:25:27,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35531', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.2509997')
2024-01-07 06:25:27,251 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39107', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.2515666')
2024-01-07 06:25:27,252 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43182; closing.
2024-01-07 06:25:27,252 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40065', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.252359')
2024-01-07 06:25:27,253 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43663', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.2531912')
2024-01-07 06:25:27,254 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43158; closing.
2024-01-07 06:25:27,254 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:27,255 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.2549715')
2024-01-07 06:25:27,255 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43176; closing.
2024-01-07 06:25:27,256 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43158>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:25:27,258 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:27,258 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36811', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608727.258233')
2024-01-07 06:25:27,258 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:27,260 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:28,256 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:28,256 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:28,257 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:28,258 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:28,259 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-07 06:25:30,458 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:30,463 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:30,466 - distributed.scheduler - INFO - State start
2024-01-07 06:25:30,493 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:30,494 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:30,495 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:30,495 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:30,822 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43343'
2024-01-07 06:25:30,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35525'
2024-01-07 06:25:30,856 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33731'
2024-01-07 06:25:30,860 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34015'
2024-01-07 06:25:30,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42501'
2024-01-07 06:25:30,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39421'
2024-01-07 06:25:30,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43553'
2024-01-07 06:25:30,897 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45979'
2024-01-07 06:25:31,121 - distributed.scheduler - INFO - Receive client connection: Client-8d0bd83a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:31,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36106
2024-01-07 06:25:32,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,703 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,704 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45241
2024-01-07 06:25:32,704 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45241
2024-01-07 06:25:32,704 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43855
2024-01-07 06:25:32,705 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,705 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,705 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,705 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,705 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ok4yo88
2024-01-07 06:25:32,705 - distributed.worker - INFO - Starting Worker plugin RMMSetup-13ff40a6-adb7-4580-a61f-e3131f280ae5
2024-01-07 06:25:32,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,928 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,929 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43123
2024-01-07 06:25:32,929 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43123
2024-01-07 06:25:32,929 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39493
2024-01-07 06:25:32,930 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,930 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,930 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,930 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,930 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-89uykhoi
2024-01-07 06:25:32,930 - distributed.worker - INFO - Starting Worker plugin PreImport-ab1a8976-0ada-40c7-90ff-a7a8918fb603
2024-01-07 06:25:32,930 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3f890c7f-ae19-430c-9cf3-a0fb9d98c671
2024-01-07 06:25:32,930 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad8bbbea-ff99-4cc4-a0fa-68ace5d50671
2024-01-07 06:25:32,932 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,932 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,933 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38209
2024-01-07 06:25:32,933 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38209
2024-01-07 06:25:32,933 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39781
2024-01-07 06:25:32,933 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,933 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,933 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,933 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pis716xx
2024-01-07 06:25:32,933 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43071
2024-01-07 06:25:32,933 - distributed.worker - INFO - Starting Worker plugin PreImport-c8aa597d-9665-466e-83f6-42e3b909e772
2024-01-07 06:25:32,933 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43071
2024-01-07 06:25:32,934 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38413
2024-01-07 06:25:32,934 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-79e6e2c4-cab0-4f5b-9003-8683c2698a09
2024-01-07 06:25:32,934 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,934 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,934 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,934 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,934 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mkpw7j6u
2024-01-07 06:25:32,934 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3db93612-c895-4af1-bb96-ab9ecc7df725
2024-01-07 06:25:32,935 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6963ec2d-f1ff-43d3-9d59-68eeacd74399
2024-01-07 06:25:32,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:32,943 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,944 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46639
2024-01-07 06:25:32,944 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46639
2024-01-07 06:25:32,944 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42555
2024-01-07 06:25:32,944 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,944 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,944 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,944 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,944 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ess3exhm
2024-01-07 06:25:32,944 - distributed.worker - INFO - Starting Worker plugin RMMSetup-282eec13-8eb8-45d5-b505-9e5bc257beee
2024-01-07 06:25:32,947 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,947 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,948 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:32,948 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34123
2024-01-07 06:25:32,948 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34123
2024-01-07 06:25:32,948 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34341
2024-01-07 06:25:32,948 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,948 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,948 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,948 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-34bdf3ak
2024-01-07 06:25:32,949 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34627
2024-01-07 06:25:32,949 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34627
2024-01-07 06:25:32,949 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38203
2024-01-07 06:25:32,949 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37987
2024-01-07 06:25:32,949 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38203
2024-01-07 06:25:32,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0aa60add-d109-4249-9111-cd2a4817ccff
2024-01-07 06:25:32,949 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,949 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44513
2024-01-07 06:25:32,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,949 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,949 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:32,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:32,949 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,949 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:32,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ewzn_ufs
2024-01-07 06:25:32,949 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:32,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5d9mfs5n
2024-01-07 06:25:32,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a851bc6f-c2bf-4757-b97c-5af9d9961cfd
2024-01-07 06:25:32,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-394853a5-cc96-48bb-930d-046035ace518
2024-01-07 06:25:33,189 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f34797b7-2f54-4345-8050-2acfdf5a31dc
2024-01-07 06:25:33,189 - distributed.worker - INFO - Starting Worker plugin PreImport-ed6eb726-d065-4a96-9367-39dce6dddbd6
2024-01-07 06:25:33,190 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:33,214 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45241', status: init, memory: 0, processing: 0>
2024-01-07 06:25:33,215 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45241
2024-01-07 06:25:33,215 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36126
2024-01-07 06:25:33,216 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:33,217 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:33,217 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:33,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,812 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,844 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38209', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,844 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38209
2024-01-07 06:25:34,844 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36138
2024-01-07 06:25:34,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,847 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,847 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,849 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,880 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c724616-6007-4122-a179-3d1b579de24d
2024-01-07 06:25:34,880 - distributed.worker - INFO - Starting Worker plugin PreImport-3b903f72-16cb-4bb7-b0ed-31f2155f9f16
2024-01-07 06:25:34,881 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,883 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9668a56-2570-448c-a954-e87a693577dc
2024-01-07 06:25:34,883 - distributed.worker - INFO - Starting Worker plugin PreImport-cc6fb7ea-b15d-46cb-8417-4d38ec679858
2024-01-07 06:25:34,885 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,887 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a9493cf5-9ba0-4613-b1a8-00ac31e7eb8e
2024-01-07 06:25:34,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1dab9d7-e519-4641-9ed3-2c0811427e0e
2024-01-07 06:25:34,888 - distributed.worker - INFO - Starting Worker plugin PreImport-901028f9-a9eb-4b89-803b-cab5470d518d
2024-01-07 06:25:34,888 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,888 - distributed.worker - INFO - Starting Worker plugin PreImport-8df6c552-caa2-4fdd-a7ab-9a382abe3302
2024-01-07 06:25:34,889 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,889 - distributed.worker - INFO - Starting Worker plugin PreImport-c671645b-695e-47d5-8913-147108d4145f
2024-01-07 06:25:34,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-65e9040d-c771-4360-aff9-f9b113ecfe62
2024-01-07 06:25:34,890 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,905 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34123', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,906 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34123
2024-01-07 06:25:34,906 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36148
2024-01-07 06:25:34,907 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,908 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,908 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,909 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,915 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43123', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,915 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43123
2024-01-07 06:25:34,916 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36164
2024-01-07 06:25:34,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,917 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,917 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34627', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,917 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,918 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34627
2024-01-07 06:25:34,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36176
2024-01-07 06:25:34,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,919 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43071', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,919 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43071
2024-01-07 06:25:34,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36192
2024-01-07 06:25:34,920 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,920 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,921 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,921 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,921 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,922 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,927 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38203', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,927 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38203
2024-01-07 06:25:34,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36152
2024-01-07 06:25:34,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46639', status: init, memory: 0, processing: 0>
2024-01-07 06:25:34,929 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46639
2024-01-07 06:25:34,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36202
2024-01-07 06:25:34,929 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,930 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,930 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,930 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:34,931 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:34,932 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:34,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:34,963 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,963 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,964 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,965 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:25:34,986 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,987 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:34,989 - distributed.scheduler - INFO - Remove client Client-8d0bd83a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:34,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36106; closing.
2024-01-07 06:25:34,990 - distributed.scheduler - INFO - Remove client Client-8d0bd83a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:34,990 - distributed.scheduler - INFO - Close client connection: Client-8d0bd83a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:34,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43343'. Reason: nanny-close
2024-01-07 06:25:34,992 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35525'. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33731'. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43071. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43123. Reason: nanny-close
2024-01-07 06:25:34,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34015'. Reason: nanny-close
2024-01-07 06:25:34,994 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,994 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42501'. Reason: nanny-close
2024-01-07 06:25:34,994 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38209. Reason: nanny-close
2024-01-07 06:25:34,994 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,994 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39421'. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45241. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43553'. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36192; closing.
2024-01-07 06:25:34,995 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34123. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43071', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608734.9955306')
2024-01-07 06:25:34,995 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,995 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45979'. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34627. Reason: nanny-close
2024-01-07 06:25:34,995 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:34,996 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46639. Reason: nanny-close
2024-01-07 06:25:34,996 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:34,996 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:34,997 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38203. Reason: nanny-close
2024-01-07 06:25:34,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,997 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36164; closing.
2024-01-07 06:25:34,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,998 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,998 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,998 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:34,999 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:34,999 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:35,000 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:35,000 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43123', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0004363')
2024-01-07 06:25:35,000 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:35,000 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:35,000 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36138; closing.
2024-01-07 06:25:35,001 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:35,001 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36148; closing.
2024-01-07 06:25:35,001 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36126; closing.
2024-01-07 06:25:35,001 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38209', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.001901')
2024-01-07 06:25:35,002 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34123', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0021863')
2024-01-07 06:25:35,002 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0024512')
2024-01-07 06:25:35,002 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:35,002 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36176; closing.
2024-01-07 06:25:35,003 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34627', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0034547')
2024-01-07 06:25:35,003 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36202; closing.
2024-01-07 06:25:35,004 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36152; closing.
2024-01-07 06:25:35,004 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46639', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0044298')
2024-01-07 06:25:35,004 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38203', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608735.0047781')
2024-01-07 06:25:35,004 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:35,005 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36152>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:25:35,006 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36202>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:25:36,058 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:36,058 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:36,059 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:36,060 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:36,060 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-07 06:25:38,271 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:38,275 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:38,278 - distributed.scheduler - INFO - State start
2024-01-07 06:25:38,300 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:38,300 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:38,301 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:38,301 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:38,458 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39159'
2024-01-07 06:25:38,472 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44295'
2024-01-07 06:25:38,482 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35365'
2024-01-07 06:25:38,495 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39409'
2024-01-07 06:25:38,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34747'
2024-01-07 06:25:38,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36439'
2024-01-07 06:25:38,517 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42177'
2024-01-07 06:25:38,527 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38609'
2024-01-07 06:25:38,802 - distributed.scheduler - INFO - Receive client connection: Client-91b942c3-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:38,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36316
2024-01-07 06:25:40,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,383 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,383 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,384 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45803
2024-01-07 06:25:40,384 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45803
2024-01-07 06:25:40,384 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39893
2024-01-07 06:25:40,384 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,384 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43809
2024-01-07 06:25:40,384 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,384 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,384 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43809
2024-01-07 06:25:40,384 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,384 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38397
2024-01-07 06:25:40,384 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g331cems
2024-01-07 06:25:40,384 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,384 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,385 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,385 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e018906f-aa02-4399-8b30-57a44fb02add
2024-01-07 06:25:40,385 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,385 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_p9o595z
2024-01-07 06:25:40,385 - distributed.worker - INFO - Starting Worker plugin PreImport-36236549-5892-4780-b252-6e5c57355f8e
2024-01-07 06:25:40,385 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c030133-9ccc-4a23-8247-c6c75b1b82e9
2024-01-07 06:25:40,385 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ff8e340-75a9-4894-b499-4447118558d8
2024-01-07 06:25:40,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,397 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,398 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44025
2024-01-07 06:25:40,399 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44025
2024-01-07 06:25:40,399 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36545
2024-01-07 06:25:40,399 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,399 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,399 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,399 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,399 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i02e6wd0
2024-01-07 06:25:40,399 - distributed.worker - INFO - Starting Worker plugin RMMSetup-715624c2-1f28-453b-8961-3206b0f5f66c
2024-01-07 06:25:40,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,422 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,423 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40783
2024-01-07 06:25:40,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40783
2024-01-07 06:25:40,423 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44597
2024-01-07 06:25:40,423 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,423 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,423 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,423 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,423 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iwsw09rx
2024-01-07 06:25:40,423 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93fec4e3-88f4-4e56-98ec-cdded994f690
2024-01-07 06:25:40,426 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,427 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38969
2024-01-07 06:25:40,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38969
2024-01-07 06:25:40,427 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40901
2024-01-07 06:25:40,427 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,427 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,427 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,427 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,427 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cevv8kjj
2024-01-07 06:25:40,427 - distributed.worker - INFO - Starting Worker plugin PreImport-7766f594-0fc9-48e0-a840-81044991e72c
2024-01-07 06:25:40,428 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-12de1ed3-c006-4d97-b6ac-58c65b35e73f
2024-01-07 06:25:40,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-571dbb79-7230-4e7d-8d23-73e6b777c11c
2024-01-07 06:25:40,428 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35207
2024-01-07 06:25:40,428 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35207
2024-01-07 06:25:40,428 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37395
2024-01-07 06:25:40,428 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,428 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,428 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,428 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d5x33wg3
2024-01-07 06:25:40,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d613b3c0-0769-4a05-a7cf-4f5c7cdaf896
2024-01-07 06:25:40,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,441 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,442 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33555
2024-01-07 06:25:40,442 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33555
2024-01-07 06:25:40,442 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37039
2024-01-07 06:25:40,442 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,442 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,442 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,442 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,442 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rg515dy4
2024-01-07 06:25:40,443 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7b86cc9d-ed5e-4c6f-bdbb-13363c29423f
2024-01-07 06:25:40,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:40,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:40,477 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:40,477 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43807
2024-01-07 06:25:40,477 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43807
2024-01-07 06:25:40,478 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44945
2024-01-07 06:25:40,478 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:40,478 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:40,478 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:40,478 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:25:40,478 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ho42dmbc
2024-01-07 06:25:40,478 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61b92003-9a7c-4a3b-8e3c-df9c045e5152
2024-01-07 06:25:42,372 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a2e69db-068c-4903-a1a7-5c42ed443d99
2024-01-07 06:25:42,373 - distributed.worker - INFO - Starting Worker plugin PreImport-3200e661-e6fc-4ddb-82f7-7471747ae3a1
2024-01-07 06:25:42,374 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,392 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,413 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44025', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,414 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44025
2024-01-07 06:25:42,414 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51570
2024-01-07 06:25:42,416 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,417 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,417 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,428 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43809', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,429 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43809
2024-01-07 06:25:42,429 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51576
2024-01-07 06:25:42,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,431 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a6acc23-54f4-4665-a250-c626bfe924f1
2024-01-07 06:25:42,432 - distributed.worker - INFO - Starting Worker plugin PreImport-28f0378c-6182-4634-8ffe-e982f93ed84c
2024-01-07 06:25:42,432 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,432 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,432 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,434 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,454 - distributed.worker - INFO - Starting Worker plugin PreImport-98d09f4b-92ef-444e-b7bc-0e0c2c67cc86
2024-01-07 06:25:42,454 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c0cfb709-1ec3-4747-9406-b5168f2a3509
2024-01-07 06:25:42,455 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40783', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40783
2024-01-07 06:25:42,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51584
2024-01-07 06:25:42,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,459 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,459 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,460 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,461 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,466 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5803477-a549-4968-80ba-da09f71bc241
2024-01-07 06:25:42,467 - distributed.worker - INFO - Starting Worker plugin PreImport-4701e59d-c011-4bf7-ba69-a14580deba3a
2024-01-07 06:25:42,469 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,485 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-08c6a2fa-9152-440d-badf-72d58435f436
2024-01-07 06:25:42,485 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38969', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,486 - distributed.worker - INFO - Starting Worker plugin PreImport-4d0c35cb-518c-413b-b576-a535d210de75
2024-01-07 06:25:42,486 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38969
2024-01-07 06:25:42,486 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51608
2024-01-07 06:25:42,486 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,488 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,488 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45803', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,494 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45803
2024-01-07 06:25:42,494 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51592
2024-01-07 06:25:42,494 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ec244852-8895-41fb-a5cd-a12190f96caa
2024-01-07 06:25:42,495 - distributed.worker - INFO - Starting Worker plugin PreImport-7bd257b9-2615-4cfa-9a05-120c6d785e2c
2024-01-07 06:25:42,495 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,498 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,498 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,500 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,506 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35207', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,506 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35207
2024-01-07 06:25:42,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51622
2024-01-07 06:25:42,508 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,509 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,509 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,511 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,511 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33555', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,512 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33555
2024-01-07 06:25:42,512 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51630
2024-01-07 06:25:42,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,514 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,514 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,518 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43807', status: init, memory: 0, processing: 0>
2024-01-07 06:25:42,519 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43807
2024-01-07 06:25:42,519 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51632
2024-01-07 06:25:42,520 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:42,521 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:42,521 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:42,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:42,568 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,568 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,569 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,569 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,569 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,570 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,570 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,570 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:25:42,575 - distributed.scheduler - INFO - Remove client Client-91b942c3-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:42,575 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36316; closing.
2024-01-07 06:25:42,575 - distributed.scheduler - INFO - Remove client Client-91b942c3-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:42,575 - distributed.scheduler - INFO - Close client connection: Client-91b942c3-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:42,576 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39159'. Reason: nanny-close
2024-01-07 06:25:42,577 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,577 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44295'. Reason: nanny-close
2024-01-07 06:25:42,578 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,578 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35365'. Reason: nanny-close
2024-01-07 06:25:42,578 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45803. Reason: nanny-close
2024-01-07 06:25:42,578 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,578 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39409'. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43809. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34747'. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38969. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36439'. Reason: nanny-close
2024-01-07 06:25:42,579 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33555. Reason: nanny-close
2024-01-07 06:25:42,580 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,580 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42177'. Reason: nanny-close
2024-01-07 06:25:42,580 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,580 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44025. Reason: nanny-close
2024-01-07 06:25:42,580 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38609'. Reason: nanny-close
2024-01-07 06:25:42,581 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:42,581 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35207. Reason: nanny-close
2024-01-07 06:25:42,581 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51592; closing.
2024-01-07 06:25:42,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,581 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40783. Reason: nanny-close
2024-01-07 06:25:42,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,581 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45803', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5815446')
2024-01-07 06:25:42,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43807. Reason: nanny-close
2024-01-07 06:25:42,582 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,582 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51608; closing.
2024-01-07 06:25:42,583 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,583 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,583 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,583 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38969', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5835712')
2024-01-07 06:25:42,583 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,583 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51630; closing.
2024-01-07 06:25:42,583 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,584 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51576; closing.
2024-01-07 06:25:42,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,584 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,584 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,584 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:42,585 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33555', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5850353')
2024-01-07 06:25:42,585 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5853932')
2024-01-07 06:25:42,585 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,585 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51570; closing.
2024-01-07 06:25:42,586 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,586 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44025', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5864594')
2024-01-07 06:25:42,586 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51584; closing.
2024-01-07 06:25:42,587 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51622; closing.
2024-01-07 06:25:42,587 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51632; closing.
2024-01-07 06:25:42,587 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:42,587 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40783', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5876825')
2024-01-07 06:25:42,588 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35207', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.587964')
2024-01-07 06:25:42,588 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608742.5883076')
2024-01-07 06:25:42,588 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:43,442 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:43,443 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:43,443 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:43,444 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:43,445 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-07 06:25:45,621 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:45,625 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:45,628 - distributed.scheduler - INFO - State start
2024-01-07 06:25:45,651 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:45,652 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:45,653 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:45,653 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:45,774 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39031'
2024-01-07 06:25:47,192 - distributed.scheduler - INFO - Receive client connection: Client-961c6181-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:47,206 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51716
2024-01-07 06:25:47,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:47,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:47,936 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:47,937 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39127
2024-01-07 06:25:47,937 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39127
2024-01-07 06:25:47,937 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-07 06:25:47,937 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:47,937 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:47,937 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:47,937 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:25:47,937 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-26cgjbw6
2024-01-07 06:25:47,938 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2fb5353b-21c3-4343-b0d4-a23355503aff
2024-01-07 06:25:47,938 - distributed.worker - INFO - Starting Worker plugin PreImport-1913f743-2dc0-4c4b-9dcb-c99edf8e38ed
2024-01-07 06:25:47,938 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5142c64c-e437-4089-82a3-7911a7e8ffdd
2024-01-07 06:25:47,939 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:48,004 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39127', status: init, memory: 0, processing: 0>
2024-01-07 06:25:48,005 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39127
2024-01-07 06:25:48,005 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51730
2024-01-07 06:25:48,006 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:48,007 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:48,007 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:48,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:48,026 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:48,029 - distributed.scheduler - INFO - Remove client Client-961c6181-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:48,029 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51716; closing.
2024-01-07 06:25:48,030 - distributed.scheduler - INFO - Remove client Client-961c6181-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:48,030 - distributed.scheduler - INFO - Close client connection: Client-961c6181-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:48,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39031'. Reason: nanny-close
2024-01-07 06:25:48,047 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:48,048 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39127. Reason: nanny-close
2024-01-07 06:25:48,050 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:48,050 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51730; closing.
2024-01-07 06:25:48,051 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39127', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608748.0509946')
2024-01-07 06:25:48,051 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:48,052 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:48,747 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:48,747 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:48,748 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:48,749 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:48,749 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-07 06:25:52,875 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:52,879 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:52,883 - distributed.scheduler - INFO - State start
2024-01-07 06:25:52,906 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:52,907 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:52,907 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:52,908 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:25:52,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39241'
2024-01-07 06:25:54,290 - distributed.scheduler - INFO - Receive client connection: Client-9a62759a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:54,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36660
2024-01-07 06:25:54,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:25:54,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:25:55,232 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:25:55,233 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41881
2024-01-07 06:25:55,233 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41881
2024-01-07 06:25:55,233 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35077
2024-01-07 06:25:55,233 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:25:55,233 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:55,233 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:25:55,233 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:25:55,233 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ay_cqmwy
2024-01-07 06:25:55,234 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9b69d78b-4cf9-4381-833d-5aa4273f7c7f
2024-01-07 06:25:55,234 - distributed.worker - INFO - Starting Worker plugin PreImport-89c53ec2-621e-4431-9033-1f13c5ff60b0
2024-01-07 06:25:55,236 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c1af677-c43d-43e8-b3f7-c2349ce7e45b
2024-01-07 06:25:55,236 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:55,301 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41881', status: init, memory: 0, processing: 0>
2024-01-07 06:25:55,302 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41881
2024-01-07 06:25:55,302 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36682
2024-01-07 06:25:55,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:25:55,304 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:25:55,304 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:25:55,306 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:25:55,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:25:55,331 - distributed.scheduler - INFO - Remove client Client-9a62759a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:55,331 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36660; closing.
2024-01-07 06:25:55,331 - distributed.scheduler - INFO - Remove client Client-9a62759a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:55,332 - distributed.scheduler - INFO - Close client connection: Client-9a62759a-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:25:55,333 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39241'. Reason: nanny-close
2024-01-07 06:25:55,340 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:25:55,341 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41881. Reason: nanny-close
2024-01-07 06:25:55,343 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36682; closing.
2024-01-07 06:25:55,343 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:25:55,343 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608755.3437247')
2024-01-07 06:25:55,344 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:25:55,345 - distributed.nanny - INFO - Worker closed
2024-01-07 06:25:56,048 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:25:56,048 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:25:56,049 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:25:56,050 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:25:56,050 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-07 06:25:58,190 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:58,195 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:25:58,198 - distributed.scheduler - INFO - State start
2024-01-07 06:25:58,223 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:25:58,224 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:25:58,225 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:25:58,225 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:26:00,532 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:36688'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36688>: Stream is closed
2024-01-07 06:26:00,752 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:26:00,752 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:26:00,753 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:26:00,754 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:26:00,754 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-07 06:26:03,017 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:03,021 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:26:03,025 - distributed.scheduler - INFO - State start
2024-01-07 06:26:03,107 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:03,108 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-07 06:26:03,109 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:26:03,109 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:26:03,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46047'
2024-01-07 06:26:03,398 - distributed.scheduler - INFO - Receive client connection: Client-a07080c8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:03,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45594
2024-01-07 06:26:04,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:04,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:04,943 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:04,943 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38817
2024-01-07 06:26:04,944 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38817
2024-01-07 06:26:04,944 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46263
2024-01-07 06:26:04,944 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:26:04,944 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:04,944 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:04,944 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:26:04,944 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-2ahze1_r
2024-01-07 06:26:04,944 - distributed.worker - INFO - Starting Worker plugin RMMSetup-10146efd-00bb-4a06-bac5-a4f71256dd36
2024-01-07 06:26:04,944 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee3df589-dbfe-4781-b55a-a08f27cfcbd3
2024-01-07 06:26:04,945 - distributed.worker - INFO - Starting Worker plugin PreImport-351f3f89-23b0-43a7-91f7-2640dcb5a461
2024-01-07 06:26:04,945 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:04,999 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38817', status: init, memory: 0, processing: 0>
2024-01-07 06:26:05,000 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38817
2024-01-07 06:26:05,000 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45608
2024-01-07 06:26:05,001 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:05,002 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:26:05,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:05,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:26:05,050 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:05,053 - distributed.scheduler - INFO - Remove client Client-a07080c8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:05,053 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45594; closing.
2024-01-07 06:26:05,053 - distributed.scheduler - INFO - Remove client Client-a07080c8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:05,054 - distributed.scheduler - INFO - Close client connection: Client-a07080c8-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:05,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46047'. Reason: nanny-close
2024-01-07 06:26:05,055 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:05,056 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38817. Reason: nanny-close
2024-01-07 06:26:05,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:26:05,058 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45608; closing.
2024-01-07 06:26:05,058 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608765.0585515')
2024-01-07 06:26:05,058 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:26:05,059 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:05,720 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:26:05,721 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:26:05,721 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:26:05,722 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-07 06:26:05,723 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-07 06:26:07,925 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:07,930 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:26:07,933 - distributed.scheduler - INFO - State start
2024-01-07 06:26:07,954 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:07,955 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:26:07,956 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:26:07,956 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:26:08,122 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33047'
2024-01-07 06:26:08,136 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41211'
2024-01-07 06:26:08,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38545'
2024-01-07 06:26:08,158 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39231'
2024-01-07 06:26:08,161 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44849'
2024-01-07 06:26:08,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34525'
2024-01-07 06:26:08,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46277'
2024-01-07 06:26:08,189 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43437'
2024-01-07 06:26:09,229 - distributed.scheduler - INFO - Receive client connection: Client-a364aea7-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:09,243 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43516
2024-01-07 06:26:10,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,039 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,040 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45713
2024-01-07 06:26:10,040 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45713
2024-01-07 06:26:10,040 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36783
2024-01-07 06:26:10,040 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,040 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,040 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,040 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,040 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_5x_2031
2024-01-07 06:26:10,041 - distributed.worker - INFO - Starting Worker plugin PreImport-c8ec3254-865f-4e0f-bc93-427131c071e0
2024-01-07 06:26:10,041 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-060a3a86-2583-4031-b878-8eca91fc515f
2024-01-07 06:26:10,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,041 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1aa4d7cb-d6de-44f3-a736-f747b997f4b3
2024-01-07 06:26:10,042 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41057
2024-01-07 06:26:10,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41057
2024-01-07 06:26:10,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40673
2024-01-07 06:26:10,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,042 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,042 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,042 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-or0r5gg4
2024-01-07 06:26:10,042 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8c8d5dd0-2e05-4d6d-87f0-5c8b006d654b
2024-01-07 06:26:10,043 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35455
2024-01-07 06:26:10,043 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35455
2024-01-07 06:26:10,043 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37633
2024-01-07 06:26:10,043 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34973
2024-01-07 06:26:10,043 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,043 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34973
2024-01-07 06:26:10,043 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,043 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44383
2024-01-07 06:26:10,043 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,043 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,043 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-08b7qtii
2024-01-07 06:26:10,043 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yp4ya2j0
2024-01-07 06:26:10,043 - distributed.worker - INFO - Starting Worker plugin PreImport-708e951e-9190-48a7-8ced-3ec225cb12b0
2024-01-07 06:26:10,044 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27d7b3ae-6b94-42ae-a350-e302ec5a879f
2024-01-07 06:26:10,044 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0097c178-4acb-4fb9-8c31-229827187fb6
2024-01-07 06:26:10,044 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01f1f078-f1d7-4d4a-8c69-4e5e8dda6bff
2024-01-07 06:26:10,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,119 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,120 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33093
2024-01-07 06:26:10,120 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33093
2024-01-07 06:26:10,120 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45205
2024-01-07 06:26:10,120 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,120 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,120 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,120 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,120 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aa96cbic
2024-01-07 06:26:10,120 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f78d004c-fb4f-43c1-b492-2246c54d5f7d
2024-01-07 06:26:10,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:10,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:10,125 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,126 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36367
2024-01-07 06:26:10,126 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36367
2024-01-07 06:26:10,126 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41087
2024-01-07 06:26:10,126 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,126 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,126 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,126 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,126 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rgwwaxx7
2024-01-07 06:26:10,126 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d7721c5-2480-4b78-a2a6-a79e4792798f
2024-01-07 06:26:10,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,128 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44027
2024-01-07 06:26:10,128 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44027
2024-01-07 06:26:10,128 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42759
2024-01-07 06:26:10,128 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,128 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,129 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,129 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,129 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kx2h_oxg
2024-01-07 06:26:10,129 - distributed.worker - INFO - Starting Worker plugin RMMSetup-edbe4639-c69b-4087-837f-a738a90f8f20
2024-01-07 06:26:10,129 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:10,130 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38369
2024-01-07 06:26:10,130 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38369
2024-01-07 06:26:10,130 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32957
2024-01-07 06:26:10,130 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:10,130 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:10,130 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:10,130 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:26:10,130 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-af3ez481
2024-01-07 06:26:10,131 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3ec4ddfa-50d6-4d05-86cd-e21f5e2fa8c8
2024-01-07 06:26:11,956 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:11,986 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35455', status: init, memory: 0, processing: 0>
2024-01-07 06:26:11,987 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35455
2024-01-07 06:26:11,987 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34762
2024-01-07 06:26:11,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:11,989 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:11,989 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:11,990 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,002 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1fed4620-0aa6-49e4-a407-bb635b9ce9f4
2024-01-07 06:26:12,002 - distributed.worker - INFO - Starting Worker plugin PreImport-d69b88e0-0091-4c2f-aa10-af490d2bbba2
2024-01-07 06:26:12,003 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,026 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34973', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,026 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34973
2024-01-07 06:26:12,027 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34764
2024-01-07 06:26:12,027 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,028 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,028 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,030 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,042 - distributed.worker - INFO - Starting Worker plugin PreImport-8f1d407d-70c7-4c60-8881-484b0a5c5cdc
2024-01-07 06:26:12,043 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed874134-0650-45ae-bfdb-ddfc60a435fe
2024-01-07 06:26:12,044 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,049 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,079 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a4d5a5c8-c309-4dac-b2e9-672a5fbb6270
2024-01-07 06:26:12,079 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84cf70d5-0e13-4e1d-b80b-910eb8a3532a
2024-01-07 06:26:12,080 - distributed.worker - INFO - Starting Worker plugin PreImport-eb5ad243-1803-4fa3-b8e4-f08dcfd41959
2024-01-07 06:26:12,080 - distributed.worker - INFO - Starting Worker plugin PreImport-d31d9533-0f1d-48cd-a15d-075c865872e1
2024-01-07 06:26:12,080 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41057', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,081 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,081 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41057
2024-01-07 06:26:12,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34770
2024-01-07 06:26:12,081 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,083 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,084 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45713', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,084 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45713
2024-01-07 06:26:12,084 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34776
2024-01-07 06:26:12,084 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,084 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,087 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,087 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,088 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de1b50ac-8b2f-4282-a161-0c16152b5513
2024-01-07 06:26:12,089 - distributed.worker - INFO - Starting Worker plugin PreImport-8284445f-50ae-4c9b-b6ce-afaa41bf8240
2024-01-07 06:26:12,089 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,089 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,091 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-17c6fd69-d068-43d9-9f80-ff08facaf29b
2024-01-07 06:26:12,092 - distributed.worker - INFO - Starting Worker plugin PreImport-ff6efdbe-a78a-4a7e-ab3f-eeb52e4e78eb
2024-01-07 06:26:12,093 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,105 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33093', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,105 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33093
2024-01-07 06:26:12,106 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34788
2024-01-07 06:26:12,107 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,107 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,108 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,109 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,113 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36367', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,114 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36367
2024-01-07 06:26:12,114 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34806
2024-01-07 06:26:12,115 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,116 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,120 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44027', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,121 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44027
2024-01-07 06:26:12,121 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34792
2024-01-07 06:26:12,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,125 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,125 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,128 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,133 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38369', status: init, memory: 0, processing: 0>
2024-01-07 06:26:12,133 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38369
2024-01-07 06:26:12,133 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34820
2024-01-07 06:26:12,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:12,136 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:12,136 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:12,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:12,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,206 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,207 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,208 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,208 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,208 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:26:12,221 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,221 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,221 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,221 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,222 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:12,226 - distributed.scheduler - INFO - Remove client Client-a364aea7-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:12,226 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43516; closing.
2024-01-07 06:26:12,226 - distributed.scheduler - INFO - Remove client Client-a364aea7-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:12,226 - distributed.scheduler - INFO - Close client connection: Client-a364aea7-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:12,227 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33047'. Reason: nanny-close
2024-01-07 06:26:12,228 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,228 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41211'. Reason: nanny-close
2024-01-07 06:26:12,229 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,229 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38545'. Reason: nanny-close
2024-01-07 06:26:12,229 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41057. Reason: nanny-close
2024-01-07 06:26:12,229 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,229 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39231'. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45713. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44849'. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35455. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34525'. Reason: nanny-close
2024-01-07 06:26:12,230 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34973. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46277'. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38369. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43437'. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,231 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:12,231 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44027. Reason: nanny-close
2024-01-07 06:26:12,232 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36367. Reason: nanny-close
2024-01-07 06:26:12,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,232 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33093. Reason: nanny-close
2024-01-07 06:26:12,233 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34764; closing.
2024-01-07 06:26:12,233 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,233 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,233 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34770; closing.
2024-01-07 06:26:12,233 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,234 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,234 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,234 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,234 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34973', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2343516')
2024-01-07 06:26:12,234 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,234 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:12,235 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2349808')
2024-01-07 06:26:12,235 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34776; closing.
2024-01-07 06:26:12,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34762; closing.
2024-01-07 06:26:12,235 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,236 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,236 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45713', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2366285')
2024-01-07 06:26:12,237 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35455', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2370179')
2024-01-07 06:26:12,237 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:12,237 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34820; closing.
2024-01-07 06:26:12,237 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34806; closing.
2024-01-07 06:26:12,237 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34792; closing.
2024-01-07 06:26:12,238 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38369', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2385726')
2024-01-07 06:26:12,239 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36367', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2389355')
2024-01-07 06:26:12,239 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44027', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.2392666')
2024-01-07 06:26:12,239 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34788; closing.
2024-01-07 06:26:12,239 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34762>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:26:12,241 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34820>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34820>: Stream is closed
2024-01-07 06:26:12,241 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34792>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34792>: Stream is closed
2024-01-07 06:26:12,241 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34776>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:26:12,242 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33093', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608772.242383')
2024-01-07 06:26:12,242 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:26:13,144 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:26:13,145 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:26:13,145 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:26:13,146 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:26:13,146 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-07 06:26:15,253 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:15,257 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:26:15,260 - distributed.scheduler - INFO - State start
2024-01-07 06:26:15,282 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:15,283 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:26:15,283 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:26:15,284 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:26:15,366 - distributed.scheduler - INFO - Receive client connection: Client-a7c6d15d-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:15,381 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34932
2024-01-07 06:26:15,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39775'
2024-01-07 06:26:17,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:17,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:17,174 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:17,175 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38237
2024-01-07 06:26:17,175 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38237
2024-01-07 06:26:17,175 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36149
2024-01-07 06:26:17,175 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:17,175 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:17,175 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:17,175 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:26:17,175 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1fql2m9e
2024-01-07 06:26:17,176 - distributed.worker - INFO - Starting Worker plugin PreImport-09abd77c-3b26-4857-9a48-dfc67b0a3baa
2024-01-07 06:26:17,176 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c06928ed-b330-4591-b039-757f46d9e280
2024-01-07 06:26:17,176 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d50987f2-a19a-4864-bb63-cc49dca8ce72
2024-01-07 06:26:17,462 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:17,601 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38237', status: init, memory: 0, processing: 0>
2024-01-07 06:26:17,602 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38237
2024-01-07 06:26:17,602 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34954
2024-01-07 06:26:17,603 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:17,604 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:17,604 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:17,605 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:17,684 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:26:17,688 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:17,690 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:17,692 - distributed.scheduler - INFO - Remove client Client-a7c6d15d-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:17,692 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34932; closing.
2024-01-07 06:26:17,692 - distributed.scheduler - INFO - Remove client Client-a7c6d15d-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:17,693 - distributed.scheduler - INFO - Close client connection: Client-a7c6d15d-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:17,693 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39775'. Reason: nanny-close
2024-01-07 06:26:17,694 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:17,695 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38237. Reason: nanny-close
2024-01-07 06:26:17,696 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:17,697 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34954; closing.
2024-01-07 06:26:17,697 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38237', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608777.6972363')
2024-01-07 06:26:17,697 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:26:17,698 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:18,359 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:26:18,359 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:26:18,360 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:26:18,361 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:26:18,361 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-07 06:26:20,494 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:20,498 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-07 06:26:20,502 - distributed.scheduler - INFO - State start
2024-01-07 06:26:20,524 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:26:20,525 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:26:20,526 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-07 06:26:20,526 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:26:20,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39691'
2024-01-07 06:26:22,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:26:22,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:26:22,353 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:26:22,353 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32973
2024-01-07 06:26:22,354 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32973
2024-01-07 06:26:22,354 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39555
2024-01-07 06:26:22,354 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:26:22,354 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:22,354 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:26:22,354 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:26:22,354 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u6vgtj2f
2024-01-07 06:26:22,354 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e768b9e7-0687-4c4e-ba54-d3c9db10866d
2024-01-07 06:26:22,639 - distributed.worker - INFO - Starting Worker plugin PreImport-263b8add-b99c-4f9d-874f-f742ea6bbc7d
2024-01-07 06:26:22,639 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-29666c61-acb8-4a3a-8731-c1f614f637ee
2024-01-07 06:26:22,640 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:22,702 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32973', status: init, memory: 0, processing: 0>
2024-01-07 06:26:22,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32973
2024-01-07 06:26:22,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50764
2024-01-07 06:26:22,718 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:26:22,719 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:26:22,719 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:26:22,720 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:26:24,083 - distributed.scheduler - INFO - Receive client connection: Client-aae2b4bc-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:24,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50772
2024-01-07 06:26:24,089 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-07 06:26:24,093 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:26:24,097 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:24,099 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:26:24,101 - distributed.scheduler - INFO - Remove client Client-aae2b4bc-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:24,101 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50772; closing.
2024-01-07 06:26:24,101 - distributed.scheduler - INFO - Remove client Client-aae2b4bc-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:24,102 - distributed.scheduler - INFO - Close client connection: Client-aae2b4bc-ad25-11ee-ba79-d8c49764f6bb
2024-01-07 06:26:24,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39691'. Reason: nanny-close
2024-01-07 06:26:24,103 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:26:24,104 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32973. Reason: nanny-close
2024-01-07 06:26:24,106 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50764; closing.
2024-01-07 06:26:24,106 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:26:24,106 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32973', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704608784.1066523')
2024-01-07 06:26:24,106 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:26:24,108 - distributed.nanny - INFO - Worker closed
2024-01-07 06:26:24,768 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:26:24,768 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:26:24,769 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:26:24,770 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:26:24,770 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] 2024-01-07 06:28:03,219 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] 2024-01-07 06:28:30,531 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1557, in _connect
    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] [1704608932.700734] [dgx13:70452:0]            sock.c:481  UCX  ERROR bind(fd=162 addr=0.0.0.0:50276) failed: Address already in use
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] [1704608940.411913] [dgx13:70571:0]            sock.c:481  UCX  ERROR bind(fd=168 addr=0.0.0.0:55048) failed: Address already in use
2024-01-07 06:29:09,728 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] [1704608980.221172] [dgx13:71229:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:42814) failed: Address already in use
[1704608980.930172] [dgx13:71234:0]            sock.c:481  UCX  ERROR bind(fd=155 addr=0.0.0.0:48558) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37893 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35633 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36661 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39873 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37393 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40521 instead
  warnings.warn(
2024-01-07 06:32:16,855 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 360, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 443, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46273 instead
  warnings.warn(
[1704609140.905508] [dgx13:73943:0]            sock.c:481  UCX  ERROR bind(fd=125 addr=0.0.0.0:38648) failed: Address already in use
[1704609144.822066] [dgx13:74030:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:55602) failed: Address already in use
[1704609144.822139] [dgx13:74030:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:33798) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42273 instead
  warnings.warn(
[1704609158.974546] [dgx13:74268:0]            sock.c:481  UCX  ERROR bind(fd=125 addr=0.0.0.0:45284) failed: Address already in use
[1704609163.838804] [dgx13:74364:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:58276) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32891 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37163 instead
  warnings.warn(
[1704609204.851241] [dgx13:75170:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:45946) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44529 instead
  warnings.warn(
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-5376' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40221 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46559 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33209 instead
  warnings.warn(
[1704609315.706883] [dgx13:76562:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:54704) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37279 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38801 instead
  warnings.warn(
[1704609375.632353] [dgx13:77383:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:48436) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34153 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37409 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46317 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37057 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37041 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41647 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45619 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40719 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41533 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41171 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36779 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46137 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35133 instead
  warnings.warn(
[1704609676.254911] [dgx13:82191:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:56197) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43277 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35263 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40327 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35403 instead
  warnings.warn(
[1704609783.688902] [dgx13:83698:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:56168) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34211 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38371 instead
  warnings.warn(
[1704609851.747729] [dgx13:84403:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:42936) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45555 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37485 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40585 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35235 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37331 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38901 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45357 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42097 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37155 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45959 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33425 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38075 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42361 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42315 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34599 instead
  warnings.warn(
[1704610049.833882] [dgx13:87513:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:37178) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46459 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45451 instead
  warnings.warn(
[1704610079.138560] [dgx13:88000:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:39746) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43653 instead
  warnings.warn(
[1704610094.103535] [dgx13:88210:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:33329) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43323 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38383 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36775 instead
  warnings.warn(
[1704610141.718042] [dgx13:88891:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:36464) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46349 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41603 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33541 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34633 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36841 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33469 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36667 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45851 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] [1704610245.453551] [dgx13:64121:0]            sock.c:481  UCX  ERROR bind(fd=245 addr=0.0.0.0:50948) failed: Address already in use
[1704610250.555159] [dgx13:90101:0]            sock.c:481  UCX  ERROR bind(fd=162 addr=0.0.0.0:41634) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] 2024-01-07 06:50:58,382 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
[1704610259.546834] [dgx13:64121] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
[1704610259.546917] [dgx13:64121] UCXPY  WARNING Listener object is being destroyed, but 1 client handler(s) is(are) still alive. This usually indicates the Listener was prematurely destroyed.
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] [1704610259.677602] [dgx13:64121:0]            sock.c:481  UCX  ERROR bind(fd=249 addr=0.0.0.0:37694) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-07 06:51:24,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:51:24,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:51:24,921 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:24,922 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35907
2024-01-07 06:51:24,922 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35907
2024-01-07 06:51:24,922 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45713
2024-01-07 06:51:24,922 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,922 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,922 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:24,923 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xfkp6g49
2024-01-07 06:51:24,923 - distributed.worker - INFO - Starting Worker plugin RMMSetup-89b36ef6-f568-4f78-ae97-4328d677464e
2024-01-07 06:51:24,923 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-813f515d-7c7e-40cd-bf37-c06dab89e7de
2024-01-07 06:51:24,923 - distributed.worker - INFO - Starting Worker plugin PreImport-30577f46-3645-41d1-a2cb-41eda8fe9011
2024-01-07 06:51:24,923 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:24,950 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41739
2024-01-07 06:51:24,951 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41739
2024-01-07 06:51:24,951 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39457
2024-01-07 06:51:24,951 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,951 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,951 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:24,951 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b48ithar
2024-01-07 06:51:24,951 - distributed.worker - INFO - Starting Worker plugin PreImport-75e45872-8608-4ca2-be6c-4abe93f4895b
2024-01-07 06:51:24,951 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15cc01b9-0144-46b6-9be3-c57217fd5a11
2024-01-07 06:51:24,952 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21c8369f-a273-4bf6-b981-b75697a9e0ab
2024-01-07 06:51:24,952 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,953 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:24,954 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45529
2024-01-07 06:51:24,954 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45529
2024-01-07 06:51:24,954 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34861
2024-01-07 06:51:24,954 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,954 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,954 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:24,954 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l5gsq8xd
2024-01-07 06:51:24,955 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8498bff-abf4-4372-8298-f8f4a9290387
2024-01-07 06:51:24,955 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-43e68f80-c962-46dd-bc4e-36f2f4231da9
2024-01-07 06:51:24,955 - distributed.worker - INFO - Starting Worker plugin PreImport-e090c76c-880b-4c19-92d8-559596ef9894
2024-01-07 06:51:24,955 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,961 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:24,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37665
2024-01-07 06:51:24,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37665
2024-01-07 06:51:24,961 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34487
2024-01-07 06:51:24,962 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,962 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,962 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:24,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8qxaluty
2024-01-07 06:51:24,962 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ca0b9035-928e-4ffe-b34f-0d04a810a8e3
2024-01-07 06:51:24,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab59c8b0-0c19-4230-bc98-ea608e1e56e1
2024-01-07 06:51:24,962 - distributed.worker - INFO - Starting Worker plugin PreImport-c4d2ffb1-d561-422a-bc27-a38cb0c48b4d
2024-01-07 06:51:24,963 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,993 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:24,994 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,994 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,995 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:24,995 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:24,995 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33261
2024-01-07 06:51:24,995 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33261
2024-01-07 06:51:24,996 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36037
2024-01-07 06:51:24,996 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:24,996 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:24,996 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:24,996 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j793iswt
2024-01-07 06:51:24,996 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1dbd766a-8e90-43c6-abe7-5aadfd6879c3
2024-01-07 06:51:24,996 - distributed.worker - INFO - Starting Worker plugin PreImport-44df31ed-e159-42e8-9634-2a051cc75070
2024-01-07 06:51:24,996 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9eb9c00c-79f3-4fb8-b46a-ad5d2de8c452
2024-01-07 06:51:24,996 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,005 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:25,006 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45079
2024-01-07 06:51:25,006 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45079
2024-01-07 06:51:25,006 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42869
2024-01-07 06:51:25,006 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,006 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,006 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:25,006 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w48s6_so
2024-01-07 06:51:25,006 - distributed.worker - INFO - Starting Worker plugin PreImport-5f50f197-3e4c-4f50-a2cf-4bc9548709be
2024-01-07 06:51:25,007 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d44d6912-5de1-4dbf-a4bc-03a4a057e092
2024-01-07 06:51:25,007 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7f1794d-3680-4928-8f0a-4b9c87fa3db8
2024-01-07 06:51:25,007 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,154 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:25,155 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44407
2024-01-07 06:51:25,155 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44407
2024-01-07 06:51:25,155 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44101
2024-01-07 06:51:25,155 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,155 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,155 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:25,156 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r9bbnmf8
2024-01-07 06:51:25,156 - distributed.worker - INFO - Starting Worker plugin PreImport-d625839e-0ace-499e-a9fa-99ebd1dd330c
2024-01-07 06:51:25,156 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bbefe48d-cedd-4113-952c-a1817572c00f
2024-01-07 06:51:25,156 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-987677bf-eb57-4329-87ec-5fba86e8abab
2024-01-07 06:51:25,156 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,162 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:51:25,163 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37603
2024-01-07 06:51:25,163 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37603
2024-01-07 06:51:25,163 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46093
2024-01-07 06:51:25,163 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,163 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,163 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:51:25,164 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4j8m6k0c
2024-01-07 06:51:25,164 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d09cd15d-1531-487e-a529-401609eb0038
2024-01-07 06:51:25,165 - distributed.worker - INFO - Starting Worker plugin PreImport-73f7b947-ae05-4258-8026-636bbaed4c21
2024-01-07 06:51:25,165 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0d828aac-0afc-46ea-980a-5bc856396907
2024-01-07 06:51:25,165 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,181 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,181 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,182 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,239 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,240 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,258 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,259 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,259 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,260 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,385 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,386 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,386 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,387 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,392 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,393 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,393 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,394 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,453 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,454 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,454 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,455 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:51:25,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,456 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33615
2024-01-07 06:51:25,456 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:51:25,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33615
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,477 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,478 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,478 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:51:25,483 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45079. Reason: nanny-close
2024-01-07 06:51:25,484 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35907. Reason: nanny-close
2024-01-07 06:51:25,484 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41739. Reason: nanny-close
2024-01-07 06:51:25,485 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,485 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37665. Reason: nanny-close
2024-01-07 06:51:25,486 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45529. Reason: nanny-close
2024-01-07 06:51:25,486 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,486 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33261. Reason: nanny-close
2024-01-07 06:51:25,486 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,487 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,487 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44407. Reason: nanny-close
2024-01-07 06:51:25,487 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,487 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,487 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,487 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37603. Reason: nanny-close
2024-01-07 06:51:25,488 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,488 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,488 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,488 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,489 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,489 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,490 - distributed.nanny - INFO - Worker closed
2024-01-07 06:51:25,490 - distributed.core - INFO - Connection to tcp://127.0.0.1:33615 has been closed.
2024-01-07 06:51:25,492 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-07 06:52:00,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:00,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:00,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:00,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32973
2024-01-07 06:52:00,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32973
2024-01-07 06:52:00,973 - distributed.worker - INFO -           Worker name:                          0
2024-01-07 06:52:00,973 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39385
2024-01-07 06:52:00,973 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:40195
2024-01-07 06:52:00,974 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:00,974 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:00,974 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:52:00,974 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ebnagb77
2024-01-07 06:52:00,974 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-acc41267-c764-4e3c-a2ff-8d8ad658346b
2024-01-07 06:52:00,974 - distributed.worker - INFO - Starting Worker plugin PreImport-b8268bc5-b1bc-4504-9ba1-4e8f75d37ffc
2024-01-07 06:52:00,978 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-07 06:52:00,978 - distributed.worker - INFO - Starting Worker plugin RMMSetup-547ffd21-0aa2-4b4a-a5f5-a22cd9add8f7
2024-01-07 06:52:00,978 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32973. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-07 06:52:00,978 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-07 06:52:00,980 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-07 06:52:06,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:52:06,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:52:06,724 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,724 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35045
2024-01-07 06:52:06,724 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35045
2024-01-07 06:52:06,725 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43043
2024-01-07 06:52:06,725 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,725 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,725 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,725 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,725 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nj2iuw1u
2024-01-07 06:52:06,725 - distributed.worker - INFO - Starting Worker plugin PreImport-8ebf0fd2-2544-40c6-a89e-534dc4c6bb7e
2024-01-07 06:52:06,725 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ca9666d-b8cb-426a-91c0-d717433e1873
2024-01-07 06:52:06,725 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b26ae3a7-da89-487e-952c-3cdf28319455
2024-01-07 06:52:06,726 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,741 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,742 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35473
2024-01-07 06:52:06,742 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35473
2024-01-07 06:52:06,742 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38385
2024-01-07 06:52:06,742 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,742 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,742 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,743 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,743 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7hp_mdn1
2024-01-07 06:52:06,743 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c9d65fb-383b-48cb-9339-a4543173ac20
2024-01-07 06:52:06,743 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd182c99-df8b-4a8d-9a44-937d576694a9
2024-01-07 06:52:06,743 - distributed.worker - INFO - Starting Worker plugin PreImport-c4bd44d0-847b-42dc-92fc-dd95c88d64a4
2024-01-07 06:52:06,743 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,761 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,761 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38329
2024-01-07 06:52:06,762 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38329
2024-01-07 06:52:06,762 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45999
2024-01-07 06:52:06,762 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,762 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,762 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,762 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,762 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3882xub4
2024-01-07 06:52:06,762 - distributed.worker - INFO - Starting Worker plugin PreImport-d973d201-0787-4c8d-b869-c2dc0f937db0
2024-01-07 06:52:06,762 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d12cb29d-44ba-4328-8193-2f820baf3e8c
2024-01-07 06:52:06,762 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36d2cc84-6711-436e-b3f9-6c844d15dcb7
2024-01-07 06:52:06,763 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,783 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,783 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45163
2024-01-07 06:52:06,783 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45163
2024-01-07 06:52:06,784 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39001
2024-01-07 06:52:06,784 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,784 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,784 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,784 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,784 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9mqovr7t
2024-01-07 06:52:06,784 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-997c5be9-51a6-46db-a7ad-0edb62279f90
2024-01-07 06:52:06,784 - distributed.worker - INFO - Starting Worker plugin PreImport-f370e1db-9102-45ab-90c3-fa304763dbef
2024-01-07 06:52:06,784 - distributed.worker - INFO - Starting Worker plugin RMMSetup-48f56415-5d57-4a76-9f7a-b9de6f899d1f
2024-01-07 06:52:06,785 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,803 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,804 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44621
2024-01-07 06:52:06,804 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44621
2024-01-07 06:52:06,804 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44459
2024-01-07 06:52:06,804 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,804 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,804 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,804 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,804 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-daau34jh
2024-01-07 06:52:06,804 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-785bdf98-1f88-47d0-b74a-9a79a18e6bfe
2024-01-07 06:52:06,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9081d685-a0a4-4a91-82c8-4ede53d42e8d
2024-01-07 06:52:06,804 - distributed.worker - INFO - Starting Worker plugin PreImport-47d2d1d4-ceb5-4eb1-b556-36abe33071ac
2024-01-07 06:52:06,805 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,808 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,809 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,809 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,828 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,829 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41045
2024-01-07 06:52:06,829 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41045
2024-01-07 06:52:06,829 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37633
2024-01-07 06:52:06,829 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,829 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,829 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,830 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,830 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rk9v5ar4
2024-01-07 06:52:06,830 - distributed.worker - INFO - Starting Worker plugin PreImport-4699be0e-3a32-4c7f-abe0-702311905d6b
2024-01-07 06:52:06,830 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e11c8c55-a4fc-4599-8bef-8033586e7e5e
2024-01-07 06:52:06,830 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e470fd56-d10e-4772-9626-c549f03043ad
2024-01-07 06:52:06,830 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,835 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36991
2024-01-07 06:52:06,836 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36991
2024-01-07 06:52:06,836 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44465
2024-01-07 06:52:06,836 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,836 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,836 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,836 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ygyysju2
2024-01-07 06:52:06,836 - distributed.worker - INFO - Starting Worker plugin PreImport-ceebb76b-aa06-4bc5-bde3-4a20d82463a9
2024-01-07 06:52:06,836 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1eb5a13d-cc04-47ea-8850-5e93bcea3a39
2024-01-07 06:52:06,836 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6d3627d0-5db1-4c05-a820-305fc012b8e2
2024-01-07 06:52:06,836 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,863 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,864 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,864 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,865 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,902 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,902 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,903 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,949 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,949 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,967 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,967 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,968 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,990 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,991 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,991 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,992 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,992 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:06,993 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,993 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,995 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:06,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:52:06,998 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38529
2024-01-07 06:52:06,998 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38529
2024-01-07 06:52:06,999 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39869
2024-01-07 06:52:06,999 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34455
2024-01-07 06:52:06,999 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:06,999 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:52:06,999 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:52:06,999 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vcs7n75e
2024-01-07 06:52:06,999 - distributed.worker - INFO - Starting Worker plugin PreImport-aca8b58d-3914-4e96-bab2-98dc4b3208c6
2024-01-07 06:52:06,999 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68efbc39-1765-4a7d-b50e-7d36a3cc9575
2024-01-07 06:52:07,000 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dee3d728-c828-441a-8647-76ef38149d60
2024-01-07 06:52:07,000 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:07,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:52:07,065 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34455
2024-01-07 06:52:07,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:52:07,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34455
2024-01-07 06:52:07,099 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35473. Reason: nanny-close
2024-01-07 06:52:07,100 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38329. Reason: nanny-close
2024-01-07 06:52:07,100 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45163. Reason: nanny-close
2024-01-07 06:52:07,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35045. Reason: nanny-close
2024-01-07 06:52:07,101 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,101 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44621. Reason: nanny-close
2024-01-07 06:52:07,102 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36991. Reason: nanny-close
2024-01-07 06:52:07,102 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,102 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41045. Reason: nanny-close
2024-01-07 06:52:07,102 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,102 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,103 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38529. Reason: nanny-close
2024-01-07 06:52:07,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,103 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,103 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,104 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,104 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,104 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,105 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,105 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,105 - distributed.core - INFO - Connection to tcp://127.0.0.1:34455 has been closed.
2024-01-07 06:52:07,106 - distributed.nanny - INFO - Worker closed
2024-01-07 06:52:07,106 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info 2024-01-07 06:53:39,333 - distributed.worker - WARNING - RMM allocation of 1.00 MiB failed, spill-on-demand couldn't find any device memory to spill.
RMM allocs: 1.00 MiB, <ProxyManager dev_limit=25.60 GiB host_limit=0.98 TiB disk=0 B(0) host=0 B(0) dev=0 B(0)>, traceback:
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 937, in _bootstrap
    self._bootstrap_inner()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/threadpoolexecutor.py", line 57, in _worker
    task.run()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/_concurrent_futures_thread.py", line 65, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1541, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2954, in apply_function
    msg = apply_function_simple(function, args, kwargs, time_delay)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2990, in apply_function_simple
    result = function(*args, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_proxify_host_file.py", line 467, in task
    rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/proxify_host_file.py", line 617, in oom
    traceback.print_stack(file=f)


2024-01-07 06:53:39,567 - distributed.worker - WARNING - Compute Failed
Key:       task-5c302f54392a5ca98adb3c55c8357b0e
Function:  task
args:      ()
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_serializer PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[numpy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[cupy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_name PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj0] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj1] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[dask] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[pickle] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[disk] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-None] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucx-None] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucx-send_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucx-send_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucxx-None] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucxx-send_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[ucxx-send_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_disk_objects[True-tcp] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_disk_objects[True-ucx] /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
