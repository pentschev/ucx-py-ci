============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-11-18 06:35:23,639 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:23,644 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41465 instead
  warnings.warn(
2023-11-18 06:35:23,649 - distributed.scheduler - INFO - State start
2023-11-18 06:35:23,674 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:23,675 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-18 06:35:23,676 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41465/status
2023-11-18 06:35:23,676 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:35:23,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36919'
2023-11-18 06:35:23,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35951'
2023-11-18 06:35:23,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45087'
2023-11-18 06:35:23,763 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37779'
2023-11-18 06:35:23,989 - distributed.scheduler - INFO - Receive client connection: Client-a5d4afa9-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:24,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35080
2023-11-18 06:35:25,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:25,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:25,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:25,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:25,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:25,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:25,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:25,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:25,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:25,487 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:25,488 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:25,488 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-11-18 06:35:25,494 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43995
2023-11-18 06:35:25,494 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43995
2023-11-18 06:35:25,494 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35329
2023-11-18 06:35:25,494 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-18 06:35:25,494 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:25,494 - distributed.worker - INFO -               Threads:                          4
2023-11-18 06:35:25,494 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-18 06:35:25,494 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-qxtxpd_4
2023-11-18 06:35:25,494 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1a25c01b-3ac4-49b3-8300-9c6da6dae011
2023-11-18 06:35:25,495 - distributed.worker - INFO - Starting Worker plugin PreImport-875dba05-fa1a-4659-b6be-9c263cc6277d
2023-11-18 06:35:25,496 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4eea743e-7938-4f6b-aa84-53f9c65ba0ce
2023-11-18 06:35:25,496 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:26,143 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43995', status: init, memory: 0, processing: 0>
2023-11-18 06:35:26,145 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43995
2023-11-18 06:35:26,145 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35098
2023-11-18 06:35:26,146 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:26,147 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-18 06:35:26,147 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:26,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-18 06:35:27,112 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34807
2023-11-18 06:35:27,116 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34807
2023-11-18 06:35:27,116 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39685
2023-11-18 06:35:27,116 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,116 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,117 - distributed.worker - INFO -               Threads:                          4
2023-11-18 06:35:27,117 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-18 06:35:27,117 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-y160ujva
2023-11-18 06:35:27,119 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-60fc99c1-18a0-43f5-b3f7-7bbf8080f4f9
2023-11-18 06:35:27,120 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6c3c1760-427a-42e8-8395-99de07dde0da
2023-11-18 06:35:27,120 - distributed.worker - INFO - Starting Worker plugin PreImport-75f3693e-4fd7-46a1-9076-aedfb324d258
2023-11-18 06:35:27,120 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,126 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42177
2023-11-18 06:35:27,127 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42177
2023-11-18 06:35:27,127 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44223
2023-11-18 06:35:27,127 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,127 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,127 - distributed.worker - INFO -               Threads:                          4
2023-11-18 06:35:27,127 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-18 06:35:27,127 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-k174i2d8
2023-11-18 06:35:27,128 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7d9bb472-d80a-430c-99ea-ec46b6e66f35
2023-11-18 06:35:27,128 - distributed.worker - INFO - Starting Worker plugin PreImport-705a931e-0772-453d-bd26-2d64ea5a4fcf
2023-11-18 06:35:27,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e321c1f3-85a9-42fc-9b40-eca13138d6d4
2023-11-18 06:35:27,128 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45069
2023-11-18 06:35:27,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45069
2023-11-18 06:35:27,135 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41349
2023-11-18 06:35:27,135 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,135 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,135 - distributed.worker - INFO -               Threads:                          4
2023-11-18 06:35:27,135 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-18 06:35:27,135 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-0db5jcml
2023-11-18 06:35:27,136 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84960a9d-7731-4de7-990d-658afe8115bd
2023-11-18 06:35:27,136 - distributed.worker - INFO - Starting Worker plugin PreImport-0361dbf7-5698-4048-8405-588a02a9b9a3
2023-11-18 06:35:27,136 - distributed.worker - INFO - Starting Worker plugin RMMSetup-77ab9a7c-40bc-42a7-9ae6-82e404bd0946
2023-11-18 06:35:27,136 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,146 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34807', status: init, memory: 0, processing: 0>
2023-11-18 06:35:27,147 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34807
2023-11-18 06:35:27,147 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35104
2023-11-18 06:35:27,148 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:27,149 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,149 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-18 06:35:27,162 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42177', status: init, memory: 0, processing: 0>
2023-11-18 06:35:27,163 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42177
2023-11-18 06:35:27,163 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35116
2023-11-18 06:35:27,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45069', status: init, memory: 0, processing: 0>
2023-11-18 06:35:27,164 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:27,164 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45069
2023-11-18 06:35:27,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35124
2023-11-18 06:35:27,165 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,165 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,165 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:27,166 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-18 06:35:27,166 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:27,167 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-18 06:35:27,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-18 06:35:27,202 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-18 06:35:27,202 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-18 06:35:27,202 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-18 06:35:27,202 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-18 06:35:27,207 - distributed.scheduler - INFO - Remove client Client-a5d4afa9-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:27,207 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35080; closing.
2023-11-18 06:35:27,208 - distributed.scheduler - INFO - Remove client Client-a5d4afa9-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:27,208 - distributed.scheduler - INFO - Close client connection: Client-a5d4afa9-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:27,209 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36919'. Reason: nanny-close
2023-11-18 06:35:27,209 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:27,210 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35951'. Reason: nanny-close
2023-11-18 06:35:27,210 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:27,211 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45069. Reason: nanny-close
2023-11-18 06:35:27,211 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42177. Reason: nanny-close
2023-11-18 06:35:27,213 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-18 06:35:27,213 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35124; closing.
2023-11-18 06:35:27,213 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45069', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289327.2134085')
2023-11-18 06:35:27,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45087'. Reason: nanny-close
2023-11-18 06:35:27,213 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-18 06:35:27,214 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:27,214 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:27,214 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35116; closing.
2023-11-18 06:35:27,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37779'. Reason: nanny-close
2023-11-18 06:35:27,214 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:27,214 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42177', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289327.214875')
2023-11-18 06:35:27,215 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34807. Reason: nanny-close
2023-11-18 06:35:27,215 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:27,215 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43995. Reason: nanny-close
2023-11-18 06:35:27,216 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-18 06:35:27,216 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35104; closing.
2023-11-18 06:35:27,217 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289327.217111')
2023-11-18 06:35:27,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-18 06:35:27,218 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35098; closing.
2023-11-18 06:35:27,218 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:27,218 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43995', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289327.2182896')
2023-11-18 06:35:27,218 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:35:27,219 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:28,426 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:35:28,427 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:35:28,428 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:35:28,429 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-18 06:35:28,430 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-11-18 06:35:30,724 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:30,729 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44393 instead
  warnings.warn(
2023-11-18 06:35:30,732 - distributed.scheduler - INFO - State start
2023-11-18 06:35:30,757 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:30,758 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:35:30,759 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44393/status
2023-11-18 06:35:30,760 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:35:30,867 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33649'
2023-11-18 06:35:30,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34777'
2023-11-18 06:35:30,899 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43319'
2023-11-18 06:35:30,901 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45083'
2023-11-18 06:35:30,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34893'
2023-11-18 06:35:30,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40835'
2023-11-18 06:35:30,927 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33885'
2023-11-18 06:35:30,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35329'
2023-11-18 06:35:32,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,826 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,836 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,873 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,874 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,875 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:32,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:32,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:32,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:33,906 - distributed.scheduler - INFO - Receive client connection: Client-aa2c36ad-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:33,921 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52934
2023-11-18 06:35:37,587 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40263
2023-11-18 06:35:37,588 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40263
2023-11-18 06:35:37,588 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37685
2023-11-18 06:35:37,588 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,588 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,589 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,589 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t93kkz6p
2023-11-18 06:35:37,589 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c81e9192-209c-4a10-92a4-33b78f29faf5
2023-11-18 06:35:37,702 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42887
2023-11-18 06:35:37,703 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42887
2023-11-18 06:35:37,703 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40951
2023-11-18 06:35:37,703 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,703 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,704 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,704 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,704 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5io4fg1p
2023-11-18 06:35:37,704 - distributed.worker - INFO - Starting Worker plugin RMMSetup-983b776c-f523-4c75-a912-e0f16620b1b4
2023-11-18 06:35:37,705 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33179
2023-11-18 06:35:37,706 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33179
2023-11-18 06:35:37,706 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46559
2023-11-18 06:35:37,706 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,706 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,706 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,706 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,706 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-na82zw5o
2023-11-18 06:35:37,707 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b804d70e-292c-4027-82c7-fad8bc79c0ae
2023-11-18 06:35:37,707 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f171679f-e365-4389-9c98-466fac86714d
2023-11-18 06:35:37,710 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46509
2023-11-18 06:35:37,711 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46509
2023-11-18 06:35:37,711 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44823
2023-11-18 06:35:37,711 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,712 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,712 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,712 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,712 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zprcy2gz
2023-11-18 06:35:37,712 - distributed.worker - INFO - Starting Worker plugin PreImport-329ca920-2e4c-4354-b3cc-ea99bcace5fc
2023-11-18 06:35:37,712 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41785
2023-11-18 06:35:37,712 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41785
2023-11-18 06:35:37,712 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4724e383-d3e6-489b-ba43-1dd17d4726b1
2023-11-18 06:35:37,712 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46505
2023-11-18 06:35:37,713 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,713 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,713 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,713 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,713 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vj2gicze
2023-11-18 06:35:37,713 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2bdc8aa9-b8fd-4b5d-8815-cf11eccf9a16
2023-11-18 06:35:37,727 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f95b0c18-d07d-41de-aabb-67390dd80309
2023-11-18 06:35:37,727 - distributed.worker - INFO - Starting Worker plugin PreImport-45d9cb2a-6105-4480-a398-638e1f99ffa4
2023-11-18 06:35:37,731 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44691
2023-11-18 06:35:37,740 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44691
2023-11-18 06:35:37,740 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36223
2023-11-18 06:35:37,740 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,740 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,740 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,740 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,741 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lnbg3mam
2023-11-18 06:35:37,741 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2605c7fb-9763-4529-a463-a61aab53b76a
2023-11-18 06:35:37,764 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40263', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,766 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40263
2023-11-18 06:35:37,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52948
2023-11-18 06:35:37,768 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,769 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,769 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,769 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37637
2023-11-18 06:35:37,770 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37637
2023-11-18 06:35:37,770 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36079
2023-11-18 06:35:37,770 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,770 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,768 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44731
2023-11-18 06:35:37,770 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44731
2023-11-18 06:35:37,770 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,770 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40465
2023-11-18 06:35:37,770 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,770 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zfc71iok
2023-11-18 06:35:37,770 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,771 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,771 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:37,771 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:37,771 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b586tvzk
2023-11-18 06:35:37,771 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d7d6b168-0f4e-4f65-837a-5b58aea10233
2023-11-18 06:35:37,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,772 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53c7ec2a-65f2-4124-b7d1-e22fb13eb38e
2023-11-18 06:35:37,868 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3628d301-66eb-4ff1-8aa3-79c6e6409c65
2023-11-18 06:35:37,869 - distributed.worker - INFO - Starting Worker plugin PreImport-ebe7954f-6a2e-4f25-9dc8-55af2ee79eba
2023-11-18 06:35:37,869 - distributed.worker - INFO - Starting Worker plugin PreImport-0737a7fb-ce06-4934-b976-9e9491c0aae3
2023-11-18 06:35:37,869 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,869 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,877 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b664484-602b-4a95-b77c-da3af1245d5c
2023-11-18 06:35:37,877 - distributed.worker - INFO - Starting Worker plugin PreImport-e5410835-60c9-4262-8010-fdbc19ec10d6
2023-11-18 06:35:37,878 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e645789-0357-4a72-b17c-a4312c30c700
2023-11-18 06:35:37,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b4d906d-81a5-4299-88d8-94aa2642aa6e
2023-11-18 06:35:37,887 - distributed.worker - INFO - Starting Worker plugin PreImport-90ebe54c-de7e-4e20-bce5-842993c3105d
2023-11-18 06:35:37,887 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-824401b6-e3eb-47c1-ac81-17e9591072e0
2023-11-18 06:35:37,891 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,895 - distributed.worker - INFO - Starting Worker plugin PreImport-80de4776-eb1b-4769-b23e-53fd4a942d2e
2023-11-18 06:35:37,896 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,897 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2eb93da9-6419-4e11-8b29-a7db7652062a
2023-11-18 06:35:37,899 - distributed.worker - INFO - Starting Worker plugin PreImport-aec99d3d-ce0d-494f-be20-50d2a4a74a83
2023-11-18 06:35:37,899 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,899 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42887', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,900 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42887
2023-11-18 06:35:37,900 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52962
2023-11-18 06:35:37,901 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,902 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,902 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,902 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33179', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,903 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33179
2023-11-18 06:35:37,903 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52964
2023-11-18 06:35:37,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,904 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,905 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,905 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,906 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,913 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44731', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,913 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44731
2023-11-18 06:35:37,913 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52976
2023-11-18 06:35:37,915 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,916 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,916 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,916 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41785', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,917 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41785
2023-11-18 06:35:37,917 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52992
2023-11-18 06:35:37,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,919 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,925 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46509', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,925 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46509
2023-11-18 06:35:37,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53004
2023-11-18 06:35:37,927 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,928 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,928 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,930 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,932 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44691', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,933 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44691
2023-11-18 06:35:37,933 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53020
2023-11-18 06:35:37,934 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,936 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,936 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,936 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37637', status: init, memory: 0, processing: 0>
2023-11-18 06:35:37,937 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37637
2023-11-18 06:35:37,937 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53036
2023-11-18 06:35:37,938 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:37,939 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:37,940 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:37,940 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:37,942 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:38,046 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,047 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,048 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:38,051 - distributed.scheduler - INFO - Remove client Client-aa2c36ad-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:38,052 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52934; closing.
2023-11-18 06:35:38,052 - distributed.scheduler - INFO - Remove client Client-aa2c36ad-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:38,052 - distributed.scheduler - INFO - Close client connection: Client-aa2c36ad-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:38,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33649'. Reason: nanny-close
2023-11-18 06:35:38,053 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,054 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34777'. Reason: nanny-close
2023-11-18 06:35:38,054 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,055 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46509. Reason: nanny-close
2023-11-18 06:35:38,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43319'. Reason: nanny-close
2023-11-18 06:35:38,055 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,055 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37637. Reason: nanny-close
2023-11-18 06:35:38,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45083'. Reason: nanny-close
2023-11-18 06:35:38,056 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,056 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33179. Reason: nanny-close
2023-11-18 06:35:38,056 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34893'. Reason: nanny-close
2023-11-18 06:35:38,056 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,056 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41785. Reason: nanny-close
2023-11-18 06:35:38,057 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40835'. Reason: nanny-close
2023-11-18 06:35:38,057 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,057 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53004; closing.
2023-11-18 06:35:38,057 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40263. Reason: nanny-close
2023-11-18 06:35:38,057 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,058 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33885'. Reason: nanny-close
2023-11-18 06:35:38,058 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46509', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.058129')
2023-11-18 06:35:38,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,058 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,058 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44691. Reason: nanny-close
2023-11-18 06:35:38,058 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35329'. Reason: nanny-close
2023-11-18 06:35:38,058 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,058 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:38,059 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44731. Reason: nanny-close
2023-11-18 06:35:38,059 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52992; closing.
2023-11-18 06:35:38,059 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42887. Reason: nanny-close
2023-11-18 06:35:38,059 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,059 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,060 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,060 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,060 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41785', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.060261')
2023-11-18 06:35:38,060 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,060 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53036; closing.
2023-11-18 06:35:38,060 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52964; closing.
2023-11-18 06:35:38,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,061 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:38,062 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,061 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52992>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52992>: Stream is closed
2023-11-18 06:35:38,063 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,063 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37637', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.0634215')
2023-11-18 06:35:38,063 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:38,063 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33179', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.0638323')
2023-11-18 06:35:38,064 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52948; closing.
2023-11-18 06:35:38,064 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40263', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.064877')
2023-11-18 06:35:38,065 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53020; closing.
2023-11-18 06:35:38,066 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44691', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.0660782')
2023-11-18 06:35:38,066 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52976; closing.
2023-11-18 06:35:38,066 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52962; closing.
2023-11-18 06:35:38,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44731', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.0671897')
2023-11-18 06:35:38,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42887', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289338.0675201')
2023-11-18 06:35:38,067 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:35:38,068 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52962>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-18 06:35:38,068 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52976>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-18 06:35:39,774 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:35:39,774 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:35:39,776 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:35:39,777 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:35:39,778 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-11-18 06:35:42,178 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:42,182 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42695 instead
  warnings.warn(
2023-11-18 06:35:42,186 - distributed.scheduler - INFO - State start
2023-11-18 06:35:42,552 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:42,553 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:35:42,554 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42695/status
2023-11-18 06:35:42,554 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:35:42,917 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36819'
2023-11-18 06:35:42,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35239'
2023-11-18 06:35:42,959 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46401'
2023-11-18 06:35:42,961 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33505'
2023-11-18 06:35:42,971 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34913'
2023-11-18 06:35:42,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43753'
2023-11-18 06:35:42,996 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40785'
2023-11-18 06:35:43,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33335'
2023-11-18 06:35:43,410 - distributed.scheduler - INFO - Receive client connection: Client-b100fe38-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:43,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50058
2023-11-18 06:35:44,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,865 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,870 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,917 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,927 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,930 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:44,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:44,943 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:44,946 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:48,491 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33957
2023-11-18 06:35:48,493 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33957
2023-11-18 06:35:48,493 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41223
2023-11-18 06:35:48,493 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41747
2023-11-18 06:35:48,493 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,494 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,494 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41747
2023-11-18 06:35:48,494 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39823
2023-11-18 06:35:48,494 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,494 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,494 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,494 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,494 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mt9hyto9
2023-11-18 06:35:48,494 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,494 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,494 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wgl_k1vw
2023-11-18 06:35:48,494 - distributed.worker - INFO - Starting Worker plugin PreImport-d28dac85-c7cf-46ab-8454-7409c9f2da15
2023-11-18 06:35:48,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a89af0f0-fa8d-4a22-a36e-20adf0d6e188
2023-11-18 06:35:48,495 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-356d7a59-7835-491f-b73b-a9ebbafd4af5
2023-11-18 06:35:48,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1cc8af85-f434-4c78-b5f8-29a8cac5a40f
2023-11-18 06:35:48,540 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35827
2023-11-18 06:35:48,541 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35827
2023-11-18 06:35:48,542 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38963
2023-11-18 06:35:48,542 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,542 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,542 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,542 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,542 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u0kla80c
2023-11-18 06:35:48,543 - distributed.worker - INFO - Starting Worker plugin PreImport-12f4040e-0b3e-497c-a184-79770a2b2538
2023-11-18 06:35:48,543 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5dfa7bc-0f0c-4a2f-b78d-68523c3bafcf
2023-11-18 06:35:48,543 - distributed.worker - INFO - Starting Worker plugin RMMSetup-202d6492-5716-428f-a48b-60a4e5e1e181
2023-11-18 06:35:48,574 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41269
2023-11-18 06:35:48,574 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41269
2023-11-18 06:35:48,575 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39575
2023-11-18 06:35:48,575 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,575 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,575 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,575 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,575 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-82f6xlzt
2023-11-18 06:35:48,575 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fddefe14-285a-4259-a82b-64efaf14bc9e
2023-11-18 06:35:48,574 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38475
2023-11-18 06:35:48,576 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38475
2023-11-18 06:35:48,576 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36229
2023-11-18 06:35:48,576 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,576 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,576 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,576 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,576 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zp6vi0j0
2023-11-18 06:35:48,576 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34749
2023-11-18 06:35:48,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34749
2023-11-18 06:35:48,577 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40939
2023-11-18 06:35:48,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,577 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,577 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9a25762-75dc-450a-bdd8-44d611c105fc
2023-11-18 06:35:48,578 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tk_65lkn
2023-11-18 06:35:48,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-439d93bc-a935-439a-9936-dc761e9e025a
2023-11-18 06:35:48,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c5ae55af-9336-4c73-b4df-3dddadec3e15
2023-11-18 06:35:48,583 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-35e03d1e-c434-4eba-b18c-4e3f6b09d397
2023-11-18 06:35:48,584 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,587 - distributed.worker - INFO - Starting Worker plugin PreImport-f39df4d5-a9d5-4fdf-bd83-bb34b0dca46e
2023-11-18 06:35:48,588 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,589 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33109
2023-11-18 06:35:48,590 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33109
2023-11-18 06:35:48,591 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45589
2023-11-18 06:35:48,589 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40639
2023-11-18 06:35:48,591 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,591 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40639
2023-11-18 06:35:48,591 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,591 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45815
2023-11-18 06:35:48,591 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,591 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,591 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,591 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,591 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h2zb5mk6
2023-11-18 06:35:48,591 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:48,591 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:48,591 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5pecj5l9
2023-11-18 06:35:48,591 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ebd03c14-c440-4365-98eb-4be21bc08378
2023-11-18 06:35:48,592 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8ab05ab1-dd72-4212-b20b-cf7f1d56130e
2023-11-18 06:35:48,598 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,604 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6d1f0f1d-b63e-4ade-8495-8a105d95112d
2023-11-18 06:35:48,604 - distributed.worker - INFO - Starting Worker plugin PreImport-db792518-164b-4cad-a926-37ba7fc94586
2023-11-18 06:35:48,604 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,605 - distributed.worker - INFO - Starting Worker plugin PreImport-3f8cc8cf-b7bf-4df1-9a5d-3a73fbf29e8e
2023-11-18 06:35:48,606 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6afc05b9-0991-4e1a-80ea-3027df1725a2
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-41a09f72-4c53-4d38-aac8-bfc53d915323
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin PreImport-29e57335-93a3-4dcd-b0de-9aa1c72ba934
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin PreImport-0ef2a85b-a538-48db-9266-005dafcf4f37
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-82fd393c-9d95-431d-b195-e715137a01ae
2023-11-18 06:35:48,610 - distributed.worker - INFO - Starting Worker plugin PreImport-9bb4d3d9-1ca3-4e15-949b-5ed9b7510f44
2023-11-18 06:35:48,610 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,610 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,611 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,614 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41747', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,615 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41747
2023-11-18 06:35:48,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50086
2023-11-18 06:35:48,616 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,617 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,618 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,619 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33957', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,620 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33957
2023-11-18 06:35:48,620 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50102
2023-11-18 06:35:48,620 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,622 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,622 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,624 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,632 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41269', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41269
2023-11-18 06:35:48,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50126
2023-11-18 06:35:48,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,634 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,634 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35827', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,638 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35827
2023-11-18 06:35:48,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50112
2023-11-18 06:35:48,639 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38475', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,639 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38475
2023-11-18 06:35:48,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50132
2023-11-18 06:35:48,639 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,640 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33109', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,640 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,640 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,641 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33109
2023-11-18 06:35:48,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50148
2023-11-18 06:35:48,641 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,641 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,641 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40639', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,642 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40639
2023-11-18 06:35:48,642 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50156
2023-11-18 06:35:48,642 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,642 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,643 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,643 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34749', status: init, memory: 0, processing: 0>
2023-11-18 06:35:48,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,643 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,644 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34749
2023-11-18 06:35:48,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50154
2023-11-18 06:35:48,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,644 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,644 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:48,646 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:48,646 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:48,646 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,649 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,656 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:48,660 - distributed.scheduler - INFO - Remove client Client-b100fe38-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:48,660 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50058; closing.
2023-11-18 06:35:48,660 - distributed.scheduler - INFO - Remove client Client-b100fe38-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:48,661 - distributed.scheduler - INFO - Close client connection: Client-b100fe38-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:48,662 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36819'. Reason: nanny-close
2023-11-18 06:35:48,662 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,663 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35239'. Reason: nanny-close
2023-11-18 06:35:48,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46401'. Reason: nanny-close
2023-11-18 06:35:48,664 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41747. Reason: nanny-close
2023-11-18 06:35:48,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33505'. Reason: nanny-close
2023-11-18 06:35:48,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34913'. Reason: nanny-close
2023-11-18 06:35:48,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43753'. Reason: nanny-close
2023-11-18 06:35:48,665 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40785'. Reason: nanny-close
2023-11-18 06:35:48,665 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33335'. Reason: nanny-close
2023-11-18 06:35:48,667 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50086; closing.
2023-11-18 06:35:48,667 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,667 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41747', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.667607')
2023-11-18 06:35:48,670 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,680 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,680 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,681 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35827. Reason: nanny-close
2023-11-18 06:35:48,681 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,681 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33109. Reason: nanny-close
2023-11-18 06:35:48,682 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,682 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33957. Reason: nanny-close
2023-11-18 06:35:48,682 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,683 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40639. Reason: nanny-close
2023-11-18 06:35:48,683 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50112; closing.
2023-11-18 06:35:48,683 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,683 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,683 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34749. Reason: nanny-close
2023-11-18 06:35:48,684 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6839762')
2023-11-18 06:35:48,684 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41269. Reason: nanny-close
2023-11-18 06:35:48,684 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,684 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:48,684 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50102; closing.
2023-11-18 06:35:48,685 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50148; closing.
2023-11-18 06:35:48,685 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,685 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,685 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,685 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,685 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38475. Reason: nanny-close
2023-11-18 06:35:48,685 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33957', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6859293')
2023-11-18 06:35:48,686 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,686 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33109', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6862884')
2023-11-18 06:35:48,686 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,686 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,687 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,687 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,687 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50156; closing.
2023-11-18 06:35:48,687 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50154; closing.
2023-11-18 06:35:48,688 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:48,688 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40639', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6882768')
2023-11-18 06:35:48,688 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34749', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.68857')
2023-11-18 06:35:48,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50126; closing.
2023-11-18 06:35:48,689 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41269', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6893373')
2023-11-18 06:35:48,689 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:48,689 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50132; closing.
2023-11-18 06:35:48,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38475', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289348.6900117')
2023-11-18 06:35:48,690 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:35:50,530 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:35:50,530 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:35:50,531 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:35:50,532 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:35:50,533 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-11-18 06:35:52,786 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:52,791 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43079 instead
  warnings.warn(
2023-11-18 06:35:52,794 - distributed.scheduler - INFO - State start
2023-11-18 06:35:53,649 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:35:53,650 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:35:53,651 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43079/status
2023-11-18 06:35:53,651 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:35:53,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35881'
2023-11-18 06:35:53,948 - distributed.scheduler - INFO - Receive client connection: Client-b7638fc8-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:53,961 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34258
2023-11-18 06:35:53,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34897'
2023-11-18 06:35:53,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45559'
2023-11-18 06:35:53,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43915'
2023-11-18 06:35:53,997 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43141'
2023-11-18 06:35:54,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35241'
2023-11-18 06:35:54,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32901'
2023-11-18 06:35:54,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42307'
2023-11-18 06:35:55,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,845 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,916 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,918 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,923 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,929 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,934 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:55,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:35:55,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:35:55,949 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:35:58,534 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34833
2023-11-18 06:35:58,535 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34833
2023-11-18 06:35:58,535 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42595
2023-11-18 06:35:58,535 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,535 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,535 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,536 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,536 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vvaudhfy
2023-11-18 06:35:58,536 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-64023a4a-b4dc-4365-8712-2889c44bc9a3
2023-11-18 06:35:58,537 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd632549-1664-46de-8b03-b37c589e1803
2023-11-18 06:35:58,712 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45003
2023-11-18 06:35:58,713 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45003
2023-11-18 06:35:58,713 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40439
2023-11-18 06:35:58,713 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,713 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,713 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,713 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,713 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vv8b_4tk
2023-11-18 06:35:58,714 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9bbc3313-d9fa-45ae-b04b-8a49869db8d9
2023-11-18 06:35:58,714 - distributed.worker - INFO - Starting Worker plugin RMMSetup-97bcd4ce-c606-4754-8dd7-af0e4b595f68
2023-11-18 06:35:58,725 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35425
2023-11-18 06:35:58,726 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35425
2023-11-18 06:35:58,726 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37819
2023-11-18 06:35:58,726 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,726 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,726 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,727 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,727 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-47vr5br4
2023-11-18 06:35:58,727 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5b17a48-e323-4052-9c48-1f586117ca8a
2023-11-18 06:35:58,734 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45847
2023-11-18 06:35:58,735 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45847
2023-11-18 06:35:58,735 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33675
2023-11-18 06:35:58,735 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,735 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,735 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,736 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,736 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u76jcm_g
2023-11-18 06:35:58,736 - distributed.worker - INFO - Starting Worker plugin PreImport-f35c5ed4-130d-47b5-bbb7-862f23f1994e
2023-11-18 06:35:58,736 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6368e24b-f246-4f9a-858a-e0c6454da22b
2023-11-18 06:35:58,739 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b6f72a61-5a2f-458b-ae7d-34b921f5fe0b
2023-11-18 06:35:58,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42227
2023-11-18 06:35:58,741 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42227
2023-11-18 06:35:58,741 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39903
2023-11-18 06:35:58,741 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,740 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42737
2023-11-18 06:35:58,741 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,741 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42737
2023-11-18 06:35:58,741 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45499
2023-11-18 06:35:58,741 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,741 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,741 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,741 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,741 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-up8kbq95
2023-11-18 06:35:58,741 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,741 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,741 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4zm7qwtn
2023-11-18 06:35:58,742 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d85cfe13-c84e-4ad9-85c5-9e603a07f9ec
2023-11-18 06:35:58,742 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc363b4a-f647-4776-b9cf-46dee101829b
2023-11-18 06:35:58,744 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44047
2023-11-18 06:35:58,745 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44047
2023-11-18 06:35:58,745 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46083
2023-11-18 06:35:58,745 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,745 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,745 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,746 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,746 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dhqa_egk
2023-11-18 06:35:58,747 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0d1f4745-dc72-43fd-8e6f-c9649dbc9c70
2023-11-18 06:35:58,753 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46025
2023-11-18 06:35:58,754 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46025
2023-11-18 06:35:58,754 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38029
2023-11-18 06:35:58,754 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,754 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,754 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:35:58,754 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:35:58,754 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b50jgtuc
2023-11-18 06:35:58,755 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c7ee5fc-9279-4216-9508-7bd02f63c1be
2023-11-18 06:35:58,755 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b3934259-18ff-421a-8176-80dc1003b3c4
2023-11-18 06:35:58,769 - distributed.worker - INFO - Starting Worker plugin PreImport-46d6b5ae-b63f-4cb8-be07-775038a89392
2023-11-18 06:35:58,770 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,813 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34833', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,815 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34833
2023-11-18 06:35:58,815 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34274
2023-11-18 06:35:58,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,817 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,817 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,819 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:58,924 - distributed.worker - INFO - Starting Worker plugin PreImport-d39b21e1-b580-4d69-b006-dfe175d90322
2023-11-18 06:35:58,925 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-59226c91-5013-4916-a5d0-a8e751125571
2023-11-18 06:35:58,926 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,945 - distributed.worker - INFO - Starting Worker plugin PreImport-1791533d-7ddb-4486-96e9-15c5698d7bc4
2023-11-18 06:35:58,945 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,949 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-86430b9d-3c58-4cf4-8a3d-96302cb8f03b
2023-11-18 06:35:58,949 - distributed.worker - INFO - Starting Worker plugin PreImport-26877e3b-cff8-47a3-ba74-35b847008b50
2023-11-18 06:35:58,950 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,956 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c627c42b-3c95-4367-a788-9357347e1ae3
2023-11-18 06:35:58,956 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-543d5dae-4635-4c2d-99dc-d9a98d2789b8
2023-11-18 06:35:58,957 - distributed.worker - INFO - Starting Worker plugin PreImport-817d0b22-0bac-4692-935a-676893ef7df4
2023-11-18 06:35:58,957 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,959 - distributed.worker - INFO - Starting Worker plugin PreImport-c9830e5a-7390-4811-8f3a-c581f1052c75
2023-11-18 06:35:58,959 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,960 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,962 - distributed.worker - INFO - Starting Worker plugin PreImport-5467002e-baf8-4144-be52-9f3a9fa8cbfa
2023-11-18 06:35:58,962 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,963 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35425', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,964 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35425
2023-11-18 06:35:58,964 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34278
2023-11-18 06:35:58,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,967 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,967 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,969 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:58,977 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42737', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,977 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42737
2023-11-18 06:35:58,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34294
2023-11-18 06:35:58,978 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,979 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,980 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,981 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:58,985 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45003', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,986 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45003
2023-11-18 06:35:58,986 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34286
2023-11-18 06:35:58,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,989 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,989 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,991 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:58,992 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42227', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,993 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42227
2023-11-18 06:35:58,993 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34310
2023-11-18 06:35:58,994 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44047', status: init, memory: 0, processing: 0>
2023-11-18 06:35:58,994 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,995 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44047
2023-11-18 06:35:58,995 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34320
2023-11-18 06:35:58,995 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,995 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,996 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:58,997 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:58,997 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:58,997 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:58,998 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:59,001 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46025', status: init, memory: 0, processing: 0>
2023-11-18 06:35:59,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46025
2023-11-18 06:35:59,002 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34342
2023-11-18 06:35:59,003 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:59,004 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45847', status: init, memory: 0, processing: 0>
2023-11-18 06:35:59,005 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:59,005 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:59,005 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45847
2023-11-18 06:35:59,005 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34334
2023-11-18 06:35:59,006 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:35:59,007 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:59,007 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:35:59,007 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:35:59,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:35:59,040 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,040 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,041 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:35:59,051 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,052 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:35:59,058 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:35:59,060 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:35:59,062 - distributed.scheduler - INFO - Remove client Client-b7638fc8-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:59,063 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34258; closing.
2023-11-18 06:35:59,063 - distributed.scheduler - INFO - Remove client Client-b7638fc8-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:59,063 - distributed.scheduler - INFO - Close client connection: Client-b7638fc8-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:35:59,064 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35881'. Reason: nanny-close
2023-11-18 06:35:59,064 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,065 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34897'. Reason: nanny-close
2023-11-18 06:35:59,065 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,066 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35425. Reason: nanny-close
2023-11-18 06:35:59,066 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45559'. Reason: nanny-close
2023-11-18 06:35:59,066 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,066 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46025. Reason: nanny-close
2023-11-18 06:35:59,066 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43915'. Reason: nanny-close
2023-11-18 06:35:59,067 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,067 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42737. Reason: nanny-close
2023-11-18 06:35:59,067 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43141'. Reason: nanny-close
2023-11-18 06:35:59,067 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,067 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42227. Reason: nanny-close
2023-11-18 06:35:59,068 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35241'. Reason: nanny-close
2023-11-18 06:35:59,068 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,068 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,068 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34278; closing.
2023-11-18 06:35:59,069 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45847. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35425', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0689404')
2023-11-18 06:35:59,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32901'. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,069 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,069 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45003. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42307'. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:35:59,069 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,070 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34833. Reason: nanny-close
2023-11-18 06:35:59,070 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,070 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44047. Reason: nanny-close
2023-11-18 06:35:59,070 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34310; closing.
2023-11-18 06:35:59,070 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,070 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34294; closing.
2023-11-18 06:35:59,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34342; closing.
2023-11-18 06:35:59,071 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,071 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42227', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.071624')
2023-11-18 06:35:59,071 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0720234')
2023-11-18 06:35:59,072 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46025', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0723803')
2023-11-18 06:35:59,072 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,073 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:35:59,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34334; closing.
2023-11-18 06:35:59,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34286; closing.
2023-11-18 06:35:59,073 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,073 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34274; closing.
2023-11-18 06:35:59,074 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,074 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0743647')
2023-11-18 06:35:59,074 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,074 - distributed.nanny - INFO - Worker closed
2023-11-18 06:35:59,074 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45003', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.074739')
2023-11-18 06:35:59,075 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0751207')
2023-11-18 06:35:59,075 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34320; closing.
2023-11-18 06:35:59,075 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44047', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289359.0758638')
2023-11-18 06:35:59,076 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:00,782 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:00,783 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:00,783 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:00,784 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:00,785 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-11-18 06:36:02,817 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:02,822 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44437 instead
  warnings.warn(
2023-11-18 06:36:02,825 - distributed.scheduler - INFO - State start
2023-11-18 06:36:02,846 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:02,847 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:02,848 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44437/status
2023-11-18 06:36:02,848 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:03,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46277'
2023-11-18 06:36:03,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38521'
2023-11-18 06:36:03,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40779'
2023-11-18 06:36:03,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37961'
2023-11-18 06:36:03,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38057'
2023-11-18 06:36:03,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34901'
2023-11-18 06:36:03,108 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40743'
2023-11-18 06:36:03,117 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46683'
2023-11-18 06:36:03,858 - distributed.scheduler - INFO - Receive client connection: Client-bd5ff10e-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:03,871 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50604
2023-11-18 06:36:04,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:04,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:04,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:04,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:04,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:04,908 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,086 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,692 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:05,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:05,695 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,699 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:05,700 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:09,200 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42913
2023-11-18 06:36:09,201 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42913
2023-11-18 06:36:09,201 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43165
2023-11-18 06:36:09,202 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,202 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,202 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,202 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,202 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v08g_k5_
2023-11-18 06:36:09,203 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7f78435-a515-40e6-b44b-7c2debfa4959
2023-11-18 06:36:09,302 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36677
2023-11-18 06:36:09,302 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39787
2023-11-18 06:36:09,303 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36677
2023-11-18 06:36:09,303 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39787
2023-11-18 06:36:09,303 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39581
2023-11-18 06:36:09,303 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39489
2023-11-18 06:36:09,303 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,303 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,303 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,303 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,303 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,303 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,303 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,303 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ouerghq9
2023-11-18 06:36:09,303 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,303 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5cgu0gla
2023-11-18 06:36:09,304 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7e21ee41-4fbb-4c62-a60d-38e488195717
2023-11-18 06:36:09,304 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d10349f6-1efb-492e-9184-574ed51ecd8b
2023-11-18 06:36:09,303 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35787
2023-11-18 06:36:09,304 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35787
2023-11-18 06:36:09,304 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42363
2023-11-18 06:36:09,304 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,304 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,304 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,305 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,305 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3qh185cg
2023-11-18 06:36:09,305 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e7119af-ea90-4d51-ae7f-99f5a9540067
2023-11-18 06:36:09,305 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35197
2023-11-18 06:36:09,306 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35197
2023-11-18 06:36:09,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42919
2023-11-18 06:36:09,307 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,307 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,307 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,307 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_ha_fh15
2023-11-18 06:36:09,308 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9180099d-ad7e-4c70-8716-1f8bce6bbdc0
2023-11-18 06:36:09,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc63da7d-8dfd-475c-af13-4b2a0aafa8dc
2023-11-18 06:36:09,400 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34621
2023-11-18 06:36:09,402 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34621
2023-11-18 06:36:09,402 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37303
2023-11-18 06:36:09,402 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,402 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,402 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,402 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,402 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dhz3t7in
2023-11-18 06:36:09,403 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a0f6edf-a638-481e-9763-c1cdd88d6fe1
2023-11-18 06:36:09,411 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44815
2023-11-18 06:36:09,413 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44815
2023-11-18 06:36:09,412 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38873
2023-11-18 06:36:09,413 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45123
2023-11-18 06:36:09,413 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38873
2023-11-18 06:36:09,413 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,413 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,413 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36101
2023-11-18 06:36:09,413 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,413 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,413 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,413 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,413 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:09,413 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r342bqmb
2023-11-18 06:36:09,413 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:09,414 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5btapr0m
2023-11-18 06:36:09,414 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be8dadf6-37c4-4bfa-aa16-f5653bb45037
2023-11-18 06:36:09,415 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c153ab68-77de-4936-ad58-2c8a3b4b7cae
2023-11-18 06:36:09,416 - distributed.worker - INFO - Starting Worker plugin PreImport-8b597854-a547-4585-a1e5-5956f36341f8
2023-11-18 06:36:09,416 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed4a48e3-11f1-4a87-857f-96a42b99d2c1
2023-11-18 06:36:09,449 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-227b1478-86c7-465d-823d-33690b1cf5f6
2023-11-18 06:36:09,451 - distributed.worker - INFO - Starting Worker plugin PreImport-0c79d6f0-67fb-491e-98e3-8579adc11743
2023-11-18 06:36:09,451 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,487 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42913', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,489 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42913
2023-11-18 06:36:09,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50624
2023-11-18 06:36:09,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,491 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,491 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,534 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-657f7d01-cd2f-41e0-aedb-d509f6308e17
2023-11-18 06:36:09,535 - distributed.worker - INFO - Starting Worker plugin PreImport-dd6e56bf-fdcf-4c5e-9e0a-e3816ef8cb27
2023-11-18 06:36:09,536 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,536 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15f7ad72-e659-4242-88de-8b0327a8a61e
2023-11-18 06:36:09,536 - distributed.worker - INFO - Starting Worker plugin PreImport-91f90401-be04-4b0b-8f42-c02bd6a858a4
2023-11-18 06:36:09,537 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,546 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4ed2aa06-d64d-429c-b003-86810bc12bbd
2023-11-18 06:36:09,547 - distributed.worker - INFO - Starting Worker plugin PreImport-fd231bb7-2cce-40da-8eda-b73eb8398a06
2023-11-18 06:36:09,548 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,559 - distributed.worker - INFO - Starting Worker plugin PreImport-d230c52b-5078-4c14-bbc5-c29213ec9f28
2023-11-18 06:36:09,560 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39787', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,571 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39787
2023-11-18 06:36:09,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50630
2023-11-18 06:36:09,572 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35787', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,572 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,572 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35787
2023-11-18 06:36:09,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50644
2023-11-18 06:36:09,573 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,573 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,575 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,575 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,582 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2b7b78d1-3295-42c4-8d70-4a8fe4d10d30
2023-11-18 06:36:09,582 - distributed.worker - INFO - Starting Worker plugin PreImport-5475bfde-b3ff-4cf9-83e0-e65b5752da07
2023-11-18 06:36:09,583 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,584 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36677', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,585 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36677
2023-11-18 06:36:09,585 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50660
2023-11-18 06:36:09,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,587 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,587 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,589 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-059d91c3-c41d-4418-be43-caccfb173e2d
2023-11-18 06:36:09,589 - distributed.worker - INFO - Starting Worker plugin PreImport-aeb795ee-c1d3-4746-8c68-8197bdd0754e
2023-11-18 06:36:09,589 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,592 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,600 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35197', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,600 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35197
2023-11-18 06:36:09,601 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50676
2023-11-18 06:36:09,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,603 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,603 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,607 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,611 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34621', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,612 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34621
2023-11-18 06:36:09,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50684
2023-11-18 06:36:09,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,614 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,614 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,614 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38873', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,615 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38873
2023-11-18 06:36:09,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50700
2023-11-18 06:36:09,616 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,616 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,617 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,617 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,621 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44815', status: init, memory: 0, processing: 0>
2023-11-18 06:36:09,622 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44815
2023-11-18 06:36:09,622 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50714
2023-11-18 06:36:09,623 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:09,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:09,624 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:09,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:09,661 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,661 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,661 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,661 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,662 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,662 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,662 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,662 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,676 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,677 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,678 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:36:09,684 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,686 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:09,688 - distributed.scheduler - INFO - Remove client Client-bd5ff10e-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:09,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50604; closing.
2023-11-18 06:36:09,688 - distributed.scheduler - INFO - Remove client Client-bd5ff10e-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:09,689 - distributed.scheduler - INFO - Close client connection: Client-bd5ff10e-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:09,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46277'. Reason: nanny-close
2023-11-18 06:36:09,691 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38521'. Reason: nanny-close
2023-11-18 06:36:09,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44815. Reason: nanny-close
2023-11-18 06:36:09,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40779'. Reason: nanny-close
2023-11-18 06:36:09,693 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,693 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38873. Reason: nanny-close
2023-11-18 06:36:09,693 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37961'. Reason: nanny-close
2023-11-18 06:36:09,693 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,694 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38057'. Reason: nanny-close
2023-11-18 06:36:09,694 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35197. Reason: nanny-close
2023-11-18 06:36:09,694 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,694 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35787. Reason: nanny-close
2023-11-18 06:36:09,695 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50714; closing.
2023-11-18 06:36:09,695 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34901'. Reason: nanny-close
2023-11-18 06:36:09,695 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,695 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44815', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.6953378')
2023-11-18 06:36:09,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,695 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39787. Reason: nanny-close
2023-11-18 06:36:09,695 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40743'. Reason: nanny-close
2023-11-18 06:36:09,695 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,696 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42913. Reason: nanny-close
2023-11-18 06:36:09,696 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46683'. Reason: nanny-close
2023-11-18 06:36:09,696 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,696 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:09,696 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34621. Reason: nanny-close
2023-11-18 06:36:09,697 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,697 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,697 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50700; closing.
2023-11-18 06:36:09,697 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36677. Reason: nanny-close
2023-11-18 06:36:09,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,699 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,699 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38873', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.6991055')
2023-11-18 06:36:09,699 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,699 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50676; closing.
2023-11-18 06:36:09,700 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,700 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,700 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35197', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.7008662')
2023-11-18 06:36:09,700 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:09,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50644; closing.
2023-11-18 06:36:09,701 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50630; closing.
2023-11-18 06:36:09,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35787', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.7026372')
2023-11-18 06:36:09,702 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,703 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39787', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.703152')
2023-11-18 06:36:09,703 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:09,703 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50624; closing.
2023-11-18 06:36:09,703 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50684; closing.
2023-11-18 06:36:09,704 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42913', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.7046216')
2023-11-18 06:36:09,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34621', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.7051432')
2023-11-18 06:36:09,705 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50660; closing.
2023-11-18 06:36:09,706 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36677', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289369.70624')
2023-11-18 06:36:09,706 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:09,706 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50660>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-18 06:36:11,308 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:11,308 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:11,309 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:11,310 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:11,311 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-11-18 06:36:13,332 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:13,336 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46267 instead
  warnings.warn(
2023-11-18 06:36:13,339 - distributed.scheduler - INFO - State start
2023-11-18 06:36:13,366 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:13,367 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:13,368 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46267/status
2023-11-18 06:36:13,368 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:13,541 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36259'
2023-11-18 06:36:13,560 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42965'
2023-11-18 06:36:13,579 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41863'
2023-11-18 06:36:13,581 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34415'
2023-11-18 06:36:13,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38989'
2023-11-18 06:36:13,598 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42269'
2023-11-18 06:36:13,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46325'
2023-11-18 06:36:13,617 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45027'
2023-11-18 06:36:14,326 - distributed.scheduler - INFO - Receive client connection: Client-c3b245fc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:14,339 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48372
2023-11-18 06:36:15,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,456 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,536 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,543 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,582 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,582 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,583 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,594 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:15,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:15,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:15,616 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:17,145 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35185
2023-11-18 06:36:17,146 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35185
2023-11-18 06:36:17,146 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43319
2023-11-18 06:36:17,146 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:17,146 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:17,146 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:17,147 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:17,147 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xhgvp3hh
2023-11-18 06:36:17,147 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0ae015ff-79ec-48e3-b7d4-dd8529aa0e48
2023-11-18 06:36:18,089 - distributed.worker - INFO - Starting Worker plugin PreImport-099c63f1-a2ff-4425-a919-1ca22e2b70df
2023-11-18 06:36:18,089 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd0d402d-4bdc-4c16-98f1-72b6cca4249b
2023-11-18 06:36:18,090 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:18,397 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35185', status: init, memory: 0, processing: 0>
2023-11-18 06:36:18,399 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35185
2023-11-18 06:36:18,399 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48394
2023-11-18 06:36:18,401 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:18,402 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:18,402 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:18,404 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,062 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44969
2023-11-18 06:36:20,063 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44969
2023-11-18 06:36:20,063 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43547
2023-11-18 06:36:20,063 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,063 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,063 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,063 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,063 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iske1y6s
2023-11-18 06:36:20,064 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9c6bcc0-f513-485f-9cb4-f9839cf1ec25
2023-11-18 06:36:20,065 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8c4e2b04-61f9-48f7-a275-0b1e01434d5b
2023-11-18 06:36:20,068 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36111
2023-11-18 06:36:20,068 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36111
2023-11-18 06:36:20,068 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46467
2023-11-18 06:36:20,069 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,069 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,069 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,069 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,069 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-103fe7nr
2023-11-18 06:36:20,069 - distributed.worker - INFO - Starting Worker plugin RMMSetup-38fb989b-eb77-4f18-9225-4404e89b9643
2023-11-18 06:36:20,070 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39641
2023-11-18 06:36:20,072 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39641
2023-11-18 06:36:20,073 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34705
2023-11-18 06:36:20,073 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,073 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,073 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,073 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,073 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-adh_prcj
2023-11-18 06:36:20,074 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6f86f33b-ff51-41ae-b06f-f958e5fdf86f
2023-11-18 06:36:20,098 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41407
2023-11-18 06:36:20,099 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41407
2023-11-18 06:36:20,099 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40397
2023-11-18 06:36:20,099 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,099 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,099 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,099 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,099 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_j38_z1l
2023-11-18 06:36:20,100 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4fa557c0-11d8-4bb5-9ed0-a91d0463fe60
2023-11-18 06:36:20,099 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38697
2023-11-18 06:36:20,100 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38697
2023-11-18 06:36:20,100 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45617
2023-11-18 06:36:20,101 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,101 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,101 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,101 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,101 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i35na4ur
2023-11-18 06:36:20,101 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-03200856-389f-4858-a823-f1088d61ebae
2023-11-18 06:36:20,103 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5d71454-1e9a-4fa4-aa24-9d3bacffae28
2023-11-18 06:36:20,113 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41669
2023-11-18 06:36:20,114 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41669
2023-11-18 06:36:20,114 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38225
2023-11-18 06:36:20,114 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,114 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,114 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,114 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,114 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zbtco_0a
2023-11-18 06:36:20,115 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9b0920e-3969-4776-af39-dedab3146497
2023-11-18 06:36:20,115 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95c8fec0-4d4d-4726-8039-61aad9ad9d56
2023-11-18 06:36:20,114 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36297
2023-11-18 06:36:20,115 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36297
2023-11-18 06:36:20,115 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39795
2023-11-18 06:36:20,115 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,115 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,115 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:20,116 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:36:20,116 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hjda6n1v
2023-11-18 06:36:20,116 - distributed.worker - INFO - Starting Worker plugin PreImport-f361e366-9a8f-43e1-b824-5711d4ff1c77
2023-11-18 06:36:20,116 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7643d7e1-1592-4ec7-bb28-d9837b0af6f8
2023-11-18 06:36:20,118 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5a4dd1f9-9ae4-4cc3-a7aa-7d870642e3e5
2023-11-18 06:36:20,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-59e6397b-1003-40ad-9fa9-696ca1863d6c
2023-11-18 06:36:20,233 - distributed.worker - INFO - Starting Worker plugin PreImport-09bbc860-fe51-43b8-baca-8128908efa2d
2023-11-18 06:36:20,234 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,234 - distributed.worker - INFO - Starting Worker plugin PreImport-e0f88600-4ef8-4b09-ae6b-de57ebe0967b
2023-11-18 06:36:20,234 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-34a069ca-8a6a-4d98-9077-ab6768a2f03c
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin PreImport-1e232405-cb77-4a51-bd76-7f63cdb29903
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-354ba58a-a2bb-4311-aea2-d112ca487ecf
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin PreImport-200b2358-7339-4740-9226-2d88d5953901
2023-11-18 06:36:20,242 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin PreImport-de0f4eb3-8825-4285-9f23-ec6a4a7b14f4
2023-11-18 06:36:20,242 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,242 - distributed.worker - INFO - Starting Worker plugin PreImport-9dd66f02-f5d9-46ff-a927-e65c2a326bd6
2023-11-18 06:36:20,242 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,242 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,243 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,270 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41669', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,270 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41669
2023-11-18 06:36:20,271 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38960
2023-11-18 06:36:20,271 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39641', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,271 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39641
2023-11-18 06:36:20,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38914
2023-11-18 06:36:20,272 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,272 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,273 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41407', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,273 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,273 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41407
2023-11-18 06:36:20,273 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38948
2023-11-18 06:36:20,274 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,274 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,275 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36111', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,275 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36111
2023-11-18 06:36:20,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38932
2023-11-18 06:36:20,275 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,275 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,276 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44969', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,276 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,276 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44969
2023-11-18 06:36:20,276 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38924
2023-11-18 06:36:20,276 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,277 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,277 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,278 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36297', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,278 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36297
2023-11-18 06:36:20,278 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38976
2023-11-18 06:36:20,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,279 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38697', status: init, memory: 0, processing: 0>
2023-11-18 06:36:20,279 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,279 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,280 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38697
2023-11-18 06:36:20,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38962
2023-11-18 06:36:20,280 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,281 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,281 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:20,282 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:20,282 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:20,282 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,283 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,284 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:20,334 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,335 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,336 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:36:20,339 - distributed.scheduler - INFO - Remove client Client-c3b245fc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:20,340 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48372; closing.
2023-11-18 06:36:20,340 - distributed.scheduler - INFO - Remove client Client-c3b245fc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:20,340 - distributed.scheduler - INFO - Close client connection: Client-c3b245fc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:20,341 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36259'. Reason: nanny-close
2023-11-18 06:36:20,341 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,342 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42965'. Reason: nanny-close
2023-11-18 06:36:20,342 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,343 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41863'. Reason: nanny-close
2023-11-18 06:36:20,343 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35185. Reason: nanny-close
2023-11-18 06:36:20,343 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,343 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34415'. Reason: nanny-close
2023-11-18 06:36:20,343 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44969. Reason: nanny-close
2023-11-18 06:36:20,344 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,344 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39641. Reason: nanny-close
2023-11-18 06:36:20,344 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38989'. Reason: nanny-close
2023-11-18 06:36:20,344 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41407. Reason: nanny-close
2023-11-18 06:36:20,345 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,345 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42269'. Reason: nanny-close
2023-11-18 06:36:20,345 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36297. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46325'. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38924; closing.
2023-11-18 06:36:20,346 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,346 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38697. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,346 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45027'. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,346 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44969', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3467023')
2023-11-18 06:36:20,346 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,346 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:20,346 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41669. Reason: nanny-close
2023-11-18 06:36:20,347 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38914; closing.
2023-11-18 06:36:20,347 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36111. Reason: nanny-close
2023-11-18 06:36:20,347 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39641', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3478234')
2023-11-18 06:36:20,348 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48394; closing.
2023-11-18 06:36:20,348 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,348 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38948; closing.
2023-11-18 06:36:20,348 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,348 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,348 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,349 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35185', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3491988')
2023-11-18 06:36:20,349 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41407', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3495638')
2023-11-18 06:36:20,349 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:20,349 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,350 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,350 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,351 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:20,350 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:38914>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-18 06:36:20,352 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38976; closing.
2023-11-18 06:36:20,352 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38962; closing.
2023-11-18 06:36:20,353 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3531117')
2023-11-18 06:36:20,353 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38697', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3534913')
2023-11-18 06:36:20,353 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38960; closing.
2023-11-18 06:36:20,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38932; closing.
2023-11-18 06:36:20,354 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41669', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3544226')
2023-11-18 06:36:20,354 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36111', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289380.3549306')
2023-11-18 06:36:20,355 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:22,159 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:22,159 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:22,160 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:22,161 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:22,161 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-11-18 06:36:24,552 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:24,556 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40019 instead
  warnings.warn(
2023-11-18 06:36:24,561 - distributed.scheduler - INFO - State start
2023-11-18 06:36:24,585 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:24,586 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:24,587 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40019/status
2023-11-18 06:36:24,587 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:24,688 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38373'
2023-11-18 06:36:25,865 - distributed.scheduler - INFO - Receive client connection: Client-ca2fa082-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:25,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39074
2023-11-18 06:36:26,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:26,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:26,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:27,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39207
2023-11-18 06:36:27,857 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39207
2023-11-18 06:36:27,857 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-11-18 06:36:27,857 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:27,857 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:27,857 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:27,857 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-18 06:36:27,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o2amofwu
2023-11-18 06:36:27,858 - distributed.worker - INFO - Starting Worker plugin PreImport-ed1a63ae-ec5c-49f5-b69d-c72567585bc2
2023-11-18 06:36:27,858 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c138f28e-47b7-4131-9ae9-893852d0a26f
2023-11-18 06:36:27,858 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0cfc3967-3cbf-4427-a4e5-1037849f9df0
2023-11-18 06:36:27,859 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:27,895 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39207', status: init, memory: 0, processing: 0>
2023-11-18 06:36:27,897 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39207
2023-11-18 06:36:27,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39090
2023-11-18 06:36:27,898 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:27,899 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:27,900 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:27,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:27,905 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:27,908 - distributed.scheduler - INFO - Remove client Client-ca2fa082-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:27,908 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39074; closing.
2023-11-18 06:36:27,908 - distributed.scheduler - INFO - Remove client Client-ca2fa082-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:27,909 - distributed.scheduler - INFO - Close client connection: Client-ca2fa082-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:27,910 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38373'. Reason: nanny-close
2023-11-18 06:36:27,928 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:27,929 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39207. Reason: nanny-close
2023-11-18 06:36:27,931 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39090; closing.
2023-11-18 06:36:27,931 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:27,931 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39207', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289387.9319081')
2023-11-18 06:36:27,932 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:27,933 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:29,176 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:29,177 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:29,177 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:29,178 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:29,178 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-11-18 06:36:33,170 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:33,174 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34857 instead
  warnings.warn(
2023-11-18 06:36:33,177 - distributed.scheduler - INFO - State start
2023-11-18 06:36:33,241 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:33,242 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:33,243 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34857/status
2023-11-18 06:36:33,243 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:33,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41629'
2023-11-18 06:36:34,971 - distributed.scheduler - INFO - Receive client connection: Client-cf768650-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:34,985 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60314
2023-11-18 06:36:35,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:35,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:35,646 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:37,228 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41087
2023-11-18 06:36:37,230 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41087
2023-11-18 06:36:37,230 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40317
2023-11-18 06:36:37,230 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:36:37,230 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:37,230 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:37,230 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-18 06:36:37,230 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fti7b50r
2023-11-18 06:36:37,231 - distributed.worker - INFO - Starting Worker plugin PreImport-28f39afa-f531-40a9-8da4-87576769a7a3
2023-11-18 06:36:37,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7f4a0df-d752-468b-8868-0e355ddc5144
2023-11-18 06:36:37,234 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6425815c-79fb-4a23-87fc-ec09d268f60e
2023-11-18 06:36:37,234 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:37,260 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41087', status: init, memory: 0, processing: 0>
2023-11-18 06:36:37,262 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41087
2023-11-18 06:36:37,262 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60334
2023-11-18 06:36:37,263 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:37,264 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:36:37,264 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:37,266 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:36:37,357 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:37,360 - distributed.scheduler - INFO - Remove client Client-cf768650-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:37,361 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60314; closing.
2023-11-18 06:36:37,361 - distributed.scheduler - INFO - Remove client Client-cf768650-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:37,361 - distributed.scheduler - INFO - Close client connection: Client-cf768650-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:37,362 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41629'. Reason: nanny-close
2023-11-18 06:36:37,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:37,364 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41087. Reason: nanny-close
2023-11-18 06:36:37,366 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60334; closing.
2023-11-18 06:36:37,366 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:36:37,366 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41087', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289397.3663552')
2023-11-18 06:36:37,366 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:37,367 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:38,529 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:38,529 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:38,530 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:38,530 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:38,531 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-11-18 06:36:40,816 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:40,821 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45985 instead
  warnings.warn(
2023-11-18 06:36:40,825 - distributed.scheduler - INFO - State start
2023-11-18 06:36:41,109 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:41,110 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:41,111 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45985/status
2023-11-18 06:36:41,111 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:45,802 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:59670'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:59670>: Stream is closed
2023-11-18 06:36:46,090 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:46,090 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:46,091 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:46,091 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:36:46,092 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-11-18 06:36:48,616 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:48,621 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34059 instead
  warnings.warn(
2023-11-18 06:36:48,626 - distributed.scheduler - INFO - State start
2023-11-18 06:36:48,705 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:48,706 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-18 06:36:48,707 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34059/status
2023-11-18 06:36:48,707 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:48,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42377'
2023-11-18 06:36:50,445 - distributed.scheduler - INFO - Receive client connection: Client-d87841bc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:50,459 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56076
2023-11-18 06:36:50,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:50,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:50,499 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:53,268 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33645
2023-11-18 06:36:53,269 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33645
2023-11-18 06:36:53,269 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38555
2023-11-18 06:36:53,269 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-18 06:36:53,269 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:53,269 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:36:53,270 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-18 06:36:53,270 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-d2pzqj26
2023-11-18 06:36:53,270 - distributed.worker - INFO - Starting Worker plugin PreImport-04e746e7-1818-4bd3-846a-740d688a72d9
2023-11-18 06:36:53,270 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b2fd023-d2a6-4db6-9dcb-5236f42ce21c
2023-11-18 06:36:53,271 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4dd0d2be-ab0f-45ee-bdc4-92ad63c1195d
2023-11-18 06:36:53,271 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:53,308 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33645', status: init, memory: 0, processing: 0>
2023-11-18 06:36:53,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33645
2023-11-18 06:36:53,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56088
2023-11-18 06:36:53,310 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:36:53,312 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-18 06:36:53,312 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:36:53,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-18 06:36:53,410 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:36:53,413 - distributed.scheduler - INFO - Remove client Client-d87841bc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:53,413 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56076; closing.
2023-11-18 06:36:53,414 - distributed.scheduler - INFO - Remove client Client-d87841bc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:53,414 - distributed.scheduler - INFO - Close client connection: Client-d87841bc-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:36:53,415 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42377'. Reason: nanny-close
2023-11-18 06:36:53,416 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:36:53,417 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33645. Reason: nanny-close
2023-11-18 06:36:53,420 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56088; closing.
2023-11-18 06:36:53,420 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-18 06:36:53,420 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33645', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289413.420399')
2023-11-18 06:36:53,420 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:36:53,422 - distributed.nanny - INFO - Worker closed
2023-11-18 06:36:54,482 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:36:54,482 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:36:54,483 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:36:54,484 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-18 06:36:54,485 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-11-18 06:36:56,760 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:56,764 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37577 instead
  warnings.warn(
2023-11-18 06:36:56,768 - distributed.scheduler - INFO - State start
2023-11-18 06:36:56,789 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:36:56,789 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:36:56,790 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37577/status
2023-11-18 06:36:56,790 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:36:57,150 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43649'
2023-11-18 06:36:57,173 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44341'
2023-11-18 06:36:57,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44119'
2023-11-18 06:36:57,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36117'
2023-11-18 06:36:57,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38723'
2023-11-18 06:36:57,255 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34107'
2023-11-18 06:36:57,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40535'
2023-11-18 06:36:57,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37373'
2023-11-18 06:36:59,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,068 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,068 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,087 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,087 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,111 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,140 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:36:59,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:36:59,207 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:36:59,208 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:37:03,688 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44037
2023-11-18 06:37:03,688 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44037
2023-11-18 06:37:03,689 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37535
2023-11-18 06:37:03,689 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,689 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,689 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,689 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,689 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wbubz9s6
2023-11-18 06:37:03,689 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab9f4600-c981-446a-9ded-fc1d2b444b3c
2023-11-18 06:37:03,690 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c357c1f-8a7d-4e40-9519-12070cd26a8e
2023-11-18 06:37:03,696 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40101
2023-11-18 06:37:03,697 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40101
2023-11-18 06:37:03,697 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42757
2023-11-18 06:37:03,697 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,697 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,697 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,697 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,697 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u5nf7jie
2023-11-18 06:37:03,698 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e10d54d1-5198-4e8f-a303-904434d67465
2023-11-18 06:37:03,698 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d82e68ff-bf4e-4ae5-bdcf-aca61298f844
2023-11-18 06:37:03,719 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46209
2023-11-18 06:37:03,720 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46209
2023-11-18 06:37:03,720 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35891
2023-11-18 06:37:03,720 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,720 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,720 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,720 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,720 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zy1w8pne
2023-11-18 06:37:03,721 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-319a65e9-f289-4eb1-ae5b-8f9dae51ac81
2023-11-18 06:37:03,721 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93a54763-2ea8-44e0-bbfc-3f2a1fa6bf20
2023-11-18 06:37:03,724 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38289
2023-11-18 06:37:03,725 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38289
2023-11-18 06:37:03,725 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37865
2023-11-18 06:37:03,725 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,725 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,725 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,725 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,725 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ur8ihgcq
2023-11-18 06:37:03,726 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e96c129-a62c-434f-916d-1ce962abdfb2
2023-11-18 06:37:03,728 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38091
2023-11-18 06:37:03,729 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38091
2023-11-18 06:37:03,729 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38307
2023-11-18 06:37:03,729 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,729 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,729 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,729 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,729 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kp4kdj0t
2023-11-18 06:37:03,730 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab46a07d-5558-4307-ad22-6097585b6499
2023-11-18 06:37:03,736 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43021
2023-11-18 06:37:03,737 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43021
2023-11-18 06:37:03,737 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41225
2023-11-18 06:37:03,737 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,737 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,737 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,737 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,737 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rcfdk7h2
2023-11-18 06:37:03,738 - distributed.worker - INFO - Starting Worker plugin RMMSetup-277fafbf-e281-4a75-b222-1c93f1d25bdd
2023-11-18 06:37:03,739 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44659
2023-11-18 06:37:03,740 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44659
2023-11-18 06:37:03,740 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38107
2023-11-18 06:37:03,740 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,740 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,740 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,740 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,741 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k4mflg6m
2023-11-18 06:37:03,741 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a6c155a7-0e79-43c2-b6e2-84e5dd8055ef
2023-11-18 06:37:03,741 - distributed.worker - INFO - Starting Worker plugin RMMSetup-097ef08a-850b-479e-9e9e-233c44f54d4b
2023-11-18 06:37:03,741 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33723
2023-11-18 06:37:03,742 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33723
2023-11-18 06:37:03,742 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46855
2023-11-18 06:37:03,743 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:03,743 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:03,743 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:03,743 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-18 06:37:03,743 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3o8pcf1n
2023-11-18 06:37:03,743 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cab03202-d562-4f80-939f-e6d660e86228
2023-11-18 06:37:04,081 - distributed.worker - INFO - Starting Worker plugin PreImport-ffe6353c-7ac8-45af-9ef3-e5b7883911aa
2023-11-18 06:37:04,081 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aae54b25-8696-4eaa-8d21-b220aa5f0a2d
2023-11-18 06:37:04,082 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e6dd4d05-fe36-4e25-b473-aea9a213309e
2023-11-18 06:37:04,084 - distributed.worker - INFO - Starting Worker plugin PreImport-244e8b01-3038-403f-993b-0e1fa0df5602
2023-11-18 06:37:04,084 - distributed.worker - INFO - Starting Worker plugin PreImport-cd063828-7473-456d-bf3e-d8574be5a8d3
2023-11-18 06:37:04,084 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,084 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,085 - distributed.worker - INFO - Starting Worker plugin PreImport-071d30d5-b06a-4cce-8ef5-34c88d7afddc
2023-11-18 06:37:04,085 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8630626-0ca5-4c82-8716-d33210618289
2023-11-18 06:37:04,085 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,085 - distributed.worker - INFO - Starting Worker plugin PreImport-ae469024-b436-4f8f-8244-bb877bb9bf7a
2023-11-18 06:37:04,085 - distributed.worker - INFO - Starting Worker plugin PreImport-ac1665c0-58a2-48ef-b087-3fd3fdd121b9
2023-11-18 06:37:04,086 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,086 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,086 - distributed.worker - INFO - Starting Worker plugin PreImport-f1348d77-08e5-4885-83ca-7f9ce949a719
2023-11-18 06:37:04,086 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a9186ef-587f-4ca4-bd1e-c8488f3df89a
2023-11-18 06:37:04,086 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,087 - distributed.worker - INFO - Starting Worker plugin PreImport-24dfaca9-9b47-4acd-a0d1-96c3481a4552
2023-11-18 06:37:04,087 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,119 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46209', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,134 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46209
2023-11-18 06:37:04,134 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54112
2023-11-18 06:37:04,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,136 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40101', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,136 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,136 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,137 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40101
2023-11-18 06:37:04,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54136
2023-11-18 06:37:04,137 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44037', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,138 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44037
2023-11-18 06:37:04,138 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54120
2023-11-18 06:37:04,139 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38091', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,139 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,139 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,139 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38091
2023-11-18 06:37:04,139 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54100
2023-11-18 06:37:04,140 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43021', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,140 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,140 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,140 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,140 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43021
2023-11-18 06:37:04,140 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,140 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54130
2023-11-18 06:37:04,141 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38289', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,141 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,141 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38289
2023-11-18 06:37:04,141 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,141 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54160
2023-11-18 06:37:04,141 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,142 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,142 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33723', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,142 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33723
2023-11-18 06:37:04,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54092
2023-11-18 06:37:04,143 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,143 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,143 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,143 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44659', status: init, memory: 0, processing: 0>
2023-11-18 06:37:04,144 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44659
2023-11-18 06:37:04,144 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54144
2023-11-18 06:37:04,144 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,144 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,145 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,145 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,146 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:04,147 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,147 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,147 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,148 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:04,148 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:04,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:04,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:06,289 - distributed.scheduler - INFO - Receive client connection: Client-dd7b6087-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:06,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54234
2023-11-18 06:37:06,303 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,303 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,303 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,303 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,304 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,303 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,304 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,305 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-18 06:37:06,318 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,318 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,319 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:06,323 - distributed.scheduler - INFO - Remove client Client-dd7b6087-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:06,324 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54234; closing.
2023-11-18 06:37:06,324 - distributed.scheduler - INFO - Remove client Client-dd7b6087-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:06,324 - distributed.scheduler - INFO - Close client connection: Client-dd7b6087-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:06,325 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38723'. Reason: nanny-close
2023-11-18 06:37:06,326 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,327 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34107'. Reason: nanny-close
2023-11-18 06:37:06,327 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,327 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33723. Reason: nanny-close
2023-11-18 06:37:06,327 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40535'. Reason: nanny-close
2023-11-18 06:37:06,328 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,328 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44659. Reason: nanny-close
2023-11-18 06:37:06,328 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37373'. Reason: nanny-close
2023-11-18 06:37:06,328 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43649'. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38289. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43021. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44341'. Reason: nanny-close
2023-11-18 06:37:06,329 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,330 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54092; closing.
2023-11-18 06:37:06,330 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,330 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44119'. Reason: nanny-close
2023-11-18 06:37:06,330 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40101. Reason: nanny-close
2023-11-18 06:37:06,330 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,330 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33723', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.330543')
2023-11-18 06:37:06,330 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46209. Reason: nanny-close
2023-11-18 06:37:06,330 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36117'. Reason: nanny-close
2023-11-18 06:37:06,331 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:06,331 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44037. Reason: nanny-close
2023-11-18 06:37:06,331 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,331 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,331 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38091. Reason: nanny-close
2023-11-18 06:37:06,332 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,332 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,332 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,332 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54130; closing.
2023-11-18 06:37:06,332 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,332 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54160; closing.
2023-11-18 06:37:06,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54144; closing.
2023-11-18 06:37:06,333 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,333 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,334 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,334 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43021', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.33416')
2023-11-18 06:37:06,334 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,334 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38289', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3344836')
2023-11-18 06:37:06,334 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,334 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44659', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3348475')
2023-11-18 06:37:06,334 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,335 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:06,336 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54136; closing.
2023-11-18 06:37:06,336 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54112; closing.
2023-11-18 06:37:06,336 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,336 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54120; closing.
2023-11-18 06:37:06,337 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40101', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3371158')
2023-11-18 06:37:06,337 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:06,337 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46209', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3375235')
2023-11-18 06:37:06,337 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44037', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3378294')
2023-11-18 06:37:06,338 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54100; closing.
2023-11-18 06:37:06,338 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38091', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289426.3386497')
2023-11-18 06:37:06,338 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:37:07,944 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:37:07,944 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:37:07,945 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:37:07,946 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:37:07,947 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-11-18 06:37:10,451 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:37:10,455 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38057 instead
  warnings.warn(
2023-11-18 06:37:10,460 - distributed.scheduler - INFO - State start
2023-11-18 06:37:10,562 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:37:10,563 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:37:10,563 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38057/status
2023-11-18 06:37:10,564 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:37:10,657 - distributed.scheduler - INFO - Receive client connection: Client-e5838629-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:10,671 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51784
2023-11-18 06:37:10,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34625'
2023-11-18 06:37:12,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:37:12,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:37:12,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:37:14,159 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37437
2023-11-18 06:37:14,161 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37437
2023-11-18 06:37:14,161 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44429
2023-11-18 06:37:14,161 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:14,161 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:14,161 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:14,161 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-18 06:37:14,161 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dkc_c1g4
2023-11-18 06:37:14,162 - distributed.worker - INFO - Starting Worker plugin PreImport-aba55424-2627-4d67-a5a4-8c32863564d9
2023-11-18 06:37:14,162 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2cd09eb6-03f0-46d1-a04f-a21948a213cf
2023-11-18 06:37:14,162 - distributed.worker - INFO - Starting Worker plugin RMMSetup-775dc93c-7a5e-4e36-8b1c-75307684f0bd
2023-11-18 06:37:14,274 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:14,303 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37437', status: init, memory: 0, processing: 0>
2023-11-18 06:37:14,305 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37437
2023-11-18 06:37:14,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51812
2023-11-18 06:37:14,306 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:14,307 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:14,307 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:14,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:14,377 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:37:14,382 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:14,383 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:14,386 - distributed.scheduler - INFO - Remove client Client-e5838629-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:14,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51784; closing.
2023-11-18 06:37:14,386 - distributed.scheduler - INFO - Remove client Client-e5838629-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:14,387 - distributed.scheduler - INFO - Close client connection: Client-e5838629-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:14,387 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34625'. Reason: nanny-close
2023-11-18 06:37:14,388 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:14,389 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37437. Reason: nanny-close
2023-11-18 06:37:14,391 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51812; closing.
2023-11-18 06:37:14,391 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:14,391 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37437', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289434.3914366')
2023-11-18 06:37:14,391 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:37:14,392 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:15,755 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:37:15,756 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:37:15,756 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:37:15,758 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:37:15,758 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-11-18 06:37:17,999 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:37:18,003 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36087 instead
  warnings.warn(
2023-11-18 06:37:18,007 - distributed.scheduler - INFO - State start
2023-11-18 06:37:18,031 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-18 06:37:18,032 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-18 06:37:18,033 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36087/status
2023-11-18 06:37:18,033 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-18 06:37:18,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35569'
2023-11-18 06:37:19,352 - distributed.scheduler - INFO - Receive client connection: Client-ea237246-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:19,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51900
2023-11-18 06:37:19,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-18 06:37:19,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-18 06:37:19,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-18 06:37:21,089 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34031
2023-11-18 06:37:21,089 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34031
2023-11-18 06:37:21,090 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38693
2023-11-18 06:37:21,090 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-18 06:37:21,090 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:21,090 - distributed.worker - INFO -               Threads:                          1
2023-11-18 06:37:21,090 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-18 06:37:21,090 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a9zphb04
2023-11-18 06:37:21,090 - distributed.worker - INFO - Starting Worker plugin PreImport-3f48e52a-7e82-4220-a258-49903ba30ddb
2023-11-18 06:37:21,091 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1213b94c-f7c9-4dce-927b-080a2a33dec8
2023-11-18 06:37:21,091 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33cdeb66-7325-4431-a711-77ef8a238cd6
2023-11-18 06:37:21,326 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:21,361 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34031', status: init, memory: 0, processing: 0>
2023-11-18 06:37:21,363 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34031
2023-11-18 06:37:21,364 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46348
2023-11-18 06:37:21,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-18 06:37:21,366 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-18 06:37:21,367 - distributed.worker - INFO - -------------------------------------------------
2023-11-18 06:37:21,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-18 06:37:21,382 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-11-18 06:37:21,390 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-18 06:37:21,395 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:21,396 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-18 06:37:21,399 - distributed.scheduler - INFO - Remove client Client-ea237246-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:21,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51900; closing.
2023-11-18 06:37:21,399 - distributed.scheduler - INFO - Remove client Client-ea237246-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:21,399 - distributed.scheduler - INFO - Close client connection: Client-ea237246-85dc-11ee-8543-d8c49764f6bb
2023-11-18 06:37:21,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35569'. Reason: nanny-close
2023-11-18 06:37:21,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-18 06:37:21,402 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34031. Reason: nanny-close
2023-11-18 06:37:21,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46348; closing.
2023-11-18 06:37:21,404 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-18 06:37:21,404 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700289441.4042547')
2023-11-18 06:37:21,404 - distributed.scheduler - INFO - Lost all workers
2023-11-18 06:37:21,405 - distributed.nanny - INFO - Worker closed
2023-11-18 06:37:23,068 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-18 06:37:23,068 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-18 06:37:23,069 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-18 06:37:23,070 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-18 06:37:23,070 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39561 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46005 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36893 instead
  warnings.warn(
2023-11-18 06:38:05,711 - distributed.nanny - WARNING - Worker process still alive after 3.199998474121094 seconds, killing
2023-11-18 06:38:05,712 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
2023-11-18 06:38:05,712 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
2023-11-18 06:38:05,712 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39875 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37095 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41141 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45423 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33011 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44269 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34653 instead
  warnings.warn(
[1700289572.611117] [dgx13:55968:0]            sock.c:470  UCX  ERROR bind(fd=127 addr=0.0.0.0:33695) failed: Address already in use
[1700289572.880983] [dgx13:55968:0]            sock.c:470  UCX  ERROR bind(fd=134 addr=0.0.0.0:40057) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37409 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46821 instead
  warnings.warn(
2023-11-18 06:40:04,665 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-18 06:40:04,669 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:40175', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37027 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34005 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33341 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43087 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33177 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38815 instead
  warnings.warn(
[1700289713.683300] [dgx13:58645:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:33020) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34779 instead
  warnings.warn(
[1700289725.763323] [dgx13:58765:0]            sock.c:470  UCX  ERROR bind(fd=127 addr=0.0.0.0:58500) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42605 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38033 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34659 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] [1700289807.929411] [dgx13:60399:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:35605) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37653 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42701 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] [1700289982.666203] [dgx13:63471:0]            sock.c:470  UCX  ERROR bind(fd=137 addr=0.0.0.0:38990) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38007 instead
  warnings.warn(
2023-11-18 06:47:12,990 - distributed.worker - WARNING - Compute Failed
Key:       ('check_partitions-7e74822dabcce2d78edea8d9a635dbde', 0)
Function:  subgraph_callable-36c88f4f-9b23-4f87-8553-abc62d4f
args:      (< could not convert arg to str >, 1, 'explicit-comms-shuffle-e097386536174eabd41defafccacc725')
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

Process SpawnProcess-34:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 146, in _test_dataframe_shuffle
    result = ddf.map_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 342, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 628, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 89, in check_partitions
    hashes = partitioning_index(df, npartitions)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/dataframe/shuffle.py", line 795, in partitioning_index
    return hash_object_dispatch(df, index=False) % int(npartitions)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cudf/backends.py", line 435, in hash_object_cudf
    return frame.hash_values()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 1813, in hash_values
    {None: libcudf.hash.hash([*self._columns], method, seed)},
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "hash.pyx", line 56, in cudf._lib.hash.hash
RuntimeError: Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory
FAILED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40353 instead
  warnings.warn(
[1700290039.285047] [dgx13:64425:0]            sock.c:470  UCX  ERROR bind(fd=160 addr=0.0.0.0:41896) failed: Address already in use
std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:47:33,963 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-65bf9c7e-5fa7-4f7f-975b-59aa705a35db
Function:  _run_coroutine_on_worker
args:      (117571358741667491761026898312661943017, <function shuffle_task at 0x7fa554437a60>, ('explicit-comms-shuffle-73594999631dcad0d65c630e2f6b18af', {0: set(), 1: set(), 2: {('from_pandas-042f56ad2fd1cc4d095a550ce07a5908', 0)}}, {0: {0}, 1: {1}, 2: set()}, ['key'], 2, False, 1, 1))
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

Process SpawnProcess-35:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 146, in _test_dataframe_shuffle
    result = ddf.map_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 342, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 628, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 101, in _run_coroutine_on_worker
    return executor.submit(_run).result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/comms.py", line 98, in _run
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 379, in shuffle_task
    await send_recv_partitions(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 296, in send_recv_partitions
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 124, in recv
    await asyncio.gather(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/explicit_comms/dataframe/shuffle.py", line 120, in read_msg
    msg: Dict[int, DataFrame] = nested_deserialize(await eps[rank].read())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
FAILED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] 2023-11-18 06:48:33,284 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,288 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,292 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:46637'.
2023-11-18 06:48:33,292 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,292 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:43148 remote=tcp://127.0.0.1:36309>: Stream is closed
2023-11-18 06:48:33,295 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f4932aa4850>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,296 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:33475'.
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,297 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:33475'. Shutting down.
2023-11-18 06:48:33,299 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:32947'.
2023-11-18 06:48:33,300 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:32947'. Shutting down.
2023-11-18 06:48:33,299 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f648b9ad820>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,303 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f6700f32820>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,344 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:33,351 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:44151'.
2023-11-18 06:48:33,352 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:44151'. Shutting down.
2023-11-18 06:48:33,355 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f45f2f81820>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-18 06:48:35,298 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-18 06:48:35,302 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-18 06:48:35,306 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-18 06:48:35,358 - distributed.nanny - ERROR - Worker process died unexpectedly
