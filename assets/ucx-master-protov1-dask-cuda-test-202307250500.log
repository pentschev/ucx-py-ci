============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.4.0, pluggy-1.2.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-07-25 05:27:00,933 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:00,937 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:00,940 - distributed.scheduler - INFO - State start
2023-07-25 05:27:00,959 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:00,960 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-07-25 05:27:00,960 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:01,035 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44007'
2023-07-25 05:27:01,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35395'
2023-07-25 05:27:01,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40611'
2023-07-25 05:27:01,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37987'
2023-07-25 05:27:01,386 - distributed.scheduler - INFO - Receive client connection: Client-e0d0a748-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:01,394 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47862
2023-07-25 05:27:02,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:02,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:02,496 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-07-25 05:27:02,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43317
2023-07-25 05:27:02,507 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43317
2023-07-25 05:27:02,507 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39325
2023-07-25 05:27:02,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-25 05:27:02,507 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:02,507 - distributed.worker - INFO -               Threads:                          4
2023-07-25 05:27:02,507 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-25 05:27:02,507 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rwpuxyp4
2023-07-25 05:27:02,508 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9c85d0c-44c4-48c4-94d4-33d8c715b005
2023-07-25 05:27:02,508 - distributed.worker - INFO - Starting Worker plugin PreImport-d9a1ac84-623e-4a0e-b430-07e930f999fa
2023-07-25 05:27:02,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4522f9ea-a7d9-44e5-83f2-efb162128d8e
2023-07-25 05:27:02,508 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:02,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:02,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:02,518 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:02,522 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43317', status: init, memory: 0, processing: 0>
2023-07-25 05:27:02,523 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43317
2023-07-25 05:27:02,523 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47882
2023-07-25 05:27:02,524 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-25 05:27:02,524 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:02,525 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-25 05:27:02,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:02,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:02,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:02,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:02,563 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:02,565 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:03,655 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43027
2023-07-25 05:27:03,655 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43027
2023-07-25 05:27:03,655 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32879
2023-07-25 05:27:03,655 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,655 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,655 - distributed.worker - INFO -               Threads:                          4
2023-07-25 05:27:03,656 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-25 05:27:03,656 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7sonb6ca
2023-07-25 05:27:03,656 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5879c35c-f831-4289-8604-4c013839cf6e
2023-07-25 05:27:03,656 - distributed.worker - INFO - Starting Worker plugin PreImport-9c05be7c-6f14-4547-a551-d7ffe3d18bdc
2023-07-25 05:27:03,656 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a0f053e-bd55-464e-bb70-0ad87e81b044
2023-07-25 05:27:03,656 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,674 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43027', status: init, memory: 0, processing: 0>
2023-07-25 05:27:03,674 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43027
2023-07-25 05:27:03,674 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47906
2023-07-25 05:27:03,675 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,675 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,677 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-25 05:27:03,873 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36399
2023-07-25 05:27:03,873 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36399
2023-07-25 05:27:03,873 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35429
2023-07-25 05:27:03,873 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,873 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,874 - distributed.worker - INFO -               Threads:                          4
2023-07-25 05:27:03,874 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-25 05:27:03,874 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-j375kyqf
2023-07-25 05:27:03,874 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b814b667-3b40-4918-972e-f50ecefbb329
2023-07-25 05:27:03,874 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a61540d6-6e31-4923-8ccc-b3834e991baa
2023-07-25 05:27:03,874 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40473
2023-07-25 05:27:03,874 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40473
2023-07-25 05:27:03,874 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46513
2023-07-25 05:27:03,874 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,874 - distributed.worker - INFO - Starting Worker plugin PreImport-09f2c9e8-bb20-4e04-87cf-c934a4e4484b
2023-07-25 05:27:03,874 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,874 - distributed.worker - INFO -               Threads:                          4
2023-07-25 05:27:03,874 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,874 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-07-25 05:27:03,874 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a695mmrp
2023-07-25 05:27:03,875 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6232ef7a-c483-4836-9cb4-9d33fbc19713
2023-07-25 05:27:03,875 - distributed.worker - INFO - Starting Worker plugin PreImport-ab0efee1-1fe7-4217-b649-3ed48ab8af99
2023-07-25 05:27:03,875 - distributed.worker - INFO - Starting Worker plugin RMMSetup-366e4359-84f8-4380-9343-8569b10c8ef8
2023-07-25 05:27:03,875 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,894 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40473', status: init, memory: 0, processing: 0>
2023-07-25 05:27:03,894 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40473
2023-07-25 05:27:03,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47926
2023-07-25 05:27:03,895 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,895 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-25 05:27:03,902 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36399', status: init, memory: 0, processing: 0>
2023-07-25 05:27:03,902 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36399
2023-07-25 05:27:03,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47912
2023-07-25 05:27:03,902 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-25 05:27:03,903 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:03,905 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-25 05:27:03,936 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-25 05:27:03,938 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-25 05:27:03,938 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-25 05:27:03,939 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-07-25 05:27:03,943 - distributed.scheduler - INFO - Remove client Client-e0d0a748-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:03,943 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47862; closing.
2023-07-25 05:27:03,943 - distributed.scheduler - INFO - Remove client Client-e0d0a748-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:03,944 - distributed.scheduler - INFO - Close client connection: Client-e0d0a748-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:03,945 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44007'. Reason: nanny-close
2023-07-25 05:27:03,946 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:03,946 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35395'. Reason: nanny-close
2023-07-25 05:27:03,946 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:03,947 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43027. Reason: nanny-close
2023-07-25 05:27:03,947 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40611'. Reason: nanny-close
2023-07-25 05:27:03,947 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:03,947 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40473. Reason: nanny-close
2023-07-25 05:27:03,948 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37987'. Reason: nanny-close
2023-07-25 05:27:03,948 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:03,948 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36399. Reason: nanny-close
2023-07-25 05:27:03,948 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47906; closing.
2023-07-25 05:27:03,948 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-25 05:27:03,949 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43027', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:03,949 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43027
2023-07-25 05:27:03,949 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43317. Reason: nanny-close
2023-07-25 05:27:03,949 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-25 05:27:03,950 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:03,950 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43027
2023-07-25 05:27:03,950 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47926; closing.
2023-07-25 05:27:03,950 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-25 05:27:03,950 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40473', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:03,950 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:03,950 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40473
2023-07-25 05:27:03,951 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43027
2023-07-25 05:27:03,951 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47912; closing.
2023-07-25 05:27:03,951 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-25 05:27:03,951 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36399', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:03,951 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36399
2023-07-25 05:27:03,951 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:03,952 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47882; closing.
2023-07-25 05:27:03,952 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43317', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:03,952 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43317
2023-07-25 05:27:03,952 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:03,953 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:04,962 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:04,963 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:04,963 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:04,964 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-07-25 05:27:04,964 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-07-25 05:27:06,677 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:06,681 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:06,684 - distributed.scheduler - INFO - State start
2023-07-25 05:27:06,702 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:06,703 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:06,704 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:06,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32839'
2023-07-25 05:27:06,867 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42973'
2023-07-25 05:27:06,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45367'
2023-07-25 05:27:06,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46345'
2023-07-25 05:27:06,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46513'
2023-07-25 05:27:06,899 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45875'
2023-07-25 05:27:06,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35779'
2023-07-25 05:27:06,915 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44809'
2023-07-25 05:27:07,192 - distributed.scheduler - INFO - Receive client connection: Client-e440b5af-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:07,201 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58902
2023-07-25 05:27:08,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,359 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,420 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,439 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:08,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:08,628 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,632 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:08,637 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:10,157 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37247
2023-07-25 05:27:10,157 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37247
2023-07-25 05:27:10,157 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40775
2023-07-25 05:27:10,157 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,157 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,157 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:10,157 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:10,157 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1k0hqiw_
2023-07-25 05:27:10,158 - distributed.worker - INFO - Starting Worker plugin RMMSetup-efc9ce5f-18b3-4a2d-969d-00fea981b38d
2023-07-25 05:27:10,358 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8426c736-49c8-45aa-96f1-89bddb892d15
2023-07-25 05:27:10,358 - distributed.worker - INFO - Starting Worker plugin PreImport-11e6ad01-bb8e-4d79-b3c6-0168b39dfbeb
2023-07-25 05:27:10,359 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,386 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37247', status: init, memory: 0, processing: 0>
2023-07-25 05:27:10,387 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37247
2023-07-25 05:27:10,387 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58916
2023-07-25 05:27:10,388 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,388 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,392 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:10,791 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34199
2023-07-25 05:27:10,791 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34199
2023-07-25 05:27:10,791 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45315
2023-07-25 05:27:10,791 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,791 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,792 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:10,792 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:10,792 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o1cyg2z0
2023-07-25 05:27:10,792 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8e99c726-d9b8-452b-b236-cfa184d1ca55
2023-07-25 05:27:10,793 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c356e119-84cc-449c-b17a-a239dc7cd726
2023-07-25 05:27:10,832 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41765
2023-07-25 05:27:10,833 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41765
2023-07-25 05:27:10,833 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46151
2023-07-25 05:27:10,833 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,833 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,833 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:10,833 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:10,833 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zi49i4jz
2023-07-25 05:27:10,834 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2a2ffc6-9c5c-44dd-a2fb-3ec5fa28e9ce
2023-07-25 05:27:10,899 - distributed.worker - INFO - Starting Worker plugin PreImport-8b7a10d7-a4e3-4a6f-bfb8-fe03921055ea
2023-07-25 05:27:10,899 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,924 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34199', status: init, memory: 0, processing: 0>
2023-07-25 05:27:10,925 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34199
2023-07-25 05:27:10,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41136
2023-07-25 05:27:10,926 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,926 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:10,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-013de205-68dd-417f-a6b8-920e91c31d58
2023-07-25 05:27:10,940 - distributed.worker - INFO - Starting Worker plugin PreImport-1cd3f381-d8f6-452e-b81d-e781a73e1b0e
2023-07-25 05:27:10,940 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,965 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41765', status: init, memory: 0, processing: 0>
2023-07-25 05:27:10,965 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41765
2023-07-25 05:27:10,965 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41148
2023-07-25 05:27:10,966 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:10,966 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:10,968 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,095 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35275
2023-07-25 05:27:11,095 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35275
2023-07-25 05:27:11,096 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43419
2023-07-25 05:27:11,096 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,096 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,096 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:11,096 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:11,096 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ue2j3pip
2023-07-25 05:27:11,096 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58f4eb40-df89-479a-bded-b9b5ea5f4fb1
2023-07-25 05:27:11,100 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44509
2023-07-25 05:27:11,100 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44509
2023-07-25 05:27:11,100 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36139
2023-07-25 05:27:11,100 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,100 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,100 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:11,101 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:11,101 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v1w7hsw3
2023-07-25 05:27:11,101 - distributed.worker - INFO - Starting Worker plugin RMMSetup-47badc48-d0eb-4c32-b5c9-50365ebbd59a
2023-07-25 05:27:11,102 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45541
2023-07-25 05:27:11,103 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45541
2023-07-25 05:27:11,103 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34431
2023-07-25 05:27:11,103 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,103 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,103 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:11,103 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:11,103 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hrxx2cl8
2023-07-25 05:27:11,103 - distributed.worker - INFO - Starting Worker plugin PreImport-e0794b62-5858-40e9-8261-80d67b4a0e2c
2023-07-25 05:27:11,104 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-872d1807-d1d4-484f-b785-b7b07482f073
2023-07-25 05:27:11,104 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b882dc9-ad64-4a0a-bcf8-7db11077af37
2023-07-25 05:27:11,104 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40167
2023-07-25 05:27:11,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40167
2023-07-25 05:27:11,105 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35655
2023-07-25 05:27:11,105 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,105 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45103
2023-07-25 05:27:11,105 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,105 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45103
2023-07-25 05:27:11,105 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:11,105 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37813
2023-07-25 05:27:11,105 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:11,105 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,105 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,105 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qja_mzua
2023-07-25 05:27:11,105 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:11,105 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:11,106 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-02z9m5qb
2023-07-25 05:27:11,106 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c43f1837-4d6f-4b07-bca0-a5dd7a5bb43d
2023-07-25 05:27:11,106 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf813b41-8b83-44f2-b035-eab58f295f1d
2023-07-25 05:27:11,223 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-afa7df69-e853-479e-9834-5c78efcf28f8
2023-07-25 05:27:11,223 - distributed.worker - INFO - Starting Worker plugin PreImport-27bc95cd-1a48-4fba-9f37-83b2be1831bc
2023-07-25 05:27:11,223 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f84d78a-0142-450b-bf77-5e3addc78560
2023-07-25 05:27:11,223 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,223 - distributed.worker - INFO - Starting Worker plugin PreImport-a5b31029-5083-45a9-9dba-b514cca80a88
2023-07-25 05:27:11,223 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,227 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-82988dca-b60a-4cf6-bd0b-efcb518276a2
2023-07-25 05:27:11,227 - distributed.worker - INFO - Starting Worker plugin PreImport-785976f9-db8e-46e2-97f4-4221549d79e8
2023-07-25 05:27:11,227 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,245 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35275', status: init, memory: 0, processing: 0>
2023-07-25 05:27:11,246 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35275
2023-07-25 05:27:11,246 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41160
2023-07-25 05:27:11,246 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,246 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,248 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,248 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-835264c4-0460-4527-b5d3-6d9c39632d8b
2023-07-25 05:27:11,248 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,248 - distributed.worker - INFO - Starting Worker plugin PreImport-67723c75-fcb4-47a4-815b-851f6bfd2e5a
2023-07-25 05:27:11,249 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,251 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44509', status: init, memory: 0, processing: 0>
2023-07-25 05:27:11,251 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44509
2023-07-25 05:27:11,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41174
2023-07-25 05:27:11,252 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,252 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,253 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45103', status: init, memory: 0, processing: 0>
2023-07-25 05:27:11,253 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45103
2023-07-25 05:27:11,253 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41184
2023-07-25 05:27:11,254 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,254 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,254 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,256 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,275 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45541', status: init, memory: 0, processing: 0>
2023-07-25 05:27:11,275 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45541
2023-07-25 05:27:11,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41198
2023-07-25 05:27:11,276 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,276 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,276 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40167', status: init, memory: 0, processing: 0>
2023-07-25 05:27:11,277 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40167
2023-07-25 05:27:11,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41214
2023-07-25 05:27:11,277 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:11,278 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:11,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:11,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:11,353 - distributed.scheduler - INFO - Remove client Client-e440b5af-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:11,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58902; closing.
2023-07-25 05:27:11,354 - distributed.scheduler - INFO - Remove client Client-e440b5af-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:11,354 - distributed.scheduler - INFO - Close client connection: Client-e440b5af-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:11,355 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42973'. Reason: nanny-close
2023-07-25 05:27:11,355 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,356 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46513'. Reason: nanny-close
2023-07-25 05:27:11,356 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,357 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45875'. Reason: nanny-close
2023-07-25 05:27:11,357 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45541. Reason: nanny-close
2023-07-25 05:27:11,357 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,357 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32839'. Reason: nanny-close
2023-07-25 05:27:11,357 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40167. Reason: nanny-close
2023-07-25 05:27:11,358 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,358 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45367'. Reason: nanny-close
2023-07-25 05:27:11,358 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37247. Reason: nanny-close
2023-07-25 05:27:11,358 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35275. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46345'. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,359 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41198; closing.
2023-07-25 05:27:11,359 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35779'. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34199. Reason: nanny-close
2023-07-25 05:27:11,359 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45541', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,360 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,360 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45541
2023-07-25 05:27:11,360 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,360 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44809'. Reason: nanny-close
2023-07-25 05:27:11,360 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41765. Reason: nanny-close
2023-07-25 05:27:11,360 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:11,360 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,360 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,360 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44509. Reason: nanny-close
2023-07-25 05:27:11,361 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,361 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,361 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45541
2023-07-25 05:27:11,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45103. Reason: nanny-close
2023-07-25 05:27:11,362 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,362 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41214; closing.
2023-07-25 05:27:11,362 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45541
2023-07-25 05:27:11,362 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,362 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45541
2023-07-25 05:27:11,362 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41160; closing.
2023-07-25 05:27:11,362 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,362 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,362 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,363 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45541
2023-07-25 05:27:11,363 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40167', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,363 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40167
2023-07-25 05:27:11,363 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,364 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:11,364 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,364 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35275', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,364 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,364 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35275
2023-07-25 05:27:11,365 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58916; closing.
2023-07-25 05:27:11,365 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:11,365 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37247', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,366 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37247
2023-07-25 05:27:11,366 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41136; closing.
2023-07-25 05:27:11,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41174; closing.
2023-07-25 05:27:11,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41148; closing.
2023-07-25 05:27:11,367 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34199', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,368 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34199
2023-07-25 05:27:11,368 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44509', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,368 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44509
2023-07-25 05:27:11,369 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41765', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,369 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41765
2023-07-25 05:27:11,369 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41184; closing.
2023-07-25 05:27:11,370 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45103', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:11,370 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45103
2023-07-25 05:27:11,370 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:12,772 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:12,772 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:12,773 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:12,774 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:12,774 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-07-25 05:27:14,501 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:14,505 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:14,508 - distributed.scheduler - INFO - State start
2023-07-25 05:27:14,527 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:14,529 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:14,529 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:14,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35501'
2023-07-25 05:27:14,687 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36155'
2023-07-25 05:27:14,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43577'
2023-07-25 05:27:14,696 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38167'
2023-07-25 05:27:14,706 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44437'
2023-07-25 05:27:14,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46683'
2023-07-25 05:27:14,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41181'
2023-07-25 05:27:14,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44901'
2023-07-25 05:27:16,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,253 - distributed.scheduler - INFO - Receive client connection: Client-e8e86493-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:16,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,267 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41396
2023-07-25 05:27:16,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:16,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:16,373 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,394 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,404 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,407 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,407 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,407 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:16,413 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:17,805 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33629
2023-07-25 05:27:17,805 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33629
2023-07-25 05:27:17,805 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45509
2023-07-25 05:27:17,805 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:17,805 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:17,805 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:17,805 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:17,805 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x9u982r1
2023-07-25 05:27:17,806 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-77ac34a0-4a6e-4376-8dac-6a63785010fb
2023-07-25 05:27:17,806 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5c536a64-57d8-4451-908a-d2cad409ba80
2023-07-25 05:27:17,852 - distributed.worker - INFO - Starting Worker plugin PreImport-bf208009-661b-44a1-861d-d966eefe1855
2023-07-25 05:27:17,852 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:17,876 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33629', status: init, memory: 0, processing: 0>
2023-07-25 05:27:17,878 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33629
2023-07-25 05:27:17,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41416
2023-07-25 05:27:17,878 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:17,878 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:17,882 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,755 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43395
2023-07-25 05:27:18,755 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43395
2023-07-25 05:27:18,756 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41805
2023-07-25 05:27:18,756 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,756 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,756 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,756 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,756 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wyxxs2pe
2023-07-25 05:27:18,756 - distributed.worker - INFO - Starting Worker plugin RMMSetup-24caeda4-ded4-434f-9d47-f168ba9c02a4
2023-07-25 05:27:18,758 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33209
2023-07-25 05:27:18,759 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33209
2023-07-25 05:27:18,759 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44167
2023-07-25 05:27:18,759 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,759 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,759 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,759 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,759 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-i5ebyh2m
2023-07-25 05:27:18,761 - distributed.worker - INFO - Starting Worker plugin PreImport-7f31355c-b066-46aa-b267-dccc17298963
2023-07-25 05:27:18,761 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e8a5b2cf-a19b-4eab-a893-316f7956e359
2023-07-25 05:27:18,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7839ec16-a09f-463d-bd46-02c69d614e99
2023-07-25 05:27:18,763 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45745
2023-07-25 05:27:18,764 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45745
2023-07-25 05:27:18,764 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37099
2023-07-25 05:27:18,764 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,764 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,764 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,764 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,764 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wzxcksrn
2023-07-25 05:27:18,765 - distributed.worker - INFO - Starting Worker plugin PreImport-c5a1133a-07ed-4589-81bb-99372bc7c30c
2023-07-25 05:27:18,765 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-85822769-a1df-4e01-9d77-1190294a9ee2
2023-07-25 05:27:18,766 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7b19e397-6a78-4d04-9a99-162717344d3f
2023-07-25 05:27:18,770 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c53663d-ebb6-4a0a-92dd-7dde2f58c6b0
2023-07-25 05:27:18,771 - distributed.worker - INFO - Starting Worker plugin PreImport-37b4f10f-ddbd-4e43-8eb7-36e815616d76
2023-07-25 05:27:18,771 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,773 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,775 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,799 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33209', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,800 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33209
2023-07-25 05:27:18,800 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41434
2023-07-25 05:27:18,801 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,801 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,803 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45745', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,803 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45745
2023-07-25 05:27:18,803 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41450
2023-07-25 05:27:18,804 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,804 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,804 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,804 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43395', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,805 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43395
2023-07-25 05:27:18,805 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41430
2023-07-25 05:27:18,805 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,805 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,806 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,875 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40179
2023-07-25 05:27:18,875 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40179
2023-07-25 05:27:18,875 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37579
2023-07-25 05:27:18,875 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,875 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,875 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,875 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,875 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f0svs04m
2023-07-25 05:27:18,876 - distributed.worker - INFO - Starting Worker plugin PreImport-9d714a97-911c-4cfb-968f-4c33ef26a74f
2023-07-25 05:27:18,876 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48061b46-af2d-485a-a521-912a235d7434
2023-07-25 05:27:18,876 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb7cd3a4-2cb1-4dc7-8ebc-9118e7529be2
2023-07-25 05:27:18,904 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43365
2023-07-25 05:27:18,904 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43365
2023-07-25 05:27:18,905 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37775
2023-07-25 05:27:18,905 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,905 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,905 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,905 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,905 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1687z7aq
2023-07-25 05:27:18,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35471
2023-07-25 05:27:18,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d05a6c58-6636-4876-b3bb-8604cfa1fe1d
2023-07-25 05:27:18,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35471
2023-07-25 05:27:18,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45355
2023-07-25 05:27:18,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,906 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,906 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,906 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0sfq_267
2023-07-25 05:27:18,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34983
2023-07-25 05:27:18,907 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34983
2023-07-25 05:27:18,907 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41207
2023-07-25 05:27:18,907 - distributed.worker - INFO - Starting Worker plugin PreImport-c44db380-a27b-46fa-95d8-2c1cfbbe0ec8
2023-07-25 05:27:18,907 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,907 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,907 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef2aa616-a14c-4690-a017-03773d213e48
2023-07-25 05:27:18,907 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:18,907 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:18,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9beecaa0-bdea-4749-a83c-5f234b497f1a
2023-07-25 05:27:18,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r7c3mgco
2023-07-25 05:27:18,908 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,908 - distributed.worker - INFO - Starting Worker plugin PreImport-d87421b7-8b23-43fb-ad37-b8933173c1cc
2023-07-25 05:27:18,909 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4396c701-dcba-42dc-a0f3-46ca9bdba362
2023-07-25 05:27:18,909 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7f0334eb-3830-4da5-b23d-4c6295e748be
2023-07-25 05:27:18,917 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1053b286-ed55-4469-af96-01f5bff3e57c
2023-07-25 05:27:18,917 - distributed.worker - INFO - Starting Worker plugin PreImport-9b15395c-e46e-40f6-b553-2ea9ce57d490
2023-07-25 05:27:18,918 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,919 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,920 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40179', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,929 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40179
2023-07-25 05:27:18,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41466
2023-07-25 05:27:18,929 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,929 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,940 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43365', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,941 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43365
2023-07-25 05:27:18,941 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41470
2023-07-25 05:27:18,941 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,941 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,942 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34983', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,942 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34983
2023-07-25 05:27:18,942 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41488
2023-07-25 05:27:18,943 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,943 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,943 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,944 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35471', status: init, memory: 0, processing: 0>
2023-07-25 05:27:18,945 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,945 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35471
2023-07-25 05:27:18,945 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41482
2023-07-25 05:27:18,945 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:18,945 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:18,948 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:18,981 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,982 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,983 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:18,987 - distributed.scheduler - INFO - Remove client Client-e8e86493-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:18,987 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41396; closing.
2023-07-25 05:27:18,987 - distributed.scheduler - INFO - Remove client Client-e8e86493-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:18,987 - distributed.scheduler - INFO - Close client connection: Client-e8e86493-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:18,988 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38167'. Reason: nanny-close
2023-07-25 05:27:18,989 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,989 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35501'. Reason: nanny-close
2023-07-25 05:27:18,990 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,990 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36155'. Reason: nanny-close
2023-07-25 05:27:18,990 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33209. Reason: nanny-close
2023-07-25 05:27:18,990 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43577'. Reason: nanny-close
2023-07-25 05:27:18,991 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33629. Reason: nanny-close
2023-07-25 05:27:18,991 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,991 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40179. Reason: nanny-close
2023-07-25 05:27:18,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44437'. Reason: nanny-close
2023-07-25 05:27:18,992 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,992 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45745. Reason: nanny-close
2023-07-25 05:27:18,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46683'. Reason: nanny-close
2023-07-25 05:27:18,992 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41416; closing.
2023-07-25 05:27:18,992 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,992 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,993 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,993 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33629', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41181'. Reason: nanny-close
2023-07-25 05:27:18,993 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33629
2023-07-25 05:27:18,993 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43395. Reason: nanny-close
2023-07-25 05:27:18,993 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,993 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44901'. Reason: nanny-close
2023-07-25 05:27:18,993 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35471. Reason: nanny-close
2023-07-25 05:27:18,994 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:18,994 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41434; closing.
2023-07-25 05:27:18,994 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,994 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,994 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34983. Reason: nanny-close
2023-07-25 05:27:18,994 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,994 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,995 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33629
2023-07-25 05:27:18,995 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33209', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,995 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33209
2023-07-25 05:27:18,995 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33629
2023-07-25 05:27:18,995 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41466; closing.
2023-07-25 05:27:18,995 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43365. Reason: nanny-close
2023-07-25 05:27:18,995 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33629
2023-07-25 05:27:18,995 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33629
2023-07-25 05:27:18,995 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,996 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40179', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,996 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,996 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40179
2023-07-25 05:27:18,996 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,996 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41450; closing.
2023-07-25 05:27:18,997 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45745', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:18,997 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45745
2023-07-25 05:27:18,997 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,997 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,997 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41430; closing.
2023-07-25 05:27:18,997 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,997 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41482; closing.
2023-07-25 05:27:18,998 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41488; closing.
2023-07-25 05:27:18,998 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:18,998 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43395', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,998 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43395
2023-07-25 05:27:18,999 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35471', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,999 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35471
2023-07-25 05:27:18,999 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34983', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:18,999 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34983
2023-07-25 05:27:19,000 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41470; closing.
2023-07-25 05:27:19,000 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43365', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:19,000 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43365
2023-07-25 05:27:19,000 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:20,355 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:20,356 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:20,356 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:20,357 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:20,357 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-07-25 05:27:22,121 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:22,125 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:22,128 - distributed.scheduler - INFO - State start
2023-07-25 05:27:22,146 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:22,147 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:22,147 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:22,323 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35713'
2023-07-25 05:27:22,334 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38779'
2023-07-25 05:27:22,348 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36661'
2023-07-25 05:27:22,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41589'
2023-07-25 05:27:22,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39237'
2023-07-25 05:27:22,367 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44873'
2023-07-25 05:27:22,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46255'
2023-07-25 05:27:22,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37195'
2023-07-25 05:27:23,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,837 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:23,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:23,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:23,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:24,074 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,077 - distributed.scheduler - INFO - Receive client connection: Client-ed7583f9-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:24,087 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,088 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45104
2023-07-25 05:27:24,088 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,094 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:24,097 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:25,242 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43559
2023-07-25 05:27:25,242 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43559
2023-07-25 05:27:25,242 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38959
2023-07-25 05:27:25,243 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:25,243 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:25,243 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:25,243 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:25,243 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w93p7yga
2023-07-25 05:27:25,243 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6d2644cf-0588-4394-a1f7-009ccec5a6e5
2023-07-25 05:27:25,833 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f81bd0b1-3975-4486-96a8-dff90b0a852d
2023-07-25 05:27:25,833 - distributed.worker - INFO - Starting Worker plugin PreImport-7c10a4d1-c881-467b-9dd5-29ef5861e47c
2023-07-25 05:27:25,834 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:25,860 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43559', status: init, memory: 0, processing: 0>
2023-07-25 05:27:25,862 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43559
2023-07-25 05:27:25,862 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45128
2023-07-25 05:27:25,862 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:25,862 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:25,866 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,483 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43815
2023-07-25 05:27:26,483 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43815
2023-07-25 05:27:26,483 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36197
2023-07-25 05:27:26,483 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,483 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,483 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,483 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,483 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rnq7fv9w
2023-07-25 05:27:26,484 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41953
2023-07-25 05:27:26,484 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41953
2023-07-25 05:27:26,484 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39291
2023-07-25 05:27:26,484 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cac8aaba-9a57-4f01-94b8-a13bfbf5f381
2023-07-25 05:27:26,484 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,484 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,484 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,484 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,485 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9ly16xv4
2023-07-25 05:27:26,485 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c807d01f-e80c-4750-b13e-6498ea0ad230
2023-07-25 05:27:26,485 - distributed.worker - INFO - Starting Worker plugin RMMSetup-24d8a130-ae60-46b8-8aad-b4494bc066e3
2023-07-25 05:27:26,644 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42343
2023-07-25 05:27:26,644 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42343
2023-07-25 05:27:26,644 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44763
2023-07-25 05:27:26,644 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35993
2023-07-25 05:27:26,644 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44763
2023-07-25 05:27:26,644 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,644 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46451
2023-07-25 05:27:26,644 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32815
2023-07-25 05:27:26,644 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,644 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46451
2023-07-25 05:27:26,645 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,645 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,645 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,645 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36191
2023-07-25 05:27:26,645 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,645 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,645 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,645 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zgt8xp3r
2023-07-25 05:27:26,645 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,645 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,645 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,645 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nl87k7ap
2023-07-25 05:27:26,645 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,645 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pz_lyab2
2023-07-25 05:27:26,645 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0c3f1dff-e705-422a-a25c-3ac062e84922
2023-07-25 05:27:26,645 - distributed.worker - INFO - Starting Worker plugin RMMSetup-00976866-d94d-41ed-bd92-98daeb4c786f
2023-07-25 05:27:26,645 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e7be740a-5f7d-4a7c-8e2e-34e5cb686deb
2023-07-25 05:27:26,646 - distributed.worker - INFO - Starting Worker plugin RMMSetup-64560598-5579-41f1-a005-cd58655bf7ab
2023-07-25 05:27:26,646 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33375
2023-07-25 05:27:26,646 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33375
2023-07-25 05:27:26,646 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36507
2023-07-25 05:27:26,646 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,646 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,646 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,646 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,646 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-90ecccdk
2023-07-25 05:27:26,647 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c5940110-c386-4408-97ae-ccda02626f66
2023-07-25 05:27:26,649 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45111
2023-07-25 05:27:26,649 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45111
2023-07-25 05:27:26,650 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45791
2023-07-25 05:27:26,650 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,650 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,650 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:26,650 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:26,650 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2vhqp_qb
2023-07-25 05:27:26,651 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56d75059-81cb-4480-830b-78971c5a8243
2023-07-25 05:27:26,669 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b06369e7-0114-4525-b636-8c0d0d2738b1
2023-07-25 05:27:26,669 - distributed.worker - INFO - Starting Worker plugin PreImport-a1889903-c679-4cec-9471-764d634eae1c
2023-07-25 05:27:26,670 - distributed.worker - INFO - Starting Worker plugin PreImport-2a6ff2b0-4558-4329-a46c-a41a416913bd
2023-07-25 05:27:26,670 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,670 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,698 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43815', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,699 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43815
2023-07-25 05:27:26,699 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45140
2023-07-25 05:27:26,699 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,700 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,705 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41953', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,706 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41953
2023-07-25 05:27:26,706 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45144
2023-07-25 05:27:26,706 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,707 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,709 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e7b8fb7-1d75-4a98-804e-61f3b529d453
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c7466f9-6c2f-4f57-aaeb-7d1cf244ee9b
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b8f8ab6a-9a64-4062-a578-cc3ac1b043d3
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin PreImport-cb11f245-04de-4690-b9d6-4bc0fbd1c3ae
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin PreImport-10ddf0b2-7dc6-42bd-9229-a0bf0da363a7
2023-07-25 05:27:26,840 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,840 - distributed.worker - INFO - Starting Worker plugin PreImport-1ddba154-7919-459d-bebe-8440bb524e4b
2023-07-25 05:27:26,840 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,841 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,841 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4d2fa65c-b3b0-483b-a105-ca34fc6fee12
2023-07-25 05:27:26,841 - distributed.worker - INFO - Starting Worker plugin PreImport-e7f4f1e6-4740-4578-b58b-d5b32fd19ca3
2023-07-25 05:27:26,841 - distributed.worker - INFO - Starting Worker plugin PreImport-d1cf9e7b-0e54-44e2-8c1f-da1b5af4a0a4
2023-07-25 05:27:26,842 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,842 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,866 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44763', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,867 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44763
2023-07-25 05:27:26,867 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45168
2023-07-25 05:27:26,867 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,867 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,868 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42343', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,869 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42343
2023-07-25 05:27:26,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45154
2023-07-25 05:27:26,869 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,869 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,870 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,870 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45111', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,871 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45111
2023-07-25 05:27:26,871 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45194
2023-07-25 05:27:26,871 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,871 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,871 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,873 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33375', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,873 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33375
2023-07-25 05:27:26,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45180
2023-07-25 05:27:26,874 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,874 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,874 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,874 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46451', status: init, memory: 0, processing: 0>
2023-07-25 05:27:26,875 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46451
2023-07-25 05:27:26,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45204
2023-07-25 05:27:26,875 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:26,876 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:26,877 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:26,943 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,943 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,944 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:26,954 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,954 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,954 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,955 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,955 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,955 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,955 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,955 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:27:26,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:27:26,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:27:26,965 - distributed.scheduler - INFO - Remove client Client-ed7583f9-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:26,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45104; closing.
2023-07-25 05:27:26,965 - distributed.scheduler - INFO - Remove client Client-ed7583f9-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:26,965 - distributed.scheduler - INFO - Close client connection: Client-ed7583f9-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:26,967 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36661'. Reason: nanny-close
2023-07-25 05:27:26,967 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,967 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44873'. Reason: nanny-close
2023-07-25 05:27:26,968 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,968 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46451. Reason: nanny-close
2023-07-25 05:27:26,968 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35713'. Reason: nanny-close
2023-07-25 05:27:26,969 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,969 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38779'. Reason: nanny-close
2023-07-25 05:27:26,969 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43815. Reason: nanny-close
2023-07-25 05:27:26,969 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,970 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45111. Reason: nanny-close
2023-07-25 05:27:26,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41589'. Reason: nanny-close
2023-07-25 05:27:26,970 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,970 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44763. Reason: nanny-close
2023-07-25 05:27:26,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39237'. Reason: nanny-close
2023-07-25 05:27:26,971 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45204; closing.
2023-07-25 05:27:26,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,971 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,971 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46451', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,971 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46451
2023-07-25 05:27:26,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41953. Reason: nanny-close
2023-07-25 05:27:26,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46255'. Reason: nanny-close
2023-07-25 05:27:26,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,971 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37195'. Reason: nanny-close
2023-07-25 05:27:26,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33375. Reason: nanny-close
2023-07-25 05:27:26,972 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,972 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:26,972 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,972 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43559. Reason: nanny-close
2023-07-25 05:27:26,972 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46451
2023-07-25 05:27:26,972 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45140; closing.
2023-07-25 05:27:26,973 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,973 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45194; closing.
2023-07-25 05:27:26,973 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42343. Reason: nanny-close
2023-07-25 05:27:26,973 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,973 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46451
2023-07-25 05:27:26,973 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,973 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46451
2023-07-25 05:27:26,973 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43815', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,973 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43815
2023-07-25 05:27:26,973 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46451
2023-07-25 05:27:26,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,974 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45111', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,974 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45111
2023-07-25 05:27:26,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,974 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45168; closing.
2023-07-25 05:27:26,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:26,974 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44763', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,975 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44763
2023-07-25 05:27:26,975 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45144; closing.
2023-07-25 05:27:26,975 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,975 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,975 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:26,976 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41953', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,976 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41953
2023-07-25 05:27:26,976 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45180; closing.
2023-07-25 05:27:26,976 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45128; closing.
2023-07-25 05:27:26,976 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45154; closing.
2023-07-25 05:27:26,977 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33375', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,977 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33375
2023-07-25 05:27:26,977 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43559', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,977 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43559
2023-07-25 05:27:26,978 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42343', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:26,978 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42343
2023-07-25 05:27:26,978 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:28,384 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:28,384 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:28,385 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:28,386 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:28,386 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-07-25 05:27:30,077 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:30,080 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:30,083 - distributed.scheduler - INFO - State start
2023-07-25 05:27:30,101 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:30,102 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:30,102 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:30,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36317'
2023-07-25 05:27:30,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33317'
2023-07-25 05:27:30,258 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43343'
2023-07-25 05:27:30,265 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38371'
2023-07-25 05:27:30,275 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33613'
2023-07-25 05:27:30,283 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46247'
2023-07-25 05:27:30,291 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39151'
2023-07-25 05:27:30,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37649'
2023-07-25 05:27:31,469 - distributed.scheduler - INFO - Receive client connection: Client-f23683db-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:31,481 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40430
2023-07-25 05:27:31,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,741 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,820 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:31,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:31,995 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,996 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,997 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:31,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:33,332 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34667
2023-07-25 05:27:33,333 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34667
2023-07-25 05:27:33,333 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42629
2023-07-25 05:27:33,333 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:33,333 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:33,333 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:33,333 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:33,333 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p4guf193
2023-07-25 05:27:33,333 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e3c486e0-3526-40f7-8a47-c2ffe575b7fa
2023-07-25 05:27:33,516 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b521b82-5143-42fc-bfe7-b5a2b1276239
2023-07-25 05:27:33,517 - distributed.worker - INFO - Starting Worker plugin PreImport-4a718367-0a50-45d4-83a6-f1ee4603f55e
2023-07-25 05:27:33,517 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:33,542 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34667', status: init, memory: 0, processing: 0>
2023-07-25 05:27:33,544 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34667
2023-07-25 05:27:33,544 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40452
2023-07-25 05:27:33,544 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:33,544 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:33,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,444 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36379
2023-07-25 05:27:34,445 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36379
2023-07-25 05:27:34,445 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45087
2023-07-25 05:27:34,445 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,445 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,445 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,445 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,445 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ug3kwcn8
2023-07-25 05:27:34,445 - distributed.worker - INFO - Starting Worker plugin RMMSetup-34cf36d3-1ed9-415e-9162-7e483c673e3a
2023-07-25 05:27:34,454 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36511
2023-07-25 05:27:34,454 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36511
2023-07-25 05:27:34,454 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41057
2023-07-25 05:27:34,454 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,454 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,455 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,455 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,455 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bxj6ustb
2023-07-25 05:27:34,455 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ddeca1c3-0883-45f7-b765-948b607d1ac3
2023-07-25 05:27:34,456 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35897
2023-07-25 05:27:34,457 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35897
2023-07-25 05:27:34,457 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39773
2023-07-25 05:27:34,457 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,457 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,457 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,457 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,457 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-aorkdvnd
2023-07-25 05:27:34,457 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c32f5d6e-4846-49f5-b18c-225279fe5e23
2023-07-25 05:27:34,458 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eae11345-620f-4f79-a281-f8d87ab8755f
2023-07-25 05:27:34,459 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44237
2023-07-25 05:27:34,459 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44237
2023-07-25 05:27:34,459 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35959
2023-07-25 05:27:34,459 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,459 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,459 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,459 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,459 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8w6rcsgt
2023-07-25 05:27:34,459 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45927
2023-07-25 05:27:34,460 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45927
2023-07-25 05:27:34,460 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0a5a143-8f27-40a3-8328-e95046da8187
2023-07-25 05:27:34,460 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36543
2023-07-25 05:27:34,460 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,460 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,460 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,460 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,460 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ajs8vv99
2023-07-25 05:27:34,460 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34545
2023-07-25 05:27:34,461 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34545
2023-07-25 05:27:34,461 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46621
2023-07-25 05:27:34,461 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,461 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,461 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,461 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,461 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3fyrc9er
2023-07-25 05:27:34,461 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2759cba2-dfaf-4c03-a608-b53aa47610b4
2023-07-25 05:27:34,461 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d474800d-7b1b-4c81-9bf7-697324dfb966
2023-07-25 05:27:34,468 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33873
2023-07-25 05:27:34,468 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33873
2023-07-25 05:27:34,468 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42883
2023-07-25 05:27:34,468 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,468 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,468 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:34,468 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:27:34,468 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1dgxk1i3
2023-07-25 05:27:34,469 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0498204e-2296-44c0-b6d6-8a411561d45a
2023-07-25 05:27:34,469 - distributed.worker - INFO - Starting Worker plugin RMMSetup-da52ce65-8360-485b-9152-2d327ab0d855
2023-07-25 05:27:34,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e357acfa-39f5-4f80-945d-38a74f6e8d35
2023-07-25 05:27:34,578 - distributed.worker - INFO - Starting Worker plugin PreImport-277f6caa-c27e-4606-bba7-6eb1d70dae0f
2023-07-25 05:27:34,578 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,604 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-31f6c2a3-867b-46a4-9ad8-7b7baa114097
2023-07-25 05:27:34,604 - distributed.worker - INFO - Starting Worker plugin PreImport-b2353592-e826-4e3a-a5d8-a195a313d788
2023-07-25 05:27:34,605 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,608 - distributed.worker - INFO - Starting Worker plugin PreImport-7e8a9e50-9548-4746-b231-b62f6da4ed79
2023-07-25 05:27:34,608 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b30fb356-a54e-4712-923c-3c4aa6155797
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin PreImport-8533241f-6f01-4087-b216-82f3fd3b18d8
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin PreImport-e144fbdf-cab3-44ee-90df-cf0610b9a8d0
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-843b492b-5bd7-45cf-a285-016d5c11163e
2023-07-25 05:27:34,609 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,609 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e3bba6e-a43d-4f53-93cd-7377957eed79
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin PreImport-d0656bc7-5410-43c6-b838-a4306b37b5a9
2023-07-25 05:27:34,609 - distributed.worker - INFO - Starting Worker plugin PreImport-f8bb0f1a-cf7b-45b5-9688-e7d11e430d39
2023-07-25 05:27:34,609 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,610 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,615 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45927', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,616 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45927
2023-07-25 05:27:34,616 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40460
2023-07-25 05:27:34,617 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,617 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,630 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35897', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,631 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35897
2023-07-25 05:27:34,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40482
2023-07-25 05:27:34,631 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,632 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,632 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33873', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,633 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33873
2023-07-25 05:27:34,633 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40484
2023-07-25 05:27:34,634 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,634 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,636 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36379', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,636 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36379
2023-07-25 05:27:34,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40470
2023-07-25 05:27:34,637 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,637 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36511', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,638 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36511
2023-07-25 05:27:34,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40510
2023-07-25 05:27:34,638 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,639 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,639 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44237', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,640 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44237
2023-07-25 05:27:34,640 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40494
2023-07-25 05:27:34,640 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,640 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,641 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34545', status: init, memory: 0, processing: 0>
2023-07-25 05:27:34,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,641 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34545
2023-07-25 05:27:34,641 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40518
2023-07-25 05:27:34,642 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:34,642 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:34,643 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,644 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:34,707 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,707 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,708 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:27:34,712 - distributed.scheduler - INFO - Remove client Client-f23683db-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:34,713 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40430; closing.
2023-07-25 05:27:34,713 - distributed.scheduler - INFO - Remove client Client-f23683db-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:34,713 - distributed.scheduler - INFO - Close client connection: Client-f23683db-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:34,714 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38371'. Reason: nanny-close
2023-07-25 05:27:34,715 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,715 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36317'. Reason: nanny-close
2023-07-25 05:27:34,716 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,716 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33873. Reason: nanny-close
2023-07-25 05:27:34,716 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33317'. Reason: nanny-close
2023-07-25 05:27:34,716 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,717 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45927. Reason: nanny-close
2023-07-25 05:27:34,717 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43343'. Reason: nanny-close
2023-07-25 05:27:34,717 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,717 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33613'. Reason: nanny-close
2023-07-25 05:27:34,717 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34545. Reason: nanny-close
2023-07-25 05:27:34,718 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,718 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,718 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40484; closing.
2023-07-25 05:27:34,718 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46247'. Reason: nanny-close
2023-07-25 05:27:34,718 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44237. Reason: nanny-close
2023-07-25 05:27:34,718 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33873', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,718 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33873
2023-07-25 05:27:34,718 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,718 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35897. Reason: nanny-close
2023-07-25 05:27:34,719 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,719 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39151'. Reason: nanny-close
2023-07-25 05:27:34,719 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,719 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,719 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37649'. Reason: nanny-close
2023-07-25 05:27:34,719 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36511. Reason: nanny-close
2023-07-25 05:27:34,719 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,719 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:34,720 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33873
2023-07-25 05:27:34,720 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36379. Reason: nanny-close
2023-07-25 05:27:34,720 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,720 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33873
2023-07-25 05:27:34,720 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,720 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40460; closing.
2023-07-25 05:27:34,720 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,720 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34667. Reason: nanny-close
2023-07-25 05:27:34,721 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,721 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33873
2023-07-25 05:27:34,721 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45927', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,721 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,721 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45927
2023-07-25 05:27:34,721 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33873
2023-07-25 05:27:34,722 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,722 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,722 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,722 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:34,722 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40518; closing.
2023-07-25 05:27:34,723 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40494; closing.
2023-07-25 05:27:34,723 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40482; closing.
2023-07-25 05:27:34,724 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,724 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,724 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34545', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,724 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:34,724 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34545
2023-07-25 05:27:34,725 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44237', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,725 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44237
2023-07-25 05:27:34,726 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35897', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,726 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35897
2023-07-25 05:27:34,726 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40510; closing.
2023-07-25 05:27:34,727 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40452; closing.
2023-07-25 05:27:34,727 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40470; closing.
2023-07-25 05:27:34,728 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36511', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,728 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36511
2023-07-25 05:27:34,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34667', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,729 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34667
2023-07-25 05:27:34,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36379', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:34,729 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36379
2023-07-25 05:27:34,729 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:36,182 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:36,182 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:36,182 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:36,183 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:36,184 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-07-25 05:27:37,892 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:37,896 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:37,899 - distributed.scheduler - INFO - State start
2023-07-25 05:27:37,918 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:37,919 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:37,919 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:37,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42313'
2023-07-25 05:27:38,932 - distributed.scheduler - INFO - Receive client connection: Client-f6dc6bca-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:38,943 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40632
2023-07-25 05:27:39,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:39,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:27:39,804 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:40,599 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34955
2023-07-25 05:27:40,599 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34955
2023-07-25 05:27:40,599 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-07-25 05:27:40,599 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:40,600 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:40,600 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:40,600 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-25 05:27:40,600 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ehfkcts2
2023-07-25 05:27:40,600 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b98278b-475a-4569-a0ec-938066c23e1a
2023-07-25 05:27:40,600 - distributed.worker - INFO - Starting Worker plugin PreImport-0cf84a0d-9661-4c24-a701-53993f26170a
2023-07-25 05:27:40,600 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7d1daeac-4d25-44b2-a49c-7ed17603f55a
2023-07-25 05:27:40,600 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:40,616 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34955', status: init, memory: 0, processing: 0>
2023-07-25 05:27:40,617 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34955
2023-07-25 05:27:40,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40660
2023-07-25 05:27:40,617 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:40,617 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:40,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:40,657 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:27:40,659 - distributed.scheduler - INFO - Remove client Client-f6dc6bca-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:40,659 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40632; closing.
2023-07-25 05:27:40,660 - distributed.scheduler - INFO - Remove client Client-f6dc6bca-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:40,660 - distributed.scheduler - INFO - Close client connection: Client-f6dc6bca-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:40,661 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42313'. Reason: nanny-close
2023-07-25 05:27:40,661 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:40,662 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34955. Reason: nanny-close
2023-07-25 05:27:40,663 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40660; closing.
2023-07-25 05:27:40,663 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:40,664 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34955', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:40,664 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34955
2023-07-25 05:27:40,664 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:40,665 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:41,527 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:41,527 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:41,528 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:41,528 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:41,529 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-07-25 05:27:44,785 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:44,789 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:44,792 - distributed.scheduler - INFO - State start
2023-07-25 05:27:44,810 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:44,811 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:44,811 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:44,888 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44247'
2023-07-25 05:27:44,946 - distributed.scheduler - INFO - Receive client connection: Client-faf5dadc-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:44,957 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52954
2023-07-25 05:27:46,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:46,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:27:46,702 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:47,495 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35411
2023-07-25 05:27:47,495 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35411
2023-07-25 05:27:47,495 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35717
2023-07-25 05:27:47,495 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:27:47,495 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:47,495 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:47,495 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-25 05:27:47,495 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jv8bpve1
2023-07-25 05:27:47,495 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5401ac6-9ebd-4f89-93e3-3f4070202705
2023-07-25 05:27:47,495 - distributed.worker - INFO - Starting Worker plugin PreImport-f9f1b1ed-873a-4df8-85ed-b8bdc04bdce9
2023-07-25 05:27:47,497 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b292939f-286b-44ae-b89d-6cb73e66be9d
2023-07-25 05:27:47,497 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:47,514 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35411', status: init, memory: 0, processing: 0>
2023-07-25 05:27:47,515 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35411
2023-07-25 05:27:47,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52958
2023-07-25 05:27:47,516 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:27:47,516 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:47,518 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:27:47,556 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:27:47,558 - distributed.scheduler - INFO - Remove client Client-faf5dadc-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:47,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52954; closing.
2023-07-25 05:27:47,558 - distributed.scheduler - INFO - Remove client Client-faf5dadc-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:47,559 - distributed.scheduler - INFO - Close client connection: Client-faf5dadc-2aab-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:47,560 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44247'. Reason: nanny-close
2023-07-25 05:27:47,568 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:47,569 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35411. Reason: nanny-close
2023-07-25 05:27:47,571 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:27:47,571 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52958; closing.
2023-07-25 05:27:47,571 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35411', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:47,571 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35411
2023-07-25 05:27:47,571 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:47,572 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:48,526 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:48,526 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:48,526 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:48,527 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:48,527 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-07-25 05:27:50,210 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:50,214 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:50,217 - distributed.scheduler - INFO - State start
2023-07-25 05:27:50,235 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:50,236 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:27:50,236 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:53,833 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:53,834 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:53,834 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:53,834 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:27:53,834 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-07-25 05:27:55,571 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:55,575 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:27:55,580 - distributed.scheduler - INFO - State start
2023-07-25 05:27:55,602 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:27:55,603 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-07-25 05:27:55,604 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:27:55,654 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33671'
2023-07-25 05:27:56,610 - distributed.scheduler - INFO - Receive client connection: Client-015e1fd6-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:56,623 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35364
2023-07-25 05:27:57,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:27:57,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:27:57,101 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:27:57,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46585
2023-07-25 05:27:57,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46585
2023-07-25 05:27:57,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41535
2023-07-25 05:27:57,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-07-25 05:27:57,906 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:57,906 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:27:57,906 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-25 05:27:57,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x1yxaw1p
2023-07-25 05:27:57,907 - distributed.worker - INFO - Starting Worker plugin PreImport-2754cb1a-e063-4900-b6ed-9ad465a228e3
2023-07-25 05:27:57,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8fb4fc39-c814-443a-a372-c22c1c961d1d
2023-07-25 05:27:57,907 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f0734e8b-fbda-409f-b1f9-b0a0fe90d6cf
2023-07-25 05:27:57,907 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:57,932 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46585', status: init, memory: 0, processing: 0>
2023-07-25 05:27:57,934 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46585
2023-07-25 05:27:57,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35384
2023-07-25 05:27:57,934 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-07-25 05:27:57,934 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:27:57,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-07-25 05:27:57,951 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:27:57,953 - distributed.scheduler - INFO - Remove client Client-015e1fd6-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:57,953 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35364; closing.
2023-07-25 05:27:57,954 - distributed.scheduler - INFO - Remove client Client-015e1fd6-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:57,954 - distributed.scheduler - INFO - Close client connection: Client-015e1fd6-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:27:57,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33671'. Reason: nanny-close
2023-07-25 05:27:57,985 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:27:57,986 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46585. Reason: nanny-close
2023-07-25 05:27:57,988 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-07-25 05:27:57,988 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35384; closing.
2023-07-25 05:27:57,988 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46585', status: closing, memory: 0, processing: 0>
2023-07-25 05:27:57,988 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46585
2023-07-25 05:27:57,989 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:27:57,989 - distributed.nanny - INFO - Worker closed
2023-07-25 05:27:58,921 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:27:58,922 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:27:58,922 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:27:58,923 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-07-25 05:27:58,923 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-07-25 05:28:00,807 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:00,811 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:28:00,814 - distributed.scheduler - INFO - State start
2023-07-25 05:28:00,833 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:00,834 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:28:00,834 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:28:00,975 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33281'
2023-07-25 05:28:00,991 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45591'
2023-07-25 05:28:01,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44295'
2023-07-25 05:28:01,002 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34207'
2023-07-25 05:28:01,010 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45675'
2023-07-25 05:28:01,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44967'
2023-07-25 05:28:01,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45681'
2023-07-25 05:28:01,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32865'
2023-07-25 05:28:02,163 - distributed.scheduler - INFO - Receive client connection: Client-0472ca0b-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:02,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54624
2023-07-25 05:28:02,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,634 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,668 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,669 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,673 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,673 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,696 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,711 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:02,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:02,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:02,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:04,910 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33981
2023-07-25 05:28:04,911 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33981
2023-07-25 05:28:04,911 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35005
2023-07-25 05:28:04,911 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:04,911 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:04,911 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:04,911 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:04,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-blxgtywc
2023-07-25 05:28:04,912 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58ffb180-76b3-476e-b9b3-8868d68cf38d
2023-07-25 05:28:05,026 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-40104092-df07-4600-ad6c-0e1752cefc51
2023-07-25 05:28:05,027 - distributed.worker - INFO - Starting Worker plugin PreImport-b2a9cac1-93e1-4f8a-acb9-9c5c596aecfc
2023-07-25 05:28:05,027 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,059 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33981', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,061 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33981
2023-07-25 05:28:05,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54636
2023-07-25 05:28:05,062 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,062 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,064 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45933
2023-07-25 05:28:05,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46703
2023-07-25 05:28:05,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45933
2023-07-25 05:28:05,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46703
2023-07-25 05:28:05,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43411
2023-07-25 05:28:05,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35131
2023-07-25 05:28:05,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,232 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,232 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,232 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,232 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6snbq9ck
2023-07-25 05:28:05,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s1cnpuyu
2023-07-25 05:28:05,232 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43173
2023-07-25 05:28:05,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43173
2023-07-25 05:28:05,232 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c6961cc0-e0b7-43d4-8e9a-6fb88a1f3251
2023-07-25 05:28:05,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3fde76b5-f43e-4449-be1d-8ca82c487832
2023-07-25 05:28:05,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39947
2023-07-25 05:28:05,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,233 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,233 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,233 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,233 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rmmx03gh
2023-07-25 05:28:05,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-29548dc4-657b-4f88-96c8-5aac4485bdbe
2023-07-25 05:28:05,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9630fa34-7107-410a-8312-5ecb812c9870
2023-07-25 05:28:05,323 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35609
2023-07-25 05:28:05,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35609
2023-07-25 05:28:05,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42501
2023-07-25 05:28:05,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,324 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,324 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2p1r2zmz
2023-07-25 05:28:05,324 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34809
2023-07-25 05:28:05,324 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cc9f2713-28d2-4842-ae96-8da70000400d
2023-07-25 05:28:05,324 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34809
2023-07-25 05:28:05,325 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45891
2023-07-25 05:28:05,325 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,325 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,325 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,325 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,325 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mbhmw4zz
2023-07-25 05:28:05,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1309743-07d7-4376-887b-9e3e2a03a8b2
2023-07-25 05:28:05,333 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35485
2023-07-25 05:28:05,333 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35485
2023-07-25 05:28:05,333 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34097
2023-07-25 05:28:05,333 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,334 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,334 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,334 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,334 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5un2udct
2023-07-25 05:28:05,334 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fa0a84e6-6bc2-48fc-86d8-13c7ee4fdde0
2023-07-25 05:28:05,334 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38945
2023-07-25 05:28:05,334 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38945
2023-07-25 05:28:05,334 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35823
2023-07-25 05:28:05,335 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,335 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,335 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:05,335 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-07-25 05:28:05,335 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1bpip2lb
2023-07-25 05:28:05,335 - distributed.worker - INFO - Starting Worker plugin RMMSetup-328b7a53-6d3d-4ace-8b9a-e83d49726c41
2023-07-25 05:28:05,336 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc5209e7-bdb7-4a3e-b8a7-0399f6d3ca53
2023-07-25 05:28:05,372 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a94943f-49ad-4510-a7ad-a55d453f2adc
2023-07-25 05:28:05,372 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c80e4d69-c566-40a5-b3d8-8e5c97704647
2023-07-25 05:28:05,372 - distributed.worker - INFO - Starting Worker plugin PreImport-2290daf6-33e4-4c07-8d26-a0bac24d9987
2023-07-25 05:28:05,373 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,380 - distributed.worker - INFO - Starting Worker plugin PreImport-542cde51-7e93-45cb-acdf-f2f20155253b
2023-07-25 05:28:05,381 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,404 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43173', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,405 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43173
2023-07-25 05:28:05,405 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54644
2023-07-25 05:28:05,406 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,406 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,408 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,446 - distributed.worker - INFO - Starting Worker plugin PreImport-a92379ad-41d0-49fb-9eaf-9268d75cd53d
2023-07-25 05:28:05,446 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,454 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46703', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,455 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46703
2023-07-25 05:28:05,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54660
2023-07-25 05:28:05,455 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,456 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,458 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,469 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eeb0c549-8849-4a24-acae-cf72febc6459
2023-07-25 05:28:05,469 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13ac2337-9486-4c2b-8783-dfa3c4d04cec
2023-07-25 05:28:05,470 - distributed.worker - INFO - Starting Worker plugin PreImport-892f26eb-9632-4766-aeb6-4f158232e04c
2023-07-25 05:28:05,470 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,470 - distributed.worker - INFO - Starting Worker plugin PreImport-766e528f-43a4-473e-b681-b78162a6b45a
2023-07-25 05:28:05,470 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,473 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8fe1c33a-507c-4852-b88b-84d15b28872c
2023-07-25 05:28:05,473 - distributed.worker - INFO - Starting Worker plugin PreImport-f2938463-c9c8-4603-9577-51d7771c0d30
2023-07-25 05:28:05,474 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,477 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45933', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,478 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45933
2023-07-25 05:28:05,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54662
2023-07-25 05:28:05,479 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,479 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,481 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,493 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35609', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,493 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35609
2023-07-25 05:28:05,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54668
2023-07-25 05:28:05,494 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,494 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,496 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,496 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35485', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,497 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35485
2023-07-25 05:28:05,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54686
2023-07-25 05:28:05,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,497 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,500 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38945', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,501 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38945
2023-07-25 05:28:05,501 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54682
2023-07-25 05:28:05,501 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,502 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,539 - distributed.worker - INFO - Starting Worker plugin PreImport-2683a0c3-170d-4bb0-9817-4e9bc828772b
2023-07-25 05:28:05,539 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,565 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34809', status: init, memory: 0, processing: 0>
2023-07-25 05:28:05,566 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34809
2023-07-25 05:28:05,566 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54692
2023-07-25 05:28:05,566 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:05,566 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:05,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:05,587 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,587 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,587 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,588 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,588 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,588 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,588 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,588 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-07-25 05:28:05,602 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,603 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:05,607 - distributed.scheduler - INFO - Remove client Client-0472ca0b-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:05,607 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54624; closing.
2023-07-25 05:28:05,608 - distributed.scheduler - INFO - Remove client Client-0472ca0b-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:05,608 - distributed.scheduler - INFO - Close client connection: Client-0472ca0b-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:05,609 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33281'. Reason: nanny-close
2023-07-25 05:28:05,610 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45591'. Reason: nanny-close
2023-07-25 05:28:05,610 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,610 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44295'. Reason: nanny-close
2023-07-25 05:28:05,611 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,611 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34207'. Reason: nanny-close
2023-07-25 05:28:05,611 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46703. Reason: nanny-close
2023-07-25 05:28:05,611 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,612 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45675'. Reason: nanny-close
2023-07-25 05:28:05,612 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33981. Reason: nanny-close
2023-07-25 05:28:05,612 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,612 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43173. Reason: nanny-close
2023-07-25 05:28:05,612 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44967'. Reason: nanny-close
2023-07-25 05:28:05,613 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,613 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45933. Reason: nanny-close
2023-07-25 05:28:05,613 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45681'. Reason: nanny-close
2023-07-25 05:28:05,613 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,613 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54660; closing.
2023-07-25 05:28:05,613 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,614 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38945. Reason: nanny-close
2023-07-25 05:28:05,614 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,614 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32865'. Reason: nanny-close
2023-07-25 05:28:05,614 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46703', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,614 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46703
2023-07-25 05:28:05,614 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,614 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,614 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35485. Reason: nanny-close
2023-07-25 05:28:05,614 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,615 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54636; closing.
2023-07-25 05:28:05,615 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,615 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,615 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35609. Reason: nanny-close
2023-07-25 05:28:05,615 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,615 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46703
2023-07-25 05:28:05,616 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:05,616 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46703
2023-07-25 05:28:05,616 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33981', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,616 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46703
2023-07-25 05:28:05,616 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33981
2023-07-25 05:28:05,616 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,616 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54644; closing.
2023-07-25 05:28:05,616 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34809. Reason: nanny-close
2023-07-25 05:28:05,616 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46703
2023-07-25 05:28:05,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,617 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,617 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43173', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,617 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43173
2023-07-25 05:28:05,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,617 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,617 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,617 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54662; closing.
2023-07-25 05:28:05,618 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45933', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,618 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45933
2023-07-25 05:28:05,618 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:05,618 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,619 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54682; closing.
2023-07-25 05:28:05,619 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54686; closing.
2023-07-25 05:28:05,619 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54668; closing.
2023-07-25 05:28:05,619 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38945', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,619 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38945
2023-07-25 05:28:05,620 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:05,620 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35485', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,620 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35485
2023-07-25 05:28:05,620 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35609', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,620 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35609
2023-07-25 05:28:05,621 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54692; closing.
2023-07-25 05:28:05,621 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34809', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:05,622 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34809
2023-07-25 05:28:05,622 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:28:07,076 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:28:07,077 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:28:07,077 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:28:07,078 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:28:07,079 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-07-25 05:28:08,947 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:08,951 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:28:08,954 - distributed.scheduler - INFO - State start
2023-07-25 05:28:08,972 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:08,973 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:28:08,973 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:28:09,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46827'
2023-07-25 05:28:09,472 - distributed.scheduler - INFO - Receive client connection: Client-094f39a8-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:09,483 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54778
2023-07-25 05:28:10,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:10,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:10,417 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:11,251 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37079
2023-07-25 05:28:11,252 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37079
2023-07-25 05:28:11,252 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42817
2023-07-25 05:28:11,252 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:11,252 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:11,252 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:11,252 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-25 05:28:11,252 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_b_8xnty
2023-07-25 05:28:11,252 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a008c3bc-260a-4f3a-9d96-0f6898e68f06
2023-07-25 05:28:11,252 - distributed.worker - INFO - Starting Worker plugin RMMSetup-830ae640-30b3-4356-b4a6-7a5c7fcbe07d
2023-07-25 05:28:11,349 - distributed.worker - INFO - Starting Worker plugin PreImport-f3d90086-07a8-47d6-8ae9-2696b8c96d7e
2023-07-25 05:28:11,350 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:11,374 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37079', status: init, memory: 0, processing: 0>
2023-07-25 05:28:11,375 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37079
2023-07-25 05:28:11,375 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59240
2023-07-25 05:28:11,375 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:11,375 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:11,377 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:11,418 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:28:11,421 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:11,422 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:11,424 - distributed.scheduler - INFO - Remove client Client-094f39a8-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:11,425 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54778; closing.
2023-07-25 05:28:11,425 - distributed.scheduler - INFO - Remove client Client-094f39a8-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:11,425 - distributed.scheduler - INFO - Close client connection: Client-094f39a8-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:11,426 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46827'. Reason: nanny-close
2023-07-25 05:28:11,426 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:11,428 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37079. Reason: nanny-close
2023-07-25 05:28:11,429 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:11,429 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59240; closing.
2023-07-25 05:28:11,430 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37079', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:11,430 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37079
2023-07-25 05:28:11,430 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:28:11,430 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:12,342 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:28:12,342 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:28:12,343 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:28:12,344 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:28:12,344 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-07-25 05:28:14,070 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:14,074 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-07-25 05:28:14,077 - distributed.scheduler - INFO - State start
2023-07-25 05:28:14,097 - distributed.scheduler - INFO - -----------------------------------------------
2023-07-25 05:28:14,097 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-07-25 05:28:14,098 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-07-25 05:28:14,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41971'
2023-07-25 05:28:14,346 - distributed.scheduler - INFO - Receive client connection: Client-0c6aac79-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:14,357 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59330
2023-07-25 05:28:15,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:15,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:15,662 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-07-25 05:28:16,516 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43349
2023-07-25 05:28:16,516 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43349
2023-07-25 05:28:16,516 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37863
2023-07-25 05:28:16,516 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-07-25 05:28:16,516 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:16,516 - distributed.worker - INFO -               Threads:                          1
2023-07-25 05:28:16,516 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-07-25 05:28:16,516 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g1obbs8m
2023-07-25 05:28:16,517 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df10447b-f70f-46f8-be64-80641bc21dfe
2023-07-25 05:28:16,517 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3cf7fe00-42a2-45d1-9e14-a0a0c57b99d2
2023-07-25 05:28:16,624 - distributed.worker - INFO - Starting Worker plugin PreImport-bb225416-00f6-4c88-86cc-40f68c47613d
2023-07-25 05:28:16,625 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:16,649 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43349', status: init, memory: 0, processing: 0>
2023-07-25 05:28:16,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43349
2023-07-25 05:28:16,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59350
2023-07-25 05:28:16,650 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-07-25 05:28:16,650 - distributed.worker - INFO - -------------------------------------------------
2023-07-25 05:28:16,652 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-07-25 05:28:16,696 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-07-25 05:28:16,700 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-07-25 05:28:16,703 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:16,705 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-07-25 05:28:16,707 - distributed.scheduler - INFO - Remove client Client-0c6aac79-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:16,707 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59330; closing.
2023-07-25 05:28:16,707 - distributed.scheduler - INFO - Remove client Client-0c6aac79-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:16,707 - distributed.scheduler - INFO - Close client connection: Client-0c6aac79-2aac-11ee-93e1-d8c49764f6bb
2023-07-25 05:28:16,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41971'. Reason: nanny-close
2023-07-25 05:28:16,709 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-07-25 05:28:16,710 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43349. Reason: nanny-close
2023-07-25 05:28:16,711 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-07-25 05:28:16,711 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59350; closing.
2023-07-25 05:28:16,712 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43349', status: closing, memory: 0, processing: 0>
2023-07-25 05:28:16,712 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43349
2023-07-25 05:28:16,712 - distributed.scheduler - INFO - Lost all workers
2023-07-25 05:28:16,713 - distributed.nanny - INFO - Worker closed
2023-07-25 05:28:17,574 - distributed._signals - INFO - Received signal SIGINT (2)
2023-07-25 05:28:17,575 - distributed.scheduler - INFO - Scheduler closing...
2023-07-25 05:28:17,575 - distributed.scheduler - INFO - Scheduler closing all comms
2023-07-25 05:28:17,576 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-07-25 05:28:17,576 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:28:26,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:26,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:26,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:28:34,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:34,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:34,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:28:42,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,489 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,489 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:42,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:42,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:28:51,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:51,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:28:51,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:28:54,365 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1262, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
Task exception was never retrieved
future: <Task finished name='Task-1157' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.2.1.
Continuing without the dashboard.
  warnings.warn(
2023-07-25 05:29:00,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-07-25 05:29:00,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-25 05:29:00,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
