2023-04-17 22:48:39,235 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,251 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,302 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,318 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,324 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,328 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:39,336 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:39,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:39,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:16111:0:16111] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  16111) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fd42872ac2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7fd42872ae34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7fd42872affa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fd49fa54980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fd4287a4534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fd4287c9939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7fd4286e542c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7fd4286e86d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fd428733559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7fd4286e75ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fd4287a1b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fd4288482d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55d4ce4c0343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55d4ce4cb1fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55d4ce4b1b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55d4ce4bb93c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x55d4ce4c8c36]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x55d4ce5c765a]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55d4ce472b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55d4ce4b2f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55d4ce4c91ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55d4ce4b1178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55d4ce4bb93c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55d4ce4afefb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55d4ce4bb93c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55d4ce4c8e8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55d4ce4b3a92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55d4ce580049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55d4ce4cb283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55d4ce4ad3de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55d4ce4c8e8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55d4ce4cb1fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55d4ce4ad3de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55d4ce4bb93c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55d4ce4aba55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55d4ce4bb8a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55d4ce4ab729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55d4ce4bb93c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55d4ce4ac53f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55d4ce4aa2f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55d4ce55ce99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55d4ce55ce5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55d4ce57d7f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x55d4ce57c7f3]
=================================
2023-04-17 22:48:42,299 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:48375 -> ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f5a7c10e1c0, tag: 0x33cafef0271d1268, nbytes: 50000000, type: <class 'cupy.ndarray'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-17 22:48:42,301 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5a7c10e100, tag: 0xcb5e39c596a3a054, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5a7c10e100, tag: 0xcb5e39c596a3a054, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-282' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-04-17 22:48:42,304 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 659, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-04-17 22:48:42,305 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 659, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-04-17 22:48:42,305 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 481, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
[dgx13:16127:0:16127] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  16127) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0ec721dc2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7f0ec721de34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7f0ec721dffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f0f50552980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f0ec7297534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f0ec72bc939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7f0ec71d842c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7f0ec71db6d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f0ec7226559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7f0ec71da5ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f0ec7294b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f0ec733b2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x5607fe5b5343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x5607fe5c01fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x5607fe5a6b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x5607fe5b093c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x5607fe5bdc36]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x5607fe6bc65a]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x5607fe567b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x5607fe5a7f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x5607fe5be1ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x5607fe5a6178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x5607fe5b093c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x5607fe5a4efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x5607fe5b093c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x5607fe5bde8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x5607fe5a8a92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x5607fe675049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x5607fe5c0283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x5607fe5a23de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x5607fe5bde8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x5607fe5c01fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x5607fe5a23de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x5607fe5b093c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x5607fe5a0a55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x5607fe5b08a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x5607fe5a0729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x5607fe5b093c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x5607fe5a153f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x5607fe59f2f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5607fe651e99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5607fe651e5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x5607fe6727f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x5607fe6717f3]
=================================
Task exception was never retrieved
future: <Task finished name='Task-273' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-301' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-04-17 22:48:42,370 - distributed.nanny - WARNING - Restarting worker
[dgx13:16132:0:16132] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  16132) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f5a7c231c2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7f5a7c231e34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7f5a7c231ffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f5af3582980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f5a7c2ab534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f5a7c2d0939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7f5a7cd8342c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7f5a7cd866d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f5a7c23a559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7f5a7cd855ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f5a7c2a8b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f5a7c34f2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x562a0bd43343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x562a0bd4e1fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x562a0bd34b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562a0bd3e93c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x562a0bd531e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7f5a8d735003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x562a0bd3730b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x562a0bcf5b07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x562a0bd35f96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x562a0bd4c1ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x562a0bd34178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562a0bd3e93c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x562a0bd32efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562a0bd3e93c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x562a0bd4be8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x562a0bd36a92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x562a0be03049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x562a0bd4e283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x562a0bd303de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x562a0bd4be8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x562a0bd4e1fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x562a0bd303de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562a0bd3e93c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x562a0bd2ea55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x562a0bd3e8a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x562a0bd2e729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x562a0bd3e93c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x562a0bd2f53f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x562a0bd2d2f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x562a0bddfe99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x562a0bddfe5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x562a0be007f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x562a0bdff7f3]
=================================
[dgx13:16135:0:16135] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  16135) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f8e79540c2d]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29e34) [0x7f8e79540e34]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x29ffa) [0x7f8e79540ffa]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f8f0285d980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f8e795ba534]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f8e795df939]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x2042c) [0x7f8e794fb42c]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(+0x236d8) [0x7f8e794fe6d8]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f8e79549559]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/./libuct.so.0(uct_tcp_iface_progress+0x7e) [0x7f8e794fd5ce]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f8e795b7b9a]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f8e7965e2d9]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x558f30588343]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x558f305931fa]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x558f30579b8b]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x558f3058393c]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x558f305981e8]
19  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7f8ef40ca003]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x558f3057c30b]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x558f3053ab07]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x558f3057af96]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x558f305911ea]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x558f30579178]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x558f3058393c]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x558f30577efb]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x558f3058393c]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x558f30590e8c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x558f3057ba92]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x558f30648049]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x558f30593283]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x558f305753de]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x558f30590e8c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x558f305931fa]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x558f305753de]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x558f3058393c]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x558f30573a55]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x558f305838a6]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x558f30573729]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x558f3058393c]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x558f3057453f]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x558f305722f1]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x558f30624e99]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x558f30624e5b]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x558f306457f9]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ea7f3) [0x558f306447f3]
=================================
2023-04-17 22:48:42,526 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49575
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f4ce1618180, tag: 0x1fcb6a23f662faeb, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f4ce1618180, tag: 0x1fcb6a23f662faeb, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-17 22:48:42,527 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49711 -> ucx://127.0.0.1:49575
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f4ce1618340, tag: 0x59f4e14bb7099d46, nbytes: 50000000, type: <class 'cupy.ndarray'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-17 22:48:42,526 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:49575
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fa5f4c01200, tag: 0x606124cf38636c22, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fa5f4c01200, tag: 0x606124cf38636c22, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-17 22:48:42,529 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42393 -> ucx://127.0.0.1:49575
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7fa5f4c01300, tag: 0x5ffbac1e22004dbd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1793, in get_data
    response = await comm.read(deserializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7fa5f4c01300, tag: 0x5ffbac1e22004dbd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-17 22:48:42,568 - distributed.nanny - WARNING - Restarting worker
2023-04-17 22:48:42,612 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42393 -> ucx://127.0.0.1:48375
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #017] ep: 0x7fa5f4c01340, tag: 0xb23d54e16536f4dd, nbytes: 50000000, type: <class 'cupy.ndarray'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-17 22:48:42,623 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fa8c5417140, tag: 0xe28359735cc833d9, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fa8c5417140, tag: 0xe28359735cc833d9, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-17 22:48:42,623 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:42393 -> ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa5f4c01280, tag: 0x9fa228bdfa9c962c, nbytes: 50000000, type: <class 'cupy.ndarray'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-17 22:48:42,623 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f4ce1618140, tag: 0xc6ce03b45216c95, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f4ce1618140, tag: 0xc6ce03b45216c95, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-17 22:48:42,624 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52907 -> ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fa8c54172c0, tag: 0xb5f0777d66ae5758, nbytes: 50000000, type: <class 'cupy.ndarray'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-17 22:48:42,624 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fa5f4c01100, tag: 0x2f004428ecb4376, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fa5f4c01100, tag: 0x2f004428ecb4376, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-04-17 22:48:42,624 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53293
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fc6491de140, tag: 0x858f59697e2358bf, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 494, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fc6491de140, tag: 0x858f59697e2358bf, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:53293 after 30 s
2023-04-17 22:48:42,655 - distributed.nanny - WARNING - Restarting worker
2023-04-17 22:48:42,701 - distributed.nanny - WARNING - Restarting worker
2023-04-17 22:48:44,229 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:44,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:44,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:44,425 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:44,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:44,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:44,486 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:44,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:44,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:48:44,493 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-17 22:48:44,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-17 22:48:44,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-17 22:49:12,025 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:52535 after 30 s
2023-04-17 22:49:12,026 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52535
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:52535 after 30 s
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
